<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 2.43.0 (0)
 -->
<!-- Title: %3 Pages: 1 -->
<svg width="3582pt" height="1965pt"
 viewBox="0.00 0.00 3582.25 1965.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 1961)">
<title>%3</title>
<polygon fill="url(#bg_pattern)" stroke="transparent" points="-4,4 -4,-1961 3578.25,-1961 3578.25,4 -4,4"/>
<g id="clust1" class="cluster">
<title>cluster_c3099a4c&#45;f897&#45;4d8c&#45;8bbe&#45;5bda437efe20</title>
<path fill="#004f4f" stroke="#003535" stroke-width="5" d="M20,-1193C20,-1193 387,-1193 387,-1193 393,-1193 399,-1199 399,-1205 399,-1205 399,-1795 399,-1795 399,-1801 393,-1807 387,-1807 387,-1807 20,-1807 20,-1807 14,-1807 8,-1801 8,-1795 8,-1795 8,-1205 8,-1205 8,-1199 14,-1193 20,-1193"/>
<text text-anchor="middle" x="279.5" y="-1200.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">Group Chat Auto Select Speaker</text>
</g>
<g id="clust2" class="cluster">
<title>cluster_fab20de3&#45;da0d&#45;441d&#45;8744&#45;03344c1d8db2</title>
<path fill="#004f4f" stroke="#003535" stroke-width="5" d="M2185,-946C2185,-946 2552,-946 2552,-946 2558,-946 2564,-952 2564,-958 2564,-958 2564,-1596 2564,-1596 2564,-1602 2558,-1608 2552,-1608 2552,-1608 2185,-1608 2185,-1608 2179,-1608 2173,-1602 2173,-1596 2173,-1596 2173,-958 2173,-958 2173,-952 2179,-946 2185,-946"/>
<text text-anchor="middle" x="2444.5" y="-953.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">Group Chat Auto Select Speaker</text>
</g>
<g id="clust3" class="cluster">
<title>cluster_f4082dd7&#45;a33e&#45;4304&#45;8bc3&#45;383c88b2c2f3</title>
<path fill="#004f4f" stroke="#003535" stroke-width="5" d="M613,-699C613,-699 980,-699 980,-699 986,-699 992,-705 992,-711 992,-711 992,-1397 992,-1397 992,-1403 986,-1409 980,-1409 980,-1409 613,-1409 613,-1409 607,-1409 601,-1403 601,-1397 601,-1397 601,-711 601,-711 601,-705 607,-699 613,-699"/>
<text text-anchor="middle" x="872.5" y="-706.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">Group Chat Auto Select Speaker</text>
</g>
<g id="clust4" class="cluster">
<title>cluster_126f1368&#45;4108&#45;44bd&#45;abb0&#45;722bf8656059</title>
<path fill="#004f4f" stroke="#003535" stroke-width="5" d="M1324,-452C1324,-452 1691,-452 1691,-452 1697,-452 1703,-458 1703,-464 1703,-464 1703,-1150 1703,-1150 1703,-1156 1697,-1162 1691,-1162 1691,-1162 1324,-1162 1324,-1162 1318,-1162 1312,-1156 1312,-1150 1312,-1150 1312,-464 1312,-464 1312,-458 1318,-452 1324,-452"/>
<text text-anchor="middle" x="1583.5" y="-459.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">Group Chat Auto Select Speaker</text>
</g>
<g id="clust5" class="cluster">
<title>cluster_9cf4c0f0&#45;3d4e&#45;49ba&#45;bc1f&#45;2def9e4ce3cc</title>
<path fill="#004f4f" stroke="#003535" stroke-width="5" d="M2906,-230C2906,-230 3285,-230 3285,-230 3291,-230 3297,-236 3297,-242 3297,-242 3297,-903 3297,-903 3297,-909 3291,-915 3285,-915 3285,-915 2906,-915 2906,-915 2900,-915 2894,-909 2894,-903 2894,-903 2894,-242 2894,-242 2894,-236 2900,-230 2906,-230"/>
<text text-anchor="middle" x="3177.5" y="-237.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">Group Chat Auto Select Speaker</text>
</g>
<g id="clust6" class="cluster">
<title>cluster_75576d69&#45;d522&#45;463f&#45;aed7&#45;4d840243eeea</title>
<path fill="#004f4f" stroke="#003535" stroke-width="5" d="M2023,-8C2023,-8 2402,-8 2402,-8 2408,-8 2414,-14 2414,-20 2414,-20 2414,-656 2414,-656 2414,-662 2408,-668 2402,-668 2402,-668 2023,-668 2023,-668 2017,-668 2011,-662 2011,-656 2011,-656 2011,-20 2011,-20 2011,-14 2017,-8 2023,-8"/>
<text text-anchor="middle" x="2294.5" y="-15.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">Group Chat Auto Select Speaker</text>
</g>
<!-- start -->
<g id="node1" class="node">
<title>start</title>
<ellipse fill="#222222" stroke="#6666ff" stroke-width="3" cx="273" cy="-1939" rx="38.99" ry="18"/>
<text text-anchor="middle" x="273" y="-1935.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#ffffff">START</text>
</g>
<!-- 139922670162320_1 -->
<g id="node2" class="node">
<title>139922670162320_1</title>
<ellipse fill="#faf4d0" stroke="#c7c19d" stroke-width="3" cx="273" cy="-1866" rx="55.49" ry="18"/>
<text text-anchor="middle" x="273" y="-1862.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Admin (1)</text>
</g>
<!-- start&#45;&gt;139922670162320_1 -->
<g id="edge1" class="edge">
<title>start&#45;&gt;139922670162320_1</title>
<path fill="none" stroke="#6666ff" d="M273,-1920.81C273,-1912.79 273,-1903.05 273,-1894.07"/>
<polygon fill="#6666ff" stroke="#6666ff" points="276.5,-1894.03 273,-1884.03 269.5,-1894.03 276.5,-1894.03"/>
</g>
<!-- 139922752308304_1 -->
<g id="node3" class="node">
<title>139922752308304_1</title>
<ellipse fill="#a9c9d4" stroke="#7696a1" stroke-width="3" cx="273" cy="-1754" rx="90.98" ry="18"/>
<text text-anchor="middle" x="273" y="-1750.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">chat_manager (1)</text>
</g>
<!-- 139922670162320_1&#45;&gt;139922752308304_1 -->
<g id="edge2" class="edge">
<title>139922670162320_1&#45;&gt;139922752308304_1</title>
<path fill="none" stroke="#6666ff" d="M273,-1847.81C273,-1830.21 273,-1802.61 273,-1782.07"/>
<polygon fill="#6666ff" stroke="#6666ff" points="276.5,-1782.07 273,-1772.07 269.5,-1782.07 276.5,-1782.07"/>
<g id="a_edge2&#45;label"><a xlink:title="&#10;find papers on LLM applications from arxiv in the last week, create a markdown table of different domains.&#10;" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="337" y="-1818.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922636535504_1 -->
<g id="node4" class="node">
<title>139922636535504_1</title>
<ellipse fill="#c0dfb7" stroke="#8dac84" stroke-width="3" cx="501" cy="-1667" rx="66.89" ry="18"/>
<text text-anchor="middle" x="501" y="-1663.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Engineer (1)</text>
</g>
<!-- 139922752308304_1&#45;&gt;139922636535504_1 -->
<g id="edge3" class="edge">
<title>139922752308304_1&#45;&gt;139922636535504_1</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M326.59,-1739.43C347.83,-1733.55 372.3,-1726.15 394,-1718 417.2,-1709.29 442.34,-1697.65 462.42,-1687.8"/>
<polygon fill="#6666ff" stroke="#6666ff" points="464.15,-1690.85 471.55,-1683.28 461.04,-1684.58 464.15,-1690.85"/>
<g id="a_edge3&#45;label"><a xlink:title="&#10;find papers on LLM applications from arxiv in the last week, create a markdown table of different domains.&#10;" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="494" y="-1706.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922637147216_1 -->
<g id="node5" class="node">
<title>139922637147216_1</title>
<ellipse fill="#edb7ad" stroke="#ba847a" stroke-width="3" cx="651" cy="-1667" rx="64.99" ry="18"/>
<text text-anchor="middle" x="651" y="-1663.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Scientist (1)</text>
</g>
<!-- 139922752308304_1&#45;&gt;139922637147216_1 -->
<g id="edge4" class="edge">
<title>139922752308304_1&#45;&gt;139922637147216_1</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M362.84,-1751.12C420.9,-1747.72 497.39,-1739.14 562,-1718 582.32,-1711.35 603.26,-1699.86 619.72,-1689.57"/>
<polygon fill="#6666ff" stroke="#6666ff" points="621.84,-1692.37 628.37,-1684.02 618.06,-1686.48 621.84,-1692.37"/>
<g id="a_edge4&#45;label"><a xlink:title="&#10;find papers on LLM applications from arxiv in the last week, create a markdown table of different domains.&#10;" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="660" y="-1706.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922637023056_1 -->
<g id="node6" class="node">
<title>139922637023056_1</title>
<ellipse fill="#fbdbd5" stroke="#c8a8a2" stroke-width="3" cx="1922" cy="-1667" rx="60.39" ry="18"/>
<text text-anchor="middle" x="1922" y="-1663.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Planner (1)</text>
</g>
<!-- 139922752308304_1&#45;&gt;139922637023056_1 -->
<g id="edge5" class="edge">
<title>139922752308304_1&#45;&gt;139922637023056_1</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M359.91,-1748.52C651.12,-1733.51 1588.87,-1685.17 1852.48,-1671.58"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1852.88,-1675.07 1862.68,-1671.06 1852.52,-1668.08 1852.88,-1675.07"/>
<g id="a_edge5&#45;label"><a xlink:title="&#10;find papers on LLM applications from arxiv in the last week, create a markdown table of different domains.&#10;" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="1260" y="-1706.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922633387152_1 -->
<g id="node7" class="node">
<title>139922633387152_1</title>
<ellipse fill="#e4eee9" stroke="#b1bbb6" stroke-width="3" cx="2066" cy="-1667" rx="65.79" ry="18"/>
<text text-anchor="middle" x="2066" y="-1663.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Executor (1)</text>
</g>
<!-- 139922752308304_1&#45;&gt;139922633387152_1 -->
<g id="edge6" class="edge">
<title>139922752308304_1&#45;&gt;139922633387152_1</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M362.64,-1750.53C544.63,-1745.4 970.49,-1732.83 1328,-1718 1622.78,-1705.78 1698.71,-1725.09 1991,-1685 1996.93,-1684.19 2003.09,-1683.14 2009.2,-1681.96"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2010.32,-1685.3 2019.42,-1679.87 2008.92,-1678.44 2010.32,-1685.3"/>
<g id="a_edge6&#45;label"><a xlink:title="&#10;find papers on LLM applications from arxiv in the last week, create a markdown table of different domains.&#10;" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="1888" y="-1706.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922677986320_1 -->
<g id="node8" class="node">
<title>139922677986320_1</title>
<ellipse fill="#cdd5c6" stroke="#9aa293" stroke-width="3" cx="2208" cy="-1667" rx="50.09" ry="18"/>
<text text-anchor="middle" x="2208" y="-1663.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Critic (1)</text>
</g>
<!-- 139922752308304_1&#45;&gt;139922677986320_1 -->
<g id="edge7" class="edge">
<title>139922752308304_1&#45;&gt;139922677986320_1</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M364.09,-1752.98C667.64,-1752.6 1643.18,-1748.96 1956,-1718 2039.11,-1709.77 2059.36,-1702.62 2141,-1685 2146.86,-1683.74 2152.99,-1682.32 2159.05,-1680.85"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2160.27,-1684.16 2169.14,-1678.36 2158.59,-1677.36 2160.27,-1684.16"/>
<g id="a_edge7&#45;label"><a xlink:title="&#10;find papers on LLM applications from arxiv in the last week, create a markdown table of different domains.&#10;" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="2122" y="-1706.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922634606416_1 -->
<g id="node10" class="node">
<title>139922634606416_1</title>
<ellipse fill="#e8c4c6" stroke="#b59193" stroke-width="3" cx="220" cy="-1667" rx="96.68" ry="18"/>
<text text-anchor="middle" x="220" y="-1663.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">checking_agent (1)</text>
</g>
<!-- 139922752308304_1&#45;&gt;139922634606416_1 -->
<g id="edge8" class="edge">
<title>139922752308304_1&#45;&gt;139922634606416_1</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M256.98,-1727.3C250.4,-1716.75 242.79,-1704.55 236.2,-1693.97"/>
<polygon fill="#6666ff" stroke="#6666ff" points="254.01,-1729.17 262.27,-1735.8 259.95,-1725.46 254.01,-1729.17"/>
<polygon fill="#6666ff" stroke="#6666ff" points="238.97,-1691.81 230.71,-1685.18 233.03,-1695.51 238.97,-1691.81"/>
<text text-anchor="middle" x="320" y="-1706.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">Auto Select Speaker</text>
</g>
<!-- d0e5dfeb&#45;be6c&#45;402b&#45;bbae&#45;f86e157d0b2c -->
<g id="node15" class="node">
<title>d0e5dfeb&#45;be6c&#45;402b&#45;bbae&#45;f86e157d0b2c</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="2599.24,-1549.44 2654,-1537 2708.76,-1549.44 2708.71,-1569.56 2599.29,-1569.56 2599.24,-1549.44"/>
<text text-anchor="middle" x="2654" y="-1551.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">OpenAI</text>
</g>
<!-- 139922637023056_1&#45;&gt;d0e5dfeb&#45;be6c&#45;402b&#45;bbae&#45;f86e157d0b2c -->
<g id="edge15" class="edge">
<title>139922637023056_1&#45;&gt;d0e5dfeb&#45;be6c&#45;402b&#45;bbae&#45;f86e157d0b2c</title>
<path fill="none" stroke="#6666ff" d="M1964.83,-1654.25C1973.44,-1652.23 1982.47,-1650.34 1991,-1649 2041.95,-1640.97 2402.55,-1619.64 2454,-1616 2479.33,-1614.21 2543.79,-1615.67 2568,-1608 2590.03,-1601.02 2612.29,-1587.34 2628.64,-1575.76"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2631.07,-1578.32 2637.08,-1569.6 2626.94,-1572.67 2631.07,-1578.32"/>
<g id="a_edge15&#45;label"><a xlink:title="### Initial Plan&#10;&#10;**Objective:** To find recent papers on Large Language Model (LLM) applications from arXiv in the last week and create a markdown table categorizing them by different domains.&#10;&#10;**Steps:**&#10;&#10;1. **Search for Papers (Scientist)**&#10; &#160;&#160;&#45; The scientist will use arXiv&#39;s search functionality to filter papers published in the last week that focus on LLM applications. This will involve using relevant keywords and possibly setting up alerts for new papers.&#10;&#10;2. **Data Extraction (Scientist)**&#10; &#160;&#160;&#45; The scientist will extract relevant information from the papers, such as title, authors, abstract, and domain of application (e.g., healthcare, education, finance, etc.).&#10;&#10;3. **Data Organization (Engineer)**&#10; &#160;&#160;&#45; The engineer will create a markdown table format to organize the extracted data. The table will include columns for the title, authors, abstract, and domain.&#10;&#10;4. **Data Entry (Engineer)**&#10; &#160;&#160;&#45; The engineer will input the extracted data into the markdown table, ensuring that it is well&#45;formatted and easy to read.&#10;&#10;5. **Review and Finalization (Scientist &amp; Engineer)**&#10; &#160;&#160;&#45; The scientist will review the markdown table for accuracy and completeness, while the engineer will ensure that the formatting is correct.&#10;&#10;6. **Submission (Scientist)**&#10; &#160;&#160;&#45; The scientist will submit the final markdown table to the admin for approval.&#10;&#10;### Feedback Request&#10;Please provide feedback on this plan, including any specific requirements or changes you would like to see." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="2519.5" y="-1619.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">generate_oai_reply</text>
</a>
</g>
</g>
<!-- 139922752308304_2 -->
<g id="node16" class="node">
<title>139922752308304_2</title>
<ellipse fill="#a9c9d4" stroke="#7696a1" stroke-width="3" cx="2299" cy="-1555" rx="90.98" ry="18"/>
<text text-anchor="middle" x="2299" y="-1551.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">chat_manager (2)</text>
</g>
<!-- 139922637023056_1&#45;&gt;139922752308304_2 -->
<g id="edge17" class="edge">
<title>139922637023056_1&#45;&gt;139922752308304_2</title>
<path fill="none" stroke="#6666ff" d="M1963.79,-1653.81C2031.03,-1634.19 2163.46,-1595.55 2240.21,-1573.15"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2241.58,-1576.4 2250.2,-1570.24 2239.62,-1569.68 2241.58,-1576.4"/>
<g id="a_edge17&#45;label"><a xlink:title="### Initial Plan&#10;&#10;**Objective:** To find recent papers on Large Language Model (LLM) applications from arXiv in the last week and create a markdown table categorizing them by different domains.&#10;&#10;**Steps:**&#10;&#10;1. **Search for Papers (Scientist)**&#10; &#160;&#160;&#45; The scientist will use arXiv&#39;s search functionality to filter papers published in the last week that focus on LLM applications. This will involve using relevant keywords and possibly setting up alerts for new papers.&#10;&#10;2. **Data Extraction (Scientist)**&#10; &#160;&#160;&#45; The scientist will extract relevant information from the papers, such as title, authors, abstract, and domain of application (e.g., healthcare, education, finance, etc.).&#10;&#10;3. **Data Organization (Engineer)**&#10; &#160;&#160;&#45; The engineer will create a markdown table format to organize the extracted data. The table will include columns for the title, authors, abstract, and domain.&#10;&#10;4. **Data Entry (Engineer)**&#10; &#160;&#160;&#45; The engineer will input the extracted data into the markdown table, ensuring that it is well&#45;formatted and easy to read.&#10;&#10;5. **Review and Finalization (Scientist &amp; Engineer)**&#10; &#160;&#160;&#45; The scientist will review the markdown table for accuracy and completeness, while the engineer will ensure that the formatting is correct.&#10;&#10;6. **Submission (Scientist)**&#10; &#160;&#160;&#45; The scientist will submit the final markdown table to the admin for approval.&#10;&#10;### Feedback Request&#10;Please provide feedback on this plan, including any specific requirements or changes you would like to see." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="2151" y="-1619.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 432f73b6&#45;eda7&#45;4f48&#45;b9b4&#45;b35b3067f73c -->
<g id="node9" class="node">
<title>432f73b6&#45;eda7&#45;4f48&#45;b9b4&#45;b35b3067f73c</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="43.24,-1462.44 98,-1450 152.76,-1462.44 152.71,-1482.56 43.29,-1482.56 43.24,-1462.44"/>
<text text-anchor="middle" x="98" y="-1464.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">OpenAI</text>
</g>
<!-- 139922634606800_1 -->
<g id="node11" class="node">
<title>139922634606800_1</title>
<ellipse fill="#ebcfb9" stroke="#b89c86" stroke-width="3" cx="213" cy="-1555" rx="136.48" ry="18"/>
<text text-anchor="middle" x="213" y="-1551.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">speaker_selection_agent (1)</text>
</g>
<!-- 432f73b6&#45;eda7&#45;4f48&#45;b9b4&#45;b35b3067f73c&#45;&gt;139922634606800_1 -->
<g id="edge11" class="edge">
<title>432f73b6&#45;eda7&#45;4f48&#45;b9b4&#45;b35b3067f73c&#45;&gt;139922634606800_1</title>
<path fill="none" stroke="#6666ff" d="M148.85,-1482.64C175.28,-1490.21 202.92,-1499.06 207,-1504 212.18,-1510.28 214.39,-1518.62 215.1,-1526.67"/>
<polygon fill="#6666ff" stroke="#6666ff" points="211.6,-1526.98 215.29,-1536.91 218.6,-1526.85 211.6,-1526.98"/>
</g>
<!-- 139922634606416_1&#45;&gt;139922634606800_1 -->
<g id="edge9" class="edge">
<title>139922634606416_1&#45;&gt;139922634606800_1</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M218.91,-1648.81C217.79,-1631.21 216.03,-1603.61 214.72,-1583.07"/>
<polygon fill="#6666ff" stroke="#6666ff" points="218.21,-1582.82 214.09,-1573.07 211.23,-1583.27 218.21,-1582.82"/>
<g id="a_edge9&#45;label"><a xlink:title="Read the above conversation. Then select the next role from [&#39;Admin&#39;, &#39;Engineer&#39;, &#39;Scientist&#39;, &#39;Planner&#39;, &#39;Executor&#39;, &#39;Critic&#39;] to play. Only return the role." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="282" y="-1619.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922634606800_1&#45;&gt;432f73b6&#45;eda7&#45;4f48&#45;b9b4&#45;b35b3067f73c -->
<g id="edge10" class="edge">
<title>139922634606800_1&#45;&gt;432f73b6&#45;eda7&#45;4f48&#45;b9b4&#45;b35b3067f73c</title>
<path fill="none" stroke="#6666ff" d="M127.45,-1540.9C104.08,-1535.48 83.19,-1528.26 76,-1519 69.56,-1510.71 72.8,-1500.25 78.55,-1491.04"/>
<polygon fill="#6666ff" stroke="#6666ff" points="81.56,-1492.85 84.6,-1482.7 75.89,-1488.74 81.56,-1492.85"/>
<g id="a_edge10&#45;label"><a xlink:title="Planner" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="141.5" y="-1507.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">generate_oai_reply</text>
</a>
</g>
</g>
<!-- 139922634606416_2 -->
<g id="node12" class="node">
<title>139922634606416_2</title>
<ellipse fill="#e8c4c6" stroke="#b59193" stroke-width="3" cx="267" cy="-1468" rx="96.68" ry="18"/>
<text text-anchor="middle" x="267" y="-1464.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">checking_agent (2)</text>
</g>
<!-- 139922634606800_1&#45;&gt;139922634606416_2 -->
<g id="edge12" class="edge">
<title>139922634606800_1&#45;&gt;139922634606416_2</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M223.93,-1536.8C231.61,-1524.7 242.03,-1508.3 250.69,-1494.67"/>
<polygon fill="#6666ff" stroke="#6666ff" points="253.68,-1496.49 256.09,-1486.18 247.77,-1492.74 253.68,-1496.49"/>
<g id="a_edge12&#45;label"><a xlink:title="Planner" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="308" y="-1507.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 1726553859.368621 -->
<g id="node13" class="node">
<title>1726553859.368621</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="290.56,-1374 146.5,-1374 109.44,-1338 253.5,-1338 290.56,-1374"/>
<text text-anchor="middle" x="200" y="-1352.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Summarize</text>
</g>
<!-- 139922634606416_2&#45;&gt;1726553859.368621 -->
<g id="edge13" class="edge">
<title>139922634606416_2&#45;&gt;1726553859.368621</title>
<path fill="none" stroke="#6666ff" d="M256.53,-1449.81C245.57,-1431.81 228.22,-1403.34 215.63,-1382.67"/>
<polygon fill="#6666ff" stroke="#6666ff" points="218.59,-1380.79 210.4,-1374.07 212.61,-1384.43 218.59,-1380.79"/>
<g id="a_edge13&#45;label"><a xlink:title="Planner" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="328" y="-1420.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">_last_msg_as_summary</text>
</a>
</g>
</g>
<!-- 0a7b6b00&#45;201d&#45;4ad6&#45;b3d7&#45;82615ecfbf5f -->
<g id="node14" class="node">
<title>0a7b6b00&#45;201d&#45;4ad6&#45;b3d7&#45;82615ecfbf5f</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="228.5,-1287 165.5,-1287 165.5,-1251 234.5,-1251 234.5,-1281 228.5,-1287"/>
<polyline fill="none" stroke="#00be92" stroke-width="3" points="228.5,-1287 228.5,-1281 "/>
<polyline fill="none" stroke="#00be92" stroke-width="3" points="234.5,-1281 228.5,-1281 "/>
<text text-anchor="middle" x="200" y="-1265.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Planner</text>
</g>
<!-- 1726553859.368621&#45;&gt;0a7b6b00&#45;201d&#45;4ad6&#45;b3d7&#45;82615ecfbf5f -->
<g id="edge14" class="edge">
<title>1726553859.368621&#45;&gt;0a7b6b00&#45;201d&#45;4ad6&#45;b3d7&#45;82615ecfbf5f</title>
<path fill="none" stroke="#6666ff" d="M200,-1337.8C200,-1326.16 200,-1310.55 200,-1297.24"/>
<polygon fill="#6666ff" stroke="#6666ff" points="203.5,-1297.18 200,-1287.18 196.5,-1297.18 203.5,-1297.18"/>
<text text-anchor="middle" x="245.5" y="-1308.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">next speaker</text>
</g>
<!-- d0e5dfeb&#45;be6c&#45;402b&#45;bbae&#45;f86e157d0b2c&#45;&gt;139922637023056_1 -->
<g id="edge16" class="edge">
<title>d0e5dfeb&#45;be6c&#45;402b&#45;bbae&#45;f86e157d0b2c&#45;&gt;139922637023056_1</title>
<path fill="none" stroke="#6666ff" d="M2646.29,-1569.6C2635.31,-1587.46 2613.32,-1618.06 2585,-1631 2524.94,-1658.45 2056.42,-1640.05 1991,-1649 1985.58,-1649.74 1979.96,-1650.74 1974.38,-1651.88"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1973.44,-1648.5 1964.42,-1654.06 1974.94,-1655.34 1973.44,-1648.5"/>
</g>
<!-- 139922670162320_2 -->
<g id="node17" class="node">
<title>139922670162320_2</title>
<ellipse fill="#faf4d0" stroke="#c7c19d" stroke-width="3" cx="2654" cy="-1468" rx="55.49" ry="18"/>
<text text-anchor="middle" x="2654" y="-1464.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Admin (2)</text>
</g>
<!-- 139922752308304_2&#45;&gt;139922670162320_2 -->
<g id="edge18" class="edge">
<title>139922752308304_2&#45;&gt;139922670162320_2</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M2357.59,-1541.1C2386.62,-1534.63 2422.2,-1526.57 2454,-1519 2504.4,-1507.01 2561.74,-1492.6 2602.06,-1482.33"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2603.1,-1485.68 2611.93,-1479.82 2601.37,-1478.89 2603.1,-1485.68"/>
<g id="a_edge18&#45;label"><a xlink:title="### Initial Plan&#10;&#10;**Objective:** To find recent papers on Large Language Model (LLM) applications from arXiv in the last week and create a markdown table categorizing them by different domains.&#10;&#10;**Steps:**&#10;&#10;1. **Search for Papers (Scientist)**&#10; &#160;&#160;&#45; The scientist will use arXiv&#39;s search functionality to filter papers published in the last week that focus on LLM applications. This will involve using relevant keywords and possibly setting up alerts for new papers.&#10;&#10;2. **Data Extraction (Scientist)**&#10; &#160;&#160;&#45; The scientist will extract relevant information from the papers, such as title, authors, abstract, and domain of application (e.g., healthcare, education, finance, etc.).&#10;&#10;3. **Data Organization (Engineer)**&#10; &#160;&#160;&#45; The engineer will create a markdown table format to organize the extracted data. The table will include columns for the title, authors, abstract, and domain.&#10;&#10;4. **Data Entry (Engineer)**&#10; &#160;&#160;&#45; The engineer will input the extracted data into the markdown table, ensuring that it is well&#45;formatted and easy to read.&#10;&#10;5. **Review and Finalization (Scientist &amp; Engineer)**&#10; &#160;&#160;&#45; The scientist will review the markdown table for accuracy and completeness, while the engineer will ensure that the formatting is correct.&#10;&#10;6. **Submission (Scientist)**&#10; &#160;&#160;&#45; The scientist will submit the final markdown table to the admin for approval.&#10;&#10;### Feedback Request&#10;Please provide feedback on this plan, including any specific requirements or changes you would like to see." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="2578" y="-1507.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922636535504_2 -->
<g id="node18" class="node">
<title>139922636535504_2</title>
<ellipse fill="#c0dfb7" stroke="#8dac84" stroke-width="3" cx="2799" cy="-1468" rx="66.89" ry="18"/>
<text text-anchor="middle" x="2799" y="-1464.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Engineer (2)</text>
</g>
<!-- 139922752308304_2&#45;&gt;139922636535504_2 -->
<g id="edge19" class="edge">
<title>139922752308304_2&#45;&gt;139922636535504_2</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M2387.15,-1550.35C2457.77,-1546.18 2559.06,-1537.37 2646,-1519 2682.72,-1511.24 2723.03,-1497.86 2753.05,-1486.89"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2754.65,-1490.03 2762.82,-1483.28 2752.22,-1483.47 2754.65,-1490.03"/>
<g id="a_edge19&#45;label"><a xlink:title="### Initial Plan&#10;&#10;**Objective:** To find recent papers on Large Language Model (LLM) applications from arXiv in the last week and create a markdown table categorizing them by different domains.&#10;&#10;**Steps:**&#10;&#10;1. **Search for Papers (Scientist)**&#10; &#160;&#160;&#45; The scientist will use arXiv&#39;s search functionality to filter papers published in the last week that focus on LLM applications. This will involve using relevant keywords and possibly setting up alerts for new papers.&#10;&#10;2. **Data Extraction (Scientist)**&#10; &#160;&#160;&#45; The scientist will extract relevant information from the papers, such as title, authors, abstract, and domain of application (e.g., healthcare, education, finance, etc.).&#10;&#10;3. **Data Organization (Engineer)**&#10; &#160;&#160;&#45; The engineer will create a markdown table format to organize the extracted data. The table will include columns for the title, authors, abstract, and domain.&#10;&#10;4. **Data Entry (Engineer)**&#10; &#160;&#160;&#45; The engineer will input the extracted data into the markdown table, ensuring that it is well&#45;formatted and easy to read.&#10;&#10;5. **Review and Finalization (Scientist &amp; Engineer)**&#10; &#160;&#160;&#45; The scientist will review the markdown table for accuracy and completeness, while the engineer will ensure that the formatting is correct.&#10;&#10;6. **Submission (Scientist)**&#10; &#160;&#160;&#45; The scientist will submit the final markdown table to the admin for approval.&#10;&#10;### Feedback Request&#10;Please provide feedback on this plan, including any specific requirements or changes you would like to see." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="2765" y="-1507.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922637147216_2 -->
<g id="node19" class="node">
<title>139922637147216_2</title>
<ellipse fill="#edb7ad" stroke="#ba847a" stroke-width="3" cx="1804" cy="-1468" rx="64.99" ry="18"/>
<text text-anchor="middle" x="1804" y="-1464.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Scientist (2)</text>
</g>
<!-- 139922752308304_2&#45;&gt;139922637147216_2 -->
<g id="edge20" class="edge">
<title>139922752308304_2&#45;&gt;139922637147216_2</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M2207.97,-1553.85C2097.28,-1552.46 1917.69,-1545.93 1857,-1519 1844.23,-1513.33 1832.61,-1503.25 1823.53,-1493.61"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1826.08,-1491.21 1816.81,-1486.07 1820.85,-1495.87 1826.08,-1491.21"/>
<g id="a_edge20&#45;label"><a xlink:title="### Initial Plan&#10;&#10;**Objective:** To find recent papers on Large Language Model (LLM) applications from arXiv in the last week and create a markdown table categorizing them by different domains.&#10;&#10;**Steps:**&#10;&#10;1. **Search for Papers (Scientist)**&#10; &#160;&#160;&#45; The scientist will use arXiv&#39;s search functionality to filter papers published in the last week that focus on LLM applications. This will involve using relevant keywords and possibly setting up alerts for new papers.&#10;&#10;2. **Data Extraction (Scientist)**&#10; &#160;&#160;&#45; The scientist will extract relevant information from the papers, such as title, authors, abstract, and domain of application (e.g., healthcare, education, finance, etc.).&#10;&#10;3. **Data Organization (Engineer)**&#10; &#160;&#160;&#45; The engineer will create a markdown table format to organize the extracted data. The table will include columns for the title, authors, abstract, and domain.&#10;&#10;4. **Data Entry (Engineer)**&#10; &#160;&#160;&#45; The engineer will input the extracted data into the markdown table, ensuring that it is well&#45;formatted and easy to read.&#10;&#10;5. **Review and Finalization (Scientist &amp; Engineer)**&#10; &#160;&#160;&#45; The scientist will review the markdown table for accuracy and completeness, while the engineer will ensure that the formatting is correct.&#10;&#10;6. **Submission (Scientist)**&#10; &#160;&#160;&#45; The scientist will submit the final markdown table to the admin for approval.&#10;&#10;### Feedback Request&#10;Please provide feedback on this plan, including any specific requirements or changes you would like to see." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="1921" y="-1507.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922633387152_2 -->
<g id="node20" class="node">
<title>139922633387152_2</title>
<ellipse fill="#e4eee9" stroke="#b1bbb6" stroke-width="3" cx="1954" cy="-1468" rx="65.79" ry="18"/>
<text text-anchor="middle" x="1954" y="-1464.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Executor (2)</text>
</g>
<!-- 139922752308304_2&#45;&gt;139922633387152_2 -->
<g id="edge21" class="edge">
<title>139922752308304_2&#45;&gt;139922633387152_2</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M2212.99,-1548.91C2142.13,-1543.72 2047.83,-1534.24 2013,-1519 1999.28,-1513 1986.31,-1502.73 1976.05,-1493.06"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1978.33,-1490.39 1968.76,-1485.85 1973.41,-1495.37 1978.33,-1490.39"/>
<g id="a_edge21&#45;label"><a xlink:title="### Initial Plan&#10;&#10;**Objective:** To find recent papers on Large Language Model (LLM) applications from arXiv in the last week and create a markdown table categorizing them by different domains.&#10;&#10;**Steps:**&#10;&#10;1. **Search for Papers (Scientist)**&#10; &#160;&#160;&#45; The scientist will use arXiv&#39;s search functionality to filter papers published in the last week that focus on LLM applications. This will involve using relevant keywords and possibly setting up alerts for new papers.&#10;&#10;2. **Data Extraction (Scientist)**&#10; &#160;&#160;&#45; The scientist will extract relevant information from the papers, such as title, authors, abstract, and domain of application (e.g., healthcare, education, finance, etc.).&#10;&#10;3. **Data Organization (Engineer)**&#10; &#160;&#160;&#45; The engineer will create a markdown table format to organize the extracted data. The table will include columns for the title, authors, abstract, and domain.&#10;&#10;4. **Data Entry (Engineer)**&#10; &#160;&#160;&#45; The engineer will input the extracted data into the markdown table, ensuring that it is well&#45;formatted and easy to read.&#10;&#10;5. **Review and Finalization (Scientist &amp; Engineer)**&#10; &#160;&#160;&#45; The scientist will review the markdown table for accuracy and completeness, while the engineer will ensure that the formatting is correct.&#10;&#10;6. **Submission (Scientist)**&#10; &#160;&#160;&#45; The scientist will submit the final markdown table to the admin for approval.&#10;&#10;### Feedback Request&#10;Please provide feedback on this plan, including any specific requirements or changes you would like to see." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="2077" y="-1507.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922677986320_2 -->
<g id="node21" class="node">
<title>139922677986320_2</title>
<ellipse fill="#cdd5c6" stroke="#9aa293" stroke-width="3" cx="2088" cy="-1468" rx="50.09" ry="18"/>
<text text-anchor="middle" x="2088" y="-1464.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Critic (2)</text>
</g>
<!-- 139922752308304_2&#45;&gt;139922677986320_2 -->
<g id="edge22" class="edge">
<title>139922752308304_2&#45;&gt;139922677986320_2</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M2242.31,-1540.91C2221.12,-1535.23 2197.09,-1527.84 2176,-1519 2156.58,-1510.86 2136.07,-1499.39 2119.73,-1489.48"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2121.47,-1486.44 2111.12,-1484.18 2117.8,-1492.4 2121.47,-1486.44"/>
<g id="a_edge22&#45;label"><a xlink:title="### Initial Plan&#10;&#10;**Objective:** To find recent papers on Large Language Model (LLM) applications from arXiv in the last week and create a markdown table categorizing them by different domains.&#10;&#10;**Steps:**&#10;&#10;1. **Search for Papers (Scientist)**&#10; &#160;&#160;&#45; The scientist will use arXiv&#39;s search functionality to filter papers published in the last week that focus on LLM applications. This will involve using relevant keywords and possibly setting up alerts for new papers.&#10;&#10;2. **Data Extraction (Scientist)**&#10; &#160;&#160;&#45; The scientist will extract relevant information from the papers, such as title, authors, abstract, and domain of application (e.g., healthcare, education, finance, etc.).&#10;&#10;3. **Data Organization (Engineer)**&#10; &#160;&#160;&#45; The engineer will create a markdown table format to organize the extracted data. The table will include columns for the title, authors, abstract, and domain.&#10;&#10;4. **Data Entry (Engineer)**&#10; &#160;&#160;&#45; The engineer will input the extracted data into the markdown table, ensuring that it is well&#45;formatted and easy to read.&#10;&#10;5. **Review and Finalization (Scientist &amp; Engineer)**&#10; &#160;&#160;&#45; The scientist will review the markdown table for accuracy and completeness, while the engineer will ensure that the formatting is correct.&#10;&#10;6. **Submission (Scientist)**&#10; &#160;&#160;&#45; The scientist will submit the final markdown table to the admin for approval.&#10;&#10;### Feedback Request&#10;Please provide feedback on this plan, including any specific requirements or changes you would like to see." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="2240" y="-1507.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922634606416_3 -->
<g id="node23" class="node">
<title>139922634606416_3</title>
<ellipse fill="#e8c4c6" stroke="#b59193" stroke-width="3" cx="2320" cy="-1468" rx="96.68" ry="18"/>
<text text-anchor="middle" x="2320" y="-1464.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">checking_agent (3)</text>
</g>
<!-- 139922752308304_2&#45;&gt;139922634606416_3 -->
<g id="edge23" class="edge">
<title>139922752308304_2&#45;&gt;139922634606416_3</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M2305.74,-1526.73C2308.15,-1516.96 2310.87,-1505.94 2313.29,-1496.17"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2302.25,-1526.25 2303.25,-1536.8 2309.05,-1527.93 2302.25,-1526.25"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2316.76,-1496.72 2315.76,-1486.18 2309.96,-1495.04 2316.76,-1496.72"/>
<text text-anchor="middle" x="2380" y="-1507.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">Auto Select Speaker</text>
</g>
<!-- 7745fb8b&#45;415e&#45;4a08&#45;b6d8&#45;c7d3842b7c3d -->
<g id="node28" class="node">
<title>7745fb8b&#45;415e&#45;4a08&#45;b6d8&#45;c7d3842b7c3d</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="1977.24,-1350.44 2032,-1338 2086.76,-1350.44 2086.71,-1370.56 1977.29,-1370.56 1977.24,-1350.44"/>
<text text-anchor="middle" x="2032" y="-1352.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">OpenAI</text>
</g>
<!-- 139922677986320_2&#45;&gt;7745fb8b&#45;415e&#45;4a08&#45;b6d8&#45;c7d3842b7c3d -->
<g id="edge30" class="edge">
<title>139922677986320_2&#45;&gt;7745fb8b&#45;415e&#45;4a08&#45;b6d8&#45;c7d3842b7c3d</title>
<path fill="none" stroke="#6666ff" d="M2050.25,-1456.04C2043.2,-1454.01 2035.88,-1451.93 2029,-1450 1999.72,-1441.79 1981.46,-1456.16 1963,-1432 1947.5,-1411.71 1971.39,-1390.47 1995.19,-1375.79"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1997.03,-1378.77 2003.89,-1370.7 1993.49,-1372.74 1997.03,-1378.77"/>
<g id="a_edge30&#45;label"><a xlink:title="### Feedback on the Plan&#10;&#10;Overall, the plan is well&#45;structured and outlines a clear process for finding and organizing recent papers on LLM applications. However, there are a few areas where improvements can be made to enhance the effectiveness and verifiability of the output:&#10;&#10;1. **Source URL Inclusion:**&#10; &#160;&#160;&#45; It is essential to include verifiable information such as the source URL for each paper in the markdown table. This will allow users to easily access the original papers for further reading and verification. Consider adding a column for the URL in the markdown table.&#10;&#10;2. **Keyword Specification:**&#10; &#160;&#160;&#45; The plan mentions using &quot;relevant keywords&quot; for searching papers. It would be beneficial to specify which keywords will be used to ensure a focused search. For example, keywords like &quot;Large Language Models,&quot; &quot;GPT,&quot; &quot;transformers,&quot; etc., could be included.&#10;&#10;3. **Domain Categorization:**&#10; &#160;&#160;&#45; While the plan mentions categorizing papers by domain, it would be helpful to define the specific domains that will be included in the table. This will provide clarity and ensure consistency in categorization.&#10;&#10;4. **Data Extraction Details:**&#10; &#160;&#160;&#45; The plan could benefit from specifying how the scientist will determine the domain of application for each paper. Will this be based on the abstract, keywords, or another method? Providing clarity on this process will enhance the reliability of the categorization.&#10;&#10;5. **Review Process:**&#10; &#160;&#160;&#45; The review process is a good step, but it might be useful to include a checklist of criteria for the scientist to use when reviewing the markdown table. This could include checking for completeness, accuracy of information, and proper formatting.&#10;&#10;6. **Timeline:**&#10; &#160;&#160;&#45; Consider adding a timeline for each step of the process. This will help in managing expectations and ensuring that the task is completed in a timely manner.&#10;&#10;### Revised Plan Suggestion&#10;&#10;**Objective:** To find recent papers on Large Language Model (LLM) applications from arXiv in the last week and create a markdown table categorizing them by different domains.&#10;&#10;**Steps:**&#10;&#10;1. **Search for Papers (Scientist)**&#10; &#160;&#160;&#45; Use arXiv&#39;s search functionality with specific keywords (e.g., &quot;Large Language Models,&quot; &quot;GPT,&quot; &quot;transformers&quot;) to filter papers published in the last week.&#10;&#10;2. **Data Extraction (Scientist)**&#10; &#160;&#160;&#45; Extract relevant information: title, authors, abstract, domain of application, and source URL.&#10;&#10;3. **Data Organization (Engineer)**&#10; &#160;&#160;&#45; Create a markdown table format with columns for title, authors, abstract, domain, and source URL.&#10;&#10;4. **Data Entry (Engineer)**&#10; &#160;&#160;&#45; Input the extracted data into the markdown table, ensuring proper formatting.&#10;&#10;5. **Review and Finalization (Scientist &amp; Engineer)**&#10; &#160;&#160;&#45; Review the markdown table for accuracy and completeness, using a checklist for verification.&#10;&#10;6. **Submission (Scientist)**&#10; &#160;&#160;&#45; Submit the final markdown table to the admin for approval.&#10;&#10;By incorporating these suggestions, the plan will be more robust, verifiable, and user&#45;friendly." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="2028.5" y="-1420.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">generate_oai_reply</text>
</a>
</g>
</g>
<!-- 139922752308304_3 -->
<g id="node29" class="node">
<title>139922752308304_3</title>
<ellipse fill="#a9c9d4" stroke="#7696a1" stroke-width="3" cx="866" cy="-1356" rx="90.98" ry="18"/>
<text text-anchor="middle" x="866" y="-1352.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">chat_manager (3)</text>
</g>
<!-- 139922677986320_2&#45;&gt;139922752308304_3 -->
<g id="edge32" class="edge">
<title>139922677986320_2&#45;&gt;139922752308304_3</title>
<path fill="none" stroke="#6666ff" d="M2052.08,-1455.41C2044.52,-1453.32 2036.55,-1451.38 2029,-1450 2002.75,-1445.22 1231.23,-1385.26 959.55,-1364.23"/>
<polygon fill="#6666ff" stroke="#6666ff" points="959.56,-1360.72 949.32,-1363.44 959.02,-1367.7 959.56,-1360.72"/>
<g id="a_edge32&#45;label"><a xlink:title="### Feedback on the Plan&#10;&#10;Overall, the plan is well&#45;structured and outlines a clear process for finding and organizing recent papers on LLM applications. However, there are a few areas where improvements can be made to enhance the effectiveness and verifiability of the output:&#10;&#10;1. **Source URL Inclusion:**&#10; &#160;&#160;&#45; It is essential to include verifiable information such as the source URL for each paper in the markdown table. This will allow users to easily access the original papers for further reading and verification. Consider adding a column for the URL in the markdown table.&#10;&#10;2. **Keyword Specification:**&#10; &#160;&#160;&#45; The plan mentions using &quot;relevant keywords&quot; for searching papers. It would be beneficial to specify which keywords will be used to ensure a focused search. For example, keywords like &quot;Large Language Models,&quot; &quot;GPT,&quot; &quot;transformers,&quot; etc., could be included.&#10;&#10;3. **Domain Categorization:**&#10; &#160;&#160;&#45; While the plan mentions categorizing papers by domain, it would be helpful to define the specific domains that will be included in the table. This will provide clarity and ensure consistency in categorization.&#10;&#10;4. **Data Extraction Details:**&#10; &#160;&#160;&#45; The plan could benefit from specifying how the scientist will determine the domain of application for each paper. Will this be based on the abstract, keywords, or another method? Providing clarity on this process will enhance the reliability of the categorization.&#10;&#10;5. **Review Process:**&#10; &#160;&#160;&#45; The review process is a good step, but it might be useful to include a checklist of criteria for the scientist to use when reviewing the markdown table. This could include checking for completeness, accuracy of information, and proper formatting.&#10;&#10;6. **Timeline:**&#10; &#160;&#160;&#45; Consider adding a timeline for each step of the process. This will help in managing expectations and ensuring that the task is completed in a timely manner.&#10;&#10;### Revised Plan Suggestion&#10;&#10;**Objective:** To find recent papers on Large Language Model (LLM) applications from arXiv in the last week and create a markdown table categorizing them by different domains.&#10;&#10;**Steps:**&#10;&#10;1. **Search for Papers (Scientist)**&#10; &#160;&#160;&#45; Use arXiv&#39;s search functionality with specific keywords (e.g., &quot;Large Language Models,&quot; &quot;GPT,&quot; &quot;transformers&quot;) to filter papers published in the last week.&#10;&#10;2. **Data Extraction (Scientist)**&#10; &#160;&#160;&#45; Extract relevant information: title, authors, abstract, domain of application, and source URL.&#10;&#10;3. **Data Organization (Engineer)**&#10; &#160;&#160;&#45; Create a markdown table format with columns for title, authors, abstract, domain, and source URL.&#10;&#10;4. **Data Entry (Engineer)**&#10; &#160;&#160;&#45; Input the extracted data into the markdown table, ensuring proper formatting.&#10;&#10;5. **Review and Finalization (Scientist &amp; Engineer)**&#10; &#160;&#160;&#45; Review the markdown table for accuracy and completeness, using a checklist for verification.&#10;&#10;6. **Submission (Scientist)**&#10; &#160;&#160;&#45; Submit the final markdown table to the admin for approval.&#10;&#10;By incorporating these suggestions, the plan will be more robust, verifiable, and user&#45;friendly." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="1884" y="-1420.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 9a511794&#45;6e62&#45;48ed&#45;ac83&#45;a12014fc8f5b -->
<g id="node22" class="node">
<title>9a511794&#45;6e62&#45;48ed&#45;ac83&#45;a12014fc8f5b</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="2208.24,-1263.44 2263,-1251 2317.76,-1263.44 2317.71,-1283.56 2208.29,-1283.56 2208.24,-1263.44"/>
<text text-anchor="middle" x="2263" y="-1265.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">OpenAI</text>
</g>
<!-- 139922634606800_2 -->
<g id="node24" class="node">
<title>139922634606800_2</title>
<ellipse fill="#ebcfb9" stroke="#b89c86" stroke-width="3" cx="2353" cy="-1356" rx="136.48" ry="18"/>
<text text-anchor="middle" x="2353" y="-1352.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">speaker_selection_agent (2)</text>
</g>
<!-- 9a511794&#45;6e62&#45;48ed&#45;ac83&#45;a12014fc8f5b&#45;&gt;139922634606800_2 -->
<g id="edge26" class="edge">
<title>9a511794&#45;6e62&#45;48ed&#45;ac83&#45;a12014fc8f5b&#45;&gt;139922634606800_2</title>
<path fill="none" stroke="#6666ff" d="M2310.52,-1283.58C2335.42,-1291.17 2361.48,-1300.07 2365,-1305 2369.87,-1311.82 2369.56,-1320.36 2367.2,-1328.44"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2363.88,-1327.33 2363.54,-1337.92 2370.41,-1329.86 2363.88,-1327.33"/>
</g>
<!-- 139922634606416_3&#45;&gt;139922634606800_2 -->
<g id="edge24" class="edge">
<title>139922634606416_3&#45;&gt;139922634606800_2</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M2325.16,-1449.81C2330.46,-1432.13 2338.79,-1404.35 2344.96,-1383.79"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2348.36,-1384.65 2347.88,-1374.07 2341.65,-1382.64 2348.36,-1384.65"/>
<g id="a_edge24&#45;label"><a xlink:title="Read the above conversation. Then select the next role from [&#39;Admin&#39;, &#39;Engineer&#39;, &#39;Scientist&#39;, &#39;Planner&#39;, &#39;Executor&#39;, &#39;Critic&#39;] to play. Only return the role." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="2398" y="-1420.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922634606800_2&#45;&gt;9a511794&#45;6e62&#45;48ed&#45;ac83&#45;a12014fc8f5b -->
<g id="edge25" class="edge">
<title>139922634606800_2&#45;&gt;9a511794&#45;6e62&#45;48ed&#45;ac83&#45;a12014fc8f5b</title>
<path fill="none" stroke="#6666ff" d="M2262.69,-1342.39C2251.51,-1337.14 2241.42,-1329.91 2234,-1320 2227.3,-1311.05 2231.92,-1300.43 2239.28,-1291.28"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2242.05,-1293.43 2246.23,-1283.69 2236.89,-1288.7 2242.05,-1293.43"/>
<g id="a_edge25&#45;label"><a xlink:title="Critic" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="2299.5" y="-1308.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">generate_oai_reply</text>
</a>
</g>
</g>
<!-- 139922634606416_4 -->
<g id="node25" class="node">
<title>139922634606416_4</title>
<ellipse fill="#e8c4c6" stroke="#b59193" stroke-width="3" cx="2432" cy="-1269" rx="96.68" ry="18"/>
<text text-anchor="middle" x="2432" y="-1265.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">checking_agent (4)</text>
</g>
<!-- 139922634606800_2&#45;&gt;139922634606416_4 -->
<g id="edge27" class="edge">
<title>139922634606800_2&#45;&gt;139922634606416_4</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M2368.99,-1337.8C2380.63,-1325.27 2396.55,-1308.14 2409.48,-1294.23"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2412.06,-1296.59 2416.31,-1286.89 2406.93,-1291.83 2412.06,-1296.59"/>
<g id="a_edge27&#45;label"><a xlink:title="Critic" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="2461" y="-1308.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 1726553862.718316 -->
<g id="node26" class="node">
<title>1726553862.718316</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="2455.56,-1127 2311.5,-1127 2274.44,-1091 2418.5,-1091 2455.56,-1127"/>
<text text-anchor="middle" x="2365" y="-1105.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Summarize</text>
</g>
<!-- 139922634606416_4&#45;&gt;1726553862.718316 -->
<g id="edge28" class="edge">
<title>139922634606416_4&#45;&gt;1726553862.718316</title>
<path fill="none" stroke="#6666ff" d="M2424.7,-1250.79C2413.02,-1223.25 2390.05,-1169.06 2376.25,-1136.53"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2379.42,-1135.03 2372.29,-1127.19 2372.97,-1137.76 2379.42,-1135.03"/>
<g id="a_edge28&#45;label"><a xlink:title="Critic" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="2478" y="-1173.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">_last_msg_as_summary</text>
</a>
</g>
</g>
<!-- 45a02a2d&#45;a672&#45;4b7a&#45;a532&#45;bbd106e43a37 -->
<g id="node27" class="node">
<title>45a02a2d&#45;a672&#45;4b7a&#45;a532&#45;bbd106e43a37</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="2386,-1040 2338,-1040 2338,-1004 2392,-1004 2392,-1034 2386,-1040"/>
<polyline fill="none" stroke="#00be92" stroke-width="3" points="2386,-1040 2386,-1034 "/>
<polyline fill="none" stroke="#00be92" stroke-width="3" points="2392,-1034 2386,-1034 "/>
<text text-anchor="middle" x="2365" y="-1018.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Critic</text>
</g>
<!-- 1726553862.718316&#45;&gt;45a02a2d&#45;a672&#45;4b7a&#45;a532&#45;bbd106e43a37 -->
<g id="edge29" class="edge">
<title>1726553862.718316&#45;&gt;45a02a2d&#45;a672&#45;4b7a&#45;a532&#45;bbd106e43a37</title>
<path fill="none" stroke="#6666ff" d="M2365,-1090.8C2365,-1079.16 2365,-1063.55 2365,-1050.24"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2368.5,-1050.18 2365,-1040.18 2361.5,-1050.18 2368.5,-1050.18"/>
<text text-anchor="middle" x="2410.5" y="-1061.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">next speaker</text>
</g>
<!-- 7745fb8b&#45;415e&#45;4a08&#45;b6d8&#45;c7d3842b7c3d&#45;&gt;139922677986320_2 -->
<g id="edge31" class="edge">
<title>7745fb8b&#45;415e&#45;4a08&#45;b6d8&#45;c7d3842b7c3d&#45;&gt;139922677986320_2</title>
<path fill="none" stroke="#6666ff" d="M2053.3,-1370.67C2067.79,-1381.33 2085.76,-1397.55 2094,-1417 2097,-1424.08 2097.23,-1432.21 2096.24,-1439.81"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2092.79,-1439.24 2094.28,-1449.73 2099.65,-1440.6 2092.79,-1439.24"/>
</g>
<!-- 139922670162320_3 -->
<g id="node30" class="node">
<title>139922670162320_3</title>
<ellipse fill="#faf4d0" stroke="#c7c19d" stroke-width="3" cx="1082" cy="-1269" rx="55.49" ry="18"/>
<text text-anchor="middle" x="1082" y="-1265.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Admin (3)</text>
</g>
<!-- 139922752308304_3&#45;&gt;139922670162320_3 -->
<g id="edge33" class="edge">
<title>139922752308304_3&#45;&gt;139922670162320_3</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M920.05,-1341.44C940.67,-1335.67 964.21,-1328.33 985,-1320 1006.27,-1311.48 1029.09,-1299.85 1047.24,-1289.96"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1049.22,-1292.86 1056.28,-1284.96 1045.84,-1286.74 1049.22,-1292.86"/>
<g id="a_edge33&#45;label"><a xlink:title="### Feedback on the Plan&#10;&#10;Overall, the plan is well&#45;structured and outlines a clear process for finding and organizing recent papers on LLM applications. However, there are a few areas where improvements can be made to enhance the effectiveness and verifiability of the output:&#10;&#10;1. **Source URL Inclusion:**&#10; &#160;&#160;&#45; It is essential to include verifiable information such as the source URL for each paper in the markdown table. This will allow users to easily access the original papers for further reading and verification. Consider adding a column for the URL in the markdown table.&#10;&#10;2. **Keyword Specification:**&#10; &#160;&#160;&#45; The plan mentions using &quot;relevant keywords&quot; for searching papers. It would be beneficial to specify which keywords will be used to ensure a focused search. For example, keywords like &quot;Large Language Models,&quot; &quot;GPT,&quot; &quot;transformers,&quot; etc., could be included.&#10;&#10;3. **Domain Categorization:**&#10; &#160;&#160;&#45; While the plan mentions categorizing papers by domain, it would be helpful to define the specific domains that will be included in the table. This will provide clarity and ensure consistency in categorization.&#10;&#10;4. **Data Extraction Details:**&#10; &#160;&#160;&#45; The plan could benefit from specifying how the scientist will determine the domain of application for each paper. Will this be based on the abstract, keywords, or another method? Providing clarity on this process will enhance the reliability of the categorization.&#10;&#10;5. **Review Process:**&#10; &#160;&#160;&#45; The review process is a good step, but it might be useful to include a checklist of criteria for the scientist to use when reviewing the markdown table. This could include checking for completeness, accuracy of information, and proper formatting.&#10;&#10;6. **Timeline:**&#10; &#160;&#160;&#45; Consider adding a timeline for each step of the process. This will help in managing expectations and ensuring that the task is completed in a timely manner.&#10;&#10;### Revised Plan Suggestion&#10;&#10;**Objective:** To find recent papers on Large Language Model (LLM) applications from arXiv in the last week and create a markdown table categorizing them by different domains.&#10;&#10;**Steps:**&#10;&#10;1. **Search for Papers (Scientist)**&#10; &#160;&#160;&#45; Use arXiv&#39;s search functionality with specific keywords (e.g., &quot;Large Language Models,&quot; &quot;GPT,&quot; &quot;transformers&quot;) to filter papers published in the last week.&#10;&#10;2. **Data Extraction (Scientist)**&#10; &#160;&#160;&#45; Extract relevant information: title, authors, abstract, domain of application, and source URL.&#10;&#10;3. **Data Organization (Engineer)**&#10; &#160;&#160;&#45; Create a markdown table format with columns for title, authors, abstract, domain, and source URL.&#10;&#10;4. **Data Entry (Engineer)**&#10; &#160;&#160;&#45; Input the extracted data into the markdown table, ensuring proper formatting.&#10;&#10;5. **Review and Finalization (Scientist &amp; Engineer)**&#10; &#160;&#160;&#45; Review the markdown table for accuracy and completeness, using a checklist for verification.&#10;&#10;6. **Submission (Scientist)**&#10; &#160;&#160;&#45; Submit the final markdown table to the admin for approval.&#10;&#10;By incorporating these suggestions, the plan will be more robust, verifiable, and user&#45;friendly." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="1081" y="-1308.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922636535504_3 -->
<g id="node31" class="node">
<title>139922636535504_3</title>
<ellipse fill="#c0dfb7" stroke="#8dac84" stroke-width="3" cx="1227" cy="-1269" rx="66.89" ry="18"/>
<text text-anchor="middle" x="1227" y="-1265.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Engineer (3)</text>
</g>
<!-- 139922752308304_3&#45;&gt;139922636535504_3 -->
<g id="edge34" class="edge">
<title>139922752308304_3&#45;&gt;139922636535504_3</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M956.64,-1354C1013.38,-1350.9 1087.19,-1342.32 1149,-1320 1166.79,-1313.58 1184.7,-1302.5 1198.86,-1292.41"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1201.18,-1295.05 1207.15,-1286.3 1197.03,-1289.41 1201.18,-1295.05"/>
<g id="a_edge34&#45;label"><a xlink:title="### Feedback on the Plan&#10;&#10;Overall, the plan is well&#45;structured and outlines a clear process for finding and organizing recent papers on LLM applications. However, there are a few areas where improvements can be made to enhance the effectiveness and verifiability of the output:&#10;&#10;1. **Source URL Inclusion:**&#10; &#160;&#160;&#45; It is essential to include verifiable information such as the source URL for each paper in the markdown table. This will allow users to easily access the original papers for further reading and verification. Consider adding a column for the URL in the markdown table.&#10;&#10;2. **Keyword Specification:**&#10; &#160;&#160;&#45; The plan mentions using &quot;relevant keywords&quot; for searching papers. It would be beneficial to specify which keywords will be used to ensure a focused search. For example, keywords like &quot;Large Language Models,&quot; &quot;GPT,&quot; &quot;transformers,&quot; etc., could be included.&#10;&#10;3. **Domain Categorization:**&#10; &#160;&#160;&#45; While the plan mentions categorizing papers by domain, it would be helpful to define the specific domains that will be included in the table. This will provide clarity and ensure consistency in categorization.&#10;&#10;4. **Data Extraction Details:**&#10; &#160;&#160;&#45; The plan could benefit from specifying how the scientist will determine the domain of application for each paper. Will this be based on the abstract, keywords, or another method? Providing clarity on this process will enhance the reliability of the categorization.&#10;&#10;5. **Review Process:**&#10; &#160;&#160;&#45; The review process is a good step, but it might be useful to include a checklist of criteria for the scientist to use when reviewing the markdown table. This could include checking for completeness, accuracy of information, and proper formatting.&#10;&#10;6. **Timeline:**&#10; &#160;&#160;&#45; Consider adding a timeline for each step of the process. This will help in managing expectations and ensuring that the task is completed in a timely manner.&#10;&#10;### Revised Plan Suggestion&#10;&#10;**Objective:** To find recent papers on Large Language Model (LLM) applications from arXiv in the last week and create a markdown table categorizing them by different domains.&#10;&#10;**Steps:**&#10;&#10;1. **Search for Papers (Scientist)**&#10; &#160;&#160;&#45; Use arXiv&#39;s search functionality with specific keywords (e.g., &quot;Large Language Models,&quot; &quot;GPT,&quot; &quot;transformers&quot;) to filter papers published in the last week.&#10;&#10;2. **Data Extraction (Scientist)**&#10; &#160;&#160;&#45; Extract relevant information: title, authors, abstract, domain of application, and source URL.&#10;&#10;3. **Data Organization (Engineer)**&#10; &#160;&#160;&#45; Create a markdown table format with columns for title, authors, abstract, domain, and source URL.&#10;&#10;4. **Data Entry (Engineer)**&#10; &#160;&#160;&#45; Input the extracted data into the markdown table, ensuring proper formatting.&#10;&#10;5. **Review and Finalization (Scientist &amp; Engineer)**&#10; &#160;&#160;&#45; Review the markdown table for accuracy and completeness, using a checklist for verification.&#10;&#10;6. **Submission (Scientist)**&#10; &#160;&#160;&#45; Submit the final markdown table to the admin for approval.&#10;&#10;By incorporating these suggestions, the plan will be more robust, verifiable, and user&#45;friendly." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="1242" y="-1308.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922637147216_3 -->
<g id="node32" class="node">
<title>139922637147216_3</title>
<ellipse fill="#edb7ad" stroke="#ba847a" stroke-width="3" cx="1496" cy="-1269" rx="64.99" ry="18"/>
<text text-anchor="middle" x="1496" y="-1265.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Scientist (3)</text>
</g>
<!-- 139922752308304_3&#45;&gt;139922637147216_3 -->
<g id="edge35" class="edge">
<title>139922752308304_3&#45;&gt;139922637147216_3</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M955.9,-1352.76C1046.02,-1349.38 1188.46,-1340.94 1310,-1320 1356.74,-1311.95 1408.78,-1297.47 1445.9,-1286.16"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1446.95,-1289.5 1455.48,-1283.21 1444.89,-1282.81 1446.95,-1289.5"/>
<g id="a_edge35&#45;label"><a xlink:title="### Feedback on the Plan&#10;&#10;Overall, the plan is well&#45;structured and outlines a clear process for finding and organizing recent papers on LLM applications. However, there are a few areas where improvements can be made to enhance the effectiveness and verifiability of the output:&#10;&#10;1. **Source URL Inclusion:**&#10; &#160;&#160;&#45; It is essential to include verifiable information such as the source URL for each paper in the markdown table. This will allow users to easily access the original papers for further reading and verification. Consider adding a column for the URL in the markdown table.&#10;&#10;2. **Keyword Specification:**&#10; &#160;&#160;&#45; The plan mentions using &quot;relevant keywords&quot; for searching papers. It would be beneficial to specify which keywords will be used to ensure a focused search. For example, keywords like &quot;Large Language Models,&quot; &quot;GPT,&quot; &quot;transformers,&quot; etc., could be included.&#10;&#10;3. **Domain Categorization:**&#10; &#160;&#160;&#45; While the plan mentions categorizing papers by domain, it would be helpful to define the specific domains that will be included in the table. This will provide clarity and ensure consistency in categorization.&#10;&#10;4. **Data Extraction Details:**&#10; &#160;&#160;&#45; The plan could benefit from specifying how the scientist will determine the domain of application for each paper. Will this be based on the abstract, keywords, or another method? Providing clarity on this process will enhance the reliability of the categorization.&#10;&#10;5. **Review Process:**&#10; &#160;&#160;&#45; The review process is a good step, but it might be useful to include a checklist of criteria for the scientist to use when reviewing the markdown table. This could include checking for completeness, accuracy of information, and proper formatting.&#10;&#10;6. **Timeline:**&#10; &#160;&#160;&#45; Consider adding a timeline for each step of the process. This will help in managing expectations and ensuring that the task is completed in a timely manner.&#10;&#10;### Revised Plan Suggestion&#10;&#10;**Objective:** To find recent papers on Large Language Model (LLM) applications from arXiv in the last week and create a markdown table categorizing them by different domains.&#10;&#10;**Steps:**&#10;&#10;1. **Search for Papers (Scientist)**&#10; &#160;&#160;&#45; Use arXiv&#39;s search functionality with specific keywords (e.g., &quot;Large Language Models,&quot; &quot;GPT,&quot; &quot;transformers&quot;) to filter papers published in the last week.&#10;&#10;2. **Data Extraction (Scientist)**&#10; &#160;&#160;&#45; Extract relevant information: title, authors, abstract, domain of application, and source URL.&#10;&#10;3. **Data Organization (Engineer)**&#10; &#160;&#160;&#45; Create a markdown table format with columns for title, authors, abstract, domain, and source URL.&#10;&#10;4. **Data Entry (Engineer)**&#10; &#160;&#160;&#45; Input the extracted data into the markdown table, ensuring proper formatting.&#10;&#10;5. **Review and Finalization (Scientist &amp; Engineer)**&#10; &#160;&#160;&#45; Review the markdown table for accuracy and completeness, using a checklist for verification.&#10;&#10;6. **Submission (Scientist)**&#10; &#160;&#160;&#45; Submit the final markdown table to the admin for approval.&#10;&#10;By incorporating these suggestions, the plan will be more robust, verifiable, and user&#45;friendly." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="1441" y="-1308.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922637023056_2 -->
<g id="node33" class="node">
<title>139922637023056_2</title>
<ellipse fill="#fbdbd5" stroke="#c8a8a2" stroke-width="3" cx="1639" cy="-1269" rx="60.39" ry="18"/>
<text text-anchor="middle" x="1639" y="-1265.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Planner (2)</text>
</g>
<!-- 139922752308304_3&#45;&gt;139922637023056_2 -->
<g id="edge36" class="edge">
<title>139922752308304_3&#45;&gt;139922637023056_2</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M956.25,-1353.56C1107.63,-1350.56 1406.24,-1341.99 1509,-1320 1540.45,-1313.27 1574.31,-1300.04 1599.59,-1288.87"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1601.15,-1292.01 1608.84,-1284.71 1598.28,-1285.63 1601.15,-1292.01"/>
<g id="a_edge36&#45;label"><a xlink:title="### Feedback on the Plan&#10;&#10;Overall, the plan is well&#45;structured and outlines a clear process for finding and organizing recent papers on LLM applications. However, there are a few areas where improvements can be made to enhance the effectiveness and verifiability of the output:&#10;&#10;1. **Source URL Inclusion:**&#10; &#160;&#160;&#45; It is essential to include verifiable information such as the source URL for each paper in the markdown table. This will allow users to easily access the original papers for further reading and verification. Consider adding a column for the URL in the markdown table.&#10;&#10;2. **Keyword Specification:**&#10; &#160;&#160;&#45; The plan mentions using &quot;relevant keywords&quot; for searching papers. It would be beneficial to specify which keywords will be used to ensure a focused search. For example, keywords like &quot;Large Language Models,&quot; &quot;GPT,&quot; &quot;transformers,&quot; etc., could be included.&#10;&#10;3. **Domain Categorization:**&#10; &#160;&#160;&#45; While the plan mentions categorizing papers by domain, it would be helpful to define the specific domains that will be included in the table. This will provide clarity and ensure consistency in categorization.&#10;&#10;4. **Data Extraction Details:**&#10; &#160;&#160;&#45; The plan could benefit from specifying how the scientist will determine the domain of application for each paper. Will this be based on the abstract, keywords, or another method? Providing clarity on this process will enhance the reliability of the categorization.&#10;&#10;5. **Review Process:**&#10; &#160;&#160;&#45; The review process is a good step, but it might be useful to include a checklist of criteria for the scientist to use when reviewing the markdown table. This could include checking for completeness, accuracy of information, and proper formatting.&#10;&#10;6. **Timeline:**&#10; &#160;&#160;&#45; Consider adding a timeline for each step of the process. This will help in managing expectations and ensuring that the task is completed in a timely manner.&#10;&#10;### Revised Plan Suggestion&#10;&#10;**Objective:** To find recent papers on Large Language Model (LLM) applications from arXiv in the last week and create a markdown table categorizing them by different domains.&#10;&#10;**Steps:**&#10;&#10;1. **Search for Papers (Scientist)**&#10; &#160;&#160;&#45; Use arXiv&#39;s search functionality with specific keywords (e.g., &quot;Large Language Models,&quot; &quot;GPT,&quot; &quot;transformers&quot;) to filter papers published in the last week.&#10;&#10;2. **Data Extraction (Scientist)**&#10; &#160;&#160;&#45; Extract relevant information: title, authors, abstract, domain of application, and source URL.&#10;&#10;3. **Data Organization (Engineer)**&#10; &#160;&#160;&#45; Create a markdown table format with columns for title, authors, abstract, domain, and source URL.&#10;&#10;4. **Data Entry (Engineer)**&#10; &#160;&#160;&#45; Input the extracted data into the markdown table, ensuring proper formatting.&#10;&#10;5. **Review and Finalization (Scientist &amp; Engineer)**&#10; &#160;&#160;&#45; Review the markdown table for accuracy and completeness, using a checklist for verification.&#10;&#10;6. **Submission (Scientist)**&#10; &#160;&#160;&#45; Submit the final markdown table to the admin for approval.&#10;&#10;By incorporating these suggestions, the plan will be more robust, verifiable, and user&#45;friendly." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="1620" y="-1308.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922633387152_3 -->
<g id="node34" class="node">
<title>139922633387152_3</title>
<ellipse fill="#e4eee9" stroke="#b1bbb6" stroke-width="3" cx="500" cy="-1269" rx="65.79" ry="18"/>
<text text-anchor="middle" x="500" y="-1265.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Executor (3)</text>
</g>
<!-- 139922752308304_3&#45;&gt;139922633387152_3 -->
<g id="edge37" class="edge">
<title>139922752308304_3&#45;&gt;139922633387152_3</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M805.15,-1342.5C774.21,-1336.02 736.04,-1327.84 702,-1320 652.51,-1308.6 596.45,-1294.64 555.97,-1284.37"/>
<polygon fill="#6666ff" stroke="#6666ff" points="556.58,-1280.92 546.03,-1281.84 554.86,-1287.7 556.58,-1280.92"/>
<g id="a_edge37&#45;label"><a xlink:title="### Feedback on the Plan&#10;&#10;Overall, the plan is well&#45;structured and outlines a clear process for finding and organizing recent papers on LLM applications. However, there are a few areas where improvements can be made to enhance the effectiveness and verifiability of the output:&#10;&#10;1. **Source URL Inclusion:**&#10; &#160;&#160;&#45; It is essential to include verifiable information such as the source URL for each paper in the markdown table. This will allow users to easily access the original papers for further reading and verification. Consider adding a column for the URL in the markdown table.&#10;&#10;2. **Keyword Specification:**&#10; &#160;&#160;&#45; The plan mentions using &quot;relevant keywords&quot; for searching papers. It would be beneficial to specify which keywords will be used to ensure a focused search. For example, keywords like &quot;Large Language Models,&quot; &quot;GPT,&quot; &quot;transformers,&quot; etc., could be included.&#10;&#10;3. **Domain Categorization:**&#10; &#160;&#160;&#45; While the plan mentions categorizing papers by domain, it would be helpful to define the specific domains that will be included in the table. This will provide clarity and ensure consistency in categorization.&#10;&#10;4. **Data Extraction Details:**&#10; &#160;&#160;&#45; The plan could benefit from specifying how the scientist will determine the domain of application for each paper. Will this be based on the abstract, keywords, or another method? Providing clarity on this process will enhance the reliability of the categorization.&#10;&#10;5. **Review Process:**&#10; &#160;&#160;&#45; The review process is a good step, but it might be useful to include a checklist of criteria for the scientist to use when reviewing the markdown table. This could include checking for completeness, accuracy of information, and proper formatting.&#10;&#10;6. **Timeline:**&#10; &#160;&#160;&#45; Consider adding a timeline for each step of the process. This will help in managing expectations and ensuring that the task is completed in a timely manner.&#10;&#10;### Revised Plan Suggestion&#10;&#10;**Objective:** To find recent papers on Large Language Model (LLM) applications from arXiv in the last week and create a markdown table categorizing them by different domains.&#10;&#10;**Steps:**&#10;&#10;1. **Search for Papers (Scientist)**&#10; &#160;&#160;&#45; Use arXiv&#39;s search functionality with specific keywords (e.g., &quot;Large Language Models,&quot; &quot;GPT,&quot; &quot;transformers&quot;) to filter papers published in the last week.&#10;&#10;2. **Data Extraction (Scientist)**&#10; &#160;&#160;&#45; Extract relevant information: title, authors, abstract, domain of application, and source URL.&#10;&#10;3. **Data Organization (Engineer)**&#10; &#160;&#160;&#45; Create a markdown table format with columns for title, authors, abstract, domain, and source URL.&#10;&#10;4. **Data Entry (Engineer)**&#10; &#160;&#160;&#45; Input the extracted data into the markdown table, ensuring proper formatting.&#10;&#10;5. **Review and Finalization (Scientist &amp; Engineer)**&#10; &#160;&#160;&#45; Review the markdown table for accuracy and completeness, using a checklist for verification.&#10;&#10;6. **Submission (Scientist)**&#10; &#160;&#160;&#45; Submit the final markdown table to the admin for approval.&#10;&#10;By incorporating these suggestions, the plan will be more robust, verifiable, and user&#45;friendly." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="766" y="-1308.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922634606416_5 -->
<g id="node36" class="node">
<title>139922634606416_5</title>
<ellipse fill="#e8c4c6" stroke="#b59193" stroke-width="3" cx="810" cy="-1269" rx="96.68" ry="18"/>
<text text-anchor="middle" x="810" y="-1265.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">checking_agent (5)</text>
</g>
<!-- 139922752308304_3&#45;&gt;139922634606416_5 -->
<g id="edge38" class="edge">
<title>139922752308304_3&#45;&gt;139922634606416_5</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M849.03,-1329.25C841.96,-1318.51 833.77,-1306.08 826.72,-1295.39"/>
<polygon fill="#6666ff" stroke="#6666ff" points="846.24,-1331.37 854.67,-1337.8 852.09,-1327.52 846.24,-1331.37"/>
<polygon fill="#6666ff" stroke="#6666ff" points="829.55,-1293.31 821.12,-1286.89 823.7,-1297.16 829.55,-1293.31"/>
<text text-anchor="middle" x="911" y="-1308.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">Auto Select Speaker</text>
</g>
<!-- 98dfddff&#45;728e&#45;41cc&#45;b800&#45;8aa864512665 -->
<g id="node41" class="node">
<title>98dfddff&#45;728e&#45;41cc&#45;b800&#45;8aa864512665</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="1738.24,-1103.44 1793,-1091 1847.76,-1103.44 1847.71,-1123.56 1738.29,-1123.56 1738.24,-1103.44"/>
<text text-anchor="middle" x="1793" y="-1105.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">OpenAI</text>
</g>
<!-- 139922637147216_3&#45;&gt;98dfddff&#45;728e&#45;41cc&#45;b800&#45;8aa864512665 -->
<g id="edge45" class="edge">
<title>139922637147216_3&#45;&gt;98dfddff&#45;728e&#45;41cc&#45;b800&#45;8aa864512665</title>
<path fill="none" stroke="#6666ff" d="M1507.43,-1251.15C1520.39,-1233.51 1543.23,-1206.54 1570,-1193 1592.04,-1181.85 1601.89,-1193.73 1625,-1185 1636.42,-1180.69 1636.56,-1174.26 1648,-1170 1672.8,-1160.77 1682.05,-1170.81 1707,-1162 1728.52,-1154.41 1750.49,-1141 1766.85,-1129.7"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1769.18,-1132.33 1775.31,-1123.69 1765.13,-1126.63 1769.18,-1132.33"/>
<g id="a_edge45&#45;label"><a xlink:title="### Revised Plan&#10;&#10;**Objective:** To find recent papers on Large Language Model (LLM) applications from arXiv in the last week and create a markdown table categorizing them by different domains.&#10;&#10;**Steps:**&#10;&#10;1. **Search for Papers (Scientist)**&#10; &#160;&#160;&#45; Use arXiv&#39;s search functionality with specific keywords such as &quot;Large Language Models,&quot; &quot;GPT,&quot; &quot;transformers,&quot; and &quot;LLM applications&quot; to filter papers published in the last week.&#10;&#10;2. **Data Extraction (Scientist)**&#10; &#160;&#160;&#45; Extract relevant information from each paper, including:&#10; &#160;&#160;&#160;&#160;&#45; Title&#10; &#160;&#160;&#160;&#160;&#45; Authors&#10; &#160;&#160;&#160;&#160;&#45; Abstract&#10; &#160;&#160;&#160;&#160;&#45; Domain of application (e.g., healthcare, education, finance, etc.)&#10; &#160;&#160;&#160;&#160;&#45; Source URL&#10;&#10;3. **Data Organization (Engineer)**&#10; &#160;&#160;&#45; Create a markdown table format with the following columns:&#10; &#160;&#160;&#160;&#160;&#45; Title&#10; &#160;&#160;&#160;&#160;&#45; Authors&#10; &#160;&#160;&#160;&#160;&#45; Abstract&#10; &#160;&#160;&#160;&#160;&#45; Domain&#10; &#160;&#160;&#160;&#160;&#45; Source URL&#10;&#10;4. **Data Entry (Engineer)**&#10; &#160;&#160;&#45; Input the extracted data into the markdown table, ensuring proper formatting and clarity.&#10;&#10;5. **Review and Finalization (Scientist &amp; Engineer)**&#10; &#160;&#160;&#45; Review the markdown table for accuracy and completeness, using a checklist that includes:&#10; &#160;&#160;&#160;&#160;&#45; Completeness of information&#10; &#160;&#160;&#160;&#160;&#45; Accuracy of details&#10; &#160;&#160;&#160;&#160;&#45; Proper formatting&#10; &#160;&#160;&#160;&#160;&#45; Correct categorization of domains&#10;&#10;6. **Submission (Scientist)**&#10; &#160;&#160;&#45; Submit the final markdown table to the admin for approval.&#10;&#10;### Timeline&#10;&#45; **Day 1:** Search for papers and extract data.&#10;&#45; **Day 2:** Organize data into markdown table format.&#10;&#45; **Day 3:** Review and finalize the table.&#10;&#45; **Day 4:** Submit the table for approval.&#10;&#10;By following this revised plan, the process will be more structured, ensuring that the output is comprehensive, verifiable, and user&#45;friendly." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="1713.5" y="-1173.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">generate_oai_reply</text>
</a>
</g>
</g>
<!-- 139922752308304_4 -->
<g id="node42" class="node">
<title>139922752308304_4</title>
<ellipse fill="#a9c9d4" stroke="#7696a1" stroke-width="3" cx="1516" cy="-1109" rx="90.98" ry="18"/>
<text text-anchor="middle" x="1516" y="-1105.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">chat_manager (4)</text>
</g>
<!-- 139922637147216_3&#45;&gt;139922752308304_4 -->
<g id="edge47" class="edge">
<title>139922637147216_3&#45;&gt;139922752308304_4</title>
<path fill="none" stroke="#6666ff" d="M1494.65,-1250.88C1493.46,-1231.21 1492.52,-1198.06 1497,-1170 1498.78,-1158.83 1502.23,-1146.89 1505.71,-1136.62"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1509.07,-1137.6 1509.13,-1127 1502.48,-1135.25 1509.07,-1137.6"/>
<g id="a_edge47&#45;label"><a xlink:title="### Revised Plan&#10;&#10;**Objective:** To find recent papers on Large Language Model (LLM) applications from arXiv in the last week and create a markdown table categorizing them by different domains.&#10;&#10;**Steps:**&#10;&#10;1. **Search for Papers (Scientist)**&#10; &#160;&#160;&#45; Use arXiv&#39;s search functionality with specific keywords such as &quot;Large Language Models,&quot; &quot;GPT,&quot; &quot;transformers,&quot; and &quot;LLM applications&quot; to filter papers published in the last week.&#10;&#10;2. **Data Extraction (Scientist)**&#10; &#160;&#160;&#45; Extract relevant information from each paper, including:&#10; &#160;&#160;&#160;&#160;&#45; Title&#10; &#160;&#160;&#160;&#160;&#45; Authors&#10; &#160;&#160;&#160;&#160;&#45; Abstract&#10; &#160;&#160;&#160;&#160;&#45; Domain of application (e.g., healthcare, education, finance, etc.)&#10; &#160;&#160;&#160;&#160;&#45; Source URL&#10;&#10;3. **Data Organization (Engineer)**&#10; &#160;&#160;&#45; Create a markdown table format with the following columns:&#10; &#160;&#160;&#160;&#160;&#45; Title&#10; &#160;&#160;&#160;&#160;&#45; Authors&#10; &#160;&#160;&#160;&#160;&#45; Abstract&#10; &#160;&#160;&#160;&#160;&#45; Domain&#10; &#160;&#160;&#160;&#160;&#45; Source URL&#10;&#10;4. **Data Entry (Engineer)**&#10; &#160;&#160;&#45; Input the extracted data into the markdown table, ensuring proper formatting and clarity.&#10;&#10;5. **Review and Finalization (Scientist &amp; Engineer)**&#10; &#160;&#160;&#45; Review the markdown table for accuracy and completeness, using a checklist that includes:&#10; &#160;&#160;&#160;&#160;&#45; Completeness of information&#10; &#160;&#160;&#160;&#160;&#45; Accuracy of details&#10; &#160;&#160;&#160;&#160;&#45; Proper formatting&#10; &#160;&#160;&#160;&#160;&#45; Correct categorization of domains&#10;&#10;6. **Submission (Scientist)**&#10; &#160;&#160;&#45; Submit the final markdown table to the admin for approval.&#10;&#10;### Timeline&#10;&#45; **Day 1:** Search for papers and extract data.&#10;&#45; **Day 2:** Organize data into markdown table format.&#10;&#45; **Day 3:** Review and finalize the table.&#10;&#45; **Day 4:** Submit the table for approval.&#10;&#10;By following this revised plan, the process will be more structured, ensuring that the output is comprehensive, verifiable, and user&#45;friendly." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="1561" y="-1173.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 5e198ab6&#45;89c5&#45;448b&#45;a1d2&#45;de0e2508c392 -->
<g id="node35" class="node">
<title>5e198ab6&#45;89c5&#45;448b&#45;a1d2&#45;de0e2508c392</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="636.24,-1016.44 691,-1004 745.76,-1016.44 745.71,-1036.56 636.29,-1036.56 636.24,-1016.44"/>
<text text-anchor="middle" x="691" y="-1018.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">OpenAI</text>
</g>
<!-- 139922634606800_3 -->
<g id="node37" class="node">
<title>139922634606800_3</title>
<ellipse fill="#ebcfb9" stroke="#b89c86" stroke-width="3" cx="808" cy="-1109" rx="136.48" ry="18"/>
<text text-anchor="middle" x="808" y="-1105.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">speaker_selection_agent (3)</text>
</g>
<!-- 5e198ab6&#45;89c5&#45;448b&#45;a1d2&#45;de0e2508c392&#45;&gt;139922634606800_3 -->
<g id="edge41" class="edge">
<title>5e198ab6&#45;89c5&#45;448b&#45;a1d2&#45;de0e2508c392&#45;&gt;139922634606800_3</title>
<path fill="none" stroke="#6666ff" d="M741.47,-1036.62C767.97,-1044.22 795.81,-1053.12 800,-1058 805.4,-1064.28 807.9,-1072.72 808.92,-1080.86"/>
<polygon fill="#6666ff" stroke="#6666ff" points="805.42,-1081.07 809.51,-1090.85 812.41,-1080.66 805.42,-1081.07"/>
</g>
<!-- 139922634606416_5&#45;&gt;139922634606800_3 -->
<g id="edge39" class="edge">
<title>139922634606416_5&#45;&gt;139922634606800_3</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M809.78,-1250.79C809.44,-1223.48 808.76,-1169.99 808.35,-1137.38"/>
<polygon fill="#6666ff" stroke="#6666ff" points="811.84,-1137.14 808.22,-1127.19 804.84,-1137.23 811.84,-1137.14"/>
<g id="a_edge39&#45;label"><a xlink:title="Read the above conversation. Then select the next role from [&#39;Admin&#39;, &#39;Engineer&#39;, &#39;Scientist&#39;, &#39;Planner&#39;, &#39;Executor&#39;, &#39;Critic&#39;] to play. Only return the role." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="873" y="-1173.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922634606800_3&#45;&gt;5e198ab6&#45;89c5&#45;448b&#45;a1d2&#45;de0e2508c392 -->
<g id="edge40" class="edge">
<title>139922634606800_3&#45;&gt;5e198ab6&#45;89c5&#45;448b&#45;a1d2&#45;de0e2508c392</title>
<path fill="none" stroke="#6666ff" d="M721.21,-1095.03C697.5,-1089.62 676.3,-1082.37 669,-1073 662.55,-1064.72 665.78,-1054.26 671.54,-1045.05"/>
<polygon fill="#6666ff" stroke="#6666ff" points="674.55,-1046.86 677.59,-1036.71 668.88,-1042.75 674.55,-1046.86"/>
<g id="a_edge40&#45;label"><a xlink:title="Scientist" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="734.5" y="-1061.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">generate_oai_reply</text>
</a>
</g>
</g>
<!-- 139922634606416_6 -->
<g id="node38" class="node">
<title>139922634606416_6</title>
<ellipse fill="#e8c4c6" stroke="#b59193" stroke-width="3" cx="860" cy="-1022" rx="96.68" ry="18"/>
<text text-anchor="middle" x="860" y="-1018.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">checking_agent (6)</text>
</g>
<!-- 139922634606800_3&#45;&gt;139922634606416_6 -->
<g id="edge42" class="edge">
<title>139922634606800_3&#45;&gt;139922634606416_6</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M818.52,-1090.8C825.85,-1078.82 835.76,-1062.62 844.06,-1049.06"/>
<polygon fill="#6666ff" stroke="#6666ff" points="847.26,-1050.53 849.49,-1040.18 841.29,-1046.88 847.26,-1050.53"/>
<g id="a_edge42&#45;label"><a xlink:title="Scientist" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="901" y="-1061.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 1726553868.939448 -->
<g id="node39" class="node">
<title>1726553868.939448</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="883.56,-880 739.5,-880 702.44,-844 846.5,-844 883.56,-880"/>
<text text-anchor="middle" x="793" y="-858.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Summarize</text>
</g>
<!-- 139922634606416_6&#45;&gt;1726553868.939448 -->
<g id="edge43" class="edge">
<title>139922634606416_6&#45;&gt;1726553868.939448</title>
<path fill="none" stroke="#6666ff" d="M852.7,-1003.79C841.02,-976.25 818.05,-922.06 804.25,-889.53"/>
<polygon fill="#6666ff" stroke="#6666ff" points="807.42,-888.03 800.29,-880.19 800.97,-890.76 807.42,-888.03"/>
<g id="a_edge43&#45;label"><a xlink:title="Scientist" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="907" y="-926.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">_last_msg_as_summary</text>
</a>
</g>
</g>
<!-- 4f1d1cf2&#45;eb9a&#45;4bfa&#45;97d1&#45;c6189b3e8f35 -->
<g id="node40" class="node">
<title>4f1d1cf2&#45;eb9a&#45;4bfa&#45;97d1&#45;c6189b3e8f35</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="825,-793 755,-793 755,-757 831,-757 831,-787 825,-793"/>
<polyline fill="none" stroke="#00be92" stroke-width="3" points="825,-793 825,-787 "/>
<polyline fill="none" stroke="#00be92" stroke-width="3" points="831,-787 825,-787 "/>
<text text-anchor="middle" x="793" y="-771.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Scientist</text>
</g>
<!-- 1726553868.939448&#45;&gt;4f1d1cf2&#45;eb9a&#45;4bfa&#45;97d1&#45;c6189b3e8f35 -->
<g id="edge44" class="edge">
<title>1726553868.939448&#45;&gt;4f1d1cf2&#45;eb9a&#45;4bfa&#45;97d1&#45;c6189b3e8f35</title>
<path fill="none" stroke="#6666ff" d="M793,-843.8C793,-832.16 793,-816.55 793,-803.24"/>
<polygon fill="#6666ff" stroke="#6666ff" points="796.5,-803.18 793,-793.18 789.5,-803.18 796.5,-803.18"/>
<text text-anchor="middle" x="838.5" y="-814.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">next speaker</text>
</g>
<!-- 98dfddff&#45;728e&#45;41cc&#45;b800&#45;8aa864512665&#45;&gt;139922637147216_3 -->
<g id="edge46" class="edge">
<title>98dfddff&#45;728e&#45;41cc&#45;b800&#45;8aa864512665&#45;&gt;139922637147216_3</title>
<path fill="none" stroke="#6666ff" d="M1795.01,-1123.82C1796.64,-1141.04 1796.34,-1170.02 1779,-1185 1761.41,-1200.19 1591.26,-1183.63 1570,-1193 1546.27,-1203.46 1526.12,-1225.34 1512.87,-1242.79"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1510,-1240.78 1506.93,-1250.92 1515.66,-1244.91 1510,-1240.78"/>
</g>
<!-- 139922670162320_4 -->
<g id="node43" class="node">
<title>139922670162320_4</title>
<ellipse fill="#faf4d0" stroke="#c7c19d" stroke-width="3" cx="1793" cy="-1022" rx="55.49" ry="18"/>
<text text-anchor="middle" x="1793" y="-1018.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Admin (4)</text>
</g>
<!-- 139922752308304_4&#45;&gt;139922670162320_4 -->
<g id="edge48" class="edge">
<title>139922752308304_4&#45;&gt;139922670162320_4</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M1575.29,-1095.29C1601.46,-1089.25 1632.46,-1081.49 1660,-1073 1690.83,-1063.5 1724.88,-1050.65 1750.8,-1040.36"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1752.33,-1043.52 1760.32,-1036.56 1749.73,-1037.02 1752.33,-1043.52"/>
<g id="a_edge48&#45;label"><a xlink:title="### Revised Plan&#10;&#10;**Objective:** To find recent papers on Large Language Model (LLM) applications from arXiv in the last week and create a markdown table categorizing them by different domains.&#10;&#10;**Steps:**&#10;&#10;1. **Search for Papers (Scientist)**&#10; &#160;&#160;&#45; Use arXiv&#39;s search functionality with specific keywords such as &quot;Large Language Models,&quot; &quot;GPT,&quot; &quot;transformers,&quot; and &quot;LLM applications&quot; to filter papers published in the last week.&#10;&#10;2. **Data Extraction (Scientist)**&#10; &#160;&#160;&#45; Extract relevant information from each paper, including:&#10; &#160;&#160;&#160;&#160;&#45; Title&#10; &#160;&#160;&#160;&#160;&#45; Authors&#10; &#160;&#160;&#160;&#160;&#45; Abstract&#10; &#160;&#160;&#160;&#160;&#45; Domain of application (e.g., healthcare, education, finance, etc.)&#10; &#160;&#160;&#160;&#160;&#45; Source URL&#10;&#10;3. **Data Organization (Engineer)**&#10; &#160;&#160;&#45; Create a markdown table format with the following columns:&#10; &#160;&#160;&#160;&#160;&#45; Title&#10; &#160;&#160;&#160;&#160;&#45; Authors&#10; &#160;&#160;&#160;&#160;&#45; Abstract&#10; &#160;&#160;&#160;&#160;&#45; Domain&#10; &#160;&#160;&#160;&#160;&#45; Source URL&#10;&#10;4. **Data Entry (Engineer)**&#10; &#160;&#160;&#45; Input the extracted data into the markdown table, ensuring proper formatting and clarity.&#10;&#10;5. **Review and Finalization (Scientist &amp; Engineer)**&#10; &#160;&#160;&#45; Review the markdown table for accuracy and completeness, using a checklist that includes:&#10; &#160;&#160;&#160;&#160;&#45; Completeness of information&#10; &#160;&#160;&#160;&#160;&#45; Accuracy of details&#10; &#160;&#160;&#160;&#160;&#45; Proper formatting&#10; &#160;&#160;&#160;&#160;&#45; Correct categorization of domains&#10;&#10;6. **Submission (Scientist)**&#10; &#160;&#160;&#45; Submit the final markdown table to the admin for approval.&#10;&#10;### Timeline&#10;&#45; **Day 1:** Search for papers and extract data.&#10;&#45; **Day 2:** Organize data into markdown table format.&#10;&#45; **Day 3:** Review and finalize the table.&#10;&#45; **Day 4:** Submit the table for approval.&#10;&#10;By following this revised plan, the process will be more structured, ensuring that the output is comprehensive, verifiable, and user&#45;friendly." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="1768" y="-1061.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922636535504_4 -->
<g id="node44" class="node">
<title>139922636535504_4</title>
<ellipse fill="#c0dfb7" stroke="#8dac84" stroke-width="3" cx="1933" cy="-1022" rx="66.89" ry="18"/>
<text text-anchor="middle" x="1933" y="-1018.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Engineer (4)</text>
</g>
<!-- 139922752308304_4&#45;&gt;139922636535504_4 -->
<g id="edge49" class="edge">
<title>139922752308304_4&#45;&gt;139922636535504_4</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M1597.54,-1100.99C1684.88,-1093.17 1813.99,-1080.63 1836,-1073 1847.88,-1068.88 1848.98,-1064.06 1860,-1058 1869.9,-1052.55 1880.78,-1047.08 1891.05,-1042.13"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1892.74,-1045.2 1900.26,-1037.74 1889.73,-1038.88 1892.74,-1045.2"/>
<g id="a_edge49&#45;label"><a xlink:title="### Revised Plan&#10;&#10;**Objective:** To find recent papers on Large Language Model (LLM) applications from arXiv in the last week and create a markdown table categorizing them by different domains.&#10;&#10;**Steps:**&#10;&#10;1. **Search for Papers (Scientist)**&#10; &#160;&#160;&#45; Use arXiv&#39;s search functionality with specific keywords such as &quot;Large Language Models,&quot; &quot;GPT,&quot; &quot;transformers,&quot; and &quot;LLM applications&quot; to filter papers published in the last week.&#10;&#10;2. **Data Extraction (Scientist)**&#10; &#160;&#160;&#45; Extract relevant information from each paper, including:&#10; &#160;&#160;&#160;&#160;&#45; Title&#10; &#160;&#160;&#160;&#160;&#45; Authors&#10; &#160;&#160;&#160;&#160;&#45; Abstract&#10; &#160;&#160;&#160;&#160;&#45; Domain of application (e.g., healthcare, education, finance, etc.)&#10; &#160;&#160;&#160;&#160;&#45; Source URL&#10;&#10;3. **Data Organization (Engineer)**&#10; &#160;&#160;&#45; Create a markdown table format with the following columns:&#10; &#160;&#160;&#160;&#160;&#45; Title&#10; &#160;&#160;&#160;&#160;&#45; Authors&#10; &#160;&#160;&#160;&#160;&#45; Abstract&#10; &#160;&#160;&#160;&#160;&#45; Domain&#10; &#160;&#160;&#160;&#160;&#45; Source URL&#10;&#10;4. **Data Entry (Engineer)**&#10; &#160;&#160;&#45; Input the extracted data into the markdown table, ensuring proper formatting and clarity.&#10;&#10;5. **Review and Finalization (Scientist &amp; Engineer)**&#10; &#160;&#160;&#45; Review the markdown table for accuracy and completeness, using a checklist that includes:&#10; &#160;&#160;&#160;&#160;&#45; Completeness of information&#10; &#160;&#160;&#160;&#160;&#45; Accuracy of details&#10; &#160;&#160;&#160;&#160;&#45; Proper formatting&#10; &#160;&#160;&#160;&#160;&#45; Correct categorization of domains&#10;&#10;6. **Submission (Scientist)**&#10; &#160;&#160;&#45; Submit the final markdown table to the admin for approval.&#10;&#10;### Timeline&#10;&#45; **Day 1:** Search for papers and extract data.&#10;&#45; **Day 2:** Organize data into markdown table format.&#10;&#45; **Day 3:** Review and finalize the table.&#10;&#45; **Day 4:** Submit the table for approval.&#10;&#10;By following this revised plan, the process will be more structured, ensuring that the output is comprehensive, verifiable, and user&#45;friendly." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="1924" y="-1061.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922637023056_3 -->
<g id="node45" class="node">
<title>139922637023056_3</title>
<ellipse fill="#fbdbd5" stroke="#c8a8a2" stroke-width="3" cx="2078" cy="-1022" rx="60.39" ry="18"/>
<text text-anchor="middle" x="2078" y="-1018.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Planner (3)</text>
</g>
<!-- 139922752308304_4&#45;&gt;139922637023056_3 -->
<g id="edge50" class="edge">
<title>139922752308304_4&#45;&gt;139922637023056_3</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M1598.17,-1101.24C1637.71,-1098.04 1685.81,-1094.22 1729,-1091 1786.53,-1086.7 1932.69,-1089.4 1988,-1073 2008.97,-1066.78 2030.45,-1055.09 2047.16,-1044.57"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2049.44,-1047.27 2055.93,-1038.89 2045.63,-1041.39 2049.44,-1047.27"/>
<g id="a_edge50&#45;label"><a xlink:title="### Revised Plan&#10;&#10;**Objective:** To find recent papers on Large Language Model (LLM) applications from arXiv in the last week and create a markdown table categorizing them by different domains.&#10;&#10;**Steps:**&#10;&#10;1. **Search for Papers (Scientist)**&#10; &#160;&#160;&#45; Use arXiv&#39;s search functionality with specific keywords such as &quot;Large Language Models,&quot; &quot;GPT,&quot; &quot;transformers,&quot; and &quot;LLM applications&quot; to filter papers published in the last week.&#10;&#10;2. **Data Extraction (Scientist)**&#10; &#160;&#160;&#45; Extract relevant information from each paper, including:&#10; &#160;&#160;&#160;&#160;&#45; Title&#10; &#160;&#160;&#160;&#160;&#45; Authors&#10; &#160;&#160;&#160;&#160;&#45; Abstract&#10; &#160;&#160;&#160;&#160;&#45; Domain of application (e.g., healthcare, education, finance, etc.)&#10; &#160;&#160;&#160;&#160;&#45; Source URL&#10;&#10;3. **Data Organization (Engineer)**&#10; &#160;&#160;&#45; Create a markdown table format with the following columns:&#10; &#160;&#160;&#160;&#160;&#45; Title&#10; &#160;&#160;&#160;&#160;&#45; Authors&#10; &#160;&#160;&#160;&#160;&#45; Abstract&#10; &#160;&#160;&#160;&#160;&#45; Domain&#10; &#160;&#160;&#160;&#160;&#45; Source URL&#10;&#10;4. **Data Entry (Engineer)**&#10; &#160;&#160;&#45; Input the extracted data into the markdown table, ensuring proper formatting and clarity.&#10;&#10;5. **Review and Finalization (Scientist &amp; Engineer)**&#10; &#160;&#160;&#45; Review the markdown table for accuracy and completeness, using a checklist that includes:&#10; &#160;&#160;&#160;&#160;&#45; Completeness of information&#10; &#160;&#160;&#160;&#160;&#45; Accuracy of details&#10; &#160;&#160;&#160;&#160;&#45; Proper formatting&#10; &#160;&#160;&#160;&#160;&#45; Correct categorization of domains&#10;&#10;6. **Submission (Scientist)**&#10; &#160;&#160;&#45; Submit the final markdown table to the admin for approval.&#10;&#10;### Timeline&#10;&#45; **Day 1:** Search for papers and extract data.&#10;&#45; **Day 2:** Organize data into markdown table format.&#10;&#45; **Day 3:** Review and finalize the table.&#10;&#45; **Day 4:** Submit the table for approval.&#10;&#10;By following this revised plan, the process will be more structured, ensuring that the output is comprehensive, verifiable, and user&#45;friendly." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="2085" y="-1061.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922633387152_4 -->
<g id="node46" class="node">
<title>139922633387152_4</title>
<ellipse fill="#e4eee9" stroke="#b1bbb6" stroke-width="3" cx="1093" cy="-1022" rx="65.79" ry="18"/>
<text text-anchor="middle" x="1093" y="-1018.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Executor (4)</text>
</g>
<!-- 139922752308304_4&#45;&gt;139922633387152_4 -->
<g id="edge51" class="edge">
<title>139922752308304_4&#45;&gt;139922633387152_4</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M1426.87,-1105.36C1363.7,-1101.71 1277.46,-1093.13 1204,-1073 1178.25,-1065.94 1150.89,-1053.68 1129.78,-1043.06"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1131.33,-1039.93 1120.84,-1038.48 1128.14,-1046.16 1131.33,-1039.93"/>
<g id="a_edge51&#45;label"><a xlink:title="### Revised Plan&#10;&#10;**Objective:** To find recent papers on Large Language Model (LLM) applications from arXiv in the last week and create a markdown table categorizing them by different domains.&#10;&#10;**Steps:**&#10;&#10;1. **Search for Papers (Scientist)**&#10; &#160;&#160;&#45; Use arXiv&#39;s search functionality with specific keywords such as &quot;Large Language Models,&quot; &quot;GPT,&quot; &quot;transformers,&quot; and &quot;LLM applications&quot; to filter papers published in the last week.&#10;&#10;2. **Data Extraction (Scientist)**&#10; &#160;&#160;&#45; Extract relevant information from each paper, including:&#10; &#160;&#160;&#160;&#160;&#45; Title&#10; &#160;&#160;&#160;&#160;&#45; Authors&#10; &#160;&#160;&#160;&#160;&#45; Abstract&#10; &#160;&#160;&#160;&#160;&#45; Domain of application (e.g., healthcare, education, finance, etc.)&#10; &#160;&#160;&#160;&#160;&#45; Source URL&#10;&#10;3. **Data Organization (Engineer)**&#10; &#160;&#160;&#45; Create a markdown table format with the following columns:&#10; &#160;&#160;&#160;&#160;&#45; Title&#10; &#160;&#160;&#160;&#160;&#45; Authors&#10; &#160;&#160;&#160;&#160;&#45; Abstract&#10; &#160;&#160;&#160;&#160;&#45; Domain&#10; &#160;&#160;&#160;&#160;&#45; Source URL&#10;&#10;4. **Data Entry (Engineer)**&#10; &#160;&#160;&#45; Input the extracted data into the markdown table, ensuring proper formatting and clarity.&#10;&#10;5. **Review and Finalization (Scientist &amp; Engineer)**&#10; &#160;&#160;&#45; Review the markdown table for accuracy and completeness, using a checklist that includes:&#10; &#160;&#160;&#160;&#160;&#45; Completeness of information&#10; &#160;&#160;&#160;&#160;&#45; Accuracy of details&#10; &#160;&#160;&#160;&#160;&#45; Proper formatting&#10; &#160;&#160;&#160;&#160;&#45; Correct categorization of domains&#10;&#10;6. **Submission (Scientist)**&#10; &#160;&#160;&#45; Submit the final markdown table to the admin for approval.&#10;&#10;### Timeline&#10;&#45; **Day 1:** Search for papers and extract data.&#10;&#45; **Day 2:** Organize data into markdown table format.&#10;&#45; **Day 3:** Review and finalize the table.&#10;&#45; **Day 4:** Submit the table for approval.&#10;&#10;By following this revised plan, the process will be more structured, ensuring that the output is comprehensive, verifiable, and user&#45;friendly." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="1268" y="-1061.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922677986320_3 -->
<g id="node47" class="node">
<title>139922677986320_3</title>
<ellipse fill="#cdd5c6" stroke="#9aa293" stroke-width="3" cx="1227" cy="-1022" rx="50.09" ry="18"/>
<text text-anchor="middle" x="1227" y="-1018.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Critic (3)</text>
</g>
<!-- 139922752308304_4&#45;&gt;139922677986320_3 -->
<g id="edge52" class="edge">
<title>139922752308304_4&#45;&gt;139922677986320_3</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M1462.21,-1094.38C1438.2,-1088.13 1409.61,-1080.47 1384,-1073 1346.09,-1061.94 1303.4,-1048.27 1272.12,-1038.02"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1272.98,-1034.62 1262.39,-1034.82 1270.8,-1041.27 1272.98,-1034.62"/>
<g id="a_edge52&#45;label"><a xlink:title="### Revised Plan&#10;&#10;**Objective:** To find recent papers on Large Language Model (LLM) applications from arXiv in the last week and create a markdown table categorizing them by different domains.&#10;&#10;**Steps:**&#10;&#10;1. **Search for Papers (Scientist)**&#10; &#160;&#160;&#45; Use arXiv&#39;s search functionality with specific keywords such as &quot;Large Language Models,&quot; &quot;GPT,&quot; &quot;transformers,&quot; and &quot;LLM applications&quot; to filter papers published in the last week.&#10;&#10;2. **Data Extraction (Scientist)**&#10; &#160;&#160;&#45; Extract relevant information from each paper, including:&#10; &#160;&#160;&#160;&#160;&#45; Title&#10; &#160;&#160;&#160;&#160;&#45; Authors&#10; &#160;&#160;&#160;&#160;&#45; Abstract&#10; &#160;&#160;&#160;&#160;&#45; Domain of application (e.g., healthcare, education, finance, etc.)&#10; &#160;&#160;&#160;&#160;&#45; Source URL&#10;&#10;3. **Data Organization (Engineer)**&#10; &#160;&#160;&#45; Create a markdown table format with the following columns:&#10; &#160;&#160;&#160;&#160;&#45; Title&#10; &#160;&#160;&#160;&#160;&#45; Authors&#10; &#160;&#160;&#160;&#160;&#45; Abstract&#10; &#160;&#160;&#160;&#160;&#45; Domain&#10; &#160;&#160;&#160;&#160;&#45; Source URL&#10;&#10;4. **Data Entry (Engineer)**&#10; &#160;&#160;&#45; Input the extracted data into the markdown table, ensuring proper formatting and clarity.&#10;&#10;5. **Review and Finalization (Scientist &amp; Engineer)**&#10; &#160;&#160;&#45; Review the markdown table for accuracy and completeness, using a checklist that includes:&#10; &#160;&#160;&#160;&#160;&#45; Completeness of information&#10; &#160;&#160;&#160;&#160;&#45; Accuracy of details&#10; &#160;&#160;&#160;&#160;&#45; Proper formatting&#10; &#160;&#160;&#160;&#160;&#45; Correct categorization of domains&#10;&#10;6. **Submission (Scientist)**&#10; &#160;&#160;&#45; Submit the final markdown table to the admin for approval.&#10;&#10;### Timeline&#10;&#45; **Day 1:** Search for papers and extract data.&#10;&#45; **Day 2:** Organize data into markdown table format.&#10;&#45; **Day 3:** Review and finalize the table.&#10;&#45; **Day 4:** Submit the table for approval.&#10;&#10;By following this revised plan, the process will be more structured, ensuring that the output is comprehensive, verifiable, and user&#45;friendly." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="1448" y="-1061.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922634606416_7 -->
<g id="node49" class="node">
<title>139922634606416_7</title>
<ellipse fill="#e8c4c6" stroke="#b59193" stroke-width="3" cx="1516" cy="-1022" rx="96.68" ry="18"/>
<text text-anchor="middle" x="1516" y="-1018.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">checking_agent (7)</text>
</g>
<!-- 139922752308304_4&#45;&gt;139922634606416_7 -->
<g id="edge53" class="edge">
<title>139922752308304_4&#45;&gt;139922634606416_7</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M1516,-1080.73C1516,-1071.06 1516,-1060.17 1516,-1050.48"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1512.5,-1080.8 1516,-1090.8 1519.5,-1080.8 1512.5,-1080.8"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1519.5,-1050.18 1516,-1040.18 1512.5,-1050.18 1519.5,-1050.18"/>
<text text-anchor="middle" x="1586" y="-1061.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">Auto Select Speaker</text>
</g>
<!-- 8497d819&#45;cdaa&#45;4bb1&#45;8575&#45;3f1896003728 -->
<g id="node54" class="node">
<title>8497d819&#45;cdaa&#45;4bb1&#45;8575&#45;3f1896003728</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="3332.24,-856.44 3387,-844 3441.76,-856.44 3441.71,-876.56 3332.29,-876.56 3332.24,-856.44"/>
<text text-anchor="middle" x="3387" y="-858.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">OpenAI</text>
</g>
<!-- 139922636535504_4&#45;&gt;8497d819&#45;cdaa&#45;4bb1&#45;8575&#45;3f1896003728 -->
<g id="edge60" class="edge">
<title>139922636535504_4&#45;&gt;8497d819&#45;cdaa&#45;4bb1&#45;8575&#45;3f1896003728</title>
<path fill="none" stroke="#6666ff" d="M1944.04,-1004.09C1957.06,-985.84 1980.58,-957.81 2009,-946 2031.57,-936.62 2864.57,-938.79 2889,-938 3072.3,-932.05 3125.78,-969.16 3301,-915 3323.08,-908.17 3345.34,-894.49 3361.68,-882.87"/>
<polygon fill="#6666ff" stroke="#6666ff" points="3364.11,-885.42 3370.1,-876.69 3359.97,-879.78 3364.11,-885.42"/>
<g id="a_edge60&#45;label"><a xlink:title="### Implementation Plan&#10;&#10;Now that we have a clear plan, I will proceed to implement the data extraction and organization of recent papers on LLM applications from arXiv. Below is the Python script that will perform the search and create the markdown table.&#10;&#10;```python&#10;import requests&#10;from datetime import datetime, timedelta&#10;&#10;# Define the search parameters&#10;keywords = &quot;Large Language Models OR GPT OR transformers OR LLM applications&quot;&#10;end_date = datetime.now()&#10;start_date = end_date &#45; timedelta(days=7)&#10;&#10;# Format dates for arXiv API&#10;start_date_str = start_date.strftime(&#39;%Y%m%d&#39;)&#10;end_date_str = end_date.strftime(&#39;%Y%m%d&#39;)&#10;&#10;# arXiv API URL&#10;url = f&quot;http://export.arxiv.org/api/query?search_query=all:{keywords}&amp;start=0&amp;max_results=100&amp;sortBy=submittedDate&amp;sortOrder=descending&quot;&#10;&#10;# Fetch the data from arXiv&#10;response = requests.get(url)&#10;data = response.text&#10;&#10;# Parse the data&#10;import xml.etree.ElementTree as ET&#10;&#10;root = ET.fromstring(data)&#10;entries = root.findall(&#39;{http://www.w3.org/2005/Atom}entry&#39;)&#10;&#10;# Prepare markdown table&#10;markdown_table = &quot;| Title | Authors | Abstract | Domain | Source URL |&quot;&#10;markdown_table += &quot;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&quot;&#10;&#10;# Extract relevant information&#10;for entry in entries:&#10; &#160;&#160;&#160;title = entry.find(&#39;{http://www.w3.org/2005/Atom}title&#39;).text&#10; &#160;&#160;&#160;authors = &#39;, &#39;.join([author.find(&#39;{http://www.w3.org/2005/Atom}name&#39;).text for author in entry.findall(&#39;{http://www.w3.org/2005/Atom}author&#39;)])&#10; &#160;&#160;&#160;abstract = entry.find(&#39;{http://www.w3.org/2005/Atom}summary&#39;).text&#10; &#160;&#160;&#160;domain = &quot;General&quot; &#160;# Placeholder for domain categorization&#10; &#160;&#160;&#160;source_url = entry.find(&#39;{http://www.w3.org/2005/Atom}id&#39;).text&#10;&#10; &#160;&#160;&#160;# Add to markdown table&#10; &#160;&#160;&#160;markdown_table += f&quot;| {title} | {authors} | {abstract} | {domain} | [Link]({source_url}) |&quot;&#10;&#10;# Output the markdown table&#10;print(markdown_table)&#10;```&#10;&#10;### Execution Instructions&#10;1. Run the script in a Python environment with internet access.&#10;2. The script will fetch the latest papers from arXiv based on the specified keywords and create a markdown table.&#10;3. Review the output for accuracy and completeness.&#10;&#10;### Note&#10;&#45; The domain categorization is currently set to &quot;General&quot; as a placeholder. You may need to manually categorize the papers based on their abstracts or content after reviewing the output.&#10;&#45; Ensure that you have the `requests` library installed in your Python environment. If not, you can install it using `pip install requests`." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="3335.5" y="-926.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">generate_oai_reply</text>
</a>
</g>
</g>
<!-- 139922752308304_5 -->
<g id="node55" class="node">
<title>139922752308304_5</title>
<ellipse fill="#a9c9d4" stroke="#7696a1" stroke-width="3" cx="3020" cy="-862" rx="90.98" ry="18"/>
<text text-anchor="middle" x="3020" y="-858.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">chat_manager (5)</text>
</g>
<!-- 139922636535504_4&#45;&gt;139922752308304_5 -->
<g id="edge62" class="edge">
<title>139922636535504_4&#45;&gt;139922752308304_5</title>
<path fill="none" stroke="#6666ff" d="M1944.44,-1004.13C1957.66,-986.21 1981.19,-958.73 2009,-946 2087.44,-910.08 2310.01,-922.03 2396,-915 2584.9,-899.56 2805.93,-881.03 2927.71,-870.78"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2928.07,-874.27 2937.74,-869.94 2927.48,-867.29 2928.07,-874.27"/>
<g id="a_edge62&#45;label"><a xlink:title="### Implementation Plan&#10;&#10;Now that we have a clear plan, I will proceed to implement the data extraction and organization of recent papers on LLM applications from arXiv. Below is the Python script that will perform the search and create the markdown table.&#10;&#10;```python&#10;import requests&#10;from datetime import datetime, timedelta&#10;&#10;# Define the search parameters&#10;keywords = &quot;Large Language Models OR GPT OR transformers OR LLM applications&quot;&#10;end_date = datetime.now()&#10;start_date = end_date &#45; timedelta(days=7)&#10;&#10;# Format dates for arXiv API&#10;start_date_str = start_date.strftime(&#39;%Y%m%d&#39;)&#10;end_date_str = end_date.strftime(&#39;%Y%m%d&#39;)&#10;&#10;# arXiv API URL&#10;url = f&quot;http://export.arxiv.org/api/query?search_query=all:{keywords}&amp;start=0&amp;max_results=100&amp;sortBy=submittedDate&amp;sortOrder=descending&quot;&#10;&#10;# Fetch the data from arXiv&#10;response = requests.get(url)&#10;data = response.text&#10;&#10;# Parse the data&#10;import xml.etree.ElementTree as ET&#10;&#10;root = ET.fromstring(data)&#10;entries = root.findall(&#39;{http://www.w3.org/2005/Atom}entry&#39;)&#10;&#10;# Prepare markdown table&#10;markdown_table = &quot;| Title | Authors | Abstract | Domain | Source URL |&#10;&quot;&#10;markdown_table += &quot;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#10;&quot;&#10;&#10;# Extract relevant information&#10;for entry in entries:&#10; &#160;&#160;&#160;title = entry.find(&#39;{http://www.w3.org/2005/Atom}title&#39;).text&#10; &#160;&#160;&#160;authors = &#39;, &#39;.join([author.find(&#39;{http://www.w3.org/2005/Atom}name&#39;).text for author in entry.findall(&#39;{http://www.w3.org/2005/Atom}author&#39;)])&#10; &#160;&#160;&#160;abstract = entry.find(&#39;{http://www.w3.org/2005/Atom}summary&#39;).text&#10; &#160;&#160;&#160;domain = &quot;General&quot; &#160;# Placeholder for domain categorization&#10; &#160;&#160;&#160;source_url = entry.find(&#39;{http://www.w3.org/2005/Atom}id&#39;).text&#10;&#10; &#160;&#160;&#160;# Add to markdown table&#10; &#160;&#160;&#160;markdown_table += f&quot;| {title} | {authors} | {abstract} | {domain} | [Link]({source_url}) |&#10;&quot;&#10;&#10;# Output the markdown table&#10;print(markdown_table)&#10;```&#10;&#10;### Execution Instructions&#10;1. Run the script in a Python environment with internet access.&#10;2. The script will fetch the latest papers from arXiv based on the specified keywords and create a markdown table.&#10;3. Review the output for accuracy and completeness.&#10;&#10;### Note&#10;&#45; The domain categorization is currently set to &quot;General&quot; as a placeholder. You may need to manually categorize the papers based on their abstracts or content after reviewing the output.&#10;&#45; Ensure that you have the `requests` library installed in your Python environment. If not, you can install it using `pip install requests`." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="2191" y="-926.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 6c37f4a7&#45;e016&#45;4bd6&#45;b143&#45;27db989f008f -->
<g id="node48" class="node">
<title>6c37f4a7&#45;e016&#45;4bd6&#45;b143&#45;27db989f008f</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="1347.24,-769.44 1402,-757 1456.76,-769.44 1456.71,-789.56 1347.29,-789.56 1347.24,-769.44"/>
<text text-anchor="middle" x="1402" y="-771.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">OpenAI</text>
</g>
<!-- 139922634606800_4 -->
<g id="node50" class="node">
<title>139922634606800_4</title>
<ellipse fill="#ebcfb9" stroke="#b89c86" stroke-width="3" cx="1516" cy="-862" rx="136.48" ry="18"/>
<text text-anchor="middle" x="1516" y="-858.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">speaker_selection_agent (4)</text>
</g>
<!-- 6c37f4a7&#45;e016&#45;4bd6&#45;b143&#45;27db989f008f&#45;&gt;139922634606800_4 -->
<g id="edge56" class="edge">
<title>6c37f4a7&#45;e016&#45;4bd6&#45;b143&#45;27db989f008f&#45;&gt;139922634606800_4</title>
<path fill="none" stroke="#6666ff" d="M1452.89,-789.61C1479.32,-797.17 1506.97,-806.02 1511,-811 1516.11,-817.32 1518.16,-825.66 1518.71,-833.72"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1515.21,-833.94 1518.68,-843.95 1522.21,-833.96 1515.21,-833.94"/>
</g>
<!-- 139922634606416_7&#45;&gt;139922634606800_4 -->
<g id="edge54" class="edge">
<title>139922634606416_7&#45;&gt;139922634606800_4</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M1516,-1003.79C1516,-976.48 1516,-922.99 1516,-890.38"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1519.5,-890.19 1516,-880.19 1512.5,-890.19 1519.5,-890.19"/>
<g id="a_edge54&#45;label"><a xlink:title="Read the above conversation. Then select the next role from [&#39;Admin&#39;, &#39;Engineer&#39;, &#39;Scientist&#39;, &#39;Planner&#39;, &#39;Executor&#39;, &#39;Critic&#39;] to play. Only return the role." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="1580" y="-926.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922634606800_4&#45;&gt;6c37f4a7&#45;e016&#45;4bd6&#45;b143&#45;27db989f008f -->
<g id="edge55" class="edge">
<title>139922634606800_4&#45;&gt;6c37f4a7&#45;e016&#45;4bd6&#45;b143&#45;27db989f008f</title>
<path fill="none" stroke="#6666ff" d="M1431.07,-847.83C1407.87,-842.41 1387.13,-835.2 1380,-826 1373.57,-817.71 1376.81,-807.24 1382.56,-798.03"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1385.56,-799.85 1388.61,-789.7 1379.9,-795.74 1385.56,-799.85"/>
<g id="a_edge55&#45;label"><a xlink:title="Engineer" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="1445.5" y="-814.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">generate_oai_reply</text>
</a>
</g>
</g>
<!-- 139922634606416_8 -->
<g id="node51" class="node">
<title>139922634606416_8</title>
<ellipse fill="#e8c4c6" stroke="#b59193" stroke-width="3" cx="1571" cy="-775" rx="96.68" ry="18"/>
<text text-anchor="middle" x="1571" y="-771.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">checking_agent (8)</text>
</g>
<!-- 139922634606800_4&#45;&gt;139922634606416_8 -->
<g id="edge57" class="edge">
<title>139922634606800_4&#45;&gt;139922634606416_8</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M1527.13,-843.8C1535.01,-831.62 1545.71,-815.09 1554.57,-801.4"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1557.58,-803.18 1560.07,-792.89 1551.7,-799.38 1557.58,-803.18"/>
<g id="a_edge57&#45;label"><a xlink:title="Engineer" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="1610" y="-814.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 1726553873.858311 -->
<g id="node52" class="node">
<title>1726553873.858311</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="1594.56,-633 1450.5,-633 1413.44,-597 1557.5,-597 1594.56,-633"/>
<text text-anchor="middle" x="1504" y="-611.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Summarize</text>
</g>
<!-- 139922634606416_8&#45;&gt;1726553873.858311 -->
<g id="edge58" class="edge">
<title>139922634606416_8&#45;&gt;1726553873.858311</title>
<path fill="none" stroke="#6666ff" d="M1563.7,-756.79C1552.02,-729.25 1529.05,-675.06 1515.25,-642.53"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1518.42,-641.03 1511.29,-633.19 1511.97,-643.76 1518.42,-641.03"/>
<g id="a_edge58&#45;label"><a xlink:title="Engineer" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="1617" y="-679.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">_last_msg_as_summary</text>
</a>
</g>
</g>
<!-- 9476abfe&#45;666c&#45;4e21&#45;9813&#45;6a073f900512 -->
<g id="node53" class="node">
<title>9476abfe&#45;666c&#45;4e21&#45;9813&#45;6a073f900512</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="1537.5,-546 1464.5,-546 1464.5,-510 1543.5,-510 1543.5,-540 1537.5,-546"/>
<polyline fill="none" stroke="#00be92" stroke-width="3" points="1537.5,-546 1537.5,-540 "/>
<polyline fill="none" stroke="#00be92" stroke-width="3" points="1543.5,-540 1537.5,-540 "/>
<text text-anchor="middle" x="1504" y="-524.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Engineer</text>
</g>
<!-- 1726553873.858311&#45;&gt;9476abfe&#45;666c&#45;4e21&#45;9813&#45;6a073f900512 -->
<g id="edge59" class="edge">
<title>1726553873.858311&#45;&gt;9476abfe&#45;666c&#45;4e21&#45;9813&#45;6a073f900512</title>
<path fill="none" stroke="#6666ff" d="M1504,-596.8C1504,-585.16 1504,-569.55 1504,-556.24"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1507.5,-556.18 1504,-546.18 1500.5,-556.18 1507.5,-556.18"/>
<text text-anchor="middle" x="1549.5" y="-567.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">next speaker</text>
</g>
<!-- 8497d819&#45;cdaa&#45;4bb1&#45;8575&#45;3f1896003728&#45;&gt;139922636535504_4 -->
<g id="edge61" class="edge">
<title>8497d819&#45;cdaa&#45;4bb1&#45;8575&#45;3f1896003728&#45;&gt;139922636535504_4</title>
<path fill="none" stroke="#6666ff" d="M3370.48,-876.66C3354.03,-889.33 3327.48,-907.34 3301,-915 3279.01,-921.36 2911.89,-922.48 2889,-923 2882.89,-923.14 2014.62,-943.61 2009,-946 1984.67,-956.36 1963.85,-978.46 1950.19,-996"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1947.27,-994.07 1944.08,-1004.18 1952.87,-998.27 1947.27,-994.07"/>
</g>
<!-- 139922670162320_5 -->
<g id="node56" class="node">
<title>139922670162320_5</title>
<ellipse fill="#faf4d0" stroke="#c7c19d" stroke-width="3" cx="3519" cy="-775" rx="55.49" ry="18"/>
<text text-anchor="middle" x="3519" y="-771.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Admin (5)</text>
</g>
<!-- 139922752308304_5&#45;&gt;139922670162320_5 -->
<g id="edge63" class="edge">
<title>139922752308304_5&#45;&gt;139922670162320_5</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M3108.49,-857.72C3179.98,-853.74 3282.85,-845.03 3371,-826 3407.44,-818.13 3447.42,-804.3 3476.63,-793.17"/>
<polygon fill="#6666ff" stroke="#6666ff" points="3478.03,-796.38 3486.1,-789.52 3475.51,-789.85 3478.03,-796.38"/>
<g id="a_edge63&#45;label"><a xlink:title="### Implementation Plan&#10;&#10;Now that we have a clear plan, I will proceed to implement the data extraction and organization of recent papers on LLM applications from arXiv. Below is the Python script that will perform the search and create the markdown table.&#10;&#10;```python&#10;import requests&#10;from datetime import datetime, timedelta&#10;&#10;# Define the search parameters&#10;keywords = &quot;Large Language Models OR GPT OR transformers OR LLM applications&quot;&#10;end_date = datetime.now()&#10;start_date = end_date &#45; timedelta(days=7)&#10;&#10;# Format dates for arXiv API&#10;start_date_str = start_date.strftime(&#39;%Y%m%d&#39;)&#10;end_date_str = end_date.strftime(&#39;%Y%m%d&#39;)&#10;&#10;# arXiv API URL&#10;url = f&quot;http://export.arxiv.org/api/query?search_query=all:{keywords}&amp;start=0&amp;max_results=100&amp;sortBy=submittedDate&amp;sortOrder=descending&quot;&#10;&#10;# Fetch the data from arXiv&#10;response = requests.get(url)&#10;data = response.text&#10;&#10;# Parse the data&#10;import xml.etree.ElementTree as ET&#10;&#10;root = ET.fromstring(data)&#10;entries = root.findall(&#39;{http://www.w3.org/2005/Atom}entry&#39;)&#10;&#10;# Prepare markdown table&#10;markdown_table = &quot;| Title | Authors | Abstract | Domain | Source URL |&#10;&quot;&#10;markdown_table += &quot;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#10;&quot;&#10;&#10;# Extract relevant information&#10;for entry in entries:&#10; &#160;&#160;&#160;title = entry.find(&#39;{http://www.w3.org/2005/Atom}title&#39;).text&#10; &#160;&#160;&#160;authors = &#39;, &#39;.join([author.find(&#39;{http://www.w3.org/2005/Atom}name&#39;).text for author in entry.findall(&#39;{http://www.w3.org/2005/Atom}author&#39;)])&#10; &#160;&#160;&#160;abstract = entry.find(&#39;{http://www.w3.org/2005/Atom}summary&#39;).text&#10; &#160;&#160;&#160;domain = &quot;General&quot; &#160;# Placeholder for domain categorization&#10; &#160;&#160;&#160;source_url = entry.find(&#39;{http://www.w3.org/2005/Atom}id&#39;).text&#10;&#10; &#160;&#160;&#160;# Add to markdown table&#10; &#160;&#160;&#160;markdown_table += f&quot;| {title} | {authors} | {abstract} | {domain} | [Link]({source_url}) |&#10;&quot;&#10;&#10;# Output the markdown table&#10;print(markdown_table)&#10;```&#10;&#10;### Execution Instructions&#10;1. Run the script in a Python environment with internet access.&#10;2. The script will fetch the latest papers from arXiv based on the specified keywords and create a markdown table.&#10;3. Review the output for accuracy and completeness.&#10;&#10;### Note&#10;&#45; The domain categorization is currently set to &quot;General&quot; as a placeholder. You may need to manually categorize the papers based on their abstracts or content after reviewing the output.&#10;&#45; Ensure that you have the `requests` library installed in your Python environment. If not, you can install it using `pip install requests`." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="3488" y="-814.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922637147216_4 -->
<g id="node57" class="node">
<title>139922637147216_4</title>
<ellipse fill="#edb7ad" stroke="#ba847a" stroke-width="3" cx="2652" cy="-775" rx="64.99" ry="18"/>
<text text-anchor="middle" x="2652" y="-771.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Scientist (4)</text>
</g>
<!-- 139922752308304_5&#45;&gt;139922637147216_4 -->
<g id="edge64" class="edge">
<title>139922752308304_5&#45;&gt;139922637147216_4</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M2929.51,-859.87C2871.85,-856.77 2796.36,-848.21 2733,-826 2714.49,-819.51 2695.73,-808.29 2680.93,-798.12"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2682.89,-795.22 2672.71,-792.3 2678.85,-800.93 2682.89,-795.22"/>
<g id="a_edge64&#45;label"><a xlink:title="### Implementation Plan&#10;&#10;Now that we have a clear plan, I will proceed to implement the data extraction and organization of recent papers on LLM applications from arXiv. Below is the Python script that will perform the search and create the markdown table.&#10;&#10;```python&#10;import requests&#10;from datetime import datetime, timedelta&#10;&#10;# Define the search parameters&#10;keywords = &quot;Large Language Models OR GPT OR transformers OR LLM applications&quot;&#10;end_date = datetime.now()&#10;start_date = end_date &#45; timedelta(days=7)&#10;&#10;# Format dates for arXiv API&#10;start_date_str = start_date.strftime(&#39;%Y%m%d&#39;)&#10;end_date_str = end_date.strftime(&#39;%Y%m%d&#39;)&#10;&#10;# arXiv API URL&#10;url = f&quot;http://export.arxiv.org/api/query?search_query=all:{keywords}&amp;start=0&amp;max_results=100&amp;sortBy=submittedDate&amp;sortOrder=descending&quot;&#10;&#10;# Fetch the data from arXiv&#10;response = requests.get(url)&#10;data = response.text&#10;&#10;# Parse the data&#10;import xml.etree.ElementTree as ET&#10;&#10;root = ET.fromstring(data)&#10;entries = root.findall(&#39;{http://www.w3.org/2005/Atom}entry&#39;)&#10;&#10;# Prepare markdown table&#10;markdown_table = &quot;| Title | Authors | Abstract | Domain | Source URL |&#10;&quot;&#10;markdown_table += &quot;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#10;&quot;&#10;&#10;# Extract relevant information&#10;for entry in entries:&#10; &#160;&#160;&#160;title = entry.find(&#39;{http://www.w3.org/2005/Atom}title&#39;).text&#10; &#160;&#160;&#160;authors = &#39;, &#39;.join([author.find(&#39;{http://www.w3.org/2005/Atom}name&#39;).text for author in entry.findall(&#39;{http://www.w3.org/2005/Atom}author&#39;)])&#10; &#160;&#160;&#160;abstract = entry.find(&#39;{http://www.w3.org/2005/Atom}summary&#39;).text&#10; &#160;&#160;&#160;domain = &quot;General&quot; &#160;# Placeholder for domain categorization&#10; &#160;&#160;&#160;source_url = entry.find(&#39;{http://www.w3.org/2005/Atom}id&#39;).text&#10;&#10; &#160;&#160;&#160;# Add to markdown table&#10; &#160;&#160;&#160;markdown_table += f&quot;| {title} | {authors} | {abstract} | {domain} | [Link]({source_url}) |&#10;&quot;&#10;&#10;# Output the markdown table&#10;print(markdown_table)&#10;```&#10;&#10;### Execution Instructions&#10;1. Run the script in a Python environment with internet access.&#10;2. The script will fetch the latest papers from arXiv based on the specified keywords and create a markdown table.&#10;3. Review the output for accuracy and completeness.&#10;&#10;### Note&#10;&#45; The domain categorization is currently set to &quot;General&quot; as a placeholder. You may need to manually categorize the papers based on their abstracts or content after reviewing the output.&#10;&#45; Ensure that you have the `requests` library installed in your Python environment. If not, you can install it using `pip install requests`." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="2797" y="-814.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922637023056_4 -->
<g id="node58" class="node">
<title>139922637023056_4</title>
<ellipse fill="#fbdbd5" stroke="#c8a8a2" stroke-width="3" cx="2799" cy="-775" rx="60.39" ry="18"/>
<text text-anchor="middle" x="2799" y="-771.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Planner (4)</text>
</g>
<!-- 139922752308304_5&#45;&gt;139922637023056_4 -->
<g id="edge65" class="edge">
<title>139922752308304_5&#45;&gt;139922637023056_4</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M2965.39,-847.48C2944.35,-841.68 2920.28,-834.32 2899,-826 2877.19,-817.48 2853.74,-805.88 2835.02,-796.01"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2836.45,-792.8 2825.98,-791.17 2833.15,-798.97 2836.45,-792.8"/>
<g id="a_edge65&#45;label"><a xlink:title="### Implementation Plan&#10;&#10;Now that we have a clear plan, I will proceed to implement the data extraction and organization of recent papers on LLM applications from arXiv. Below is the Python script that will perform the search and create the markdown table.&#10;&#10;```python&#10;import requests&#10;from datetime import datetime, timedelta&#10;&#10;# Define the search parameters&#10;keywords = &quot;Large Language Models OR GPT OR transformers OR LLM applications&quot;&#10;end_date = datetime.now()&#10;start_date = end_date &#45; timedelta(days=7)&#10;&#10;# Format dates for arXiv API&#10;start_date_str = start_date.strftime(&#39;%Y%m%d&#39;)&#10;end_date_str = end_date.strftime(&#39;%Y%m%d&#39;)&#10;&#10;# arXiv API URL&#10;url = f&quot;http://export.arxiv.org/api/query?search_query=all:{keywords}&amp;start=0&amp;max_results=100&amp;sortBy=submittedDate&amp;sortOrder=descending&quot;&#10;&#10;# Fetch the data from arXiv&#10;response = requests.get(url)&#10;data = response.text&#10;&#10;# Parse the data&#10;import xml.etree.ElementTree as ET&#10;&#10;root = ET.fromstring(data)&#10;entries = root.findall(&#39;{http://www.w3.org/2005/Atom}entry&#39;)&#10;&#10;# Prepare markdown table&#10;markdown_table = &quot;| Title | Authors | Abstract | Domain | Source URL |&#10;&quot;&#10;markdown_table += &quot;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#10;&quot;&#10;&#10;# Extract relevant information&#10;for entry in entries:&#10; &#160;&#160;&#160;title = entry.find(&#39;{http://www.w3.org/2005/Atom}title&#39;).text&#10; &#160;&#160;&#160;authors = &#39;, &#39;.join([author.find(&#39;{http://www.w3.org/2005/Atom}name&#39;).text for author in entry.findall(&#39;{http://www.w3.org/2005/Atom}author&#39;)])&#10; &#160;&#160;&#160;abstract = entry.find(&#39;{http://www.w3.org/2005/Atom}summary&#39;).text&#10; &#160;&#160;&#160;domain = &quot;General&quot; &#160;# Placeholder for domain categorization&#10; &#160;&#160;&#160;source_url = entry.find(&#39;{http://www.w3.org/2005/Atom}id&#39;).text&#10;&#10; &#160;&#160;&#160;# Add to markdown table&#10; &#160;&#160;&#160;markdown_table += f&quot;| {title} | {authors} | {abstract} | {domain} | [Link]({source_url}) |&#10;&quot;&#10;&#10;# Output the markdown table&#10;print(markdown_table)&#10;```&#10;&#10;### Execution Instructions&#10;1. Run the script in a Python environment with internet access.&#10;2. The script will fetch the latest papers from arXiv based on the specified keywords and create a markdown table.&#10;3. Review the output for accuracy and completeness.&#10;&#10;### Note&#10;&#45; The domain categorization is currently set to &quot;General&quot; as a placeholder. You may need to manually categorize the papers based on their abstracts or content after reviewing the output.&#10;&#45; Ensure that you have the `requests` library installed in your Python environment. If not, you can install it using `pip install requests`." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="2963" y="-814.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922633387152_5 -->
<g id="node59" class="node">
<title>139922633387152_5</title>
<ellipse fill="#e4eee9" stroke="#b1bbb6" stroke-width="3" cx="2325" cy="-775" rx="65.79" ry="18"/>
<text text-anchor="middle" x="2325" y="-771.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Executor (5)</text>
</g>
<!-- 139922752308304_5&#45;&gt;139922633387152_5 -->
<g id="edge66" class="edge">
<title>139922752308304_5&#45;&gt;139922633387152_5</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M2931.7,-857.36C2840.71,-852.86 2694.94,-843.54 2570,-826 2505.25,-816.91 2431.88,-801.21 2382.45,-789.82"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2383.11,-786.38 2372.58,-787.53 2381.53,-793.2 2383.11,-786.38"/>
<g id="a_edge66&#45;label"><a xlink:title="### Implementation Plan&#10;&#10;Now that we have a clear plan, I will proceed to implement the data extraction and organization of recent papers on LLM applications from arXiv. Below is the Python script that will perform the search and create the markdown table.&#10;&#10;```python&#10;import requests&#10;from datetime import datetime, timedelta&#10;&#10;# Define the search parameters&#10;keywords = &quot;Large Language Models OR GPT OR transformers OR LLM applications&quot;&#10;end_date = datetime.now()&#10;start_date = end_date &#45; timedelta(days=7)&#10;&#10;# Format dates for arXiv API&#10;start_date_str = start_date.strftime(&#39;%Y%m%d&#39;)&#10;end_date_str = end_date.strftime(&#39;%Y%m%d&#39;)&#10;&#10;# arXiv API URL&#10;url = f&quot;http://export.arxiv.org/api/query?search_query=all:{keywords}&amp;start=0&amp;max_results=100&amp;sortBy=submittedDate&amp;sortOrder=descending&quot;&#10;&#10;# Fetch the data from arXiv&#10;response = requests.get(url)&#10;data = response.text&#10;&#10;# Parse the data&#10;import xml.etree.ElementTree as ET&#10;&#10;root = ET.fromstring(data)&#10;entries = root.findall(&#39;{http://www.w3.org/2005/Atom}entry&#39;)&#10;&#10;# Prepare markdown table&#10;markdown_table = &quot;| Title | Authors | Abstract | Domain | Source URL |&#10;&quot;&#10;markdown_table += &quot;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#10;&quot;&#10;&#10;# Extract relevant information&#10;for entry in entries:&#10; &#160;&#160;&#160;title = entry.find(&#39;{http://www.w3.org/2005/Atom}title&#39;).text&#10; &#160;&#160;&#160;authors = &#39;, &#39;.join([author.find(&#39;{http://www.w3.org/2005/Atom}name&#39;).text for author in entry.findall(&#39;{http://www.w3.org/2005/Atom}author&#39;)])&#10; &#160;&#160;&#160;abstract = entry.find(&#39;{http://www.w3.org/2005/Atom}summary&#39;).text&#10; &#160;&#160;&#160;domain = &quot;General&quot; &#160;# Placeholder for domain categorization&#10; &#160;&#160;&#160;source_url = entry.find(&#39;{http://www.w3.org/2005/Atom}id&#39;).text&#10;&#10; &#160;&#160;&#160;# Add to markdown table&#10; &#160;&#160;&#160;markdown_table += f&quot;| {title} | {authors} | {abstract} | {domain} | [Link]({source_url}) |&#10;&quot;&#10;&#10;# Output the markdown table&#10;print(markdown_table)&#10;```&#10;&#10;### Execution Instructions&#10;1. Run the script in a Python environment with internet access.&#10;2. The script will fetch the latest papers from arXiv based on the specified keywords and create a markdown table.&#10;3. Review the output for accuracy and completeness.&#10;&#10;### Note&#10;&#45; The domain categorization is currently set to &quot;General&quot; as a placeholder. You may need to manually categorize the papers based on their abstracts or content after reviewing the output.&#10;&#45; Ensure that you have the `requests` library installed in your Python environment. If not, you can install it using `pip install requests`." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="2634" y="-814.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922677986320_4 -->
<g id="node60" class="node">
<title>139922677986320_4</title>
<ellipse fill="#cdd5c6" stroke="#9aa293" stroke-width="3" cx="3382" cy="-775" rx="50.09" ry="18"/>
<text text-anchor="middle" x="3382" y="-771.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Critic (4)</text>
</g>
<!-- 139922752308304_5&#45;&gt;139922677986320_4 -->
<g id="edge67" class="edge">
<title>139922752308304_5&#45;&gt;139922677986320_4</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M3078.96,-848.15C3108.44,-841.65 3144.64,-833.55 3177,-826 3230.06,-813.62 3290.67,-798.74 3332.14,-788.46"/>
<polygon fill="#6666ff" stroke="#6666ff" points="3333.13,-791.82 3341.99,-786.01 3331.44,-785.02 3333.13,-791.82"/>
<g id="a_edge67&#45;label"><a xlink:title="### Implementation Plan&#10;&#10;Now that we have a clear plan, I will proceed to implement the data extraction and organization of recent papers on LLM applications from arXiv. Below is the Python script that will perform the search and create the markdown table.&#10;&#10;```python&#10;import requests&#10;from datetime import datetime, timedelta&#10;&#10;# Define the search parameters&#10;keywords = &quot;Large Language Models OR GPT OR transformers OR LLM applications&quot;&#10;end_date = datetime.now()&#10;start_date = end_date &#45; timedelta(days=7)&#10;&#10;# Format dates for arXiv API&#10;start_date_str = start_date.strftime(&#39;%Y%m%d&#39;)&#10;end_date_str = end_date.strftime(&#39;%Y%m%d&#39;)&#10;&#10;# arXiv API URL&#10;url = f&quot;http://export.arxiv.org/api/query?search_query=all:{keywords}&amp;start=0&amp;max_results=100&amp;sortBy=submittedDate&amp;sortOrder=descending&quot;&#10;&#10;# Fetch the data from arXiv&#10;response = requests.get(url)&#10;data = response.text&#10;&#10;# Parse the data&#10;import xml.etree.ElementTree as ET&#10;&#10;root = ET.fromstring(data)&#10;entries = root.findall(&#39;{http://www.w3.org/2005/Atom}entry&#39;)&#10;&#10;# Prepare markdown table&#10;markdown_table = &quot;| Title | Authors | Abstract | Domain | Source URL |&#10;&quot;&#10;markdown_table += &quot;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#10;&quot;&#10;&#10;# Extract relevant information&#10;for entry in entries:&#10; &#160;&#160;&#160;title = entry.find(&#39;{http://www.w3.org/2005/Atom}title&#39;).text&#10; &#160;&#160;&#160;authors = &#39;, &#39;.join([author.find(&#39;{http://www.w3.org/2005/Atom}name&#39;).text for author in entry.findall(&#39;{http://www.w3.org/2005/Atom}author&#39;)])&#10; &#160;&#160;&#160;abstract = entry.find(&#39;{http://www.w3.org/2005/Atom}summary&#39;).text&#10; &#160;&#160;&#160;domain = &quot;General&quot; &#160;# Placeholder for domain categorization&#10; &#160;&#160;&#160;source_url = entry.find(&#39;{http://www.w3.org/2005/Atom}id&#39;).text&#10;&#10; &#160;&#160;&#160;# Add to markdown table&#10; &#160;&#160;&#160;markdown_table += f&quot;| {title} | {authors} | {abstract} | {domain} | [Link]({source_url}) |&#10;&quot;&#10;&#10;# Output the markdown table&#10;print(markdown_table)&#10;```&#10;&#10;### Execution Instructions&#10;1. Run the script in a Python environment with internet access.&#10;2. The script will fetch the latest papers from arXiv based on the specified keywords and create a markdown table.&#10;3. Review the output for accuracy and completeness.&#10;&#10;### Note&#10;&#45; The domain categorization is currently set to &quot;General&quot; as a placeholder. You may need to manually categorize the papers based on their abstracts or content after reviewing the output.&#10;&#45; Ensure that you have the `requests` library installed in your Python environment. If not, you can install it using `pip install requests`." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="3303" y="-814.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922634606416_9 -->
<g id="node62" class="node">
<title>139922634606416_9</title>
<ellipse fill="#e8c4c6" stroke="#b59193" stroke-width="3" cx="3045" cy="-775" rx="96.68" ry="18"/>
<text text-anchor="middle" x="3045" y="-771.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">checking_agent (9)</text>
</g>
<!-- 139922752308304_5&#45;&gt;139922634606416_9 -->
<g id="edge68" class="edge">
<title>139922752308304_5&#45;&gt;139922634606416_9</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M3027.9,-834.13C3030.83,-824.18 3034.14,-812.91 3037.07,-802.96"/>
<polygon fill="#6666ff" stroke="#6666ff" points="3024.52,-833.22 3025.06,-843.8 3031.24,-835.19 3024.52,-833.22"/>
<polygon fill="#6666ff" stroke="#6666ff" points="3040.48,-803.76 3039.95,-793.18 3033.77,-801.78 3040.48,-803.76"/>
<text text-anchor="middle" x="3103" y="-814.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">Auto Select Speaker</text>
</g>
<!-- 139922752308304_6 -->
<g id="node68" class="node">
<title>139922752308304_6</title>
<ellipse fill="#a9c9d4" stroke="#7696a1" stroke-width="3" cx="2288" cy="-615" rx="90.98" ry="18"/>
<text text-anchor="middle" x="2288" y="-611.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">chat_manager (6)</text>
</g>
<!-- 139922633387152_5&#45;&gt;139922752308304_6 -->
<g id="edge76" class="edge">
<title>139922633387152_5&#45;&gt;139922752308304_6</title>
<path fill="none" stroke="#6666ff" d="M2320.97,-756.79C2314.55,-729.37 2301.94,-675.53 2294.31,-642.96"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2297.71,-642.13 2292.03,-633.19 2290.9,-643.72 2297.71,-642.13"/>
<g id="a_edge76&#45;label"><a xlink:title="exitcode: 0 (execution succeeded)&#10;Code output: &#10;| Title | Authors | Abstract | Domain | Source URL |&#10;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#10;| The VIRUS&#45;dE Survey I: Stars in dwarf elliptical galaxies &#45; 3D dynamics&#10; &#160;and radially resolved stellar initial mass functions | Mathias Lipka, Jens Thomas, Roberto Saglia, Ralf Bender, Maximilian Fabricius, Gary J. Hill, Matthias Kluge, Martin Landriau, Ximena Mazzalay, Eva Noyola, Taniya Parikh, Jan Snigula | &#160;&#160;We analyse the stellar structure of a sample of dwarf ellipticals (dE)&#10;inhabiting various environments within the Virgo cluster. Integral&#45;field&#10;observations with a high spectral resolution allow us to robustly determine&#10;their low velocity dispersions ($sim25$ km s$^{&#45;1}$) and higher&#45;order&#10;kinematic moments out to the half&#45;light radius. We find the dEs exhibit a&#10;diversity in ages with the younger dEs being less enhanced than the older,&#10;suggesting a complex star formation history for those dEs that recently entered&#10;Virgo while others have been quenched shortly after reionization.&#10;Orbit&#45;superposition modeling allowed us to recover viewing angles, stellar&#10;mass&#45;to&#45;light ratios (with gradients), as well as the intrinsic orbit&#10;structure. We find that the angular momentum of the dEs is strongly suppressed&#10;compared to ordinary early&#45;type galaxies and correlates with the environment.&#10;Flattened dEs are so because of a suppressed kinetic energy perpendicular to&#10;their equatorial plane. Combining population and dynamical modeling results, we&#10;find an age&#45;dependent stellar initial mass function (IMF) or, alternatively,&#10;evidence for a more extended star formation history for those galaxies that&#10;have had higher initial mass and/or inhabited lower density environments. dEs&#10;appear to have a spatially homogeneous stellar structure but the state they&#10;were `frozen&#39; in as they stopped forming stars varies dramatically according to&#10;their initial conditions.&#10; | General | [Link](http://arxiv.org/abs/2409.10518v1) |&#10;| RetrievalAttention: Accelerating Long&#45;Context LLM Inference via Vector&#10; &#160;Retrieval | Di Liu, Meng Chen, Baotong Lu, Huiqiang Jiang, Zhenhua Han, Qianxi Zhang, Qi Chen, Chengruidong Zhang, Bailu Ding, Kai Zhang, Chen Chen, Fan Yang, Yuqing Yang, Lili Qiu | &#160;&#160;Transformer&#45;based large Language Models (LLMs) become increasingly important&#10;in various domains. However, the quadratic time complexity of attention&#10;operation poses a significant challenge for scaling to longer contexts due to&#10;the extremely high inference latency and GPU memory consumption for caching&#10;key&#45;value (KV) vectors. This paper proposes RetrievalAttention, a training&#45;free&#10;approach to accelerate attention computation. To leverage the dynamic sparse&#10;property of attention, RetrievalAttention builds approximate nearest neighbor&#10;search (ANNS) indexes upon KV vectors in CPU memory and retrieves the most&#10;relevant ones via vector search during generation. Due to the&#10;out&#45;of&#45;distribution (OOD) between query vectors and key vectors, off&#45;the&#45;shelf&#10;ANNS indexes still need to scan O(N) (usually 30% of all keys) data for&#10;accurate retrieval, which fails to exploit the high sparsity.&#10;RetrievalAttention first identifies the OOD challenge of ANNS&#45;based attention,&#10;and addresses it via an attention&#45;aware vector search algorithm that can adapt&#10;to queries and only access 1&#45;&#45;3% of data, thus achieving a sub&#45;linear time&#10;complexity. RetrievalAttention greatly reduces the inference cost of&#10;long&#45;context LLM with much lower GPU memory requirements while maintaining the&#10;model accuracy. Especially, RetrievalAttention only needs 16GB GPU memory for&#10;serving 128K tokens in LLMs with 8B parameters, which is capable of generating&#10;one token in 0.188 seconds on a single NVIDIA RTX4090 (24GB).&#10; | General | [Link](http://arxiv.org/abs/2409.10516v1) |&#10;| An Efficient Self&#45;Learning Framework For Interactive Spoken Dialog&#10; &#160;Systems | Hitesh Tulsiani, David M. Chan, Shalini Ghosh, Garima Lalwani, Prabhat Pandey, Ankish Bansal, Sri Garimella, Ariya Rastrow, Bjrn Hoffmeister | &#160;&#160;Dialog systems, such as voice assistants, are expected to engage with users&#10;in complex, evolving conversations. Unfortunately, traditional automatic speech&#10;recognition (ASR) systems deployed in such applications are usually trained to&#10;recognize each turn independently and lack the ability to adapt to the&#10;conversational context or incorporate user feedback. In this work, we introduce&#10;a general framework for ASR in dialog systems that can go beyond learning from&#10;single&#45;turn utterances and learn over time how to adapt to both explicit&#10;supervision and implicit user feedback present in multi&#45;turn conversations. We&#10;accomplish that by leveraging advances in student&#45;teacher learning and&#10;context&#45;aware dialog processing, and designing contrastive self&#45;supervision&#10;approaches with Ohm, a new online hard&#45;negative mining approach. We show that&#10;leveraging our new framework compared to traditional training leads to relative&#10;WER reductions of close to 10% in real&#45;world dialog systems, and up to 26% on&#10;public synthetic data.&#10; | General | [Link](http://arxiv.org/abs/2409.10515v1) |&#10;| Constraints on axions from patchy screening of the cosmic microwave&#10; &#160;background | Samuel Goldstein, Fiona McCarthy, Cristina Mondino, J. Colin Hill, Junwu Huang, Matthew C. Johnson | &#160;&#160;The resonant conversion of cosmic microwave background (CMB) photons into&#10;axions within large&#45;scale structure induces an anisotropic spectral distortion&#10;in CMB temperature maps. Applying state&#45;of&#45;the&#45;art foreground cleaning&#10;techniques to $textit{Planck}$ CMB observations, we construct maps of&#10;axion&#45;induced &quot;patchy screening&quot; of the CMB. We cross&#45;correlate these maps with&#10;data from the $textit{unWISE}$ galaxy survey and find no evidence of axions.&#10;We constrain the axion&#45;photon coupling, $g_{agammagamma} &#10;esssim 2 times&#10;10^{&#45;12}~{&#13;m GeV}^{&#45;1}$, at the 95% confidence level for axion masses in the&#10;range $10^{&#45;13}~{&#13;m eV} &#10;esssim m_a &#10;esssim 10^{&#45;12}~{&#13;m eV}$. These&#10;constraints are competitive with the tightest astrophysical axion limits in&#10;this mass range and are inferred from robust population&#45;level statistics, which&#10;makes them complementary to existing searches that rely on modeling of&#10;individual systems.&#10; | General | [Link](http://arxiv.org/abs/2409.10514v1) |&#10;| Weak Superimposed Codes of Improved Asymptotic Rate and Their Randomized&#10; &#160;Construction | Yu Tsunoda, Yuichiro Fujiwara | &#160;&#160;Weak superimposed codes are combinatorial structures related closely to&#10;generalized cover&#45;free families, superimposed codes, and disjunct matrices in&#10;that they are only required to satisfy similar but less stringent conditions.&#10;This class of codes may also be seen as a stricter variant of what are known as&#10;locally thin families in combinatorics. Originally, weak superimposed codes&#10;were introduced in the context of multimedia content protection against illegal&#10;distribution of copies under the assumption that a coalition of malicious users&#10;may employ the averaging attack with adversarial noise. As in many other kinds&#10;of codes in information theory, it is of interest and importance in the study&#10;of weak superimposed codes to find the highest achievable rate in the&#10;asymptotic regime and give an efficient construction that produces an infinite&#10;sequence of codes that achieve it. Here, we prove a tighter lower bound than&#10;the sharpest known one on the rate of optimal weak superimposed codes and give&#10;a polynomial&#45;time randomized construction algorithm for codes that&#10;asymptotically attain our improved bound with high probability. Our&#10;probabilistic approach is versatile and applicable to many other related codes&#10;and arrays.&#10; | General | [Link](http://arxiv.org/abs/2409.10511v1) |&#10;| Pennsieve &#45; A Collaborative Platform for Translational Neuroscience and&#10; &#160;Beyond | Zack Goldblum, Zhongchuan Xu, Haoer Shi, Patryk Orzechowski, Jamaal Spence, Kathryn A Davis, Brian Litt, Nishant Sinha, Joost Wagenaar | &#160;&#160;The exponential growth of neuroscientific data necessitates platforms that&#10;facilitate data management and multidisciplinary collaboration. In this paper,&#10;we introduce Pennsieve &#45; an open&#45;source, cloud&#45;based scientific data management&#10;platform built to meet these needs. Pennsieve supports complex multimodal&#10;datasets and provides tools for data visualization and analyses. It takes a&#10;comprehensive approach to data integration, enabling researchers to define&#10;custom metadata schemas and utilize advanced tools to filter and query their&#10;data. Pennsieve&#39;s modular architecture allows external applications to extend&#10;its capabilities, and collaborative workspaces with peer&#45;reviewed data&#10;publishing mechanisms promote high&#45;quality datasets optimized for downstream&#10;analysis, both in the cloud and on&#45;premises.&#10; &#160;Pennsieve forms the core for major neuroscience research programs including&#10;the NIH SPARC Initiative, NIH HEAL Initiative&#39;s PRECISION Human Pain Network,&#10;and NIH HEAL RE&#45;JOIN Initiative. It serves more than 80 research groups&#10;worldwide, along with several large&#45;scale, inter&#45;institutional projects at&#10;clinical sites through the University of Pennsylvania. Underpinning the&#10;SPARC.Science, Epilepsy.Science, and Pennsieve Discover portals, Pennsieve&#10;stores over 125 TB of scientific data, with 35 TB of data publicly available&#10;across more than 350 high&#45;impact datasets. It adheres to the findable,&#10;accessible, interoperable, and reusable (FAIR) principles of data sharing and&#10;is recognized as one of the NIH&#45;approved Data Repositories. By facilitating&#10;scientific data management, discovery, and analysis, Pennsieve fosters a robust&#10;and collaborative research ecosystem for neuroscience and beyond.&#10; | General | [Link](http://arxiv.org/abs/2409.10509v1) |&#10;| General&#45;relativistic resistive&#45;magnetohydrodynamics simulations of&#10; &#160;self&#45;consistent magnetized rotating neutron stars | Patrick Chi&#45;Kit Cheong, Antonios Tsokaros, Milton Ruiz, Fabrizio Venturi, Juno Chun Lung Chan, Anson Ka Long Yip, Koji Uryu | &#160;&#160;We present the first general&#45;relativistic resistive magnetohydrodynamics&#10;simulations of self&#45;consistent, rotating neutron stars with mixed poloidal and&#10;toroidal magnetic fields. Specifically, we investigate the role of resistivity&#10;in the dynamical evolution of neutron stars over a period of up to 100 ms and&#10;its effects on their quasi&#45;equilibrium configurations. Our results demonstrate&#10;that resistivity can significantly influence the development of&#10;magnetohydrodynamic instabilities, resulting in markedly different magnetic&#10;field geometries. Additionally, resistivity suppresses the growth of these&#10;instabilities, leading to a reduction in the amplitude of emitted gravitational&#10;waves. Despite the variations in magnetic field geometries, the ratio of&#10;poloidal to toroidal field energies remains consistently 9:1 throughout the&#10;simulations, for the models we investigated.&#10; | General | [Link](http://arxiv.org/abs/2409.10508v1) |&#10;| Beth&#45;Uhlenbeck equation for the thermodynamics of fluctuations in a&#10; &#160;generalised 2+1D Gross&#45;Neveu model | Biplab Mahato, David Blaschke, Dietmar Ebert | &#160;&#160;We study a generalised version of Gross&#45;Neveu model in 2+1 dimensions. The&#10;model is inspired from graphene which shows a linear dispersion relation near&#10;the Dirac points. The phase structure and the thermodynamic properties in the&#10;mean field approximation have been studied before. Here we go beyond the mean&#10;field level by deriving a Beth&#45;Uhlenbeck equation for Gaussian fluctuations,&#10;solutions of which we explore numerically, for the first time including their&#10;momentum dependence. We discuss the excitonic mass, fluctuation pressure and&#10;phase shifts. We also perform a comparison with the NJL model in 3+1 dimension&#10;and discuss its implication for graphene.&#10; | General | [Link](http://arxiv.org/abs/2409.10507v1) |&#10;| Context&#45;aware Code Segmentation for C&#45;to&#45;Rust Translation using Large&#10; &#160;Language Models | Momoko Shiraishi, Takahiro Shinagawa | &#160;&#160;There is strong motivation to translate C code into Rust code due to the&#10;continuing threat of memory safety vulnerabilities in existing C programs and&#10;the significant attention paid to Rust as an alternative to the C language.&#10;While large language models (LLMs) show promise for automating this translation&#10;by generating more natural and safer code than rule&#45;based methods, previous&#10;studies have shown that LLM&#45;generated Rust code often fails to compile, even&#10;for relatively small C programs, due to significant differences between the two&#10;languages and context window limitations. We propose an LLM&#45;based translation&#10;scheme that improves the success rate of translating large&#45;scale C code into&#10;compilable Rust code. Our approach involves three key techniques: (1)&#10;pre&#45;processing the C code to better align its structure and expressions with&#10;Rust, (2) segmenting the code into optimally sized translation units to avoid&#10;exceeding the LLM&#39;s context window limits, and (3) iteratively compiling and&#10;repairing errors while maintaining consistency between translation units using&#10;context&#45;supplementing prompts. Compilation success is an essential first step&#10;in achieving functional equivalence, as only compilable code can be further&#10;tested. In experiments with 20 benchmark C programs, including those exceeding&#10;4 kilo lines of code, we successfully translated all programs into compilable&#10;Rust code without losing corresponding parts of the original code.&#10; | General | [Link](http://arxiv.org/abs/2409.10506v1) |&#10;| Machine Learning Optimization of non&#45;Kasha Behavior and of Transient&#10; &#160;Dynamics in Model Retinal Isomerization | Davinder Singh, Chern Chuang, Paul Brumer | &#160;&#160;Designing a model of retinal isomerization in Rhodopsin, the first step in&#10;vision, that accounts for both experimental transient and stationary state&#10;observables is challenging. Here, multi&#45;objective Bayesian optimization is&#10;employed to refine the parameters of a minimal two&#45;state&#45;two&#45;mode (TM) model&#10;describing the photoisomerization of retinal in Rhodopsin. With an appropriate&#10;selection of objectives, the optimized retinal model predicts excitation&#10;wavelength&#45;dependent fluorescence spectra that closely align with&#10;experimentally observed non&#45;Kasha behavior in the non&#45;equilibrium steady state.&#10;Further, adjustments to the potential energy surface within the TM model reduce&#10;the discrepancies across the time domain. Overall, agreement with experimental&#10;data is excellent.&#10; | General | [Link](http://arxiv.org/abs/2409.10505v1) |&#10;| DILA: Dictionary Label Attention for Mechanistic Interpretability in&#10; &#160;High&#45;dimensional Multi&#45;label Medical Coding Prediction | John Wu, David Wu, Jimeng Sun | &#160;&#160;Predicting high&#45;dimensional or extreme multilabels, such as in medical&#10;coding, requires both accuracy and interpretability. Existing works often rely&#10;on local interpretability methods, failing to provide comprehensive&#10;explanations of the overall mechanism behind each label prediction within a&#10;multilabel set. We propose a mechanistic interpretability module called&#10;DIctionary Label Attention (method) that disentangles uninterpretable dense&#10;embeddings into a sparse embedding space, where each nonzero element (a&#10;dictionary feature) represents a globally learned medical concept. Through&#10;human evaluations, we show that our sparse embeddings are more human&#10;understandable than its dense counterparts by at least 50 percent. Our&#10;automated dictionary feature identification pipeline, leveraging large language&#10;models (LLMs), uncovers thousands of learned medical concepts by examining and&#10;summarizing the highest activating tokens for each dictionary feature. We&#10;represent the relationships between dictionary features and medical codes&#10;through a sparse interpretable matrix, enhancing the mechanistic and global&#10;understanding of the model&#39;s predictions while maintaining competitive&#10;performance and scalability without extensive human annotation.&#10; | General | [Link](http://arxiv.org/abs/2409.10504v1) |&#10;| Causal Language Modeling Can Elicit Search and Reasoning Capabilities on&#10; &#160;Logic Puzzles | Kulin Shah, Nishanth Dikkala, Xin Wang, Rina Panigrahy | &#160;&#160;Causal language modeling using the Transformer architecture has yielded&#10;remarkable capabilities in Large Language Models (LLMs) over the last few&#10;years. However, the extent to which fundamental search and reasoning&#10;capabilities emerged within LLMs remains a topic of ongoing debate. In this&#10;work, we study if causal language modeling can learn a complex task such as&#10;solving Sudoku puzzles. To solve a Sudoku, the model is first required to&#10;search over all empty cells of the puzzle to decide on a cell to fill and then&#10;apply an appropriate strategy to fill the decided cell. Sometimes, the&#10;application of a strategy only results in thinning down the possible values in&#10;a cell rather than concluding the exact value of the cell. In such cases,&#10;multiple strategies are applied one after the other to fill a single cell. We&#10;observe that Transformer models trained on this synthetic task can indeed learn&#10;to solve Sudokus (our model solves $94.21%$ of the puzzles fully correctly)&#10;when trained on a logical sequence of steps taken by a solver. We find that&#10;training Transformers with the logical sequence of steps is necessary and&#10;without such training, they fail to learn Sudoku. We also extend our analysis&#10;to Zebra puzzles (known as Einstein puzzles) and show that the model solves&#10;$92.04 %$ of the puzzles fully correctly. In addition, we study the internal&#10;representations of the trained Transformer and find that through linear&#10;probing, we can decode information about the set of possible values in any&#10;given cell from them, pointing to the presence of a strong reasoning engine&#10;implicit in the Transformer weights.&#10; | General | [Link](http://arxiv.org/abs/2409.10502v1) |&#10;| Alignment with nonlinear velocity couplings: collision&#45;avoidance and&#10; &#160;micro&#45;to&#45;macro mean&#45;field limits | Young&#45;Pil Choi, Micha Fabisiak, Jan Peszek | &#160;&#160;We investigate the pressureless fractional Euler&#45;alignment system with&#10;nonlinear velocity couplings, referred to as the $p$&#45;Euler&#45;alignment system.&#10;This model features a nonlinear velocity alignment force, interpreted as a&#10;density&#45;weighted fractional $p$&#45;Laplacian when the singularity parameter&#10;$alpha$ exceeds the spatial dimension $d$. Our primary goal is to establish&#10;the existence of solutions for strongly singular interactions ($alpha ge d$)&#10;and compactly supported initial conditions. We construct solutions as&#10;mean&#45;field limits of empirical measures from a kinetic variant of the&#10;$p$&#45;Euler&#45;alignment system. Specifically, we show that a sequence of empirical&#10;measures converges to a finite Radon measure, whose local density and velocity&#10;satisfy the $p$&#45;Euler&#45;alignment system. Our results are the first to prove the&#10;existence of solutions to this system in multi&#45;dimensional settings without&#10;significant initial data restrictions, covering both nonlinear ($p&gt;2$) and&#10;linear ($p=2$) cases. Additionally, we establish global existence, uniqueness,&#10;and collision avoidance for the corresponding particle ODE system under&#10;non&#45;collisional initial conditions, extending previous results for $1 &#10;e p &#10;e&#10;alpha + 2$. This analysis supports our mean&#45;field limit argument and&#10;contributes to understanding alignment models with singular communication.&#10; | General | [Link](http://arxiv.org/abs/2409.10501v1) |&#10;| Focus diverse phase retrieval test results on broadband continuous&#10; &#160;wavefront sensing in space telescope applications | Hyukmo Kang, Kyle Van Gorkom, Meghdoot Biswas, Daewook Kim, Ewan S. Douglas | &#160;&#160;Continuous wavefront sensing benefits space observatories in on&#45;orbit optical&#10;performance maintenance. To measure the phase of a wavefront, phase retrieval&#10;is an attractive technique as it uses multiple point spread function (PSF)&#10;images that are acquired by the telescope itself without extra metrology&#10;systems nor complicated calibration. The focus diverse phase retrieval utilizes&#10;PSFs from predetermined defocused positions to enhance the dynamic range of the&#10;algorithm. We describe an updated visible light active optics testbed with the&#10;addition of a linear motorized focus stage. The performance of the phase&#10;retrieval algorithm in broadband is tested under various cases. While broadband&#10;pass filters have advantages in higher signal&#45;to&#45;noise ratio (SNR), the&#10;performance of phase retrieval can be restricted due to blurred image caused by&#10;diffraction and increased computing cost. We used multiple bandpass filters (10&#10;nm, 88 nm, and 150 nm) and investigated effects of bandwidth on the accuracy&#10;and required image acquisition conditions such as SNR, reaching accuracies&#10;below 20 nm RMS wavefront error at the widest bandwidth. We also investigated&#10;the dynamic range of the phase retrieval algorithm depending on the bandwidth&#10;and required amount of defocus to expand dynamic range. Finally, we simulated&#10;the continuous wavefront sensing and correction loop with a range of&#10;statistically generated representative telescope disturbance time series to&#10;test for edge cases.&#10; | General | [Link](http://arxiv.org/abs/2409.10500v1) |&#10;| The role of higher&#45;order terms in trapped&#45;ion quantum computing with&#10; &#160;magnetic gradient induced coupling | Sebastian Nagies, Kevin T. Geier, Javed Akram, Junichi Okamoto, Dimitris Badounas, Christof Wunderlich, Michael Johanning, Philipp Hauke | &#160;&#160;Trapped&#45;ion hardware based on the Magnetic Gradient Induced Coupling (MAGIC)&#10;scheme is emerging as a promising platform for quantum computing. Nevertheless,&#10;in this (as in any other) quantum&#45;computing platform, many technical questions&#10;still have to be resolved before large&#45;scale and error&#45;tolerant applications&#10;are possible. In this work, we present a thorough discussion of the&#10;contribution of higher&#45;order terms to the MAGIC setup, which can occur due to&#10;anharmonicities in the external potential of the ion crystal (e.g., through&#10;Coulomb repulsion) or through curvature of the applied magnetic field. These&#10;terms take the form of three&#45;spin couplings as well as diverse terms that&#10;couple spins to phonons. We find that most of these are negligible in realistic&#10;situations, with only two contributions that need careful attention. First,&#10;there are parasitic longitudinal fields whose strength increases with chain&#10;length, but which can easily be compensated by a microwave detuning. Second,&#10;anharmonicities of the Coulomb interaction can lead to well&#45;known two&#45;to&#45;one&#10;conversions of phonon excitations, which can be avoided if the phonons are&#10;ground&#45;state cooled. Our detailed analysis constitutes an important&#10;contribution on the way of making magnetic&#45;gradient trapped&#45;ion quantum&#10;technology fit for large&#45;scale applications, and it may inspire new ways to&#10;purposefully design interaction terms.&#10; | General | [Link](http://arxiv.org/abs/2409.10498v1) |&#10;| MusicLIME: Explainable Multimodal Music Understanding | Theodoros Sotirou, Vassilis Lyberatos, Orfeas Menis Mastromichalakis, Giorgos Stamou | &#160;&#160;Multimodal models are critical for music understanding tasks, as they capture&#10;the complex interplay between audio and lyrics. However, as these models become&#10;more prevalent, the need for explainability grows&#45;understanding how these&#10;systems make decisions is vital for ensuring fairness, reducing bias, and&#10;fostering trust. In this paper, we introduce MusicLIME, a model&#45;agnostic&#10;feature importance explanation method designed for multimodal music models.&#10;Unlike traditional unimodal methods, which analyze each modality separately&#10;without considering the interaction between them, often leading to incomplete&#10;or misleading explanations, MusicLIME reveals how audio and lyrical features&#10;interact and contribute to predictions, providing a holistic view of the&#10;model&#39;s decision&#45;making. Additionally, we enhance local explanations by&#10;aggregating them into global explanations, giving users a broader perspective&#10;of model behavior. Through this work, we contribute to improving the&#10;interpretability of multimodal music models, empowering users to make informed&#10;choices, and fostering more equitable, fair, and transparent music&#10;understanding systems.&#10; | General | [Link](http://arxiv.org/abs/2409.10496v1) |&#10;| Incorporating Classifier&#45;Free Guidance in Diffusion Model&#45;Based&#10; &#160;Recommendation | Noah Buchanan, Susan Gauch, Quan Mai | &#160;&#160;This paper presents a diffusion&#45;based recommender system that incorporates&#10;classifier&#45;free guidance. Most current recommender systems provide&#10;recommendations using conventional methods such as collaborative or&#10;content&#45;based filtering. Diffusion is a new approach to generative AI that&#10;improves on previous generative AI approaches such as Variational Autoencoders&#10;(VAEs) and Generative Adversarial Networks (GANs). We incorporate diffusion in&#10;a recommender system that mirrors the sequence users take when browsing and&#10;rating items. Although a few current recommender systems incorporate diffusion,&#10;they do not incorporate classifier&#45;free guidance, a new innovation in diffusion&#10;models as a whole. In this paper, we present a diffusion recommender system&#10;that augments the underlying recommender system model for improved performance&#10;and also incorporates classifier&#45;free guidance. Our findings show improvements&#10;over state&#45;of&#45;the&#45;art recommender systems for most metrics for several&#10;recommendation tasks on a variety of datasets. In particular, our approach&#10;demonstrates the potential to provide better recommendations when data is&#10;sparse.&#10; | General | [Link](http://arxiv.org/abs/2409.10494v1) |&#10;| Renormalization of the Einstein&#45;Cartan Theory in First&#45;Order Form | F. T. Brandt, J. Frenkel, S. Martins&#45;Filho, D. G. C. McKeon | &#160;&#160;We examine the Einstein&#45;Cartan (EC) theory in first&#45;order form, which has a&#10;diffeomorphism as well as a local Lorentz invariance. We study the&#10;renormalizability of this theory in the framework of the Batalin&#45;Vilkovisky&#10;formalism, which allows for a gauge invariant renormalization. Using the&#10;background field method, we discuss the gauge invariance of the background&#10;effective action and analyze the Ward identities which reflect the symmetries&#10;of the EC theory. As an application, we compute, in a general background gauge,&#10;the self&#45;energy of the tetrad field at one&#45;loop order.&#10; | General | [Link](http://arxiv.org/abs/2409.10493v1) |&#10;| What we can learn from the angular differential rates (only) in&#10; &#160;semileptonic $B to D^* ell _ell$ decays | G. Martinelli, S. Simula, L. Vittorio | &#160;&#160;We present a new, simple approach to the study of semileptonic $B to D^*&#10;ell &#10;u_ell$ decays based on the angular distributions of the final state&#10;particles only. Our approach is model independent and never requires the&#10;knowledge of $vert V_{cb}vert$. By studying such distributions in the case of&#10;light leptons, a comparison between results from different data sets from the&#10;Belle and BelleII Collaborations and between data and Standard Model&#10;calculations is also given for several interesting quantities. A good&#10;consistency is observed between some of the experimental results and the&#10;theoretical predictions.&#10; | General | [Link](http://arxiv.org/abs/2409.10492v1) |&#10;| Code Vulnerability Detection: A Comparative Analysis of Emerging Large&#10; &#160;Language Models | Shaznin Sultana, Sadia Afreen, Nasir U. Eisty | &#160;&#160;The growing trend of vulnerability issues in software development as a result&#10;of a large dependence on open&#45;source projects has received considerable&#10;attention recently. This paper investigates the effectiveness of Large Language&#10;Models (LLMs) in identifying vulnerabilities within codebases, with a focus on&#10;the latest advancements in LLM technology. Through a comparative analysis, we&#10;assess the performance of emerging LLMs, specifically Llama, CodeLlama, Gemma,&#10;and CodeGemma, alongside established state&#45;of&#45;the&#45;art models such as BERT,&#10;RoBERTa, and GPT&#45;3. Our study aims to shed light on the capabilities of LLMs in&#10;vulnerability detection, contributing to the enhancement of software security&#10;practices across diverse open&#45;source repositories. We observe that CodeGemma&#10;achieves the highest F1&#45;score of 58 and a Recall of 87, amongst the recent&#10;additions of large language models to detect software security vulnerabilities.&#10; | General | [Link](http://arxiv.org/abs/2409.10490v1) |&#10;| Flash STU: Fast Spectral Transform Units | Y. Isabel Liu, Windsor Nguyen, Yagiz Devre, Evan Dogariu, Anirudha Majumdar, Elad Hazan | &#160;&#160;This paper describes an efficient, open source PyTorch implementation of the&#10;Spectral Transform Unit. We investigate sequence prediction tasks over several&#10;modalities including language, robotics, and simulated dynamical systems. We&#10;find that for the same parameter count, the STU and its variants outperform the&#10;Transformer as well as other leading state space models across various&#10;modalities.&#10; | General | [Link](http://arxiv.org/abs/2409.10489v1) |&#10;| Do Pre&#45;trained Vision&#45;Language Models Encode Object States? | Kaleb Newman, Shijie Wang, Yuan Zang, David Heffren, Chen Sun | &#160;&#160;For a vision&#45;language model (VLM) to understand the physical world, such as&#10;cause and effect, a first step is to capture the temporal dynamics of the&#10;visual world, for example how the physical states of objects evolve over time&#10;(e.g. a whole apple into a sliced apple). Our paper aims to investigate if VLMs&#10;pre&#45;trained on web&#45;scale data learn to encode object states, which can be&#10;extracted with zero&#45;shot text prompts. We curate an object state recognition&#10;dataset ChangeIt&#45;Frames, and evaluate nine open&#45;source VLMs, including models&#10;trained with contrastive and generative objectives. We observe that while these&#10;state&#45;of&#45;the&#45;art vision&#45;language models can reliably perform object&#10;recognition, they consistently fail to accurately distinguish the objects&#39;&#10;physical states. Through extensive experiments, we identify three areas for&#10;improvements for VLMs to better encode object states, namely the quality of&#10;object localization, the architecture to bind concepts to objects, and the&#10;objective to learn discriminative visual and language encoders on object&#10;states. Data and code are released.&#10; | General | [Link](http://arxiv.org/abs/2409.10488v1) |&#10;| A Host Galaxy Morphology Link Between Quasi&#45;Periodic Eruptions and Tidal&#10; &#160;Disruption Events | Olivier Gilbert, John J. Ruan, Michael Eracleous, Daryl Haggard, Jessie C. Runnoe | &#160;&#160;The physical processes that produce X&#45;ray Quasi&#45;Periodic Eruptions (QPEs)&#10;recently discovered from the nuclei of several low&#45;redshift galaxies are&#10;mysterious. Several pieces of observational evidence strongly suggest a link&#10;between QPEs and Tidal Disruption Events (TDE). Previous studies also reveal&#10;that the morphologies of TDE host galaxies are highly concentrated, with high&#10;Sersic indicies, bulge&#45;to&#45;total light (B/T) ratios, and stellar surface mass&#10;densities relative to the broader galaxy population. We use these distinctive&#10;properties to test the link between QPEs and TDEs, by comparing these&#10;parameters of QPE host galaxies to TDE host galaxies. We employ archival Legacy&#10;Survey images of a sample of 9 QPE host galaxies and a sample of 13 TDE host&#10;galaxies, and model their surface brightness profiles. We show that QPE host&#10;galaxies have high Sersic indices of ~3, high B/T ratios of ~0.5, and high&#10;surface mass densities of ~10^10 Msun kpc^&#45;2. These properties are similar to&#10;TDE host galaxies, but are in strong contrast to a mass&#45; and redshift&#45;matched&#10;control sample of galaxies. We also find tentative evidence that the central&#10;black holes in both QPE and TDE host galaxies are undermassive relative to&#10;their stellar mass. The morphological similarities between QPE and TDE host&#10;galaxies at the population level add to the mounting evidence of a physical&#10;link between these phenomena, and favor QPE models that also invoke TDEs.&#10; | General | [Link](http://arxiv.org/abs/2409.10486v1) |&#10;| Tuning the Rate of Tightly Packed Systems To Produce Planet Occurrence&#10; &#160;Trends with Galactic Height | Sarah Ballard | &#160;&#160;The formation of planetary systems has historically been considered in&#10;isolation, decoupled from processes on galactic scales. Recent findings&#10;employing data from ESA&#39;s Gaia mission challenge this narrative, identifying&#10;trends in planet occurrence with galactic kinematics and stellar age. The&#10;findings indicate changes in planet occurrence over and above the predicted&#10;changes from metallicity variation within the Milky Way, so that changes to&#10;stellar metallicity alone (long understood to be deterministic in planet&#10;outcomes) cannot explain the trends entirely. The scope of potential factors&#10;influencing planet formation has grown progressively wider, with accompanying&#10;theoretical support for galactic&#45;scale influences upon planet formation. In&#10;this manuscript, we investigate specifically how changes to the rate of Systems&#10;of Tightly&#45;packed Inner Planets (STIPs) could manifest as a trend in planet&#10;occurrence with galactic height. We focus our study upon M dwarf planetary&#10;systems for two reasons: first, they host STIPs at high rates, and secondly,&#10;their longevity makes them useful probes for kinematic trends over Gyr. We&#10;consider two models for a varying STIP rate: one in which STIP likelihood is&#10;determined by stellar age alone, irrespective of galactic time, and another in&#10;which the STIP likelihood suddenly increased in recent galactic history. Both&#10;models, which impose a higher STIP likelihood among younger stars, produce a&#10;negative gradient in planet occurrence with increasing height from the galactic&#10;midplane. We find that a step function model in which STIP likelihood increased&#10;by a factor of several ~a few Gyr ago resembles an observed trend among FGK&#10;dwarfs. We consider plausible physical mechanisms that could mimic the&#10;hypothesized model, given known links between STIP occurrence and other stellar&#10;and planetary properties.&#10; | General | [Link](http://arxiv.org/abs/2409.10485v1) |&#10;| XLM for Autonomous Driving Systems: A Comprehensive Review | Sonda Fourati, Wael Jaafar, Noura Baccar, Safwan Alfattani | &#160;&#160;Large Language Models (LLMs) have showcased remarkable proficiency in various&#10;information&#45;processing tasks. These tasks span from extracting data and&#10;summarizing literature to generating content, predictive modeling,&#10;decision&#45;making, and system controls. Moreover, Vision Large Models (VLMs) and&#10;Multimodal LLMs (MLLMs), which represent the next generation of language&#10;models, a.k.a., XLMs, can combine and integrate many data modalities with the&#10;strength of language understanding, thus advancing several information&#45;based&#10;systems, such as Autonomous Driving Systems (ADS). Indeed, by combining&#10;language communication with multimodal sensory inputs, e.g., panoramic images&#10;and LiDAR or radar data, accurate driving actions can be taken. In this&#10;context, we provide in this survey paper a comprehensive overview of the&#10;potential of XLMs towards achieving autonomous driving. Specifically, we review&#10;the relevant literature on ADS and XLMs, including their architectures, tools,&#10;and frameworks. Then, we detail the proposed approaches to deploy XLMs for&#10;autonomous driving solutions. Finally, we provide the related challenges to XLM&#10;deployment for ADS and point to future research directions aiming to enable XLM&#10;adoption in future ADS frameworks.&#10; | General | [Link](http://arxiv.org/abs/2409.10484v1) |&#10;| Efficient polarizable QM/MM using the direct reaction field Hamiltonian&#10; &#160;with electrostatic potential fitted multipole operators | Thomas P. Fay, Nicolas Ferr, Miquel Huix&#45;Rotllant | &#160;&#160;Electronic polarization and dispersion are decisive actors in determining&#10;interaction energies between molecules. These interactions have a particularly&#10;profound effect on excitation energies of molecules in complex environments,&#10;especially when the excitation involves a significant degree of charge&#10;reorganisation. The direct reaction field (DRF) approach, which has seen a&#10;recent revival of interest, provides a powerful framework for describing these&#10;interactions in quantum mechanics/molecular mechanics (QM/MM) models of&#10;systems, where a small subsystem of interest is described using quantum&#10;chemical methods and the remainder is treated with a simple MM force field. In&#10;this paper we show how the DRF approach can be combined with the electrostatic&#10;potential fitted (ESPF) multipole operator description of the QM region charge&#10;density, which reduces the scaling $mathcal{O}(N_mathrm{MM}^3)$ of the method&#10;with MM system to $mathcal{O}(N_mathrm{MM}^2)$. We also show how the DRF&#10;approach can be combined with fluctuating charge descriptions of the&#10;polarizable environment, as well as previously used atom&#45;centred&#10;dipole&#45;polarizability based models. We further show that the ESPF&#45;DRF method&#10;provides an accurate description of molecular interactions in both ground and&#10;excited electronic states of the QM system and apply it to predict the gas to&#10;aqueous solution solvatochromic shifts in the UV/visible absorption spectrum of&#10;acrolein.&#10; | General | [Link](http://arxiv.org/abs/2409.10483v1) |&#10;| Schrodinger&#39;s Memory: Large Language Models | Wei Wang, Qing Li | &#160;&#160;Memory is the foundation of LLMs&#39; functionality, yet past research has lacked&#10;an in&#45;depth exploration of their memory capabilities and underlying theory. In&#10;this paper, we apply UAT theory to explain the memory mechanism of LLMs and&#10;propose a new approach for evaluating LLM performance by comparing the memory&#10;capacities of different models. Through extensive experiments, we validate our&#10;theory and the memory abilities of LLMs. Finally, we compare the capabilities&#10;of the human brain and LLMs, highlighting both their similarities and&#10;differences in terms of working mechanisms.&#10; | General | [Link](http://arxiv.org/abs/2409.10482v1) |&#10;| Exploring 3D Face Reconstruction and Fusion Methods for Face&#10; &#160;Verification: A Case&#45;Study in Video Surveillance | Simone Maurizio La Cava, Sara Concas, Ruben Tolosana, Roberto Casula, Giulia Orr, Martin Drahansky, Julian Fierrez, Gian Luca Marcialis | &#160;&#160;3D face reconstruction (3DFR) algorithms are based on specific assumptions&#10;tailored to distinct application scenarios. These assumptions limit their use&#10;when acquisition conditions, such as the subject&#39;s distance from the camera or&#10;the camera&#39;s characteristics, are different than expected, as typically happens&#10;in video surveillance. Additionally, 3DFR algorithms follow various strategies&#10;to address the reconstruction of a 3D shape from 2D data, such as statistical&#10;model fitting, photometric stereo, or deep learning. In the present study, we&#10;explore the application of three 3DFR algorithms representative of the SOTA,&#10;employing each one as the template set generator for a face verification&#10;system. The scores provided by each system are combined by score&#45;level fusion.&#10;We show that the complementarity induced by different 3DFR algorithms improves&#10;performance when tests are conducted at never&#45;seen&#45;before distances from the&#10;camera and camera characteristics (cross&#45;distance and cross&#45;camera settings),&#10;thus encouraging further investigations on multiple 3DFR&#45;based approaches.&#10; | General | [Link](http://arxiv.org/abs/2409.10481v1) |&#10;| Addressing misspecification in contextual optimization | Omar Bennouna, Jiawei Zhang, Saurabh Amin, Asuman Ozdaglar | &#160;&#160;We study a linear contextual optimization problem where a decision maker has&#10;access to historical data and contextual features to learn a cost prediction&#10;model aimed at minimizing decision error. We adopt the predict&#45;then&#45;optimize&#10;framework for this analysis. Given that perfect model alignment with reality is&#10;often unrealistic in practice, we focus on scenarios where the chosen&#10;hypothesis set is misspecified. In this context, it remains unclear whether&#10;current contextual optimization approaches can effectively address such model&#10;misspecification. In this paper, we present a novel integrated learning and&#10;optimization approach designed to tackle model misspecification in contextual&#10;optimization. This approach offers theoretical generalizability, tractability,&#10;and optimality guarantees, along with strong practical performance. Our method&#10;involves minimizing a tractable surrogate loss that aligns with the performance&#10;value from cost vector predictions, regardless of whether the model&#10;misspecified or not, and can be optimized in reasonable time. To our knowledge,&#10;no previous work has provided an approach with such guarantees in the context&#10;of model misspecification.&#10; | General | [Link](http://arxiv.org/abs/2409.10479v1) |&#10;| Local SGD for Near&#45;Quadratic Problems: Improving Convergence under&#10; &#160;Unconstrained Noise Conditions | Andrey Sadchikov, Savelii Chezhegov, Aleksandr Beznosikov, Alexander Gasnikov | &#160;&#160;Distributed optimization plays an important role in modern large&#45;scale&#10;machine learning and data processing systems by optimizing the utilization of&#10;computational resources. One of the classical and popular approaches is Local&#10;Stochastic Gradient Descent (Local SGD), characterized by multiple local&#10;updates before averaging, which is particularly useful in distributed&#10;environments to reduce communication bottlenecks and improve scalability. A&#10;typical feature of this method is the dependence on the frequency of&#10;communications. But in the case of a quadratic target function with homogeneous&#10;data distribution over all devices, the influence of frequency of&#10;communications vanishes. As a natural consequence, subsequent studies include&#10;the assumption of a Lipschitz Hessian, as this indicates the similarity of the&#10;optimized function to a quadratic one to some extent. However, in order to&#10;extend the completeness of the Local SGD theory and unlock its potential, in&#10;this paper we abandon the Lipschitz Hessian assumption by introducing a new&#10;concept of $textit{approximate quadraticity}$. This assumption gives a new&#10;perspective on problems that have near quadratic properties. In addition,&#10;existing theoretical analyses of Local SGD often assume bounded variance. We,&#10;in turn, consider the unbounded noise condition, which allows us to broaden the&#10;class of studied problems.&#10; | General | [Link](http://arxiv.org/abs/2409.10478v1) |&#10;| SimInversion: A Simple Framework for Inversion&#45;Based Text&#45;to&#45;Image&#10; &#160;Editing | Qi Qian, Haiyang Xu, Ming Yan, Juhua Hu | &#160;&#160;Diffusion models demonstrate impressive image generation performance with&#10;text guidance. Inspired by the learning process of diffusion, existing images&#10;can be edited according to text by DDIM inversion. However, the vanilla DDIM&#10;inversion is not optimized for classifier&#45;free guidance and the accumulated&#10;error will result in the undesired performance. While many algorithms are&#10;developed to improve the framework of DDIM inversion for editing, in this work,&#10;we investigate the approximation error in DDIM inversion and propose to&#10;disentangle the guidance scale for the source and target branches to reduce the&#10;error while keeping the original framework. Moreover, a better guidance scale&#10;(i.e., 0.5) than default settings can be derived theoretically. Experiments on&#10;PIE&#45;Bench show that our proposal can improve the performance of DDIM inversion&#10;dramatically without sacrificing efficiency.&#10; | General | [Link](http://arxiv.org/abs/2409.10476v1) |&#10;| Leadership and Engagement Dynamics in Legislative Twitter Networks:&#10; &#160;Statistical Analysis and Modeling | Carolina Luque, Juan Sosa | &#160;&#160;In this manuscript, we analyze the interaction network on Twitter among&#10;members of the 117th U.S. Congress to assess the visibility of political&#10;leaders and explore how systemic properties and node attributes influence the&#10;formation of legislative connections. We employ descriptive social network&#10;statistical methods, the exponential random graph model (ERGM), and the&#10;stochastic block model (SBM) to evaluate the relative impact of network&#10;systemic properties, as well as institutional and personal traits, on the&#10;generation of online relationships among legislators. Our findings reveal that&#10;legislative networks on social media platforms like Twitter tend to reinforce&#10;the leadership of dominant political actors rather than diminishing their&#10;influence. However, we identify that these leadership roles can manifest in&#10;various forms. Additionally, we highlight that online connections within&#10;legislative networks are influenced by both the systemic properties of the&#10;network and institutional characteristics.&#10; | General | [Link](http://arxiv.org/abs/2409.10475v1) |&#10;| MacDiff: Unified Skeleton Modeling with Masked Conditional Diffusion | Lehong Wu, Lilang Lin, Jiahang Zhang, Yiyang Ma, Jiaying Liu | &#160;&#160;Self&#45;supervised learning has proved effective for skeleton&#45;based human action&#10;understanding. However, previous works either rely on contrastive learning that&#10;suffers false negative problems or are based on reconstruction that learns too&#10;much unessential low&#45;level clues, leading to limited representations for&#10;downstream tasks. Recently, great advances have been made in generative&#10;learning, which is naturally a challenging yet meaningful pretext task to model&#10;the general underlying data distributions. However, the representation learning&#10;capacity of generative models is under&#45;explored, especially for the skeletons&#10;with spacial sparsity and temporal redundancy. To this end, we propose Masked&#10;Conditional Diffusion (MacDiff) as a unified framework for human skeleton&#10;modeling. For the first time, we leverage diffusion models as effective&#10;skeleton representation learners. Specifically, we train a diffusion decoder&#10;conditioned on the representations extracted by a semantic encoder. Random&#10;masking is applied to encoder inputs to introduce a information bottleneck and&#10;remove redundancy of skeletons. Furthermore, we theoretically demonstrate that&#10;our generative objective involves the contrastive learning objective which&#10;aligns the masked and noisy views. Meanwhile, it also enforces the&#10;representation to complement for the noisy view, leading to better&#10;generalization performance. MacDiff achieves state&#45;of&#45;the&#45;art performance on&#10;representation learning benchmarks while maintaining the competence for&#10;generative tasks. Moreover, we leverage the diffusion model for data&#10;augmentation, significantly enhancing the fine&#45;tuning performance in scenarios&#10;with scarce labeled data. Our project is available at&#10;https://lehongwu.github.io/ECCV24MacDiff/.&#10; | General | [Link](http://arxiv.org/abs/2409.10473v1) |&#10;| Towards Semantic Versioning of Open Pre&#45;trained Language Model Releases&#10; &#160;on Hugging Face | Adekunle Ajibode, Abdul Ali Bangash, Filipe Roseiro Cogo, Bram Adams, Ahmed E. Hassan | &#160;&#160;The proliferation of open Pre&#45;trained Language Models (PTLMs) on model&#10;registry platforms like Hugging Face (HF) presents both opportunities and&#10;challenges for companies building products around them. Similar to traditional&#10;software dependencies, PTLMs continue to evolve after a release. However, the&#10;current state of release practices of PTLMs on model registry platforms are&#10;plagued by a variety of inconsistencies, such as ambiguous naming conventions&#10;and inaccessible model training documentation. Given the knowledge gap on&#10;current PTLM release practices, our empirical study uses a mixed&#45;methods&#10;approach to analyze the releases of 52,227 PTLMs on the most well&#45;known model&#10;registry, HF. Our results reveal 148 different naming practices for PTLM&#10;releases, with 40.87% of changes to model weight files not represented in the&#10;adopted name&#45;based versioning practice or their documentation. In addition, we&#10;identified that the 52,227 PTLMs are derived from only 299 different base&#10;models (the modified original models used to create 52,227 PTLMs), with&#10;Fine&#45;tuning and Quantization being the most prevalent modification methods&#10;applied to these base models. Significant gaps in release transparency, in&#10;terms of training dataset specifications and model card availability, still&#10;exist, highlighting the need for standardized documentation. While we&#10;identified a model naming practice explicitly differentiating between major and&#10;minor PTLM releases, we did not find any significant difference in the types of&#10;changes that went into either type of releases, suggesting that major/minor&#10;version numbers for PTLMs often are chosen arbitrarily. Our findings provide&#10;valuable insights to improve PTLM release practices, nudging the field towards&#10;more formal semantic versioning practices.&#10; | General | [Link](http://arxiv.org/abs/2409.10472v1) |&#10;| Real&#45;Time Whole&#45;Body Control of Legged Robots with Model&#45;Predictive Path&#10; &#160;Integral Control | Juan Alvarez&#45;Padilla, John Z. Zhang, Sofia Kwok, John M. Dolan, Zachary Manchester | &#160;&#160;This paper presents a system for enabling real&#45;time synthesis of whole&#45;body&#10;locomotion and manipulation policies for real&#45;world legged robots. Motivated by&#10;recent advancements in robot simulation, we leverage the efficient&#10;parallelization capabilities of the MuJoCo simulator to achieve fast sampling&#10;over the robot state and action trajectories. Our results show surprisingly&#10;effective real&#45;world locomotion and manipulation capabilities with a very&#10;simple control strategy. We demonstrate our approach on several hardware and&#10;simulation experiments: robust locomotion over flat and uneven terrains,&#10;climbing over a box whose height is comparable to the robot, and pushing a box&#10;to a goal position. To our knowledge, this is the first successful deployment&#10;of whole&#45;body sampling&#45;based MPC on real&#45;world legged robot hardware.&#10;Experiment videos and code can be found at: https://whole&#45;body&#45;mppi.github.io/&#10; | General | [Link](http://arxiv.org/abs/2409.10469v1) |&#10;| Assortativity in sympatric speciation and species classification | Joao U. F. Lizarraga, Flavia M. D. Marquitti, Marcus A. M. de Aguiar | &#160;&#160;We investigate the role of assortative mating in speciation using the&#10;sympatric model of Derrida and Higgs. The model explores the idea that genetic&#10;differences create incompatibilities between individuals, preventing mating if&#10;the number of such differences is too large. Speciation, however, only happens&#10;in this mating system if the number of genes is large. Here we show that&#10;speciation with small genome sizes can occur if assortative mating is&#10;introduced. In our model individuals are represented by three chromosomes: one&#10;responsible for reproductive compatibility, one for coding the trait on which&#10;assortativity will operate, and a neutral chromosome. Reproduction is possible&#10;if individuals are genetically similar with respect to the first chromosome,&#10;but among these compatible mating partners, the one with the most similar trait&#10;coded by the second chromosome is selected. We show that this type of&#10;assortativity facilitates speciation, which can happen with a small number of&#10;genes in the first chromosome. Species, classified according to reproductive&#10;isolation, dictated by the first chromosome, can display different traits&#10;values, as measured by the second and the third chromosomes. Therefore, species&#10;can also be identified based on similarity of the neutral trait, which works as&#10;a proxy for reproductive isolation.&#10; | General | [Link](http://arxiv.org/abs/2409.10466v1) |&#10;| A stabilized total pressure&#45;formulation of the Biot&#39;s poroelasticity&#10; &#160;equations in frequency domain: numerical analysis and applications | Cristian Crcamo, Alfonso Caiazzo, Felipe Galarce, Joaqun Mura | &#160;&#160;This work focuses on the numerical solution of the dynamics of a poroelastic&#10;material in the frequency domain. We provide a detailed stability analysis&#10;based on the application of the Fredholm alternative in the continuous case,&#10;considering a total pressure formulation of the Biot&#39;s equations. In the&#10;discrete setting, we propose a stabilized equal order finite element method&#10;complemented by an additional pressure stabilization to enhance the robustness&#10;of the numerical scheme with respect to the fluid permeability. Utilizing the&#10;Fredholm alternative, we extend the well&#45;posedness results to the discrete&#10;setting, obtaining theoretical optimal convergence for the case of linear&#10;finite elements. We present different numerical experiments to validate the&#10;proposed method. First, we consider model problems with known analytic&#10;solutions in two and three dimensions. As next, we show that the method is&#10;robust for a wide range of permeabilities, including the case of discontinuous&#10;coefficients. Lastly, we show the application for the simulation of brain&#10;elastography on a realistic brain geometry obtained from medical imaging.&#10; | General | [Link](http://arxiv.org/abs/2409.10465v1) |&#10;| New Direct Sum Tests | Alek Westover, Edward Yu, Kai Zheng | &#160;&#160;A function $f:[n]^{d} to mathbb{F}_2$ is a defn{direct sum} if there are&#10;functions $L_i:[n]to mathbb{F}_2$ such that ${f(x) = sum_{i}L_i(x_i)}$. In&#10;this work we give multiple results related to the property testing of direct&#10;sums.&#10; &#160;Our first result concerns a test proposed by Dinur and Golubev in 2019. We&#10;call their test the Diamond test and show that it is indeed a direct sum&#10;tester. More specifically, we show that if a function $f$ is $epsilon$&#45;far&#10;from being a direct sum function, then the Diamond test rejects $f$ with&#10;probability at least $Omega_{n,epsilon}(1)$. Even in the case of $n = 2$, the&#10;Diamond test is, to the best of our knowledge, novel and yields a new tester&#10;for the classic property of affinity.&#10; &#160;Apart from the Diamond test, we also analyze a broad family of direct sum&#10;tests, which at a high level, run an arbitrary affinity test on the restriction&#10;of $f$ to a random hypercube inside of $[n]^d$. This family of tests includes&#10;the direct sum test analyzed in cite{di19}, but does not include the Diamond&#10;test. As an application of our result, we obtain a direct sum test which works&#10;in the online adversary model of cite{KRV}.&#10; &#160;Finally, we also discuss a Fourier analytic interpretation of the diamond&#10;tester in the $n=2$ case, as well as prove local correction results for direct&#10;sum as conjectured by Dinur and Golubev.&#10; | General | [Link](http://arxiv.org/abs/2409.10464v1) |&#10;| Kolmogorov&#45;Arnold Networks in Low&#45;Data Regimes: A Comparative Study with&#10; &#160;Multilayer Perceptrons | Farhad Pourkamali&#45;Anaraki | &#160;&#160;Multilayer Perceptrons (MLPs) have long been a cornerstone in deep learning,&#10;known for their capacity to model complex relationships. Recently,&#10;Kolmogorov&#45;Arnold Networks (KANs) have emerged as a compelling alternative,&#10;utilizing highly flexible learnable activation functions directly on network&#10;edges, a departure from the neuron&#45;centric approach of MLPs. However, KANs&#10;significantly increase the number of learnable parameters, raising concerns&#10;about their effectiveness in data&#45;scarce environments. This paper presents a&#10;comprehensive comparative study of MLPs and KANs from both algorithmic and&#10;experimental perspectives, with a focus on low&#45;data regimes. We introduce an&#10;effective technique for designing MLPs with unique, parameterized activation&#10;functions for each neuron, enabling a more balanced comparison with KANs. Using&#10;empirical evaluations on simulated data and two real&#45;world data sets from&#10;medicine and engineering, we explore the trade&#45;offs between model complexity&#10;and accuracy, with particular attention to the role of network depth. Our&#10;findings show that MLPs with individualized activation functions achieve&#10;significantly higher predictive accuracy with only a modest increase in&#10;parameters, especially when the sample size is limited to around one hundred.&#10;For example, in a three&#45;class classification problem within additive&#10;manufacturing, MLPs achieve a median accuracy of 0.91, significantly&#10;outperforming KANs, which only reach a median accuracy of 0.53 with default&#10;hyperparameters. These results offer valuable insights into the impact of&#10;activation function selection in neural networks.&#10; | General | [Link](http://arxiv.org/abs/2409.10463v1) |&#10;| Effects of synapse location, delay and background stochastic activity on&#10; &#160;synchronising hippocampal CA1 neurons | Alessandro Fiasconaro, Michele Migliore | &#160;&#160;We study the synchronisation of neurons in a realistic model under the&#10;Hodgkin&#45;Huxley dynamics. To focus on the role of the different locations of the&#10;excitatory synapses, we use two identical neurons where the set of input&#10;signals is grouped at two different distances from the soma. The system is&#10;intended to represent a CA1 hippocampal neuron in which the synapses arriving&#10;from the CA3 neurons of the trisynaptic pathway appear to be localised in the&#10;apical dendritic region and are, in principle, either proximal or distal to the&#10;soma. Synchronisation is studied using a specifically defined spiking&#10;correlation function as a function of various parameters such as the distance&#10;from the soma of one of the synaptic groups, the inhibition weight and the&#10;associated activation delay. We found that the neurons&#39; spiking activity&#10;depends nonmonotonically on the relative dendritic location of the synapses and&#10;their inhibitory weight, whereas the synchronisation measure always decreases&#10;with inhibition, and strongly depends on its activation time delay. The&#10;background activity on the somas results essentially independent on the&#10;fluctuation intensity and strongly support the importance of the balance&#10;between inhibition and excitation for neuronal synchronization.&#10; | General | [Link](http://arxiv.org/abs/2409.10460v1) |&#10;| Efficiently Crowdsourcing Visual Importance with Punch&#45;Hole Annotation | Minsuk Chang, Soohyun Lee, Aeri Cho, Hyeon Jeon, Seokhyeon Park, Cindy Xiong Bearfield, Jinwook Seo | &#160;&#160;We introduce a novel crowdsourcing method for identifying important areas in&#10;graphical images through punch&#45;hole labeling. Traditional methods, such as gaze&#10;trackers and mouse&#45;based annotations, which generate continuous data, can be&#10;impractical in crowdsourcing scenarios. They require many participants, and the&#10;outcome data can be noisy. In contrast, our method first segments the graphical&#10;image with a grid and drops a portion of the patches (punch holes). Then, we&#10;iteratively ask the labeler to validate each annotation with holes, narrowing&#10;down the annotation only having the most important area. This approach aims to&#10;reduce annotation noise in crowdsourcing by standardizing the annotations while&#10;enhancing labeling efficiency and reliability. Preliminary findings from&#10;fundamental charts demonstrate that punch&#45;hole labeling can effectively&#10;pinpoint critical regions. This also highlights its potential for broader&#10;application in visualization research, particularly in studying large&#45;scale&#10;users&#39; graphical perception. Our future work aims to enhance the algorithm to&#10;achieve faster labeling speed and prove its utility through large&#45;scale&#10;experiments.&#10; | General | [Link](http://arxiv.org/abs/2409.10459v1) |&#10;| Full distribution of local observables in an exactly solvable current&#10; &#160;carrying steady states of a driven XXZ chain | Sandipan Manna, G J Sreejith | &#160;&#160;Current carrying steady states of interacting spins chains exhibit rich&#10;structures generated through an interplay of current induced correlations and&#10;energetic constraints from the Hamiltonian. The XXZ spin chain when coupled to&#10;maximally polarizing Lindblad terms admits an exact solution in a matrix&#10;product state (MPS) form. We use this exact solution to study the correlations&#10;and distributions of simple local spin observables in the non equilibrium&#10;steady state (NESS). We present exact expressions for spin correlators, entropy&#10;per site, cumulant generating functions for distributions of local observables&#10;in the XX limit (Ising anisotropy $Delta=0$). Further, we use the exact MPS&#10;solution in systems with $Delta&gt;0$, to numerically exactly calculate the&#10;entropy, correlations, as well as distributions of spin observables in blocks&#10;as large as $nsim 200$ sites allowing an estimation of the rate functions. The&#10;$z$ magnetization distribution is consistant with short range spin correlations&#10;in the $z$ direction while the $x$&#45;magnetization shows a double peak structure&#10;at larger $Delta$ suggesting short range ferromagnetic ordering. We find that&#10;the distribution of $z$&#45;magnetization sharpens for parameters where the current&#10;is maximized.&#10; | General | [Link](http://arxiv.org/abs/2409.10458v1) |&#10;| Mean Residual Life Ageing Intensity Function | Ashutosh Singh, Ishapathik Das, Asok Kumar Nanda, Sumen Sen | &#160;&#160;The ageing intensity function is a powerful analytical tool that provides&#10;valuable insights into the ageing process across diverse domains such as&#10;reliability engineering, actuarial science, and healthcare. Its applications&#10;continue to expand as researchers delve deeper into understanding the complex&#10;dynamics of ageing and its implications for society. One common approach to&#10;defining the ageing intensity function is through the hazard rate or failure&#10;rate function, extensively explored in scholarly literature. Equally&#10;significant to the hazard rate function is the mean residual life function,&#10;which plays a crucial role in analyzing the ageing patterns exhibited by units&#10;or components. This article introduces the mean residual life ageing intensity&#10;(MRLAI) function to delve into component ageing behaviours across various&#10;distributions. Additionally, we scrutinize the closure properties of the MRLAI&#10;function across different reliability operations. Furthermore, a new order&#10;termed the mean residual life ageing intensity order is defined to analyze the&#10;ageing behaviour of a system, and the closure property of this order under&#10;various reliability operations is discussed.&#10; | General | [Link](http://arxiv.org/abs/2409.10456v1) |&#10;| Quantile Fourier regressions for decision making under uncertainty | Arash Khojaste, Geoffrey Pritchard, Golbon Zakeri | &#160;&#160;Weconsider Markov decision processes arising from a Markov model of an&#10;underlying natural phenomenon. Such phenomena are usually periodic (e.g.&#10;annual) in time, and so the Markov processes modelling them must be&#10;time&#45;inhomogeneous, with cyclostationary rather than stationary behaviour. We&#10;describe a technique for constructing such processes that allows for periodic&#10;variations both in the values taken by the process and in the serial dependence&#10;structure. We include two illustrative numerical examples: a hydropower&#10;scheduling problem and a model of offshore wind power integration.&#10; | General | [Link](http://arxiv.org/abs/2409.10455v1) |&#10;| The Debiased Near&#45;Earth Object Population from ATLAS Telescopes | Rogerio Deienno, Larry Denneau, David Nesvorn, David Vokrouhlick, William F. Bottke, Robert Jedicke, Shantanu Naidu, Steven R. Chesley, Davide Farnocchia, Paul W. Chodas | &#160;&#160;This work is dedicated to debias the Near&#45;Earth Objects (NEO) population&#10;based on observations from the Asteroid Terrestrial&#45;impact Last Alert System&#10;(ATLAS) telescopes. We have applied similar methods used to develop the&#10;recently released NEO model generator (NEOMOD), once debiasing the NEO&#10;population using data from Catalina Sky Survey (CSS) G96 telescope. ATLAS is&#10;composed of four different telescopes. We first analyzed observational data&#10;from each of all four telescopes separately and later combined them. Our&#10;results highlight main differences between CSS and ATLAS, e.g., sky coverage&#10;and survey power at debiasing the NEO population. ATLAS has a much larger sky&#10;coverage than CSS, allowing it to find bright NEOs that would be constantly&#10;&quot;hiding&quot; from CSS. Consequently, ATLAS is more powerful than CSS at debiasing&#10;the NEO population for H $&#10;esssim$ 19. With its intrinsically greater&#10;sensitivity and emphasis on observing near opposition, CSS excels in the&#10;debiasing of smaller objects. ATLAS, as an all sky survey designed to find&#10;imminent hazardous objects, necessarily spends a significant fraction of time&#10;looking at places on the sky where objects do not appear, reducing its power&#10;for debiasing the population of small objects. We estimate a NEO population&#10;completeness of $approx$ 88%$^{+3%}_{&#45;2%}$ for H $&lt;$ 17.75 and $approx$&#10;36%$^{+1%}_{&#45;1%}$ for H $&lt;$ 22.25. Those numbers are similar to previous&#10;estimates (within error bars for H $&lt;$ 17.75) from CSS, yet, around 3% and 8%&#10;smaller at their face values, respectively. We also confirm previous finding&#10;that the $&#10;u_6$ secular resonance is the main source of small and faint NEOs&#10;at H = 28, whereas the 3:1 mean motion resonance with Jupiter dominates for&#10;larger and brighter NEOs at H = 15.&#10; | General | [Link](http://arxiv.org/abs/2409.10453v1) |&#10;| Signed Graph Autoencoder for Explainable and Polarization&#45;Aware Network&#10; &#160;Embeddings | Nikolaos Nakis, Chrysoula Kosma, Giannis Nikolentzos, Michalis Chatzianastasis, Iakovos Evdaimon, Michalis Vazirgiannis | &#160;&#160;Autoencoders based on Graph Neural Networks (GNNs) have garnered significant&#10;attention in recent years for their ability to extract informative latent&#10;representations, characterizing the structure of complex topologies, such as&#10;graphs. Despite the prevalence of Graph Autoencoders, there has been limited&#10;focus on developing and evaluating explainable neural&#45;based graph generative&#10;models specifically designed for signed networks. To address this gap, we&#10;propose the Signed Graph Archetypal Autoencoder (SGAAE) framework. SGAAE&#10;extracts node&#45;level representations that express node memberships over distinct&#10;extreme profiles, referred to as archetypes, within the network. This is&#10;achieved by projecting the graph onto a learned polytope, which governs its&#10;polarization. The framework employs a recently proposed likelihood for&#10;analyzing signed networks based on the Skellam distribution, combined with&#10;relational archetypal analysis and GNNs. Our experimental evaluation&#10;demonstrates the SGAAEs&#39; capability to successfully infer node memberships over&#10;the different underlying latent structures while extracting competing&#10;communities formed through the participation of the opposing views in the&#10;network. Additionally, we introduce the 2&#45;level network polarization problem&#10;and show how SGAAE is able to characterize such a setting. The proposed model&#10;achieves high performance in different tasks of signed link prediction across&#10;four real&#45;world datasets, outperforming several baseline models.&#10; | General | [Link](http://arxiv.org/abs/2409.10452v1) |&#10;| Why you should also use OLS estimation of tail exponents | Thiago Trafane Oliveira Santos, Daniel Oliveira Cajueiro | &#160;&#160;Even though practitioners often estimate Pareto exponents running OLS&#10;rank&#45;size regressions, the usual recommendation is to use the Hill MLE with a&#10;small&#45;sample correction instead, due to its unbiasedness and efficiency. In&#10;this paper, we advocate that you should also apply OLS in empirical&#10;applications. On the one hand, we demonstrate that, with a small&#45;sample&#10;correction, the OLS estimator is also unbiased. On the other hand, we show that&#10;the MLE assigns significantly greater weight to smaller observations. This&#10;suggests that the OLS estimator may outperform the MLE in cases where the&#10;distribution is (i) strictly Pareto but only in the upper tail or (ii)&#10;regularly varying rather than strictly Pareto. We substantiate our theoretical&#10;findings with Monte Carlo simulations and real&#45;world applications,&#10;demonstrating the practical relevance of the OLS method in estimating tail&#10;exponents.&#10; | General | [Link](http://arxiv.org/abs/2409.10448v1) |&#10;| Hydrodynamic hovering of swimming bacteria above surfaces | Pyae Hein Htet, Debasish Das, Eric Lauga | &#160;&#160;Flagellated bacteria are hydrodynamically attracted to rigid walls, yet past&#10;work shows a &#39;hovering&#39; state where they swim stably at a finite height above&#10;surfaces. We use numerics and theory to reveal the physical origin of hovering.&#10;Simulations first show that hovering requires an elongated cell body and&#10;results from a tilt away from the wall. Theoretical models then identify two&#10;essential asymmetries: the response of width&#45;asymmetric cells to active flows&#10;created by length&#45;asymmetric cells. A minimal model reconciles near and&#10;far&#45;field hydrodynamics, capturing all key features of hovering.&#10; | General | [Link](http://arxiv.org/abs/2409.10447v1) |&#10;| KoroT&#45;3E: A Personalized Musical Mnemonics Tool for Enhancing Memory&#10; &#160;Retention of Complex Computer Science Concepts | Xiangzhe Yuan, Jiajun Wang, Siying Hu, Andrew Cheung, Zhicong Lu | &#160;&#160;As the demand for computer science (CS) skills grows, mastering foundational&#10;concepts is crucial yet challenging for novice learners. To address this&#10;challenge, we present KoroT&#45;3E, an AI&#45;based system that creates personalized&#10;musical mnemonics to enhance both memory retention and understanding of&#10;concepts in CS. KoroT&#45;3E enables users to transform complex concepts into&#10;memorable lyrics and compose melodies that suit their musical preferences. We&#10;conducted semi&#45;structured interviews (n=12) to investigate why novice learners&#10;find it challenging to memorize and understand CS concepts. The findings,&#10;combined with constructivist learning theory, established our initial design,&#10;which was then refined following consultations with CS education experts. An&#10;empirical experiment(n=36) showed that those using KoroT&#45;3E (n=18)&#10;significantly outperformed the control group (n=18), with improved memory&#10;efficiency, increased motivation, and a positive learning experience. These&#10;findings demonstrate the effectiveness of integrating multimodal generative AI&#10;into CS education to create personalized and interactive learning experiences.&#10; | General | [Link](http://arxiv.org/abs/2409.10446v1) |&#10;| Deep&#45;Wide Learning Assistance for Insect Pest Classification | Toan Nguyen, Huy Nguyen, Huy Ung, Hieu Ung, Binh Nguyen | &#160;&#160;Accurate insect pest recognition plays a critical role in agriculture. It is&#10;a challenging problem due to the intricate characteristics of insects. In this&#10;paper, we present DeWi, novel learning assistance for insect pest&#10;classification. With a one&#45;stage and alternating training strategy, DeWi&#10;simultaneously improves several Convolutional Neural Networks in two&#10;perspectives: discrimination (by optimizing a triplet margin loss in a&#10;supervised training manner) and generalization (via data augmentation). From&#10;that, DeWi can learn discriminative and in&#45;depth features of insect pests&#10;(deep) yet still generalize well to a large number of insect categories (wide).&#10;Experimental results show that DeWi achieves the highest performances on two&#10;insect pest classification benchmarks (76.44% accuracy on the IP102 dataset&#10;and 99.79% accuracy on the D0 dataset, respectively). In addition, extensive&#10;evaluations and ablation studies are conducted to thoroughly investigate our&#10;DeWi and demonstrate its superiority. Our source code is available at&#10;https://github.com/toannguyen1904/DeWi.&#10; | General | [Link](http://arxiv.org/abs/2409.10445v1) |&#10;| LLM as BT&#45;Planner: Leveraging LLMs for Behavior Tree Generation in Robot&#10; &#160;Task Planning | Jicong Ao, Fan Wu, Yansong Wu, Abdalla Swikir, Sami Haddadin | &#160;&#160;Robotic assembly tasks are open challenges due to the long task horizon and&#10;complex part relations. Behavior trees (BTs) are increasingly used in robot&#10;task planning for their modularity and flexibility, but manually designing them&#10;can be effort&#45;intensive. Large language models (LLMs) have recently been&#10;applied in robotic task planning for generating action sequences, but their&#10;ability to generate BTs has not been fully investigated. To this end, We&#10;propose LLM as BT&#45;planner, a novel framework to leverage LLMs for BT generation&#10;in robotic assembly task planning and execution. Four in&#45;context learning&#10;methods are introduced to utilize the natural language processing and inference&#10;capabilities of LLMs to produce task plans in BT format, reducing manual effort&#10;and ensuring robustness and comprehensibility. We also evaluate the performance&#10;of fine&#45;tuned, fewer&#45;parameter LLMs on the same tasks. Experiments in simulated&#10;and real&#45;world settings show that our framework enhances LLMs&#39; performance in&#10;BT generation, improving success rates in BT generation through in&#45;context&#10;learning and supervised fine&#45;tuning.&#10; | General | [Link](http://arxiv.org/abs/2409.10444v1) |&#10;| The James Webb Space Telescope Absolute Flux Calibration. II.&#10; &#160;Mid&#45;Infrared Instrument Imaging and Coronagraphy | Karl D. Gordon, G. C. Sloan, Macarena Garcia Marin, Mattia Libralato, George Rieke, Jonathan A. Aguilar, Ralph Bohlin, Misty Cracraft, Marjorie Decleir, Andras Gaspar, David R. Law, Alberto Noriega&#45;Crespo, Michael Regan | &#160;&#160;The absolute flux calibration of the Mid&#45;Infrared Instrument Imaging and&#10;Coronagraphy is based on observations of multiple stars taken during the first&#10;2.5 years of JWST operations. The observations were designed to ensure that the&#10;flux calibration is valid for a range of flux densities, different subarrays,&#10;and different types of stars. The flux calibration was measured by combining&#10;observed aperture photometry corrected to infinite aperture with predictions&#10;based on previous observations and models of stellar atmospheres. A subset of&#10;these observations were combined with model point&#45;spread&#45;functions to measure&#10;the corrections to infinite aperture. Variations in the calibration factor with&#10;time, flux density, background level, type of star, subarray, integration time,&#10;rate, and well depth were investigated, and the only significant variations&#10;were with time and subarray. Observations of the same star taken approximately&#10;every month revealed a modest time&#45;dependent response loss seen mainly at the&#10;longest wavelengths. This loss is well characterized by a decaying exponential&#10;with a time constant of ~200 days. After correcting for the response loss, the&#10;band&#45;dependent scatter around the corrected average (aka repeatability) was&#10;found to range from 0.1 to 1.2%. Signals in observations taken with different&#10;subarrays can be lower by up to 3.4% compared to FULL frame. After correcting&#10;for the time and subarray dependencies, the scatter in the calibration factors&#10;measured for individual stars ranges from 1 to 4% depending on the band. The&#10;formal uncertainties on the flux calibration averaged for all observations are&#10;0.3 to 1.0%, with longer&#45;wavelength bands generally having larger&#10;uncertainties.&#10; | General | [Link](http://arxiv.org/abs/2409.10443v1) |&#10;| CtRNet&#45;X: Camera&#45;to&#45;Robot Pose Estimation in Real&#45;world Conditions Using&#10; &#160;a Single Camera | Jingpei Lu, Zekai Liang, Tristin Xie, Florian Ritcher, Shan Lin, Sainan Liu, Michael C. Yip | &#160;&#160;Camera&#45;to&#45;robot calibration is crucial for vision&#45;based robot control and&#10;requires effort to make it accurate. Recent advancements in markerless pose&#10;estimation methods have eliminated the need for time&#45;consuming physical setups&#10;for camera&#45;to&#45;robot calibration. While the existing markerless pose estimation&#10;methods have demonstrated impressive accuracy without the need for cumbersome&#10;setups, they rely on the assumption that all the robot joints are visible&#10;within the camera&#39;s field of view. However, in practice, robots usually move in&#10;and out of view, and some portion of the robot may stay out&#45;of&#45;frame during the&#10;whole manipulation task due to real&#45;world constraints, leading to a lack of&#10;sufficient visual features and subsequent failure of these approaches. To&#10;address this challenge and enhance the applicability to vision&#45;based robot&#10;control, we propose a novel framework capable of estimating the robot pose with&#10;partially visible robot manipulators. Our approach leverages the&#10;Vision&#45;Language Models for fine&#45;grained robot components detection, and&#10;integrates it into a keypoint&#45;based pose estimation network, which enables more&#10;robust performance in varied operational conditions. The framework is evaluated&#10;on both public robot datasets and self&#45;collected partial&#45;view datasets to&#10;demonstrate our robustness and generalizability. As a result, this method is&#10;effective for robot pose estimation in a wider range of real&#45;world manipulation&#10;scenarios.&#10; | General | [Link](http://arxiv.org/abs/2409.10441v1) |&#10;| Successive topological phase transitions in two distinct spin&#45;flop&#10; &#160;phases on the honeycomb lattice | Xudong Li, Jize Zhao, Jinbin Li, Qiang Luo | &#160;&#160;The Kitaev magnets with bond&#45;dependent interactions have garnered&#10;considerable attention in recent years for their ability to harbor exotic&#10;phases and nontrivial excitations. The topological magnons, which are indicated&#10;by nonzero Chern number and thermal Hall conductivity, are proposed to&#10;partially explain thermal Hall measurements in real materials. Hitherto,&#10;topological magnons have been extensively explored when the magnetic field is&#10;normal to the honeycomb plane, but their topological characteristics are less&#10;studied in the presence of in&#45;plane magnetic field. Here, we study two distinct&#10;in&#45;plane field induced spin&#45;flop phases in the $Gamma$&#45;$Gamma&#39;$ model, both&#10;of which are off&#45;diagonal couplings that have intimate relation to the Kitaev&#10;interaction. The two spin&#45;flop phases are distinguished by their out&#45;of&#45;plane&#10;spin components which can be either antiparallel or parallel, thus dubbing&#10;antiferromagnetic (AFM) or ferromagnetic (FM) spin&#45;flop phases, respectively.&#10;We map out topological phase diagrams for both phases, revealing a rich pattern&#10;of the Chern number over exchange parameters and magnetic field. We&#10;analytically calculate the boundaries of topological phase transitions when the&#10;magnetic field is along the $a$ and $b$ directions. We find that the thermal&#10;Hall conductivity and its derivative display contrasting behaviors when&#10;crossing different topological phase transitions. The striking difference of&#10;the two phases lies in that when the magnetic field is along the $b$ direction,&#10;topological magnons are totally absent in the AFM spin&#45;flop phase, while they&#10;can survive in the FM analogue in certain parameter regions.&#10; | General | [Link](http://arxiv.org/abs/2409.10439v1) |&#10;| A functorial approach to $n$&#45;abelian categories | Vitor Gulisz | &#160;&#160;We develop a functorial approach to the study of $n$&#45;abelian categories by&#10;reformulating their axioms in terms of their categories of finitely presented&#10;functors. Such an approach allows the use of classical homological algebra and&#10;representation theory techniques to understand higher homological algebra. As&#10;an application, we present two possible generalizations of the axioms &quot;every&#10;monomorphism is a kernel&quot; and &quot;every epimorphism is a cokernel&quot; of an abelian&#10;category to $n$&#45;abelian categories. We also specialize our results to modules&#10;over rings, thereby describing when the category of finitely generated&#10;projective modules over a ring is $n$&#45;abelian. Moreover, we establish a&#10;correspondence for $n$&#45;abelian categories with additive generators, which&#10;extends the higher Auslander correspondence.&#10; | General | [Link](http://arxiv.org/abs/2409.10438v1) |&#10;| Color symmetry breaking in the Potts spin glass | Jean&#45;Christophe Mourrat | &#160;&#160;The Potts spin glass is an analogue of the Sherrington&#45;Kirkpatrick model in&#10;which each spin can take one of $kappa$ possible values, which we interpret as&#10;colors. It was suggested in arXiv:2310.06745 that the order parameter for this&#10;model is always invariant with respect to permutations of the colors. We show&#10;here that this is false whenever $kappa ge 58$.&#10; | General | [Link](http://arxiv.org/abs/2409.10437v1) |&#10;| Infector characteristics exposed by spatial analysis of SARS&#45;CoV&#45;2&#10; &#160;sequence and demographic data analysed at fine geographical scales | Anna Gama, Samantha Lycett, Will Harvey, Joseph Hughes, Sema Nickbakhsh, David L Robertson, Alison Smith Palmer, Anthony Wood, Rowland Kao | &#160;&#160;Characterising drivers of SARS&#45;CoV&#45;2 circulation is crucial for understanding&#10;COVID&#45;19 because of the severity of control measures adopted during the&#10;pandemic. Whole genome sequence data augmented with demographic metadata&#10;provides the best opportunity to do this. We use Random Forest Decision Tree&#10;models to analyse a combination of over 4000 SARS&#45;CoV2 sequences from a densely&#10;sampled, mixed urban and rural population (Tayside) in Scotland in the period&#10;from August 2020 to July 2021, with fine scale geographical and&#10;socio&#45;demographic metadata. Comparing periods in versus out of &quot;lockdown&quot;&#10;restrictions, we show using genetic distance relationships that individuals&#10;from more deprived areas are more likely to get infected during lockdown but&#10;less likely to spread the infection further. As disadvantaged communities were&#10;the most affected by both COVID&#45;19 and its restrictions, our finding has&#10;important implications for informing future approaches to control future&#10;pandemics driven by similar respiratory infections.&#10; | General | [Link](http://arxiv.org/abs/2409.10436v1) |&#10;| A study of pure multi&#45;strange hadrons production in Pb+Pb collisions at&#10; &#160;LHC energies using HYDJET++ model | Gauri Devi, B. K. Singh | &#160;&#160;For the present work, we have used the HYDJET++ model to explore the&#10;production of pure multi&#45;strange hadrons in Pb+Pb collisions at&#10;$sqrt{s_{NN}}$= 2.76 TeV and $sqrt{s_{NN}}$= 5.02 TeV collision energies,&#10;respectively. We have simulated the $p_{T}$&#45;spectra and elliptic flow ($v_{2}$)&#10;of $phi$&#45;meson and $Omega$&#45;baryons comparing our results with ALICE&#10;experimental data and several phenomenological models (HIJING/$Boverline{B}$,&#10;VISHNU, EPOS, AMPT, and Krakow) across various centrality intervals.&#10;Additionally, we have calculated the nuclear modification factors ($R_{AA}$ and&#10;$R_{CP}$), which provide a perception of jet quenching phenomena. Hence, our&#10;findings enable the study of the energy and system dependence of $phi$ and&#10;$Omega$ hadrons production over a wide range of ultra&#45;relativistic collision&#10;energies. We also present the particle ratios ($Omega/phi$,&#10;$overline{Omega}^{+}/Omega^{&#45;}$, $Omega/pi$, and $phi/pi$), offering&#10;insights on the strangeness enhancement and chemical properties of the medium&#10;at both LHC collision energies.&#10; | General | [Link](http://arxiv.org/abs/2409.10435v1) |&#10;| Magnetic metamaterials by ion&#45;implantation | Christina Vantaraki, Petter Strm, Tuan T. Tran, Matas P. Grassi, Giovanni Fevola, Michael Foerster, Jerzy T. Sadowski, Daniel Primetzhofer, Vassilios Kapaklis | &#160;&#160;We present a method for the additive fabrication of planar magnetic&#10;nanoarrays with minimal surface roughness. Synthesis is accomplished by&#10;combining electron&#45;beam lithography, used to generate nanometric patterned&#10;masks, with ion implantation in thin films. By implanting $^{56}$Fe$^{+}$ ions,&#10;we are able to introduce magnetic functionality in a controlled manner into&#10;continuous Pd thin films, achieving 3D spatial resolution down to a few tens of&#10;nanometers. Our results demonstrate the successful application of this&#10;technique in fabricating square artificial spin ice lattices, which exhibit&#10;well&#45;defined magnetization textures and interactions among the patterned&#10;magnetic elements.&#10; | General | [Link](http://arxiv.org/abs/2409.10433v1) |&#10;| Structure&#45;preserving learning for multi&#45;symplectic PDEs | Sleyman Yldz, Pawan Goyal, Peter Benner | &#160;&#160;This paper presents an energy&#45;preserving machine learning method for&#10;inferring reduced&#45;order models (ROMs) by exploiting the multi&#45;symplectic form&#10;of partial differential equations (PDEs). The vast majority of&#10;energy&#45;preserving reduced&#45;order methods use symplectic Galerkin projection to&#10;construct reduced&#45;order Hamiltonian models by projecting the full models onto a&#10;symplectic subspace. However, symplectic projection requires the existence of&#10;fully discrete operators, and in many cases, such as black&#45;box PDE solvers,&#10;these operators are inaccessible. In this work, we propose an energy&#45;preserving&#10;machine learning method that can infer the dynamics of the given PDE using data&#10;only, so that the proposed framework does not depend on the fully discrete&#10;operators. In this context, the proposed method is non&#45;intrusive. The proposed&#10;method is grey box in the sense that it requires only some basic knowledge of&#10;the multi&#45;symplectic model at the partial differential equation level. We prove&#10;that the proposed method satisfies spatially discrete local energy conservation&#10;and preserves the multi&#45;symplectic conservation laws. We test our method on the&#10;linear wave equation, the Korteweg&#45;de Vries equation, and the&#10;Zakharov&#45;Kuznetsov equation. We test the generalization of our learned models&#10;by testing them far outside the training time interval.&#10; | General | [Link](http://arxiv.org/abs/2409.10432v1) |&#10;| Hippocampal synchronization in a realistic CA1 neuron model | Alessandro Fiasconaro, Michele Migliore | &#160;&#160;This work delves into studying the synchronization in two realistic neuron&#10;models using Hodgkin&#45;Huxley dynamics. Unlike simplistic point&#45;like models,&#10;excitatory synapses are here randomly distributed along the dendrites,&#10;introducing strong stochastic contributions into their signal propagation. To&#10;focus on the role of different excitatory positions, we use two copies of the&#10;same neuron whose synapses are located at different distances from the soma and&#10;are exposed to identical Poissonian distributed current pulses. The&#10;synchronization is investigated through a specifically defined spiking&#10;correlation function, and its behavior is analyzed as a function of several&#10;parameters: inhibition weight, distance from the soma of one synaptic group,&#10;excitatory inactivation delay, and weight of the excitatory synapses.&#10; | General | [Link](http://arxiv.org/abs/2409.10431v1) |&#10;| Meta&#45;Whisper: Speech&#45;Based Meta&#45;ICL for ASR on Low&#45;Resource Languages | Ming&#45;Hao Hsu, Kuan Po Huang, Hung&#45;yi Lee | &#160;&#160;This paper presents Meta&#45;Whisper, a novel approach to improve automatic&#10;speech recognition (ASR) for low&#45;resource languages using the Whisper model. By&#10;leveraging Meta In&#45;Context Learning (Meta&#45;ICL) and a k&#45;Nearest Neighbors (KNN)&#10;algorithm for sample selection, Meta&#45;Whisper enhances Whisper&#39;s ability to&#10;recognize speech in unfamiliar languages without extensive fine&#45;tuning.&#10;Experiments on the ML&#45;SUPERB dataset show that Meta&#45;Whisper significantly&#10;reduces the Character Error Rate (CER) for low&#45;resource languages compared to&#10;the original Whisper model. This method offers a promising solution for&#10;developing more adaptable multilingual ASR systems, particularly for languages&#10;with limited resources.&#10; | General | [Link](http://arxiv.org/abs/2409.10429v1) |&#10;| User&#45;Authenticated Device&#45;Independent Quantum Secure Direct&#10; &#160;Communication Protocol | Nayana Das, Saikat Basu, Goutam Paul, Vijay S. Rao | &#160;&#160;Device&#45;Independent Quantum Secure Direct Communication (DI&#45;QSDC) enhances&#10;quantum cryptography by enabling secure message transmission without relying on&#10;the trustworthiness of the devices involved. This approach mitigates risks&#10;associated with compromised or untrusted devices, common in traditional quantum&#10;communication.&#10; &#160;In this paper, we propose the first of its kind DI&#45;QSDC protocol with user&#10;identity authentication. This ensures the authenticity of both the sender and&#10;receiver prior to message exchange. We then discuss the security of the&#10;proposed protocol against common attacks, demonstrating that no eavesdropper&#10;gains any information from either the quantum or the classical channel. Next,&#10;we implement the protocol on IBM&#39;s quantum hardware and evaluate its&#10;performance in a realistic noisy environment. Additionally, by simulating&#10;common attack models, we showcase that the protocol is secure against any&#10;eavesdropper in the channel. These findings highlight the protocol&#39;s robust&#10;security and practical feasibility for real&#45;world secure quantum communication.&#10; | General | [Link](http://arxiv.org/abs/2409.10427v1) |&#10;| Role of kinematic constraints in the time reversal symmetry breaking of&#10; &#160;a model active matter | Soumen Das, Shankar Ghosh, Tridib Sadhu, Juliane U Klamser | &#160;&#160;Active&#45;matter systems are inherently out&#45;of&#45;equilibrium and perform&#10;mechanical work by utilizing their internal energy sources. Breakdown of&#10;time&#45;reversal symmetry (BTRS) is a hallmark of such dissipative non&#45;equilibrium&#10;dynamics. We introduce a robust, experimentally accessible, noninvasive,&#10;quantitative measure of BTRS in terms of the Kullback&#45;Leibler divergence in&#10;collision events, demonstrated in our novel artificial active matter, comprised&#10;of battery&#45;powered spherical rolling robots whose energetics in different modes&#10;of motion can be measured with high precision. Our dimensionless measure&#10;characterizes how dissipation and internal energetics are influenced by&#10;kinematic constraints from interactions with the environment. We propose this&#10;measure of BTRS as an empirical estimate of the distance from equilibrium. An&#10;energetic insight into this departure of active matter from equilibrium comes&#10;from our demonstration of a non&#45;trivial fluctuation symmetry, which reveals a&#10;potentially universal thermodynamic characteristic of active energetics. As a&#10;many&#45;body consequence of BTRS in our experimental active system, we demonstrate&#10;the emergence of activity&#45;induced herding, which has no equilibrium analogue.&#10; | General | [Link](http://arxiv.org/abs/2409.10425v1) |&#10;| Unveiling V Modes: Enhancing CMB Sensitivity to BSM Physics with a&#10; &#160;Non&#45;Ideal Half&#45;Wave Plate | N. Raffuzzi, M. Lembo, S. Giardiello, M. Gerbino, M. Lattanzi, P. Natoli, L. Pagano | &#160;&#160;V&#45;mode polarization of the cosmic microwave background is expected to be&#10;vanishingly small in the $Lambda$CDM model and, hence, usually ignored.&#10;Nonetheless, several astrophysical effects, as well as beyond standard model&#10;physics could produce it at a detectable level. A realistic half&#45;wave plate &#45;&#10;an optical element commonly used in CMB experiments to modulate the polarized&#10;signal &#45; can provide sensitivity to V modes without significantly spoiling that&#10;to linear polarization. We assess this sensitivity for some new&#45;generation CMB&#10;experiments, such as the LiteBIRD satellite, the ground&#45;based Simons&#10;Observatory and a CMB&#45;S4&#45;like experiment. We forecast the efficiency of these&#10;experiments to constrain the phenomenology of certain classes of BSM models&#10;inducing mixing of linear polarization states and generation of V modes in the&#10;CMB. We find that new&#45;generation experiments can improve current limits by&#10;1&#45;to&#45;3 orders of magnitude, depending on the data combination. The inclusion of&#10;V&#45;mode information dramatically boosts the sensitivity to these BSM models.&#10; | General | [Link](http://arxiv.org/abs/2409.10424v1) |&#10;| Initial data for a deformed isolated horizon | Ale Flandera, David Kofro, Tom Ledvinka | &#160;&#160;Within the isolated horizon formalism, we investigate a static axisymmetric&#10;space&#45;time of a black hole influenced by matter in its neighborhood. To&#10;illustrate the role of ingredients and assumptions in this formalism, we first&#10;show how, in spherical symmetry, the field equations and gauge conditions imply&#10;the isolated horizon initial data leading to the Schwarzschild space&#45;time.&#10;Then, we construct the initial data for a static axisymmetric isolated horizon&#10;representing a deformed black hole. The space&#45;time description in the&#10;Bondi&#45;like coordinates is then found as a series expansion in the vicinity of&#10;the horizon. To graphically illustrate this construction, we also find a&#10;numerical solution for a black hole deformed by a particular analytic model of&#10;a thin accretion disk. We also discuss how an accretion disk affects the&#10;analytical properties of the horizon geometry.&#10; | General | [Link](http://arxiv.org/abs/2409.10423v1) |&#10;| Learning Semi&#45;Supervised Medical Image Segmentation from Spatial&#10; &#160;Registration | Qianying Liu, Paul Henderson, Xiao Gu, Hang Dai, Fani Deligianni | &#160;&#160;Semi&#45;supervised medical image segmentation has shown promise in training&#10;models with limited labeled data and abundant unlabeled data. However,&#10;state&#45;of&#45;the&#45;art methods ignore a potentially valuable source of unsupervised&#10;semantic information &#45;&#45; spatial registration transforms between image volumes.&#10;To address this, we propose CCT&#45;R, a contrastive cross&#45;teaching framework&#10;incorporating registration information. To leverage the semantic information&#10;available in registrations between volume pairs, CCT&#45;R incorporates two&#10;proposed modules: Registration Supervision Loss (RSL) and Registration&#45;Enhanced&#10;Positive Sampling (REPS). The RSL leverages segmentation knowledge derived from&#10;transforms between labeled and unlabeled volume pairs, providing an additional&#10;source of pseudo&#45;labels. REPS enhances contrastive learning by identifying&#10;anatomically&#45;corresponding positives across volumes using registration&#10;transforms. Experimental results on two challenging medical segmentation&#10;benchmarks demonstrate the effectiveness and superiority of CCT&#45;R across&#10;various semi&#45;supervised settings, with as few as one labeled case. Our code is&#10;available at&#10;https://github.com/kathyliu579/ContrastiveCross&#45;teachingWithRegistration.&#10; | General | [Link](http://arxiv.org/abs/2409.10422v1) |&#10;| Multidimensional Deconvolution with Profiling | Huanbiao Zhu, Krish Desai, Mikael Kuusela, Vinicius Mikuni, Benjamin Nachman, Larry Wasserman | &#160;&#160;In many experimental contexts, it is necessary to statistically remove the&#10;impact of instrumental effects in order to physically interpret measurements.&#10;This task has been extensively studied in particle physics, where the&#10;deconvolution task is called unfolding. A number of recent methods have shown&#10;how to perform high&#45;dimensional, unbinned unfolding using machine learning.&#10;However, one of the assumptions in all of these methods is that the detector&#10;response is accurately modeled in the Monte Carlo simulation. In practice, the&#10;detector response depends on a number of nuisance parameters that can be&#10;constrained with data. We propose a new algorithm called Profile OmniFold&#10;(POF), which works in a similar iterative manner as the OmniFold (OF) algorithm&#10;while being able to simultaneously profile the nuisance parameters. We&#10;illustrate the method with a Gaussian example as a proof of concept&#10;highlighting its promising capabilities.&#10; | General | [Link](http://arxiv.org/abs/2409.10421v1) |&#10;| HiFi&#45;CS: Towards Open Vocabulary Visual Grounding For Robotic Grasping&#10; &#160;Using Vision&#45;Language Models | Vineet Bhat, Prashanth Krishnamurthy, Ramesh Karri, Farshad Khorrami | &#160;&#160;Robots interacting with humans through natural language can unlock numerous&#10;applications such as Referring Grasp Synthesis (RGS). Given a text query, RGS&#10;determines a stable grasp pose to manipulate the referred object in the robot&#39;s&#10;workspace. RGS comprises two steps: visual grounding and grasp pose estimation.&#10;Recent studies leverage powerful Vision&#45;Language Models (VLMs) for visually&#10;grounding free&#45;flowing natural language in real&#45;world robotic execution.&#10;However, comparisons in complex, cluttered environments with multiple instances&#10;of the same object are lacking. This paper introduces HiFi&#45;CS, featuring&#10;hierarchical application of Featurewise Linear Modulation (FiLM) to fuse image&#10;and text embeddings, enhancing visual grounding for complex attribute rich text&#10;queries encountered in robotic grasping. Visual grounding associates an object&#10;in 2D/3D space with natural language input and is studied in two scenarios:&#10;Closed and Open Vocabulary. HiFi&#45;CS features a lightweight decoder combined&#10;with a frozen VLM and outperforms competitive baselines in closed vocabulary&#10;settings while being 100x smaller in size. Our model can effectively guide&#10;open&#45;set object detectors like GroundedSAM to enhance open&#45;vocabulary&#10;performance. We validate our approach through real&#45;world RGS experiments using&#10;a 7&#45;DOF robotic arm, achieving 90.33% visual grounding accuracy in 15 tabletop&#10;scenes. We include our codebase in the supplementary material.&#10; | General | [Link](http://arxiv.org/abs/2409.10419v1) |&#10;| X&#45;ray reverberation as an explanation for UV/optical variability in&#10; &#160;nearby Seyferts | M. Papoutsis, I. E. Papadakis, C. Panagiotou, M. Doviak, E. Kammoun | &#160;&#160;Active galactic nuclei (AGNs) are known to be variable across all&#10;wavelengths. Significant observational efforts have been invested in the last&#10;decade in studying their ultraviolet (UV) and optical variability. Long and&#10;densely sampled, multi&#45;wavelength monitoring campaigns of numerous Seyfert&#10;galaxies have been conducted with the aim of determining the X&#45;ray/UV/optical&#10;continuum time lags. Time&#45;lag studies can be used to constrain theoretical&#10;models. The observed time lags can be explained by thermal reprocessing of the&#10;X&#45;rays illuminating the accretion disc (known as the X&#45;ray reverberation&#10;model). However, the observed light curves contain more information that can be&#10;used to further constrain physical models. Our primary objective is to&#10;investigate whether, in addition to time lags, the X&#45;ray reverberation model&#10;can also explain the UV/optical variability amplitude of nearby Seyferts. To do&#10;this, we measured the excess variance of four sources (namely Mrk 509, NGC&#10;4151, NGC 2617, and Mrk 142) as a function of wavelength using data from&#10;archival long, multi&#45;wavelength campaigns with Swift, and ground&#45;based&#10;telescopes. We also computed the model excess variance in the case of the X&#45;ray&#10;reverberation model by determining the disc&#39;s transfer function and assuming a&#10;bending power law for the X&#45;ray power spectrum. We tested the validity of the&#10;model by comparing the measured and model variances for a range of accretion&#10;rates and X&#45;ray source heights. We conclude that the X&#45;ray thermal&#10;reverberation model can fit both the continuum, UV/optical time lags, as well&#10;as the variance in these AGNs, for the same physical parameters. Our results&#10;suggest that the accretion disc is constant and that all the observed&#10;UV/optical variations, on timescales of days and up to a few weeks, can be&#10;fully explained by the variable X&#45;rays as they illuminate the accretion disc.&#10; | General | [Link](http://arxiv.org/abs/2409.10417v1) |&#10;| Local central limit theorem for Mallows measure | Alexey Bufetov, Kailun Chen | &#160;&#160;We study the statistics of the Mallows measure on permutations in the limit&#10;pioneered by Starr (2009). Our main result is the local central limit theorem&#10;for its height function. We also re&#45;derive versions of the law of large numbers&#10;and the large deviation principle, obtain the standard central limit theorem&#10;from the local one, and establish a multi&#45;point version of the local central&#10;limit theorem.&#10; | General | [Link](http://arxiv.org/abs/2409.10415v1) |&#10;| On interactive anisotropic walks in two dimensions generated from a&#10; &#160;three state opinion dynamics model | Surajit Saha, Parongama Sen | &#160;&#160;A system of interacting walkers on a two&#45;dimensional space where the dynamics&#10;of each walker are governed by the opinions of agents of a three&#45;state opinion&#10;dynamics model are considered. Such walks, inspired by Ising&#45;like models and&#10;opinions dynamics models, are usually considered in one&#45;dimensional virtual&#10;spaces. Here, the mapping is done in such a way that the walk is directed along&#10;the $y$ axis while it can move either way along the $x$ axis. We explore the&#10;properties of such walks as the parameter representing the noise in the opinion&#10;dynamics model, responsible for a continuous phase transition, is varied. The&#10;walk features show marked differences as the system crosses the critical point.&#10;The bivariate distribution of the displacements below the critical point is a&#10;modified biased Gaussian function of x and y which is symmetric about the X&#10;axis.&#10; &#160;The marginal probability distributions can be extracted and the scaling forms&#10;of different quantities, showing power law behaviour, are obtained. The&#10;directed nature of the walk is reflected in the marginal distributions as well&#10;as in the exponents.&#10; | General | [Link](http://arxiv.org/abs/2409.10413v1) |&#10;| A Large&#45;Scale Privacy Assessment of Android Third&#45;Party SDKs | Mark Huasong Meng, Chuan Yan, Yun Hao, Qing Zhang, Zeyu Wang, Kailong Wang, Sin Gee Teo, Guangdong Bai, Jin Song Dong | &#160;&#160;Third&#45;party Software Development Kits (SDKs) are widely adopted in Android&#10;app development, to effortlessly accelerate development pipelines and enhance&#10;app functionality. However, this convenience raises substantial concerns about&#10;unauthorized access to users&#39; privacy&#45;sensitive information, which could be&#10;further abused for illegitimate purposes like user tracking or monetization.&#10;Our study offers a targeted analysis of user privacy protection among Android&#10;third&#45;party SDKs, filling a critical gap in the Android software supply chain.&#10;It focuses on two aspects of their privacy practices, including data&#10;exfiltration and behavior&#45;policy compliance (or privacy compliance), utilizing&#10;techniques of taint analysis and large language models. It covers 158&#10;widely&#45;used SDKs from two key SDK release platforms, the official one and a&#10;large alternative one. From them, we identified 338 instances of privacy data&#10;exfiltration. On the privacy compliance, our study reveals that more than 30%&#10;of the examined SDKs fail to provide a privacy policy to disclose their data&#10;handling practices. Among those that provide privacy policies, 37% of them&#10;over&#45;collect user data, and 88% falsely claim access to sensitive data. We&#10;revisit the latest versions of the SDKs after 12 months. Our analysis&#10;demonstrates a persistent lack of improvement in these concerning trends. Based&#10;on our findings, we propose three actionable recommendations to mitigate the&#10;privacy leakage risks and enhance privacy protection for Android users. Our&#10;research not only serves as an urgent call for industry attention but also&#10;provides crucial insights for future regulatory interventions.&#10; | General | [Link](http://arxiv.org/abs/2409.10411v1) |&#10;| A point process approach for the classification of noisy calcium imaging&#10; &#160;data | Arianna Burzacchi, Nicoletta D&#39;Angelo, David Payares&#45;Garcia, Jorge Mateu | &#160;&#160;We study noisy calcium imaging data, with a focus on the classification of&#10;spike traces. As raw traces obscure the true temporal structure of neuron&#39;s&#10;activity, we performed a tuned filtering of the calcium concentration using two&#10;methods: a biophysical model and a kernel mapping. The former characterizes&#10;spike trains related to a particular triggering event, while the latter filters&#10;out the signal and refines the selection of the underlying neuronal response.&#10;Transitioning from traditional time series analysis to point process theory,&#10;the study explores spike&#45;time distance metrics and point pattern prototypes to&#10;describe repeated observations. We assume that the analyzed neuron&#39;s firing&#10;events, i.e. spike occurrences, are temporal point process events. In&#10;particular, the study aims to categorize 47 point patterns by depth, assuming&#10;the similarity of spike occurrences within specific depth categories. The&#10;results highlight the pivotal roles of depth and stimuli in discerning diverse&#10;temporal structures of neuron firing events, confirming the point process&#10;approach based on prototype analysis is largely useful in the classification of&#10;spike traces.&#10; | General | [Link](http://arxiv.org/abs/2409.10409v1) |&#10;| Variational closures for composite homogenised fluid flows | Theo Diamantakis, Ruiao Hu | &#160;&#160;The Stochastic Advection by Lie Transport is a variational formulation of&#10;stochastic fluid dynamics introduced to model the effects of unresolved scales,&#10;whilst preserving the geometric structure of ideal fluid flows. In this work,&#10;we show that the SALT equations can arise from the decomposition of the fluid&#10;flow map into its mean and fluctuating components. The fluctuating component is&#10;realised as a prescribed stochastic diffeomorphism that introduces stochastic&#10;transport into the system and we construct it using homogenisation theory. The&#10;dynamics of the mean component are derived from a variational principle&#10;utilising particular forms of variations that preserve the composite structure&#10;of the flow. Using a new variational principle, we show that SALT equations can&#10;arise from random Lagrangians and are equivalent to random coefficient PDEs. We&#10;also demonstrate how to modify the composite flow and the associated&#10;variational principle to derive models inspired by the Lagrangian Averaged&#10;Euler&#45;Poincare (LAEP) theory.&#10; | General | [Link](http://arxiv.org/abs/2409.10408v1) |&#10;| Bitcoin Transaction Behavior Modeling Based on Balance Data | Yu Zhang, Claudio Tessone | &#160;&#160;When analyzing Bitcoin users&#39; balance distribution, we observed that it&#10;follows a log&#45;normal pattern. Drawing parallels from the successful application&#10;of Gibrat&#39;s law of proportional growth in explaining city size and word&#10;frequency distributions, we tested whether the same principle could account for&#10;the log&#45;normal distribution in Bitcoin balances. However, our calculations&#10;revealed that the exponent parameters in both the drift and variance terms&#10;deviate slightly from one. This suggests that Gibrat&#39;s proportional growth rule&#10;alone does not fully explain the log&#45;normal distribution observed in Bitcoin&#10;users&#39; balances. During our exploration, we discovered an intriguing&#10;phenomenon: Bitcoin users tend to fall into two distinct categories based on&#10;their behavior, which we refer to as ``poor&quot; and ``wealthy&quot; users. Poor users,&#10;who initially purchase only a small amount of Bitcoin, tend to buy more&#10;bitcoins first and then sell out all their holdings gradually over time. The&#10;certainty of selling all their coins is higher and higher with time. In&#10;contrast, wealthy users, who acquire a large amount of Bitcoin from the start,&#10;tend to sell off their holdings over time. The speed at which they sell their&#10;bitcoins is lower and lower over time and they will hold at least a small part&#10;of their initial holdings at last. Interestingly, the wealthier the user, the&#10;larger the proportion of their balance and the higher the certainty they tend&#10;to sell. This research provided an interesting perspective to explore bitcoin&#10;users&#39; behaviors which may apply to other finance markets.&#10; | General | [Link](http://arxiv.org/abs/2409.10407v1) |&#10;| Stochastic Data&#45;Driven Predictive Control: Chance&#45;Constraint&#10; &#160;Satisfaction with Identified Multi&#45;step Predictors | Haldun Balim, Andrea Carron, Melanie N. Zeilinger, Johannes Khler | &#160;&#160;We propose a novel data&#45;driven stochastic model predictive control framework&#10;for uncertain linear systems with noisy output measurements. Our approach&#10;leverages multi&#45;step predictors to efficiently propagate uncertainty, ensuring&#10;chance constraint satisfaction with minimal conservatism. In particular, we&#10;present a strategy to identify multi&#45;step predictors and quantify the&#10;associated uncertainty using a surrogate (data&#45;driven) state space model. Then,&#10;we utilize the derived distribution to formulate a constraint tightening that&#10;ensures chance constraint satisfaction. A numerical example highlights the&#10;reduced conservatism of handling parametric uncertainty in the proposed method&#10;compared to state&#45;of&#45;the&#45;art solutions.&#10; | General | [Link](http://arxiv.org/abs/2409.10405v1) |&#10;| A Knowledge&#45;Enhanced Disease Diagnosis Method Based on Prompt Learning&#10; &#160;and BERT Integration | Zhang Zheng | &#160;&#160;This paper proposes a knowledge&#45;enhanced disease diagnosis method based on a&#10;prompt learning framework. The method retrieves structured knowledge from&#10;external knowledge graphs related to clinical cases, encodes it, and injects it&#10;into the prompt templates to enhance the language model&#39;s understanding and&#10;reasoning capabilities for the task.We conducted experiments on three public&#10;datasets: CHIP&#45;CTC, IMCS&#45;V2&#45;NER, and KUAKE&#45;QTR. The results show that the&#10;proposed method significantly outperforms existing models across multiple&#10;evaluation metrics, with an F1 score improvement of 2.4% on the CHIP&#45;CTC&#10;dataset, 3.1% on the IMCS&#45;V2&#45;NER dataset,and 4.2% on the KUAKE&#45;QTR dataset.&#10;Additionally,ablation studies confirmed the critical role of the knowledge&#10;injection module,as the removal of this module resulted in a significant drop&#10;in F1 score. The experimental results demonstrate that the proposed method not&#10;only effectively improves the accuracy of disease diagnosis but also enhances&#10;the interpretability of the predictions, providing more reliable support and&#10;evidence for clinical diagnosis.&#10; | General | [Link](http://arxiv.org/abs/2409.10403v1) |&#10;| A Statistical Equilibrium Approach to Adam Smith&#39;s Labor Theory of Value | Ellis Scharfenaker, Bruno Theodosio, Duncan K. Foley | &#160;&#160;Adam Smith&#39;s inquiry into the emergence and stability of the&#10;self&#45;organization of the division of labor in commodity production and exchange&#10;is considered using statistical equilibrium methods from statistical physics.&#10;We develop a statistical equilibrium model of the distribution of independent&#10;direct producers in a hub&#45;and&#45;spoke framework that predicts both the center of&#10;gravity of producers across lines of production as well as the endogenous&#10;fluctuations between lines of production that arise from Smith&#39;s concept of&#10;&quot;perfect liberty&quot;. The ergodic distribution of producers implies a long&#45;run&#10;balancing of &quot;advantages to disadvantages&quot; across lines of employment and&#10;gravitation of market prices around Smith&#39;s natural prices.&#10; | General | [Link](http://arxiv.org/abs/2409.10402v1) |&#10;| Hydrodynamic mechanism for stable spindle positioning in meiosis II&#10; &#160;oocytes | Weida Liao, Eric Lauga | &#160;&#160;Cytoplasmic streaming, the persistent flow of fluid inside a cell, induces&#10;intracellular transport, which plays a key role in fundamental biological&#10;processes. In meiosis II mouse oocytes (developing egg cells) awaiting&#10;fertilisation, the spindle, which is the protein structure responsible for&#10;dividing genetic material in a cell, must maintain its position near the cell&#10;cortex (the thin actin network bound to the cell membrane) for many hours.&#10;However, the cytoplasmic streaming that accompanies this stable positioning&#10;would intuitively appear to destabilise the spindle position. Here, through a&#10;combination of numerical and analytical modelling, we reveal a new,&#10;hydrodynamic mechanism for stable spindle positioning beneath the cortical cap.&#10;We show that this stability depends critically on the spindle size and the&#10;active driving from the cortex, and demonstrate that stable spindle positioning&#10;can result purely from a hydrodynamic suction force exerted on the spindle by&#10;the cytoplasmic flow. Our findings show that local fluid dynamic forces can be&#10;sufficient to stabilise the spindle, explaining robustness against&#10;perturbations not only perpendicular but also parallel to the cortex. Our&#10;results shed light on the importance of cytoplasmic streaming in mammalian&#10;meiosis.&#10; | General | [Link](http://arxiv.org/abs/2409.10401v1) |&#10;| Sherpa: An Open Source Python Fitting Package | Aneta Siemiginowska, Douglas Burke, Hans Moritz Gnther, Nicholas P. Lee, Warren McLaughlin, David A. Principe, Harlan Cheer, Antonella Fruscione, Omar Laurino, Jonathan McDowell, Marie Terrell | &#160;&#160;We present an overview of Sherpa, an open source Python project, and discuss&#10;its development history, broad design concepts and capabilities. Sherpa&#10;contains powerful tools for combining parametric models into complex&#10;expressions that can be fit to data using a variety of statistics and&#10;optimization methods. It is easily extensible to include user&#45;defined models,&#10;statistics, and optimization methods. It provides a high&#45;level User Interface&#10;for interactive data&#45;analysis, such as within a Jupyter notebook, and it can&#10;also be used as a library component, providing fitting and modeling&#10;capabilities to an application. We include a few examples of Sherpa&#10;applications to multiwavelength astronomical data. The code is available&#10;GitHub: https://github.com/sherpa/sherpa&#10; | General | [Link](http://arxiv.org/abs/2409.10400v1) |&#10;| Minimally coupled $$&#45;exponential inflation with an $R^2$ term in&#10; &#160;the Palatini formulation | Nilay Bostan, Rafid H. Dejrah | &#160;&#160;We focus on the inflationary predictions of $beta$&#45;exponential potential&#10;models, in which the inflaton is a representation of the field delineating the&#10;size of extra&#45;dimension. Since it offers a well&#45;motivated starting point for&#10;the study of physics at very high energies, we incorporate an $R^2$ term in the&#10;Palatini gravity. In addition, afterward the inflation, the inflaton oscillates&#10;about the minimum of the inflation potential, and reheats the universe. This&#10;occurs during the reheating phase, at which the inflaton decays into the&#10;standard model particles, which fill the universe. We extend our examination by&#10;considering the reheating effects on inflationary observables by employing the&#10;different scenarios of the reheat temperature. Supposing the standard thermal&#10;history after inflation, we display the inflationary predictions, $n_s, r,&#10;mathrm{d}n_s/mathrm{d}&#10;n k$ of $beta$&#45;exponential potential with minimal&#10;coupling in Palatini $R^2$ gravity. Also, different kinds of constraints from a&#10;variety of observations, such as BICEP/Keck, Planck 2018, as well as future&#10;possible detectable sensitivities that might be reached by CMB experiments:&#10;CMB&#45;S4 and LiteBIRD are taken into account in this work. We indicate that our&#10;results are consistent with both the latest data and the future sensitivity&#10;forecasts of LiteBIRD/Planck and CMB&#45;S4. Finally, the results in this study&#10;highlight the viability of our model even in the case of the existence of more&#10;stringent constraints expected from future achievable confidence level limits.&#10; | General | [Link](http://arxiv.org/abs/2409.10398v1) |&#10;| Quantifying Observational Projection Effects with a Simulation&#45;based hot&#10; &#160;CGM model | Soumya Shreeram, Johan Comparat, Andrea Merloni, Yi Zhang, Gabriele Ponti, Kirpal Nandra, John ZuHone, Ilaria Marini, Stephan Vladutescu&#45;Zopp, Paola Popesso, Ruediger Pakmor, Riccardo Seppi, Celine Peroux, Daniele Sorini | &#160;&#160;The hot phase of the circumgalactic medium (CGM) allows us to probe the&#10;inflow and outflow of gas within a galaxy, which is responsible for dictating&#10;the evolution of the galaxy. Studying the hot CGM sheds light on a better&#10;understanding of gas physics, which is crucial to inform and constrain&#10;simulation models. With the recent advances in observational measurements&#10;probing the hot CGM in X&#45;rays and tSZ, we have a new avenue for widening our&#10;knowledge of gas physics and feedback by exploiting the information from&#10;current/future observations. In this paper, we use the TNG300 hydrodynamical&#10;simulations to build a fully self&#45;consistent forward model for the hot CGM. We&#10;construct a lightcone and generate mock X&#45;ray observations. We quantify the&#10;projection effects, namely the locally correlated large&#45;scale structure in&#10;X&#45;rays and the effect due to satellite galaxies misclassified as centrals which&#10;affects the measured hot CGM galactocentric profiles in stacking experiments.&#10;We present an analytical model that describes the intrinsic X&#45;ray surface&#10;brightness profile across the stellar and halo mass bins. The increasing&#10;stellar mass bins result in decreasing values of $beta$, the exponent&#10;quantifying the slope of the intrinsic galactocentric profiles. We carry&#10;forward the current state&#45;of&#45;the&#45;art by also showing the impact of the locally&#10;correlated environment on the measured X&#45;ray surface brightness profiles. We&#10;also present, for the first time, the effect of misclassified centrals in&#10;stacking experiments for three stellar mass bins: $10^{10.5&#45;11} M_odot$,&#10;$10^{11&#45;11.2} M_odot$, and $10^{11.2&#45;11.5} M_odot$. We find that the&#10;contaminating effect of the misclassified centrals on the stacked profiles&#10;increases when the stellar mass decreases.&#10; | General | [Link](http://arxiv.org/abs/2409.10397v1) |&#10;| MOST: MR reconstruction Optimization for multiple downStream Tasks via&#10; &#160;continual learning | Hwihun Jeong, Se Young Chun, Jongho Lee | &#160;&#160;Deep learning&#45;based Magnetic Resonance (MR) reconstruction methods have&#10;focused on generating high&#45;quality images but they often overlook the impact on&#10;downstream tasks (e.g., segmentation) that utilize the reconstructed images.&#10;Cascading separately trained reconstruction network and downstream task network&#10;has been shown to introduce performance degradation due to error propagation&#10;and domain gaps between training datasets. To mitigate this issue, downstream&#10;task&#45;oriented reconstruction optimization has been proposed for a single&#10;downstream task. Expanding this optimization to multi&#45;task scenarios is not&#10;straightforward. In this work, we extended this optimization to sequentially&#10;introduced multiple downstream tasks and demonstrated that a single MR&#10;reconstruction network can be optimized for multiple downstream tasks by&#10;deploying continual learning (MOST). MOST integrated techniques from&#10;replay&#45;based continual learning and image&#45;guided loss to overcome catastrophic&#10;forgetting. Comparative experiments demonstrated that MOST outperformed a&#10;reconstruction network without finetuning, a reconstruction network with&#10;na&quot;ive finetuning, and conventional continual learning methods. This&#10;advancement empowers the application of a single MR reconstruction network for&#10;multiple downstream tasks. The source code is available at:&#10;https://github.com/SNU&#45;LIST/MOST&#10; | General | [Link](http://arxiv.org/abs/2409.10394v1) |&#10;| Multicopy quantum state teleportation with application to storage and&#10; &#160;retrieval of quantum programs | Frdric Grosshans, Micha Horodecki, Mio Murao, Tomasz Mynik, Marco Tlio Quintino, Micha Studziski, Satoshi Yoshida | &#160;&#160;This work considers a teleportation task for Alice and Bob in a scenario&#10;where Bob cannot perform corrections. In particular, we analyse the task of&#10;textit{multicopy state teleportation}, where Alice has $k$ identical copies of&#10;an arbitrary unknown $d$&#45;dimensional qudit state $vertpsi&#13;angle$ to teleport&#10;a single copy of $vertpsi&#13;angle$ to Bob using a maximally entangled&#10;two&#45;qudit state shared between Alice and Bob without Bob&#39;s correction. Alice&#10;may perform a joint measurement on her half of the entangled state and the $k$&#10;copies of $vertpsi&#13;angle$. We prove that the maximal probability of success&#10;for teleporting the exact state $vertpsi&#13;angle$ to Bob is&#10;$p(d,k)=frac{k}{d(k&#45;1+d)}$ and present an explicit protocol to attain this&#10;performance. Then, by utilising $k$ copies of an arbitrary target state&#10;$vertpsi&#13;angle$, we show how the multicopy state teleportation protocol can&#10;be employed to enhance the success probability of storage and retrieval of&#10;quantum programs, which aims to universally retrieve the action of an arbitrary&#10;quantum channel that is stored in a state. Our proofs make use of group&#10;representation theory methods, which may find applications beyond the problems&#10;addressed in this work.&#10; | General | [Link](http://arxiv.org/abs/2409.10393v1) |&#10;| TPFL: Tsetlin&#45;Personalized Federated Learning with Confidence&#45;Based&#10; &#160;Clustering | Rasoul Jafari Gohari, Laya Aliahmadipour, Ezat Valipour | &#160;&#160;The world of Machine Learning (ML) has witnessed rapid changes in terms of&#10;new models and ways to process users data. The majority of work that has been&#10;done is focused on Deep Learning (DL) based approaches. However, with the&#10;emergence of new algorithms such as the Tsetlin Machine (TM) algorithm, there&#10;is growing interest in exploring alternative approaches that may offer unique&#10;advantages in certain domains or applications. One of these domains is&#10;Federated Learning (FL), in which users privacy is of utmost importance. Due to&#10;its novelty, FL has seen a surge in the incorporation of personalization&#10;techniques to enhance model accuracy while maintaining user privacy under&#10;personalized conditions. In this work, we propose a novel approach dubbed TPFL:&#10;Tsetlin&#45;Personalized Federated Learning, in which models are grouped into&#10;clusters based on their confidence towards a specific class. In this way,&#10;clustering can benefit from two key advantages. Firstly, clients share only&#10;what they are confident about, resulting in the elimination of wrongful weight&#10;aggregation among clients whose data for a specific class may have not been&#10;enough during the training. This phenomenon is prevalent when the data are&#10;non&#45;Independent and Identically Distributed (non&#45;IID). Secondly, by sharing&#10;only weights towards a specific class, communication cost is substantially&#10;reduced, making TPLF efficient in terms of both accuracy and communication&#10;cost. The results of TPFL demonstrated the highest accuracy on three different&#10;datasets; namely MNIST, FashionMNIST and FEMNIST.&#10; | General | [Link](http://arxiv.org/abs/2409.10392v1) |&#10;| Prompt&#45;and&#45;Transfer: Dynamic Class&#45;aware Enhancement for Few&#45;shot&#10; &#160;Segmentation | Hanbo Bi, Yingchao Feng, Wenhui Diao, Peijin Wang, Yongqiang Mao, Kun Fu, Hongqi Wang, Xian Sun | &#160;&#160;For more efficient generalization to unseen domains (classes), most Few&#45;shot&#10;Segmentation (FSS) would directly exploit pre&#45;trained encoders and only&#10;fine&#45;tune the decoder, especially in the current era of large models. However,&#10;such fixed feature encoders tend to be class&#45;agnostic, inevitably activating&#10;objects that are irrelevant to the target class. In contrast, humans can&#10;effortlessly focus on specific objects in the line of sight. This paper mimics&#10;the visual perception pattern of human beings and proposes a novel and powerful&#10;prompt&#45;driven scheme, called ``Prompt and Transfer&quot; (PAT), which constructs a&#10;dynamic class&#45;aware prompting paradigm to tune the encoder for focusing on the&#10;interested object (target class) in the current task. Three key points are&#10;elaborated to enhance the prompting: 1) Cross&#45;modal linguistic information is&#10;introduced to initialize prompts for each task. 2) Semantic Prompt Transfer&#10;(SPT) that precisely transfers the class&#45;specific semantics within the images&#10;to prompts. 3) Part Mask Generator (PMG) that works in conjunction with SPT to&#10;adaptively generate different but complementary part prompts for different&#10;individuals. Surprisingly, PAT achieves competitive performance on 4 different&#10;tasks including standard FSS, Cross&#45;domain FSS (e.g., CV, medical, and remote&#10;sensing domains), Weak&#45;label FSS, and Zero&#45;shot Segmentation, setting new&#10;state&#45;of&#45;the&#45;arts on 11 benchmarks.&#10; | General | [Link](http://arxiv.org/abs/2409.10389v1) |&#10;| Revising the Structure of Recurrent Neural Networks to Eliminate&#10; &#160;Numerical Derivatives in Forming Physics Informed Loss Terms with Respect to&#10; &#160;Time | Mahyar Jahani&#45;nasab, Mohamad Ali Bijarchi | &#160;&#160;Solving unsteady partial differential equations (PDEs) using recurrent neural&#10;networks (RNNs) typically requires numerical derivatives between each block of&#10;the RNN to form the physics informed loss function. However, this introduces&#10;the complexities of numerical derivatives into the training process of these&#10;models. In this study, we propose modifying the structure of the traditional&#10;RNN to enable the prediction of each block over a time interval, making it&#10;possible to calculate the derivative of the output with respect to time using&#10;the backpropagation algorithm. To achieve this, the time intervals of these&#10;blocks are overlapped, defining a mutual loss function between them.&#10;Additionally, the employment of conditional hidden states enables us to achieve&#10;a unique solution for each block. The forget factor is utilized to control the&#10;influence of the conditional hidden state on the prediction of the subsequent&#10;block. This new model, termed the Mutual Interval RNN (MI&#45;RNN), is applied to&#10;solve three different benchmarks: the Burgers equation, unsteady heat&#10;conduction in an irregular domain, and the Green vortex problem. Our results&#10;demonstrate that MI&#45;RNN can find the exact solution more accurately compared to&#10;existing RNN models. For instance, in the second problem, MI&#45;RNN achieved one&#10;order of magnitude less relative error compared to the RNN model with numerical&#10;derivatives.&#10; | General | [Link](http://arxiv.org/abs/2409.10388v1) |&#10;| Sharp decay rate for eigenfunctions of perturbed periodic Schrdinger&#10; &#160;operators | Wencai Liu, Rodrigo Matos, John N. Treuer | &#160;&#160;This paper investigates uniqueness results for perturbed periodic&#10;Schr&quot;odinger operators on $mathbb{Z}^d$. Specifically, we consider operators&#10;of the form $H = &#45;Delta + V + v$, where $Delta$ is the discrete Laplacian,&#10;$V: mathbb{Z}^d &#13;ightarrow mathbb{R}$ is a periodic potential, and $v:&#10;mathbb{Z}^d &#13;ightarrow mathbb{C}$ represents a decaying impurity. We&#10;establish quantitative conditions under which the equation $&#45;Delta u + V u + v&#10;u = &#10;ambda u$, for $&#10;ambda in mathbb{C}$, admits only the trivial solution&#10;$u equiv 0$. Key applications include the absence of embedded eigenvalues for&#10;operators with impurities decaying faster than any exponential function and the&#10;determination of sharp decay rates for eigenfunctions. Our findings extend&#10;previous works by providing precise decay conditions for impurities and&#10;analyzing different spectral regimes of $&#10;ambda$.&#10; | General | [Link](http://arxiv.org/abs/2409.10387v1) |&#10;| Mamba&#45;ST: State Space Model for Efficient Style Transfer | Filippo Botti, Alex Ergasti, Leonardo Rossi, Tomaso Fontanini, Claudio Ferrari, Massimo Bertozzi, Andrea Prati | &#160;&#160;The goal of style transfer is, given a content image and a style source,&#10;generating a new image preserving the content but with the artistic&#10;representation of the style source. Most of the state&#45;of&#45;the&#45;art architectures&#10;use transformers or diffusion&#45;based models to perform this task, despite the&#10;heavy computational burden that they require. In particular, transformers use&#10;self&#45; and cross&#45;attention layers which have large memory footprint, while&#10;diffusion models require high inference time. To overcome the above, this paper&#10;explores a novel design of Mamba, an emergent State&#45;Space Model (SSM), called&#10;Mamba&#45;ST, to perform style transfer. To do so, we adapt Mamba linear equation&#10;to simulate the behavior of cross&#45;attention layers, which are able to combine&#10;two separate embeddings into a single output, but drastically reducing memory&#10;usage and time complexity. We modified the Mamba&#39;s inner equations so to accept&#10;inputs from, and combine, two separate data streams. To the best of our&#10;knowledge, this is the first attempt to adapt the equations of SSMs to a vision&#10;task like style transfer without requiring any other module like&#10;cross&#45;attention or custom normalization layers. An extensive set of experiments&#10;demonstrates the superiority and efficiency of our method in performing style&#10;transfer compared to transformers and diffusion models. Results show improved&#10;quality in terms of both ArtFID and FID metrics. Code is available at&#10;https://github.com/FilippoBotti/MambaST.&#10; | General | [Link](http://arxiv.org/abs/2409.10385v1) |&#10;| Performance&#45;Portable Numerical Relativity with AthenaK | Hengrui Zhu, Jacob Fields, Francesco Zappa, David Radice, James Stone, Alireza Rashti, William Cook, Sebastiano Bernuzzi, Boris Daszuta | &#160;&#160;We present the numerical relativity module within AthenaK, an open source&#10;performance&#45;portable astrophysics code designed for exascale computing&#10;applications. This module employs the Z4c formulation to solve the Einstein&#10;equations. We demonstrate its accuracy through a series of standard numerical&#10;relativity tests, including convergence of the gravitational waveform from&#10;binary black hole coalescence. Furthermore, we conduct scaling tests on OLCF&#10;Frontier and NERSC Perlmutter, where AthenaK exhibits excellent weak scaling&#10;efficiency of 80% on up to 65,536 AMD MI250X GPUs on Frontier (relative to 4&#10;GPUs) and strong scaling efficiencies of 84% and 77% on AMD MI250X and NVIDIA&#10;A100 GPUs on Frontier and Perlmutter respectively. Additionally, we observe a&#10;significant performance boost, with two orders of magnitude speedup ($gtrsim&#10;200times$) on a GPU compared to a single CPU core, affirming that AthenaK is&#10;well&#45;suited for exascale computing, thereby expanding the potential for&#10;breakthroughs in numerical relativity research.&#10; | General | [Link](http://arxiv.org/abs/2409.10383v1) |&#10;| J&#45;UBIK: The JAX&#45;accelerated Universal Bayesian Imaging Kit | Vincent Eberle, Matteo Guardiani, Margret Westerkamp, Philipp Frank, Julian Rstig, Julia Stadler, Torsten A. Enlin | &#160;&#160;Many advances in astronomy and astrophysics originate from accurate images of&#10;the sky emission across multiple wavelengths. This often requires&#10;reconstructing spatially and spectrally correlated signals detected from&#10;multiple instruments. To facilitate the high&#45;fidelity imaging of these signals,&#10;we introduce the universal Bayesian imaging kit (UBIK). Specifically, we&#10;present J&#45;UBIK, a flexible and modular implementation leveraging the&#10;JAX&#45;accelerated NIFTy.re software as its backend. J&#45;UBIK streamlines the&#10;implementation of the key Bayesian inference components, providing for all the&#10;necessary steps of Bayesian imaging pipelines. First, it provides adaptable&#10;prior models for different sky realizations. Second, it includes likelihood&#10;models tailored to specific instruments. So far, the package includes three&#10;instruments: Chandra and eROSITA for X&#45;ray observations, and the James Webb&#10;Space Telescope (JWST) for the near&#45; and mid&#45;infrared. The aim is to expand&#10;this set in the future. Third, these models can be integrated with various&#10;inference and optimization schemes, such as maximum a posteriori estimation and&#10;variational inference. Explicit demos show how to integrate the individual&#10;modules into a full analysis pipeline. Overall, J&#45;UBIK enables efficient&#10;generation of high&#45;fidelity images via Bayesian pipelines that can be tailored&#10;to specific research objectives.&#10; | General | [Link](http://arxiv.org/abs/2409.10381v1) |&#10;| Thermolectricity in irradiated bilayer graphene flakes | Cynthia Ihuoma Osuala, Tanu Choudhary, Raju K. Biswas, Sudin Ganguly, Chunlei Qu, Santanu K. Maiti | &#160;&#160;We present a comprehensive study on enhancing the thermoelectric (TE)&#10;performance of bilayer graphene (BLG) through irradiation with arbitrarily&#10;polarized light, focusing on $AA$&#45; and $AB$&#45;stacked configurations with zigzag&#10;edges. Utilizing a combination of tight&#45;binding theory and density functional&#10;theory (DFT), we systematically analyze the impact of light irradiation on&#10;electronic and phononic transport properties. Light irradiation alters the&#10;electronic hopping parameters, creating an asymmetric transmission function,&#10;which significantly increases the Seebeck coefficient, thereby boosting the&#10;overall {it figure of merit} (FOM). For the phononic contribution, DFT&#10;calculations reveal that $AB$&#45;stacked BLG exhibits lower lattice thermal&#10;conductivity compared to $AA$&#45;stacked, attributed to enhanced anharmonic&#10;scattering and phonon group velocity. The combined analysis shows that FOM&#10;exceeds unity in both stacking types, with notable improvements near the&#10;irradiation&#45;induced gap. Additionally, we explore the dependence of FOM on the&#10;system dimensions and temperature, demonstrating that light&#45;irradiated BLG&#10;holds great promise for efficient thermoelectric energy conversion and waste&#10;heat recovery. Our results show favorable responses over a wide range of&#10;irradiation parameters. These findings provide crucial insights into optimizing&#10;BLG for advanced TE applications through light&#45;induced modifications.&#10; | General | [Link](http://arxiv.org/abs/2409.10380v1) |&#10;| Leveraging Joint Spectral and Spatial Learning with MAMBA for&#10; &#160;Multichannel Speech Enhancement | Wenze Ren, Haibin Wu, Yi&#45;Cheng Lin, Xuanjun Chen, Rong Chao, Kuo&#45;Hsuan Hung, You&#45;Jin Li, Wen&#45;Yuan Ting, Hsin&#45;Min Wang, Yu Tsao | &#160;&#160;In multichannel speech enhancement, effectively capturing spatial and&#10;spectral information across different microphones is crucial for noise&#10;reduction. Traditional methods, such as CNN or LSTM, attempt to model the&#10;temporal dynamics of full&#45;band and sub&#45;band spectral and spatial features.&#10;However, these approaches face limitations in fully modeling complex temporal&#10;dependencies, especially in dynamic acoustic environments. To overcome these&#10;challenges, we modify the current advanced model McNet by introducing an&#10;improved version of Mamba, a state&#45;space model, and further propose MCMamba.&#10;MCMamba has been completely reengineered to integrate full&#45;band and narrow&#45;band&#10;spatial information with sub&#45;band and full&#45;band spectral features, providing a&#10;more comprehensive approach to modeling spatial and spectral information. Our&#10;experimental results demonstrate that MCMamba significantly improves the&#10;modeling of spatial and spectral features in multichannel speech enhancement,&#10;outperforming McNet and achieving state&#45;of&#45;the&#45;art performance on the CHiME&#45;3&#10;dataset. Additionally, we find that Mamba performs exceptionally well in&#10;modeling spectral information.&#10; | General | [Link](http://arxiv.org/abs/2409.10376v1) |&#10;| Nonlinear Causality in Brain Networks: With Application to Motor Imagery&#10; &#160;vs Execution | Sipan Aslan, Hernando Ombao | &#160;&#160;One fundamental challenge of data&#45;driven analysis in neuroscience is modeling&#10;causal interactions and exploring the connectivity of nodes in a brain network.&#10;Various statistical methods, relying on various perspectives and employing&#10;different data modalities, are being developed to examine and comprehend the&#10;underlying causal structures inherent to brain dynamics. This study introduces&#10;a novel statistical approach, TAR4C, to dissect causal interactions in&#10;multichannel EEG recordings. TAR4C uses the threshold autoregressive model to&#10;describe the causal interaction between nodes or clusters of nodes in a brain&#10;network. The perspective involves testing whether one node, which may represent&#10;a brain region, can control the dynamics of the other. The node that has such&#10;an impact on the other is called a threshold variable and can be classified as&#10;a causative because its functionality is the leading source operating as an&#10;instantaneous switching mechanism that regulates the time&#45;varying&#10;autoregressive structure of the other. This statistical concept is commonly&#10;referred to as threshold non&#45;linearity. Once threshold non&#45;linearity has been&#10;verified between a pair of nodes, the subsequent essential facet of TAR&#10;modeling is to assess the predictive ability of the causal node for the current&#10;activity on the other and represent causal interactions in autoregressive&#10;terms. This predictive ability is what underlies Granger causality. The TAR4C&#10;approach can discover non&#45;linear and time&#45;dependent causal interactions without&#10;negating the G&#45;causality perspective. The efficacy of the proposed approach is&#10;exemplified by analyzing the EEG signals recorded during the motor&#10;movement/imagery experiment. The similarities and differences between the&#10;causal interactions manifesting during the execution and the imagery of a given&#10;motor movement are demonstrated by analyzing EEG recordings from multiple&#10;subjects.&#10; | General | [Link](http://arxiv.org/abs/2409.10374v1) |&#10;| Instigating Cooperation among LLM Agents Using Adaptive Information&#10; &#160;Modulation | Qiliang Chen, &#160;Alireza, &#160;Ilami, Nunzio Lore, Babak Heydari | &#160;&#160;This paper introduces a novel framework combining LLM agents as proxies for&#10;human strategic behavior with reinforcement learning (RL) to engage these&#10;agents in evolving strategic interactions within team environments. Our&#10;approach extends traditional agent&#45;based simulations by using strategic LLM&#10;agents (SLA) and introducing dynamic and adaptive governance through a&#10;pro&#45;social promoting RL agent (PPA) that modulates information access across&#10;agents in a network, optimizing social welfare and promoting pro&#45;social&#10;behavior. Through validation in iterative games, including the prisoner&#10;dilemma, we demonstrate that SLA agents exhibit nuanced strategic adaptations.&#10;The PPA agent effectively learns to adjust information transparency, resulting&#10;in enhanced cooperation rates. This framework offers significant insights into&#10;AI&#45;mediated social dynamics, contributing to the deployment of AI in real&#45;world&#10;team settings.&#10; | General | [Link](http://arxiv.org/abs/2409.10372v1) |&#10;| Learning Gentle Grasping from Human&#45;Free Force Control Demonstration | Mingxuan Li, Lunwei Zhang, Tiemin Li, Yao Jiang | &#160;&#160;Humans can steadily and gently grasp unfamiliar objects based on tactile&#10;perception. Robots still face challenges in achieving similar performance due&#10;to the difficulty of learning accurate grasp&#45;force predictions and force&#10;control strategies that can be generalized from limited data. In this article,&#10;we propose an approach for learning grasping from ideal force control&#10;demonstrations, to achieve similar performance of human hands with limited data&#10;size. Our approach utilizes objects with known contact characteristics to&#10;automatically generate reference force curves without human demonstrations. In&#10;addition, we design the dual convolutional neural networks (Dual&#45;CNN)&#10;architecture which incorporating a physics&#45;based mechanics module for learning&#10;target grasping force predictions from demonstrations. The described method can&#10;be effectively applied in vision&#45;based tactile sensors and enables gentle and&#10;stable grasping of objects from the ground. The described prediction model and&#10;grasping strategy were validated in offline evaluations and online experiments,&#10;and the accuracy and generalizability were demonstrated.&#10; | General | [Link](http://arxiv.org/abs/2409.10371v1) |&#10;| Uncovering the Mechanism of Hepatotoxiciy of PFAS Targeting L&#45;FABP Using&#10; &#160;GCN and Computational Modeling | Lucas Jividen, Tibo Duran, Xi&#45;Zhi Niu, Jun Bai | &#160;&#160;Per&#45; and polyfluoroalkyl substances (PFAS) are persistent environmental&#10;pollutants with known toxicity and bioaccumulation issues. Their widespread&#10;industrial use and resistance to degradation have led to global environmental&#10;contamination and significant health concerns. While a minority of PFAS have&#10;been extensively studied, the toxicity of many PFAS remains poorly understood&#10;due to limited direct toxicological data. This study advances the predictive&#10;modeling of PFAS toxicity by combining semi&#45;supervised graph convolutional&#10;networks (GCNs) with molecular descriptors and fingerprints. We propose a novel&#10;approach to enhance the prediction of PFAS binding affinities by isolating&#10;molecular fingerprints to construct graphs where then descriptors are set as&#10;the node features. This approach specifically captures the structural,&#10;physicochemical, and topological features of PFAS without overfitting due to an&#10;abundance of features. Unsupervised clustering then identifies representative&#10;compounds for detailed binding studies. Our results provide a more accurate&#10;ability to estimate PFAS hepatotoxicity to provide guidance in chemical&#10;discovery of new PFAS and the development of new safety regulations.&#10; | General | [Link](http://arxiv.org/abs/2409.10370v1) |&#10;| Stochastic Control of UAVs: An Optimal Tradeoff between Performance,&#10; &#160;Flight Smoothness and Control Effort | George Rapakoulias, Panagiotis Tsiotras | &#160;&#160;Safe and accurate control of unmanned aerial vehicles in the presence of&#10;winds is a challenging control problem due to the hard&#45;to&#45;model and highly&#10;stochastic nature of the disturbance forces acting upon the vehicle. To meet&#10;performance constraints, state&#45;of&#45;the&#45;art control methods such as Incremental&#10;Nonlinear Dynamic Inversion (INDI) or other adaptive control techniques require&#10;high control gains to mitigate the effects of uncertainty entering the system.&#10;While achieving good tracking performance, IDNI requires excessive control&#10;effort, results in high actuator strain, and reduced flight smoothness due to&#10;constant and aggressive corrective actions commanded by the controller. In this&#10;paper, we propose a novel control architecture that allows the user to&#10;systematically address the trade&#45;off between high authority control and&#10;performance constraint satisfaction. Our approach consists of two parts. To&#10;cancel out biases introduced by unmodelled aerodynamic effects we propose a&#10;hybrid, model&#45;based disturbance force estimator augmented with a neural&#10;network, that can adapt to external wind conditions using a Kalman Filter. We&#10;then utilize state&#45;of&#45;the&#45;art results from Covariance Steering theory, which&#10;offers a principled way of controlling the uncertainty of the tracking error&#10;dynamics. We first analyze the properties of the combined system and then&#10;provide extensive experimental results to verify the advantages of the proposed&#10;approach over existing methods&#10; | General | [Link](http://arxiv.org/abs/2409.10369v1) |&#10;| Integrated nowcasting of convective precipitation with Transformer&#45;based&#10; &#160;models using multi&#45;source data | alar Kk, Aitor Atencia, Markus Dabernig | &#160;&#160;Precipitation nowcasting is crucial for mitigating the impacts of severe&#10;weather events and supporting daily activities. Conventional models&#10;predominantly relying on radar data have limited performance in predicting&#10;cases with complex temporal features such as convection initiation,&#10;highlighting the need to integrate data from other sources for more&#10;comprehensive nowcasting. Unlike physics&#45;based models, machine learning&#10;(ML)&#45;based models offer promising solutions for efficiently integrating large&#10;volumes of diverse data. We present EF4INCA, a spatiotemporal Transformer model&#10;for precipitation nowcasting that integrates satellite&#45; and ground&#45;based&#10;observations with numerical weather prediction outputs. EF4INCA provides&#10;high&#45;resolution forecasts over Austria, accurately predicting the location and&#10;shape of precipitation fields with a spatial resolution of 1 kilometre and a&#10;temporal resolution of 5 minutes, up to 90 minutes ahead. Our evaluation shows&#10;that EF4INCA outperforms conventional nowcasting models, including the&#10;operational model of Austria, particularly in scenarios with complex temporal&#10;features such as convective initiation and rapid weather changes. EF4INCA&#10;maintains higher accuracy in location forecasting but generates smoother fields&#10;at later prediction times compared to traditional models. Interpretation of our&#10;model showed that precipitation products and SEVIRI infrared channels CH7 and&#10;CH9 are the most important data streams. These results underscore the&#10;importance of combining data from different domains, including physics&#45;based&#10;model products, with ML approaches. Our study highlights the robustness of&#10;EF4INCA and its potential for improved precipitation nowcasting. We provide&#10;access to our code repository, model weights, and the dataset curated for&#10;benchmarking, facilitating further development and application.&#10; | General | [Link](http://arxiv.org/abs/2409.10367v1) |&#10;&#10;">
<text font-weight="bold" text-anchor="middle" x="2369" y="-679.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- a6a39d20&#45;81af&#45;4f11&#45;a2ae&#45;5c1728d9ee01 -->
<g id="node61" class="node">
<title>a6a39d20&#45;81af&#45;4f11&#45;a2ae&#45;5c1728d9ee01</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="2929.24,-522.44 2984,-510 3038.76,-522.44 3038.71,-542.56 2929.29,-542.56 2929.24,-522.44"/>
<text text-anchor="middle" x="2984" y="-524.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">OpenAI</text>
</g>
<!-- 139922634606800_5 -->
<g id="node63" class="node">
<title>139922634606800_5</title>
<ellipse fill="#ebcfb9" stroke="#b89c86" stroke-width="3" cx="3074" cy="-615" rx="136.48" ry="18"/>
<text text-anchor="middle" x="3074" y="-611.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">speaker_selection_agent (5)</text>
</g>
<!-- a6a39d20&#45;81af&#45;4f11&#45;a2ae&#45;5c1728d9ee01&#45;&gt;139922634606800_5 -->
<g id="edge71" class="edge">
<title>a6a39d20&#45;81af&#45;4f11&#45;a2ae&#45;5c1728d9ee01&#45;&gt;139922634606800_5</title>
<path fill="none" stroke="#6666ff" d="M3034.91,-542.59C3061.08,-550.08 3088.28,-558.88 3092,-564 3097.07,-570.97 3096.04,-579.52 3092.69,-587.55"/>
<polygon fill="#6666ff" stroke="#6666ff" points="3089.47,-586.16 3087.92,-596.64 3095.67,-589.41 3089.47,-586.16"/>
</g>
<!-- 139922634606416_9&#45;&gt;139922634606800_5 -->
<g id="edge69" class="edge">
<title>139922634606416_9&#45;&gt;139922634606800_5</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M3048.16,-756.79C3053.17,-729.48 3062.99,-675.99 3068.97,-643.38"/>
<polygon fill="#6666ff" stroke="#6666ff" points="3072.48,-643.66 3070.85,-633.19 3065.6,-642.39 3072.48,-643.66"/>
<g id="a_edge69&#45;label"><a xlink:title="Read the above conversation. Then select the next role from [&#39;Admin&#39;, &#39;Engineer&#39;, &#39;Scientist&#39;, &#39;Planner&#39;, &#39;Executor&#39;, &#39;Critic&#39;] to play. Only return the role." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="3126" y="-679.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922634606800_5&#45;&gt;a6a39d20&#45;81af&#45;4f11&#45;a2ae&#45;5c1728d9ee01 -->
<g id="edge70" class="edge">
<title>139922634606800_5&#45;&gt;a6a39d20&#45;81af&#45;4f11&#45;a2ae&#45;5c1728d9ee01</title>
<path fill="none" stroke="#6666ff" d="M2988.73,-600.92C2977.9,-595.75 2968.13,-588.67 2961,-579 2954.81,-570.61 2958.08,-560.28 2963.87,-551.2"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2966.82,-553.1 2969.96,-542.98 2961.19,-548.93 2966.82,-553.1"/>
<g id="a_edge70&#45;label"><a xlink:title="Executor" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="3026.5" y="-567.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">generate_oai_reply</text>
</a>
</g>
</g>
<!-- 139922634606416_10 -->
<g id="node64" class="node">
<title>139922634606416_10</title>
<ellipse fill="#e8c4c6" stroke="#b59193" stroke-width="3" cx="3159" cy="-528" rx="102.88" ry="18"/>
<text text-anchor="middle" x="3159" y="-524.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">checking_agent (10)</text>
</g>
<!-- 139922634606800_5&#45;&gt;139922634606416_10 -->
<g id="edge72" class="edge">
<title>139922634606800_5&#45;&gt;139922634606416_10</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M3091.2,-596.8C3103.73,-584.27 3120.86,-567.14 3134.77,-553.23"/>
<polygon fill="#6666ff" stroke="#6666ff" points="3137.52,-555.43 3142.11,-545.89 3132.57,-550.48 3137.52,-555.43"/>
<g id="a_edge72&#45;label"><a xlink:title="Executor" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="3185" y="-567.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 1726553885.882256 -->
<g id="node65" class="node">
<title>1726553885.882256</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="3188.56,-411 3044.5,-411 3007.44,-375 3151.5,-375 3188.56,-411"/>
<text text-anchor="middle" x="3098" y="-389.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Summarize</text>
</g>
<!-- 139922634606416_10&#45;&gt;1726553885.882256 -->
<g id="edge73" class="edge">
<title>139922634606416_10&#45;&gt;1726553885.882256</title>
<path fill="none" stroke="#6666ff" d="M3151.15,-509.88C3140.72,-487.14 3122.19,-446.74 3110,-420.16"/>
<polygon fill="#6666ff" stroke="#6666ff" points="3113.17,-418.68 3105.82,-411.05 3106.81,-421.6 3113.17,-418.68"/>
<g id="a_edge73&#45;label"><a xlink:title="Executor" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="3201" y="-432.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">_last_msg_as_summary</text>
</a>
</g>
</g>
<!-- 189b624b&#45;6d3e&#45;4d47&#45;af26&#45;2044438a531c -->
<g id="node66" class="node">
<title>189b624b&#45;6d3e&#45;4d47&#45;af26&#45;2044438a531c</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="3130.5,-324 3059.5,-324 3059.5,-288 3136.5,-288 3136.5,-318 3130.5,-324"/>
<polyline fill="none" stroke="#00be92" stroke-width="3" points="3130.5,-324 3130.5,-318 "/>
<polyline fill="none" stroke="#00be92" stroke-width="3" points="3136.5,-318 3130.5,-318 "/>
<text text-anchor="middle" x="3098" y="-302.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Executor</text>
</g>
<!-- 1726553885.882256&#45;&gt;189b624b&#45;6d3e&#45;4d47&#45;af26&#45;2044438a531c -->
<g id="edge74" class="edge">
<title>1726553885.882256&#45;&gt;189b624b&#45;6d3e&#45;4d47&#45;af26&#45;2044438a531c</title>
<path fill="none" stroke="#6666ff" d="M3098,-374.8C3098,-363.16 3098,-347.55 3098,-334.24"/>
<polygon fill="#6666ff" stroke="#6666ff" points="3101.5,-334.18 3098,-324.18 3094.5,-334.18 3101.5,-334.18"/>
<text text-anchor="middle" x="3143.5" y="-345.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">next speaker</text>
</g>
<!-- 1726553894.222013 -->
<g id="node67" class="node">
<title>1726553894.222013</title>
<g id="a_node67"><a xlink:title="exitcode: 0 (execution succeeded)&#10;Code output: &#10;| Title | Authors | Abstract | Domain | Source URL |&#10;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#10;| The VIRUS&#45;dE Survey I: Stars in dwarf elliptical galaxies &#45; 3D dynamics&#10; &#160;and radially resolved stellar initial mass functions | Mathias Lipka, Jens Thomas, Roberto Saglia, Ralf Bender, Maximilian Fabricius, Gary J. Hill, Matthias Kluge, Martin Landriau, Ximena Mazzalay, Eva Noyola, Taniya Parikh, Jan Snigula | &#160;&#160;We analyse the stellar structure of a sample of dwarf ellipticals (dE)&#10;inhabiting various environments within the Virgo cluster. Integral&#45;field&#10;observations with a high spectral resolution allow us to robustly determine&#10;their low velocity dispersions ($sim25$ km s$^{&#45;1}$) and higher&#45;order&#10;kinematic moments out to the half&#45;light radius. We find the dEs exhibit a&#10;diversity in ages with the younger dEs being less enhanced than the older,&#10;suggesting a complex star formation history for those dEs that recently entered&#10;Virgo while others have been quenched shortly after reionization.&#10;Orbit&#45;superposition modeling allowed us to recover viewing angles, stellar&#10;mass&#45;to&#45;light ratios (with gradients), as well as the intrinsic orbit&#10;structure. We find that the angular momentum of the dEs is strongly suppressed&#10;compared to ordinary early&#45;type galaxies and correlates with the environment.&#10;Flattened dEs are so because of a suppressed kinetic energy perpendicular to&#10;their equatorial plane. Combining population and dynamical modeling results, we&#10;find an age&#45;dependent stellar initial mass function (IMF) or, alternatively,&#10;evidence for a more extended star formation history for those galaxies that&#10;have had higher initial mass and/or inhabited lower density environments. dEs&#10;appear to have a spatially homogeneous stellar structure but the state they&#10;were `frozen&#39; in as they stopped forming stars varies dramatically according to&#10;their initial conditions.&#10; | General | [Link](http://arxiv.org/abs/2409.10518v1) |&#10;| RetrievalAttention: Accelerating Long&#45;Context LLM Inference via Vector&#10; &#160;Retrieval | Di Liu, Meng Chen, Baotong Lu, Huiqiang Jiang, Zhenhua Han, Qianxi Zhang, Qi Chen, Chengruidong Zhang, Bailu Ding, Kai Zhang, Chen Chen, Fan Yang, Yuqing Yang, Lili Qiu | &#160;&#160;Transformer&#45;based large Language Models (LLMs) become increasingly important&#10;in various domains. However, the quadratic time complexity of attention&#10;operation poses a significant challenge for scaling to longer contexts due to&#10;the extremely high inference latency and GPU memory consumption for caching&#10;key&#45;value (KV) vectors. This paper proposes RetrievalAttention, a training&#45;free&#10;approach to accelerate attention computation. To leverage the dynamic sparse&#10;property of attention, RetrievalAttention builds approximate nearest neighbor&#10;search (ANNS) indexes upon KV vectors in CPU memory and retrieves the most&#10;relevant ones via vector search during generation. Due to the&#10;out&#45;of&#45;distribution (OOD) between query vectors and key vectors, off&#45;the&#45;shelf&#10;ANNS indexes still need to scan O(N) (usually 30% of all keys) data for&#10;accurate retrieval, which fails to exploit the high sparsity.&#10;RetrievalAttention first identifies the OOD challenge of ANNS&#45;based attention,&#10;and addresses it via an attention&#45;aware vector search algorithm that can adapt&#10;to queries and only access 1&#45;&#45;3% of data, thus achieving a sub&#45;linear time&#10;complexity. RetrievalAttention greatly reduces the inference cost of&#10;long&#45;context LLM with much lower GPU memory requirements while maintaining the&#10;model accuracy. Especially, RetrievalAttention only needs 16GB GPU memory for&#10;serving 128K tokens in LLMs with 8B parameters, which is capable of generating&#10;one token in 0.188 seconds on a single NVIDIA RTX4090 (24GB).&#10; | General | [Link](http://arxiv.org/abs/2409.10516v1) |&#10;| An Efficient Self&#45;Learning Framework For Interactive Spoken Dialog&#10; &#160;Systems | Hitesh Tulsiani, David M. Chan, Shalini Ghosh, Garima Lalwani, Prabhat Pandey, Ankish Bansal, Sri Garimella, Ariya Rastrow, Bjrn Hoffmeister | &#160;&#160;Dialog systems, such as voice assistants, are expected to engage with users&#10;in complex, evolving conversations. Unfortunately, traditional automatic speech&#10;recognition (ASR) systems deployed in such applications are usually trained to&#10;recognize each turn independently and lack the ability to adapt to the&#10;conversational context or incorporate user feedback. In this work, we introduce&#10;a general framework for ASR in dialog systems that can go beyond learning from&#10;single&#45;turn utterances and learn over time how to adapt to both explicit&#10;supervision and implicit user feedback present in multi&#45;turn conversations. We&#10;accomplish that by leveraging advances in student&#45;teacher learning and&#10;context&#45;aware dialog processing, and designing contrastive self&#45;supervision&#10;approaches with Ohm, a new online hard&#45;negative mining approach. We show that&#10;leveraging our new framework compared to traditional training leads to relative&#10;WER reductions of close to 10% in real&#45;world dialog systems, and up to 26% on&#10;public synthetic data.&#10; | General | [Link](http://arxiv.org/abs/2409.10515v1) |&#10;| Constraints on axions from patchy screening of the cosmic microwave&#10; &#160;background | Samuel Goldstein, Fiona McCarthy, Cristina Mondino, J. Colin Hill, Junwu Huang, Matthew C. Johnson | &#160;&#160;The resonant conversion of cosmic microwave background (CMB) photons into&#10;axions within large&#45;scale structure induces an anisotropic spectral distortion&#10;in CMB temperature maps. Applying state&#45;of&#45;the&#45;art foreground cleaning&#10;techniques to $textit{Planck}$ CMB observations, we construct maps of&#10;axion&#45;induced &quot;patchy screening&quot; of the CMB. We cross&#45;correlate these maps with&#10;data from the $textit{unWISE}$ galaxy survey and find no evidence of axions.&#10;We constrain the axion&#45;photon coupling, $g_{agammagamma} &#10;esssim 2 times&#10;10^{&#45;12}~{&#13;m GeV}^{&#45;1}$, at the 95% confidence level for axion masses in the&#10;range $10^{&#45;13}~{&#13;m eV} &#10;esssim m_a &#10;esssim 10^{&#45;12}~{&#13;m eV}$. These&#10;constraints are competitive with the tightest astrophysical axion limits in&#10;this mass range and are inferred from robust population&#45;level statistics, which&#10;makes them complementary to existing searches that rely on modeling of&#10;individual systems.&#10; | General | [Link](http://arxiv.org/abs/2409.10514v1) |&#10;| Weak Superimposed Codes of Improved Asymptotic Rate and Their Randomized&#10; &#160;Construction | Yu Tsunoda, Yuichiro Fujiwara | &#160;&#160;Weak superimposed codes are combinatorial structures related closely to&#10;generalized cover&#45;free families, superimposed codes, and disjunct matrices in&#10;that they are only required to satisfy similar but less stringent conditions.&#10;This class of codes may also be seen as a stricter variant of what are known as&#10;locally thin families in combinatorics. Originally, weak superimposed codes&#10;were introduced in the context of multimedia content protection against illegal&#10;distribution of copies under the assumption that a coalition of malicious users&#10;may employ the averaging attack with adversarial noise. As in many other kinds&#10;of codes in information theory, it is of interest and importance in the study&#10;of weak superimposed codes to find the highest achievable rate in the&#10;asymptotic regime and give an efficient construction that produces an infinite&#10;sequence of codes that achieve it. Here, we prove a tighter lower bound than&#10;the sharpest known one on the rate of optimal weak superimposed codes and give&#10;a polynomial&#45;time randomized construction algorithm for codes that&#10;asymptotically attain our improved bound with high probability. Our&#10;probabilistic approach is versatile and applicable to many other related codes&#10;and arrays.&#10; | General | [Link](http://arxiv.org/abs/2409.10511v1) |&#10;| Pennsieve &#45; A Collaborative Platform for Translational Neuroscience and&#10; &#160;Beyond | Zack Goldblum, Zhongchuan Xu, Haoer Shi, Patryk Orzechowski, Jamaal Spence, Kathryn A Davis, Brian Litt, Nishant Sinha, Joost Wagenaar | &#160;&#160;The exponential growth of neuroscientific data necessitates platforms that&#10;facilitate data management and multidisciplinary collaboration. In this paper,&#10;we introduce Pennsieve &#45; an open&#45;source, cloud&#45;based scientific data management&#10;platform built to meet these needs. Pennsieve supports complex multimodal&#10;datasets and provides tools for data visualization and analyses. It takes a&#10;comprehensive approach to data integration, enabling researchers to define&#10;custom metadata schemas and utilize advanced tools to filter and query their&#10;data. Pennsieve&#39;s modular architecture allows external applications to extend&#10;its capabilities, and collaborative workspaces with peer&#45;reviewed data&#10;publishing mechanisms promote high&#45;quality datasets optimized for downstream&#10;analysis, both in the cloud and on&#45;premises.&#10; &#160;Pennsieve forms the core for major neuroscience research programs including&#10;the NIH SPARC Initiative, NIH HEAL Initiative&#39;s PRECISION Human Pain Network,&#10;and NIH HEAL RE&#45;JOIN Initiative. It serves more than 80 research groups&#10;worldwide, along with several large&#45;scale, inter&#45;institutional projects at&#10;clinical sites through the University of Pennsylvania. Underpinning the&#10;SPARC.Science, Epilepsy.Science, and Pennsieve Discover portals, Pennsieve&#10;stores over 125 TB of scientific data, with 35 TB of data publicly available&#10;across more than 350 high&#45;impact datasets. It adheres to the findable,&#10;accessible, interoperable, and reusable (FAIR) principles of data sharing and&#10;is recognized as one of the NIH&#45;approved Data Repositories. By facilitating&#10;scientific data management, discovery, and analysis, Pennsieve fosters a robust&#10;and collaborative research ecosystem for neuroscience and beyond.&#10; | General | [Link](http://arxiv.org/abs/2409.10509v1) |&#10;| General&#45;relativistic resistive&#45;magnetohydrodynamics simulations of&#10; &#160;self&#45;consistent magnetized rotating neutron stars | Patrick Chi&#45;Kit Cheong, Antonios Tsokaros, Milton Ruiz, Fabrizio Venturi, Juno Chun Lung Chan, Anson Ka Long Yip, Koji Uryu | &#160;&#160;We present the first general&#45;relativistic resistive magnetohydrodynamics&#10;simulations of self&#45;consistent, rotating neutron stars with mixed poloidal and&#10;toroidal magnetic fields. Specifically, we investigate the role of resistivity&#10;in the dynamical evolution of neutron stars over a period of up to 100 ms and&#10;its effects on their quasi&#45;equilibrium configurations. Our results demonstrate&#10;that resistivity can significantly influence the development of&#10;magnetohydrodynamic instabilities, resulting in markedly different magnetic&#10;field geometries. Additionally, resistivity suppresses the growth of these&#10;instabilities, leading to a reduction in the amplitude of emitted gravitational&#10;waves. Despite the variations in magnetic field geometries, the ratio of&#10;poloidal to toroidal field energies remains consistently 9:1 throughout the&#10;simulations, for the models we investigated.&#10; | General | [Link](http://arxiv.org/abs/2409.10508v1) |&#10;| Beth&#45;Uhlenbeck equation for the thermodynamics of fluctuations in a&#10; &#160;generalised 2+1D Gross&#45;Neveu model | Biplab Mahato, David Blaschke, Dietmar Ebert | &#160;&#160;We study a generalised version of Gross&#45;Neveu model in 2+1 dimensions. The&#10;model is inspired from graphene which shows a linear dispersion relation near&#10;the Dirac points. The phase structure and the thermodynamic properties in the&#10;mean field approximation have been studied before. Here we go beyond the mean&#10;field level by deriving a Beth&#45;Uhlenbeck equation for Gaussian fluctuations,&#10;solutions of which we explore numerically, for the first time including their&#10;momentum dependence. We discuss the excitonic mass, fluctuation pressure and&#10;phase shifts. We also perform a comparison with the NJL model in 3+1 dimension&#10;and discuss its implication for graphene.&#10; | General | [Link](http://arxiv.org/abs/2409.10507v1) |&#10;| Context&#45;aware Code Segmentation for C&#45;to&#45;Rust Translation using Large&#10; &#160;Language Models | Momoko Shiraishi, Takahiro Shinagawa | &#160;&#160;There is strong motivation to translate C code into Rust code due to the&#10;continuing threat of memory safety vulnerabilities in existing C programs and&#10;the significant attention paid to Rust as an alternative to the C language.&#10;While large language models (LLMs) show promise for automating this translation&#10;by generating more natural and safer code than rule&#45;based methods, previous&#10;studies have shown that LLM&#45;generated Rust code often fails to compile, even&#10;for relatively small C programs, due to significant differences between the two&#10;languages and context window limitations. We propose an LLM&#45;based translation&#10;scheme that improves the success rate of translating large&#45;scale C code into&#10;compilable Rust code. Our approach involves three key techniques: (1)&#10;pre&#45;processing the C code to better align its structure and expressions with&#10;Rust, (2) segmenting the code into optimally sized translation units to avoid&#10;exceeding the LLM&#39;s context window limits, and (3) iteratively compiling and&#10;repairing errors while maintaining consistency between translation units using&#10;context&#45;supplementing prompts. Compilation success is an essential first step&#10;in achieving functional equivalence, as only compilable code can be further&#10;tested. In experiments with 20 benchmark C programs, including those exceeding&#10;4 kilo lines of code, we successfully translated all programs into compilable&#10;Rust code without losing corresponding parts of the original code.&#10; | General | [Link](http://arxiv.org/abs/2409.10506v1) |&#10;| Machine Learning Optimization of non&#45;Kasha Behavior and of Transient&#10; &#160;Dynamics in Model Retinal Isomerization | Davinder Singh, Chern Chuang, Paul Brumer | &#160;&#160;Designing a model of retinal isomerization in Rhodopsin, the first step in&#10;vision, that accounts for both experimental transient and stationary state&#10;observables is challenging. Here, multi&#45;objective Bayesian optimization is&#10;employed to refine the parameters of a minimal two&#45;state&#45;two&#45;mode (TM) model&#10;describing the photoisomerization of retinal in Rhodopsin. With an appropriate&#10;selection of objectives, the optimized retinal model predicts excitation&#10;wavelength&#45;dependent fluorescence spectra that closely align with&#10;experimentally observed non&#45;Kasha behavior in the non&#45;equilibrium steady state.&#10;Further, adjustments to the potential energy surface within the TM model reduce&#10;the discrepancies across the time domain. Overall, agreement with experimental&#10;data is excellent.&#10; | General | [Link](http://arxiv.org/abs/2409.10505v1) |&#10;| DILA: Dictionary Label Attention for Mechanistic Interpretability in&#10; &#160;High&#45;dimensional Multi&#45;label Medical Coding Prediction | John Wu, David Wu, Jimeng Sun | &#160;&#160;Predicting high&#45;dimensional or extreme multilabels, such as in medical&#10;coding, requires both accuracy and interpretability. Existing works often rely&#10;on local interpretability methods, failing to provide comprehensive&#10;explanations of the overall mechanism behind each label prediction within a&#10;multilabel set. We propose a mechanistic interpretability module called&#10;DIctionary Label Attention (method) that disentangles uninterpretable dense&#10;embeddings into a sparse embedding space, where each nonzero element (a&#10;dictionary feature) represents a globally learned medical concept. Through&#10;human evaluations, we show that our sparse embeddings are more human&#10;understandable than its dense counterparts by at least 50 percent. Our&#10;automated dictionary feature identification pipeline, leveraging large language&#10;models (LLMs), uncovers thousands of learned medical concepts by examining and&#10;summarizing the highest activating tokens for each dictionary feature. We&#10;represent the relationships between dictionary features and medical codes&#10;through a sparse interpretable matrix, enhancing the mechanistic and global&#10;understanding of the model&#39;s predictions while maintaining competitive&#10;performance and scalability without extensive human annotation.&#10; | General | [Link](http://arxiv.org/abs/2409.10504v1) |&#10;| Causal Language Modeling Can Elicit Search and Reasoning Capabilities on&#10; &#160;Logic Puzzles | Kulin Shah, Nishanth Dikkala, Xin Wang, Rina Panigrahy | &#160;&#160;Causal language modeling using the Transformer architecture has yielded&#10;remarkable capabilities in Large Language Models (LLMs) over the last few&#10;years. However, the extent to which fundamental search and reasoning&#10;capabilities emerged within LLMs remains a topic of ongoing debate. In this&#10;work, we study if causal language modeling can learn a complex task such as&#10;solving Sudoku puzzles. To solve a Sudoku, the model is first required to&#10;search over all empty cells of the puzzle to decide on a cell to fill and then&#10;apply an appropriate strategy to fill the decided cell. Sometimes, the&#10;application of a strategy only results in thinning down the possible values in&#10;a cell rather than concluding the exact value of the cell. In such cases,&#10;multiple strategies are applied one after the other to fill a single cell. We&#10;observe that Transformer models trained on this synthetic task can indeed learn&#10;to solve Sudokus (our model solves $94.21%$ of the puzzles fully correctly)&#10;when trained on a logical sequence of steps taken by a solver. We find that&#10;training Transformers with the logical sequence of steps is necessary and&#10;without such training, they fail to learn Sudoku. We also extend our analysis&#10;to Zebra puzzles (known as Einstein puzzles) and show that the model solves&#10;$92.04 %$ of the puzzles fully correctly. In addition, we study the internal&#10;representations of the trained Transformer and find that through linear&#10;probing, we can decode information about the set of possible values in any&#10;given cell from them, pointing to the presence of a strong reasoning engine&#10;implicit in the Transformer weights.&#10; | General | [Link](http://arxiv.org/abs/2409.10502v1) |&#10;| Alignment with nonlinear velocity couplings: collision&#45;avoidance and&#10; &#160;micro&#45;to&#45;macro mean&#45;field limits | Young&#45;Pil Choi, Micha Fabisiak, Jan Peszek | &#160;&#160;We investigate the pressureless fractional Euler&#45;alignment system with&#10;nonlinear velocity couplings, referred to as the $p$&#45;Euler&#45;alignment system.&#10;This model features a nonlinear velocity alignment force, interpreted as a&#10;density&#45;weighted fractional $p$&#45;Laplacian when the singularity parameter&#10;$alpha$ exceeds the spatial dimension $d$. Our primary goal is to establish&#10;the existence of solutions for strongly singular interactions ($alpha ge d$)&#10;and compactly supported initial conditions. We construct solutions as&#10;mean&#45;field limits of empirical measures from a kinetic variant of the&#10;$p$&#45;Euler&#45;alignment system. Specifically, we show that a sequence of empirical&#10;measures converges to a finite Radon measure, whose local density and velocity&#10;satisfy the $p$&#45;Euler&#45;alignment system. Our results are the first to prove the&#10;existence of solutions to this system in multi&#45;dimensional settings without&#10;significant initial data restrictions, covering both nonlinear ($p&gt;2$) and&#10;linear ($p=2$) cases. Additionally, we establish global existence, uniqueness,&#10;and collision avoidance for the corresponding particle ODE system under&#10;non&#45;collisional initial conditions, extending previous results for $1 &#10;e p &#10;e&#10;alpha + 2$. This analysis supports our mean&#45;field limit argument and&#10;contributes to understanding alignment models with singular communication.&#10; | General | [Link](http://arxiv.org/abs/2409.10501v1) |&#10;| Focus diverse phase retrieval test results on broadband continuous&#10; &#160;wavefront sensing in space telescope applications | Hyukmo Kang, Kyle Van Gorkom, Meghdoot Biswas, Daewook Kim, Ewan S. Douglas | &#160;&#160;Continuous wavefront sensing benefits space observatories in on&#45;orbit optical&#10;performance maintenance. To measure the phase of a wavefront, phase retrieval&#10;is an attractive technique as it uses multiple point spread function (PSF)&#10;images that are acquired by the telescope itself without extra metrology&#10;systems nor complicated calibration. The focus diverse phase retrieval utilizes&#10;PSFs from predetermined defocused positions to enhance the dynamic range of the&#10;algorithm. We describe an updated visible light active optics testbed with the&#10;addition of a linear motorized focus stage. The performance of the phase&#10;retrieval algorithm in broadband is tested under various cases. While broadband&#10;pass filters have advantages in higher signal&#45;to&#45;noise ratio (SNR), the&#10;performance of phase retrieval can be restricted due to blurred image caused by&#10;diffraction and increased computing cost. We used multiple bandpass filters (10&#10;nm, 88 nm, and 150 nm) and investigated effects of bandwidth on the accuracy&#10;and required image acquisition conditions such as SNR, reaching accuracies&#10;below 20 nm RMS wavefront error at the widest bandwidth. We also investigated&#10;the dynamic range of the phase retrieval algorithm depending on the bandwidth&#10;and required amount of defocus to expand dynamic range. Finally, we simulated&#10;the continuous wavefront sensing and correction loop with a range of&#10;statistically generated representative telescope disturbance time series to&#10;test for edge cases.&#10; | General | [Link](http://arxiv.org/abs/2409.10500v1) |&#10;| The role of higher&#45;order terms in trapped&#45;ion quantum computing with&#10; &#160;magnetic gradient induced coupling | Sebastian Nagies, Kevin T. Geier, Javed Akram, Junichi Okamoto, Dimitris Badounas, Christof Wunderlich, Michael Johanning, Philipp Hauke | &#160;&#160;Trapped&#45;ion hardware based on the Magnetic Gradient Induced Coupling (MAGIC)&#10;scheme is emerging as a promising platform for quantum computing. Nevertheless,&#10;in this (as in any other) quantum&#45;computing platform, many technical questions&#10;still have to be resolved before large&#45;scale and error&#45;tolerant applications&#10;are possible. In this work, we present a thorough discussion of the&#10;contribution of higher&#45;order terms to the MAGIC setup, which can occur due to&#10;anharmonicities in the external potential of the ion crystal (e.g., through&#10;Coulomb repulsion) or through curvature of the applied magnetic field. These&#10;terms take the form of three&#45;spin couplings as well as diverse terms that&#10;couple spins to phonons. We find that most of these are negligible in realistic&#10;situations, with only two contributions that need careful attention. First,&#10;there are parasitic longitudinal fields whose strength increases with chain&#10;length, but which can easily be compensated by a microwave detuning. Second,&#10;anharmonicities of the Coulomb interaction can lead to well&#45;known two&#45;to&#45;one&#10;conversions of phonon excitations, which can be avoided if the phonons are&#10;ground&#45;state cooled. Our detailed analysis constitutes an important&#10;contribution on the way of making magnetic&#45;gradient trapped&#45;ion quantum&#10;technology fit for large&#45;scale applications, and it may inspire new ways to&#10;purposefully design interaction terms.&#10; | General | [Link](http://arxiv.org/abs/2409.10498v1) |&#10;| MusicLIME: Explainable Multimodal Music Understanding | Theodoros Sotirou, Vassilis Lyberatos, Orfeas Menis Mastromichalakis, Giorgos Stamou | &#160;&#160;Multimodal models are critical for music understanding tasks, as they capture&#10;the complex interplay between audio and lyrics. However, as these models become&#10;more prevalent, the need for explainability grows&#45;understanding how these&#10;systems make decisions is vital for ensuring fairness, reducing bias, and&#10;fostering trust. In this paper, we introduce MusicLIME, a model&#45;agnostic&#10;feature importance explanation method designed for multimodal music models.&#10;Unlike traditional unimodal methods, which analyze each modality separately&#10;without considering the interaction between them, often leading to incomplete&#10;or misleading explanations, MusicLIME reveals how audio and lyrical features&#10;interact and contribute to predictions, providing a holistic view of the&#10;model&#39;s decision&#45;making. Additionally, we enhance local explanations by&#10;aggregating them into global explanations, giving users a broader perspective&#10;of model behavior. Through this work, we contribute to improving the&#10;interpretability of multimodal music models, empowering users to make informed&#10;choices, and fostering more equitable, fair, and transparent music&#10;understanding systems.&#10; | General | [Link](http://arxiv.org/abs/2409.10496v1) |&#10;| Incorporating Classifier&#45;Free Guidance in Diffusion Model&#45;Based&#10; &#160;Recommendation | Noah Buchanan, Susan Gauch, Quan Mai | &#160;&#160;This paper presents a diffusion&#45;based recommender system that incorporates&#10;classifier&#45;free guidance. Most current recommender systems provide&#10;recommendations using conventional methods such as collaborative or&#10;content&#45;based filtering. Diffusion is a new approach to generative AI that&#10;improves on previous generative AI approaches such as Variational Autoencoders&#10;(VAEs) and Generative Adversarial Networks (GANs). We incorporate diffusion in&#10;a recommender system that mirrors the sequence users take when browsing and&#10;rating items. Although a few current recommender systems incorporate diffusion,&#10;they do not incorporate classifier&#45;free guidance, a new innovation in diffusion&#10;models as a whole. In this paper, we present a diffusion recommender system&#10;that augments the underlying recommender system model for improved performance&#10;and also incorporates classifier&#45;free guidance. Our findings show improvements&#10;over state&#45;of&#45;the&#45;art recommender systems for most metrics for several&#10;recommendation tasks on a variety of datasets. In particular, our approach&#10;demonstrates the potential to provide better recommendations when data is&#10;sparse.&#10; | General | [Link](http://arxiv.org/abs/2409.10494v1) |&#10;| Renormalization of the Einstein&#45;Cartan Theory in First&#45;Order Form | F. T. Brandt, J. Frenkel, S. Martins&#45;Filho, D. G. C. McKeon | &#160;&#160;We examine the Einstein&#45;Cartan (EC) theory in first&#45;order form, which has a&#10;diffeomorphism as well as a local Lorentz invariance. We study the&#10;renormalizability of this theory in the framework of the Batalin&#45;Vilkovisky&#10;formalism, which allows for a gauge invariant renormalization. Using the&#10;background field method, we discuss the gauge invariance of the background&#10;effective action and analyze the Ward identities which reflect the symmetries&#10;of the EC theory. As an application, we compute, in a general background gauge,&#10;the self&#45;energy of the tetrad field at one&#45;loop order.&#10; | General | [Link](http://arxiv.org/abs/2409.10493v1) |&#10;| What we can learn from the angular differential rates (only) in&#10; &#160;semileptonic $B to D^* ell _ell$ decays | G. Martinelli, S. Simula, L. Vittorio | &#160;&#160;We present a new, simple approach to the study of semileptonic $B to D^*&#10;ell &#10;u_ell$ decays based on the angular distributions of the final state&#10;particles only. Our approach is model independent and never requires the&#10;knowledge of $vert V_{cb}vert$. By studying such distributions in the case of&#10;light leptons, a comparison between results from different data sets from the&#10;Belle and BelleII Collaborations and between data and Standard Model&#10;calculations is also given for several interesting quantities. A good&#10;consistency is observed between some of the experimental results and the&#10;theoretical predictions.&#10; | General | [Link](http://arxiv.org/abs/2409.10492v1) |&#10;| Code Vulnerability Detection: A Comparative Analysis of Emerging Large&#10; &#160;Language Models | Shaznin Sultana, Sadia Afreen, Nasir U. Eisty | &#160;&#160;The growing trend of vulnerability issues in software development as a result&#10;of a large dependence on open&#45;source projects has received considerable&#10;attention recently. This paper investigates the effectiveness of Large Language&#10;Models (LLMs) in identifying vulnerabilities within codebases, with a focus on&#10;the latest advancements in LLM technology. Through a comparative analysis, we&#10;assess the performance of emerging LLMs, specifically Llama, CodeLlama, Gemma,&#10;and CodeGemma, alongside established state&#45;of&#45;the&#45;art models such as BERT,&#10;RoBERTa, and GPT&#45;3. Our study aims to shed light on the capabilities of LLMs in&#10;vulnerability detection, contributing to the enhancement of software security&#10;practices across diverse open&#45;source repositories. We observe that CodeGemma&#10;achieves the highest F1&#45;score of 58 and a Recall of 87, amongst the recent&#10;additions of large language models to detect software security vulnerabilities.&#10; | General | [Link](http://arxiv.org/abs/2409.10490v1) |&#10;| Flash STU: Fast Spectral Transform Units | Y. Isabel Liu, Windsor Nguyen, Yagiz Devre, Evan Dogariu, Anirudha Majumdar, Elad Hazan | &#160;&#160;This paper describes an efficient, open source PyTorch implementation of the&#10;Spectral Transform Unit. We investigate sequence prediction tasks over several&#10;modalities including language, robotics, and simulated dynamical systems. We&#10;find that for the same parameter count, the STU and its variants outperform the&#10;Transformer as well as other leading state space models across various&#10;modalities.&#10; | General | [Link](http://arxiv.org/abs/2409.10489v1) |&#10;| Do Pre&#45;trained Vision&#45;Language Models Encode Object States? | Kaleb Newman, Shijie Wang, Yuan Zang, David Heffren, Chen Sun | &#160;&#160;For a vision&#45;language model (VLM) to understand the physical world, such as&#10;cause and effect, a first step is to capture the temporal dynamics of the&#10;visual world, for example how the physical states of objects evolve over time&#10;(e.g. a whole apple into a sliced apple). Our paper aims to investigate if VLMs&#10;pre&#45;trained on web&#45;scale data learn to encode object states, which can be&#10;extracted with zero&#45;shot text prompts. We curate an object state recognition&#10;dataset ChangeIt&#45;Frames, and evaluate nine open&#45;source VLMs, including models&#10;trained with contrastive and generative objectives. We observe that while these&#10;state&#45;of&#45;the&#45;art vision&#45;language models can reliably perform object&#10;recognition, they consistently fail to accurately distinguish the objects&#39;&#10;physical states. Through extensive experiments, we identify three areas for&#10;improvements for VLMs to better encode object states, namely the quality of&#10;object localization, the architecture to bind concepts to objects, and the&#10;objective to learn discriminative visual and language encoders on object&#10;states. Data and code are released.&#10; | General | [Link](http://arxiv.org/abs/2409.10488v1) |&#10;| A Host Galaxy Morphology Link Between Quasi&#45;Periodic Eruptions and Tidal&#10; &#160;Disruption Events | Olivier Gilbert, John J. Ruan, Michael Eracleous, Daryl Haggard, Jessie C. Runnoe | &#160;&#160;The physical processes that produce X&#45;ray Quasi&#45;Periodic Eruptions (QPEs)&#10;recently discovered from the nuclei of several low&#45;redshift galaxies are&#10;mysterious. Several pieces of observational evidence strongly suggest a link&#10;between QPEs and Tidal Disruption Events (TDE). Previous studies also reveal&#10;that the morphologies of TDE host galaxies are highly concentrated, with high&#10;Sersic indicies, bulge&#45;to&#45;total light (B/T) ratios, and stellar surface mass&#10;densities relative to the broader galaxy population. We use these distinctive&#10;properties to test the link between QPEs and TDEs, by comparing these&#10;parameters of QPE host galaxies to TDE host galaxies. We employ archival Legacy&#10;Survey images of a sample of 9 QPE host galaxies and a sample of 13 TDE host&#10;galaxies, and model their surface brightness profiles. We show that QPE host&#10;galaxies have high Sersic indices of ~3, high B/T ratios of ~0.5, and high&#10;surface mass densities of ~10^10 Msun kpc^&#45;2. These properties are similar to&#10;TDE host galaxies, but are in strong contrast to a mass&#45; and redshift&#45;matched&#10;control sample of galaxies. We also find tentative evidence that the central&#10;black holes in both QPE and TDE host galaxies are undermassive relative to&#10;their stellar mass. The morphological similarities between QPE and TDE host&#10;galaxies at the population level add to the mounting evidence of a physical&#10;link between these phenomena, and favor QPE models that also invoke TDEs.&#10; | General | [Link](http://arxiv.org/abs/2409.10486v1) |&#10;| Tuning the Rate of Tightly Packed Systems To Produce Planet Occurrence&#10; &#160;Trends with Galactic Height | Sarah Ballard | &#160;&#160;The formation of planetary systems has historically been considered in&#10;isolation, decoupled from processes on galactic scales. Recent findings&#10;employing data from ESA&#39;s Gaia mission challenge this narrative, identifying&#10;trends in planet occurrence with galactic kinematics and stellar age. The&#10;findings indicate changes in planet occurrence over and above the predicted&#10;changes from metallicity variation within the Milky Way, so that changes to&#10;stellar metallicity alone (long understood to be deterministic in planet&#10;outcomes) cannot explain the trends entirely. The scope of potential factors&#10;influencing planet formation has grown progressively wider, with accompanying&#10;theoretical support for galactic&#45;scale influences upon planet formation. In&#10;this manuscript, we investigate specifically how changes to the rate of Systems&#10;of Tightly&#45;packed Inner Planets (STIPs) could manifest as a trend in planet&#10;occurrence with galactic height. We focus our study upon M dwarf planetary&#10;systems for two reasons: first, they host STIPs at high rates, and secondly,&#10;their longevity makes them useful probes for kinematic trends over Gyr. We&#10;consider two models for a varying STIP rate: one in which STIP likelihood is&#10;determined by stellar age alone, irrespective of galactic time, and another in&#10;which the STIP likelihood suddenly increased in recent galactic history. Both&#10;models, which impose a higher STIP likelihood among younger stars, produce a&#10;negative gradient in planet occurrence with increasing height from the galactic&#10;midplane. We find that a step function model in which STIP likelihood increased&#10;by a factor of several ~a few Gyr ago resembles an observed trend among FGK&#10;dwarfs. We consider plausible physical mechanisms that could mimic the&#10;hypothesized model, given known links between STIP occurrence and other stellar&#10;and planetary properties.&#10; | General | [Link](http://arxiv.org/abs/2409.10485v1) |&#10;| XLM for Autonomous Driving Systems: A Comprehensive Review | Sonda Fourati, Wael Jaafar, Noura Baccar, Safwan Alfattani | &#160;&#160;Large Language Models (LLMs) have showcased remarkable proficiency in various&#10;information&#45;processing tasks. These tasks span from extracting data and&#10;summarizing literature to generating content, predictive modeling,&#10;decision&#45;making, and system controls. Moreover, Vision Large Models (VLMs) and&#10;Multimodal LLMs (MLLMs), which represent the next generation of language&#10;models, a.k.a., XLMs, can combine and integrate many data modalities with the&#10;strength of language understanding, thus advancing several information&#45;based&#10;systems, such as Autonomous Driving Systems (ADS). Indeed, by combining&#10;language communication with multimodal sensory inputs, e.g., panoramic images&#10;and LiDAR or radar data, accurate driving actions can be taken. In this&#10;context, we provide in this survey paper a comprehensive overview of the&#10;potential of XLMs towards achieving autonomous driving. Specifically, we review&#10;the relevant literature on ADS and XLMs, including their architectures, tools,&#10;and frameworks. Then, we detail the proposed approaches to deploy XLMs for&#10;autonomous driving solutions. Finally, we provide the related challenges to XLM&#10;deployment for ADS and point to future research directions aiming to enable XLM&#10;adoption in future ADS frameworks.&#10; | General | [Link](http://arxiv.org/abs/2409.10484v1) |&#10;| Efficient polarizable QM/MM using the direct reaction field Hamiltonian&#10; &#160;with electrostatic potential fitted multipole operators | Thomas P. Fay, Nicolas Ferr, Miquel Huix&#45;Rotllant | &#160;&#160;Electronic polarization and dispersion are decisive actors in determining&#10;interaction energies between molecules. These interactions have a particularly&#10;profound effect on excitation energies of molecules in complex environments,&#10;especially when the excitation involves a significant degree of charge&#10;reorganisation. The direct reaction field (DRF) approach, which has seen a&#10;recent revival of interest, provides a powerful framework for describing these&#10;interactions in quantum mechanics/molecular mechanics (QM/MM) models of&#10;systems, where a small subsystem of interest is described using quantum&#10;chemical methods and the remainder is treated with a simple MM force field. In&#10;this paper we show how the DRF approach can be combined with the electrostatic&#10;potential fitted (ESPF) multipole operator description of the QM region charge&#10;density, which reduces the scaling $mathcal{O}(N_mathrm{MM}^3)$ of the method&#10;with MM system to $mathcal{O}(N_mathrm{MM}^2)$. We also show how the DRF&#10;approach can be combined with fluctuating charge descriptions of the&#10;polarizable environment, as well as previously used atom&#45;centred&#10;dipole&#45;polarizability based models. We further show that the ESPF&#45;DRF method&#10;provides an accurate description of molecular interactions in both ground and&#10;excited electronic states of the QM system and apply it to predict the gas to&#10;aqueous solution solvatochromic shifts in the UV/visible absorption spectrum of&#10;acrolein.&#10; | General | [Link](http://arxiv.org/abs/2409.10483v1) |&#10;| Schrodinger&#39;s Memory: Large Language Models | Wei Wang, Qing Li | &#160;&#160;Memory is the foundation of LLMs&#39; functionality, yet past research has lacked&#10;an in&#45;depth exploration of their memory capabilities and underlying theory. In&#10;this paper, we apply UAT theory to explain the memory mechanism of LLMs and&#10;propose a new approach for evaluating LLM performance by comparing the memory&#10;capacities of different models. Through extensive experiments, we validate our&#10;theory and the memory abilities of LLMs. Finally, we compare the capabilities&#10;of the human brain and LLMs, highlighting both their similarities and&#10;differences in terms of working mechanisms.&#10; | General | [Link](http://arxiv.org/abs/2409.10482v1) |&#10;| Exploring 3D Face Reconstruction and Fusion Methods for Face&#10; &#160;Verification: A Case&#45;Study in Video Surveillance | Simone Maurizio La Cava, Sara Concas, Ruben Tolosana, Roberto Casula, Giulia Orr, Martin Drahansky, Julian Fierrez, Gian Luca Marcialis | &#160;&#160;3D face reconstruction (3DFR) algorithms are based on specific assumptions&#10;tailored to distinct application scenarios. These assumptions limit their use&#10;when acquisition conditions, such as the subject&#39;s distance from the camera or&#10;the camera&#39;s characteristics, are different than expected, as typically happens&#10;in video surveillance. Additionally, 3DFR algorithms follow various strategies&#10;to address the reconstruction of a 3D shape from 2D data, such as statistical&#10;model fitting, photometric stereo, or deep learning. In the present study, we&#10;explore the application of three 3DFR algorithms representative of the SOTA,&#10;employing each one as the template set generator for a face verification&#10;system. The scores provided by each system are combined by score&#45;level fusion.&#10;We show that the complementarity induced by different 3DFR algorithms improves&#10;performance when tests are conducted at never&#45;seen&#45;before distances from the&#10;camera and camera characteristics (cross&#45;distance and cross&#45;camera settings),&#10;thus encouraging further investigations on multiple 3DFR&#45;based approaches.&#10; | General | [Link](http://arxiv.org/abs/2409.10481v1) |&#10;| Addressing misspecification in contextual optimization | Omar Bennouna, Jiawei Zhang, Saurabh Amin, Asuman Ozdaglar | &#160;&#160;We study a linear contextual optimization problem where a decision maker has&#10;access to historical data and contextual features to learn a cost prediction&#10;model aimed at minimizing decision error. We adopt the predict&#45;then&#45;optimize&#10;framework for this analysis. Given that perfect model alignment with reality is&#10;often unrealistic in practice, we focus on scenarios where the chosen&#10;hypothesis set is misspecified. In this context, it remains unclear whether&#10;current contextual optimization approaches can effectively address such model&#10;misspecification. In this paper, we present a novel integrated learning and&#10;optimization approach designed to tackle model misspecification in contextual&#10;optimization. This approach offers theoretical generalizability, tractability,&#10;and optimality guarantees, along with strong practical performance. Our method&#10;involves minimizing a tractable surrogate loss that aligns with the performance&#10;value from cost vector predictions, regardless of whether the model&#10;misspecified or not, and can be optimized in reasonable time. To our knowledge,&#10;no previous work has provided an approach with such guarantees in the context&#10;of model misspecification.&#10; | General | [Link](http://arxiv.org/abs/2409.10479v1) |&#10;| Local SGD for Near&#45;Quadratic Problems: Improving Convergence under&#10; &#160;Unconstrained Noise Conditions | Andrey Sadchikov, Savelii Chezhegov, Aleksandr Beznosikov, Alexander Gasnikov | &#160;&#160;Distributed optimization plays an important role in modern large&#45;scale&#10;machine learning and data processing systems by optimizing the utilization of&#10;computational resources. One of the classical and popular approaches is Local&#10;Stochastic Gradient Descent (Local SGD), characterized by multiple local&#10;updates before averaging, which is particularly useful in distributed&#10;environments to reduce communication bottlenecks and improve scalability. A&#10;typical feature of this method is the dependence on the frequency of&#10;communications. But in the case of a quadratic target function with homogeneous&#10;data distribution over all devices, the influence of frequency of&#10;communications vanishes. As a natural consequence, subsequent studies include&#10;the assumption of a Lipschitz Hessian, as this indicates the similarity of the&#10;optimized function to a quadratic one to some extent. However, in order to&#10;extend the completeness of the Local SGD theory and unlock its potential, in&#10;this paper we abandon the Lipschitz Hessian assumption by introducing a new&#10;concept of $textit{approximate quadraticity}$. This assumption gives a new&#10;perspective on problems that have near quadratic properties. In addition,&#10;existing theoretical analyses of Local SGD often assume bounded variance. We,&#10;in turn, consider the unbounded noise condition, which allows us to broaden the&#10;class of studied problems.&#10; | General | [Link](http://arxiv.org/abs/2409.10478v1) |&#10;| SimInversion: A Simple Framework for Inversion&#45;Based Text&#45;to&#45;Image&#10; &#160;Editing | Qi Qian, Haiyang Xu, Ming Yan, Juhua Hu | &#160;&#160;Diffusion models demonstrate impressive image generation performance with&#10;text guidance. Inspired by the learning process of diffusion, existing images&#10;can be edited according to text by DDIM inversion. However, the vanilla DDIM&#10;inversion is not optimized for classifier&#45;free guidance and the accumulated&#10;error will result in the undesired performance. While many algorithms are&#10;developed to improve the framework of DDIM inversion for editing, in this work,&#10;we investigate the approximation error in DDIM inversion and propose to&#10;disentangle the guidance scale for the source and target branches to reduce the&#10;error while keeping the original framework. Moreover, a better guidance scale&#10;(i.e., 0.5) than default settings can be derived theoretically. Experiments on&#10;PIE&#45;Bench show that our proposal can improve the performance of DDIM inversion&#10;dramatically without sacrificing efficiency.&#10; | General | [Link](http://arxiv.org/abs/2409.10476v1) |&#10;| Leadership and Engagement Dynamics in Legislative Twitter Networks:&#10; &#160;Statistical Analysis and Modeling | Carolina Luque, Juan Sosa | &#160;&#160;In this manuscript, we analyze the interaction network on Twitter among&#10;members of the 117th U.S. Congress to assess the visibility of political&#10;leaders and explore how systemic properties and node attributes influence the&#10;formation of legislative connections. We employ descriptive social network&#10;statistical methods, the exponential random graph model (ERGM), and the&#10;stochastic block model (SBM) to evaluate the relative impact of network&#10;systemic properties, as well as institutional and personal traits, on the&#10;generation of online relationships among legislators. Our findings reveal that&#10;legislative networks on social media platforms like Twitter tend to reinforce&#10;the leadership of dominant political actors rather than diminishing their&#10;influence. However, we identify that these leadership roles can manifest in&#10;various forms. Additionally, we highlight that online connections within&#10;legislative networks are influenced by both the systemic properties of the&#10;network and institutional characteristics.&#10; | General | [Link](http://arxiv.org/abs/2409.10475v1) |&#10;| MacDiff: Unified Skeleton Modeling with Masked Conditional Diffusion | Lehong Wu, Lilang Lin, Jiahang Zhang, Yiyang Ma, Jiaying Liu | &#160;&#160;Self&#45;supervised learning has proved effective for skeleton&#45;based human action&#10;understanding. However, previous works either rely on contrastive learning that&#10;suffers false negative problems or are based on reconstruction that learns too&#10;much unessential low&#45;level clues, leading to limited representations for&#10;downstream tasks. Recently, great advances have been made in generative&#10;learning, which is naturally a challenging yet meaningful pretext task to model&#10;the general underlying data distributions. However, the representation learning&#10;capacity of generative models is under&#45;explored, especially for the skeletons&#10;with spacial sparsity and temporal redundancy. To this end, we propose Masked&#10;Conditional Diffusion (MacDiff) as a unified framework for human skeleton&#10;modeling. For the first time, we leverage diffusion models as effective&#10;skeleton representation learners. Specifically, we train a diffusion decoder&#10;conditioned on the representations extracted by a semantic encoder. Random&#10;masking is applied to encoder inputs to introduce a information bottleneck and&#10;remove redundancy of skeletons. Furthermore, we theoretically demonstrate that&#10;our generative objective involves the contrastive learning objective which&#10;aligns the masked and noisy views. Meanwhile, it also enforces the&#10;representation to complement for the noisy view, leading to better&#10;generalization performance. MacDiff achieves state&#45;of&#45;the&#45;art performance on&#10;representation learning benchmarks while maintaining the competence for&#10;generative tasks. Moreover, we leverage the diffusion model for data&#10;augmentation, significantly enhancing the fine&#45;tuning performance in scenarios&#10;with scarce labeled data. Our project is available at&#10;https://lehongwu.github.io/ECCV24MacDiff/.&#10; | General | [Link](http://arxiv.org/abs/2409.10473v1) |&#10;| Towards Semantic Versioning of Open Pre&#45;trained Language Model Releases&#10; &#160;on Hugging Face | Adekunle Ajibode, Abdul Ali Bangash, Filipe Roseiro Cogo, Bram Adams, Ahmed E. Hassan | &#160;&#160;The proliferation of open Pre&#45;trained Language Models (PTLMs) on model&#10;registry platforms like Hugging Face (HF) presents both opportunities and&#10;challenges for companies building products around them. Similar to traditional&#10;software dependencies, PTLMs continue to evolve after a release. However, the&#10;current state of release practices of PTLMs on model registry platforms are&#10;plagued by a variety of inconsistencies, such as ambiguous naming conventions&#10;and inaccessible model training documentation. Given the knowledge gap on&#10;current PTLM release practices, our empirical study uses a mixed&#45;methods&#10;approach to analyze the releases of 52,227 PTLMs on the most well&#45;known model&#10;registry, HF. Our results reveal 148 different naming practices for PTLM&#10;releases, with 40.87% of changes to model weight files not represented in the&#10;adopted name&#45;based versioning practice or their documentation. In addition, we&#10;identified that the 52,227 PTLMs are derived from only 299 different base&#10;models (the modified original models used to create 52,227 PTLMs), with&#10;Fine&#45;tuning and Quantization being the most prevalent modification methods&#10;applied to these base models. Significant gaps in release transparency, in&#10;terms of training dataset specifications and model card availability, still&#10;exist, highlighting the need for standardized documentation. While we&#10;identified a model naming practice explicitly differentiating between major and&#10;minor PTLM releases, we did not find any significant difference in the types of&#10;changes that went into either type of releases, suggesting that major/minor&#10;version numbers for PTLMs often are chosen arbitrarily. Our findings provide&#10;valuable insights to improve PTLM release practices, nudging the field towards&#10;more formal semantic versioning practices.&#10; | General | [Link](http://arxiv.org/abs/2409.10472v1) |&#10;| Real&#45;Time Whole&#45;Body Control of Legged Robots with Model&#45;Predictive Path&#10; &#160;Integral Control | Juan Alvarez&#45;Padilla, John Z. Zhang, Sofia Kwok, John M. Dolan, Zachary Manchester | &#160;&#160;This paper presents a system for enabling real&#45;time synthesis of whole&#45;body&#10;locomotion and manipulation policies for real&#45;world legged robots. Motivated by&#10;recent advancements in robot simulation, we leverage the efficient&#10;parallelization capabilities of the MuJoCo simulator to achieve fast sampling&#10;over the robot state and action trajectories. Our results show surprisingly&#10;effective real&#45;world locomotion and manipulation capabilities with a very&#10;simple control strategy. We demonstrate our approach on several hardware and&#10;simulation experiments: robust locomotion over flat and uneven terrains,&#10;climbing over a box whose height is comparable to the robot, and pushing a box&#10;to a goal position. To our knowledge, this is the first successful deployment&#10;of whole&#45;body sampling&#45;based MPC on real&#45;world legged robot hardware.&#10;Experiment videos and code can be found at: https://whole&#45;body&#45;mppi.github.io/&#10; | General | [Link](http://arxiv.org/abs/2409.10469v1) |&#10;| Assortativity in sympatric speciation and species classification | Joao U. F. Lizarraga, Flavia M. D. Marquitti, Marcus A. M. de Aguiar | &#160;&#160;We investigate the role of assortative mating in speciation using the&#10;sympatric model of Derrida and Higgs. The model explores the idea that genetic&#10;differences create incompatibilities between individuals, preventing mating if&#10;the number of such differences is too large. Speciation, however, only happens&#10;in this mating system if the number of genes is large. Here we show that&#10;speciation with small genome sizes can occur if assortative mating is&#10;introduced. In our model individuals are represented by three chromosomes: one&#10;responsible for reproductive compatibility, one for coding the trait on which&#10;assortativity will operate, and a neutral chromosome. Reproduction is possible&#10;if individuals are genetically similar with respect to the first chromosome,&#10;but among these compatible mating partners, the one with the most similar trait&#10;coded by the second chromosome is selected. We show that this type of&#10;assortativity facilitates speciation, which can happen with a small number of&#10;genes in the first chromosome. Species, classified according to reproductive&#10;isolation, dictated by the first chromosome, can display different traits&#10;values, as measured by the second and the third chromosomes. Therefore, species&#10;can also be identified based on similarity of the neutral trait, which works as&#10;a proxy for reproductive isolation.&#10; | General | [Link](http://arxiv.org/abs/2409.10466v1) |&#10;| A stabilized total pressure&#45;formulation of the Biot&#39;s poroelasticity&#10; &#160;equations in frequency domain: numerical analysis and applications | Cristian Crcamo, Alfonso Caiazzo, Felipe Galarce, Joaqun Mura | &#160;&#160;This work focuses on the numerical solution of the dynamics of a poroelastic&#10;material in the frequency domain. We provide a detailed stability analysis&#10;based on the application of the Fredholm alternative in the continuous case,&#10;considering a total pressure formulation of the Biot&#39;s equations. In the&#10;discrete setting, we propose a stabilized equal order finite element method&#10;complemented by an additional pressure stabilization to enhance the robustness&#10;of the numerical scheme with respect to the fluid permeability. Utilizing the&#10;Fredholm alternative, we extend the well&#45;posedness results to the discrete&#10;setting, obtaining theoretical optimal convergence for the case of linear&#10;finite elements. We present different numerical experiments to validate the&#10;proposed method. First, we consider model problems with known analytic&#10;solutions in two and three dimensions. As next, we show that the method is&#10;robust for a wide range of permeabilities, including the case of discontinuous&#10;coefficients. Lastly, we show the application for the simulation of brain&#10;elastography on a realistic brain geometry obtained from medical imaging.&#10; | General | [Link](http://arxiv.org/abs/2409.10465v1) |&#10;| New Direct Sum Tests | Alek Westover, Edward Yu, Kai Zheng | &#160;&#160;A function $f:[n]^{d} to mathbb{F}_2$ is a defn{direct sum} if there are&#10;functions $L_i:[n]to mathbb{F}_2$ such that ${f(x) = sum_{i}L_i(x_i)}$. In&#10;this work we give multiple results related to the property testing of direct&#10;sums.&#10; &#160;Our first result concerns a test proposed by Dinur and Golubev in 2019. We&#10;call their test the Diamond test and show that it is indeed a direct sum&#10;tester. More specifically, we show that if a function $f$ is $epsilon$&#45;far&#10;from being a direct sum function, then the Diamond test rejects $f$ with&#10;probability at least $Omega_{n,epsilon}(1)$. Even in the case of $n = 2$, the&#10;Diamond test is, to the best of our knowledge, novel and yields a new tester&#10;for the classic property of affinity.&#10; &#160;Apart from the Diamond test, we also analyze a broad family of direct sum&#10;tests, which at a high level, run an arbitrary affinity test on the restriction&#10;of $f$ to a random hypercube inside of $[n]^d$. This family of tests includes&#10;the direct sum test analyzed in cite{di19}, but does not include the Diamond&#10;test. As an application of our result, we obtain a direct sum test which works&#10;in the online adversary model of cite{KRV}.&#10; &#160;Finally, we also discuss a Fourier analytic interpretation of the diamond&#10;tester in the $n=2$ case, as well as prove local correction results for direct&#10;sum as conjectured by Dinur and Golubev.&#10; | General | [Link](http://arxiv.org/abs/2409.10464v1) |&#10;| Kolmogorov&#45;Arnold Networks in Low&#45;Data Regimes: A Comparative Study with&#10; &#160;Multilayer Perceptrons | Farhad Pourkamali&#45;Anaraki | &#160;&#160;Multilayer Perceptrons (MLPs) have long been a cornerstone in deep learning,&#10;known for their capacity to model complex relationships. Recently,&#10;Kolmogorov&#45;Arnold Networks (KANs) have emerged as a compelling alternative,&#10;utilizing highly flexible learnable activation functions directly on network&#10;edges, a departure from the neuron&#45;centric approach of MLPs. However, KANs&#10;significantly increase the number of learnable parameters, raising concerns&#10;about their effectiveness in data&#45;scarce environments. This paper presents a&#10;comprehensive comparative study of MLPs and KANs from both algorithmic and&#10;experimental perspectives, with a focus on low&#45;data regimes. We introduce an&#10;effective technique for designing MLPs with unique, parameterized activation&#10;functions for each neuron, enabling a more balanced comparison with KANs. Using&#10;empirical evaluations on simulated data and two real&#45;world data sets from&#10;medicine and engineering, we explore the trade&#45;offs between model complexity&#10;and accuracy, with particular attention to the role of network depth. Our&#10;findings show that MLPs with individualized activation functions achieve&#10;significantly higher predictive accuracy with only a modest increase in&#10;parameters, especially when the sample size is limited to around one hundred.&#10;For example, in a three&#45;class classification problem within additive&#10;manufacturing, MLPs achieve a median accuracy of 0.91, significantly&#10;outperforming KANs, which only reach a median accuracy of 0.53 with default&#10;hyperparameters. These results offer valuable insights into the impact of&#10;activation function selection in neural networks.&#10; | General | [Link](http://arxiv.org/abs/2409.10463v1) |&#10;| Effects of synapse location, delay and background stochastic activity on&#10; &#160;synchronising hippocampal CA1 neurons | Alessandro Fiasconaro, Michele Migliore | &#160;&#160;We study the synchronisation of neurons in a realistic model under the&#10;Hodgkin&#45;Huxley dynamics. To focus on the role of the different locations of the&#10;excitatory synapses, we use two identical neurons where the set of input&#10;signals is grouped at two different distances from the soma. The system is&#10;intended to represent a CA1 hippocampal neuron in which the synapses arriving&#10;from the CA3 neurons of the trisynaptic pathway appear to be localised in the&#10;apical dendritic region and are, in principle, either proximal or distal to the&#10;soma. Synchronisation is studied using a specifically defined spiking&#10;correlation function as a function of various parameters such as the distance&#10;from the soma of one of the synaptic groups, the inhibition weight and the&#10;associated activation delay. We found that the neurons&#39; spiking activity&#10;depends nonmonotonically on the relative dendritic location of the synapses and&#10;their inhibitory weight, whereas the synchronisation measure always decreases&#10;with inhibition, and strongly depends on its activation time delay. The&#10;background activity on the somas results essentially independent on the&#10;fluctuation intensity and strongly support the importance of the balance&#10;between inhibition and excitation for neuronal synchronization.&#10; | General | [Link](http://arxiv.org/abs/2409.10460v1) |&#10;| Efficiently Crowdsourcing Visual Importance with Punch&#45;Hole Annotation | Minsuk Chang, Soohyun Lee, Aeri Cho, Hyeon Jeon, Seokhyeon Park, Cindy Xiong Bearfield, Jinwook Seo | &#160;&#160;We introduce a novel crowdsourcing method for identifying important areas in&#10;graphical images through punch&#45;hole labeling. Traditional methods, such as gaze&#10;trackers and mouse&#45;based annotations, which generate continuous data, can be&#10;impractical in crowdsourcing scenarios. They require many participants, and the&#10;outcome data can be noisy. In contrast, our method first segments the graphical&#10;image with a grid and drops a portion of the patches (punch holes). Then, we&#10;iteratively ask the labeler to validate each annotation with holes, narrowing&#10;down the annotation only having the most important area. This approach aims to&#10;reduce annotation noise in crowdsourcing by standardizing the annotations while&#10;enhancing labeling efficiency and reliability. Preliminary findings from&#10;fundamental charts demonstrate that punch&#45;hole labeling can effectively&#10;pinpoint critical regions. This also highlights its potential for broader&#10;application in visualization research, particularly in studying large&#45;scale&#10;users&#39; graphical perception. Our future work aims to enhance the algorithm to&#10;achieve faster labeling speed and prove its utility through large&#45;scale&#10;experiments.&#10; | General | [Link](http://arxiv.org/abs/2409.10459v1) |&#10;| Full distribution of local observables in an exactly solvable current&#10; &#160;carrying steady states of a driven XXZ chain | Sandipan Manna, G J Sreejith | &#160;&#160;Current carrying steady states of interacting spins chains exhibit rich&#10;structures generated through an interplay of current induced correlations and&#10;energetic constraints from the Hamiltonian. The XXZ spin chain when coupled to&#10;maximally polarizing Lindblad terms admits an exact solution in a matrix&#10;product state (MPS) form. We use this exact solution to study the correlations&#10;and distributions of simple local spin observables in the non equilibrium&#10;steady state (NESS). We present exact expressions for spin correlators, entropy&#10;per site, cumulant generating functions for distributions of local observables&#10;in the XX limit (Ising anisotropy $Delta=0$). Further, we use the exact MPS&#10;solution in systems with $Delta&gt;0$, to numerically exactly calculate the&#10;entropy, correlations, as well as distributions of spin observables in blocks&#10;as large as $nsim 200$ sites allowing an estimation of the rate functions. The&#10;$z$ magnetization distribution is consistant with short range spin correlations&#10;in the $z$ direction while the $x$&#45;magnetization shows a double peak structure&#10;at larger $Delta$ suggesting short range ferromagnetic ordering. We find that&#10;the distribution of $z$&#45;magnetization sharpens for parameters where the current&#10;is maximized.&#10; | General | [Link](http://arxiv.org/abs/2409.10458v1) |&#10;| Mean Residual Life Ageing Intensity Function | Ashutosh Singh, Ishapathik Das, Asok Kumar Nanda, Sumen Sen | &#160;&#160;The ageing intensity function is a powerful analytical tool that provides&#10;valuable insights into the ageing process across diverse domains such as&#10;reliability engineering, actuarial science, and healthcare. Its applications&#10;continue to expand as researchers delve deeper into understanding the complex&#10;dynamics of ageing and its implications for society. One common approach to&#10;defining the ageing intensity function is through the hazard rate or failure&#10;rate function, extensively explored in scholarly literature. Equally&#10;significant to the hazard rate function is the mean residual life function,&#10;which plays a crucial role in analyzing the ageing patterns exhibited by units&#10;or components. This article introduces the mean residual life ageing intensity&#10;(MRLAI) function to delve into component ageing behaviours across various&#10;distributions. Additionally, we scrutinize the closure properties of the MRLAI&#10;function across different reliability operations. Furthermore, a new order&#10;termed the mean residual life ageing intensity order is defined to analyze the&#10;ageing behaviour of a system, and the closure property of this order under&#10;various reliability operations is discussed.&#10; | General | [Link](http://arxiv.org/abs/2409.10456v1) |&#10;| Quantile Fourier regressions for decision making under uncertainty | Arash Khojaste, Geoffrey Pritchard, Golbon Zakeri | &#160;&#160;Weconsider Markov decision processes arising from a Markov model of an&#10;underlying natural phenomenon. Such phenomena are usually periodic (e.g.&#10;annual) in time, and so the Markov processes modelling them must be&#10;time&#45;inhomogeneous, with cyclostationary rather than stationary behaviour. We&#10;describe a technique for constructing such processes that allows for periodic&#10;variations both in the values taken by the process and in the serial dependence&#10;structure. We include two illustrative numerical examples: a hydropower&#10;scheduling problem and a model of offshore wind power integration.&#10; | General | [Link](http://arxiv.org/abs/2409.10455v1) |&#10;| The Debiased Near&#45;Earth Object Population from ATLAS Telescopes | Rogerio Deienno, Larry Denneau, David Nesvorn, David Vokrouhlick, William F. Bottke, Robert Jedicke, Shantanu Naidu, Steven R. Chesley, Davide Farnocchia, Paul W. Chodas | &#160;&#160;This work is dedicated to debias the Near&#45;Earth Objects (NEO) population&#10;based on observations from the Asteroid Terrestrial&#45;impact Last Alert System&#10;(ATLAS) telescopes. We have applied similar methods used to develop the&#10;recently released NEO model generator (NEOMOD), once debiasing the NEO&#10;population using data from Catalina Sky Survey (CSS) G96 telescope. ATLAS is&#10;composed of four different telescopes. We first analyzed observational data&#10;from each of all four telescopes separately and later combined them. Our&#10;results highlight main differences between CSS and ATLAS, e.g., sky coverage&#10;and survey power at debiasing the NEO population. ATLAS has a much larger sky&#10;coverage than CSS, allowing it to find bright NEOs that would be constantly&#10;&quot;hiding&quot; from CSS. Consequently, ATLAS is more powerful than CSS at debiasing&#10;the NEO population for H $&#10;esssim$ 19. With its intrinsically greater&#10;sensitivity and emphasis on observing near opposition, CSS excels in the&#10;debiasing of smaller objects. ATLAS, as an all sky survey designed to find&#10;imminent hazardous objects, necessarily spends a significant fraction of time&#10;looking at places on the sky where objects do not appear, reducing its power&#10;for debiasing the population of small objects. We estimate a NEO population&#10;completeness of $approx$ 88%$^{+3%}_{&#45;2%}$ for H $&lt;$ 17.75 and $approx$&#10;36%$^{+1%}_{&#45;1%}$ for H $&lt;$ 22.25. Those numbers are similar to previous&#10;estimates (within error bars for H $&lt;$ 17.75) from CSS, yet, around 3% and 8%&#10;smaller at their face values, respectively. We also confirm previous finding&#10;that the $&#10;u_6$ secular resonance is the main source of small and faint NEOs&#10;at H = 28, whereas the 3:1 mean motion resonance with Jupiter dominates for&#10;larger and brighter NEOs at H = 15.&#10; | General | [Link](http://arxiv.org/abs/2409.10453v1) |&#10;| Signed Graph Autoencoder for Explainable and Polarization&#45;Aware Network&#10; &#160;Embeddings | Nikolaos Nakis, Chrysoula Kosma, Giannis Nikolentzos, Michalis Chatzianastasis, Iakovos Evdaimon, Michalis Vazirgiannis | &#160;&#160;Autoencoders based on Graph Neural Networks (GNNs) have garnered significant&#10;attention in recent years for their ability to extract informative latent&#10;representations, characterizing the structure of complex topologies, such as&#10;graphs. Despite the prevalence of Graph Autoencoders, there has been limited&#10;focus on developing and evaluating explainable neural&#45;based graph generative&#10;models specifically designed for signed networks. To address this gap, we&#10;propose the Signed Graph Archetypal Autoencoder (SGAAE) framework. SGAAE&#10;extracts node&#45;level representations that express node memberships over distinct&#10;extreme profiles, referred to as archetypes, within the network. This is&#10;achieved by projecting the graph onto a learned polytope, which governs its&#10;polarization. The framework employs a recently proposed likelihood for&#10;analyzing signed networks based on the Skellam distribution, combined with&#10;relational archetypal analysis and GNNs. Our experimental evaluation&#10;demonstrates the SGAAEs&#39; capability to successfully infer node memberships over&#10;the different underlying latent structures while extracting competing&#10;communities formed through the participation of the opposing views in the&#10;network. Additionally, we introduce the 2&#45;level network polarization problem&#10;and show how SGAAE is able to characterize such a setting. The proposed model&#10;achieves high performance in different tasks of signed link prediction across&#10;four real&#45;world datasets, outperforming several baseline models.&#10; | General | [Link](http://arxiv.org/abs/2409.10452v1) |&#10;| Why you should also use OLS estimation of tail exponents | Thiago Trafane Oliveira Santos, Daniel Oliveira Cajueiro | &#160;&#160;Even though practitioners often estimate Pareto exponents running OLS&#10;rank&#45;size regressions, the usual recommendation is to use the Hill MLE with a&#10;small&#45;sample correction instead, due to its unbiasedness and efficiency. In&#10;this paper, we advocate that you should also apply OLS in empirical&#10;applications. On the one hand, we demonstrate that, with a small&#45;sample&#10;correction, the OLS estimator is also unbiased. On the other hand, we show that&#10;the MLE assigns significantly greater weight to smaller observations. This&#10;suggests that the OLS estimator may outperform the MLE in cases where the&#10;distribution is (i) strictly Pareto but only in the upper tail or (ii)&#10;regularly varying rather than strictly Pareto. We substantiate our theoretical&#10;findings with Monte Carlo simulations and real&#45;world applications,&#10;demonstrating the practical relevance of the OLS method in estimating tail&#10;exponents.&#10; | General | [Link](http://arxiv.org/abs/2409.10448v1) |&#10;| Hydrodynamic hovering of swimming bacteria above surfaces | Pyae Hein Htet, Debasish Das, Eric Lauga | &#160;&#160;Flagellated bacteria are hydrodynamically attracted to rigid walls, yet past&#10;work shows a &#39;hovering&#39; state where they swim stably at a finite height above&#10;surfaces. We use numerics and theory to reveal the physical origin of hovering.&#10;Simulations first show that hovering requires an elongated cell body and&#10;results from a tilt away from the wall. Theoretical models then identify two&#10;essential asymmetries: the response of width&#45;asymmetric cells to active flows&#10;created by length&#45;asymmetric cells. A minimal model reconciles near and&#10;far&#45;field hydrodynamics, capturing all key features of hovering.&#10; | General | [Link](http://arxiv.org/abs/2409.10447v1) |&#10;| KoroT&#45;3E: A Personalized Musical Mnemonics Tool for Enhancing Memory&#10; &#160;Retention of Complex Computer Science Concepts | Xiangzhe Yuan, Jiajun Wang, Siying Hu, Andrew Cheung, Zhicong Lu | &#160;&#160;As the demand for computer science (CS) skills grows, mastering foundational&#10;concepts is crucial yet challenging for novice learners. To address this&#10;challenge, we present KoroT&#45;3E, an AI&#45;based system that creates personalized&#10;musical mnemonics to enhance both memory retention and understanding of&#10;concepts in CS. KoroT&#45;3E enables users to transform complex concepts into&#10;memorable lyrics and compose melodies that suit their musical preferences. We&#10;conducted semi&#45;structured interviews (n=12) to investigate why novice learners&#10;find it challenging to memorize and understand CS concepts. The findings,&#10;combined with constructivist learning theory, established our initial design,&#10;which was then refined following consultations with CS education experts. An&#10;empirical experiment(n=36) showed that those using KoroT&#45;3E (n=18)&#10;significantly outperformed the control group (n=18), with improved memory&#10;efficiency, increased motivation, and a positive learning experience. These&#10;findings demonstrate the effectiveness of integrating multimodal generative AI&#10;into CS education to create personalized and interactive learning experiences.&#10; | General | [Link](http://arxiv.org/abs/2409.10446v1) |&#10;| Deep&#45;Wide Learning Assistance for Insect Pest Classification | Toan Nguyen, Huy Nguyen, Huy Ung, Hieu Ung, Binh Nguyen | &#160;&#160;Accurate insect pest recognition plays a critical role in agriculture. It is&#10;a challenging problem due to the intricate characteristics of insects. In this&#10;paper, we present DeWi, novel learning assistance for insect pest&#10;classification. With a one&#45;stage and alternating training strategy, DeWi&#10;simultaneously improves several Convolutional Neural Networks in two&#10;perspectives: discrimination (by optimizing a triplet margin loss in a&#10;supervised training manner) and generalization (via data augmentation). From&#10;that, DeWi can learn discriminative and in&#45;depth features of insect pests&#10;(deep) yet still generalize well to a large number of insect categories (wide).&#10;Experimental results show that DeWi achieves the highest performances on two&#10;insect pest classification benchmarks (76.44% accuracy on the IP102 dataset&#10;and 99.79% accuracy on the D0 dataset, respectively). In addition, extensive&#10;evaluations and ablation studies are conducted to thoroughly investigate our&#10;DeWi and demonstrate its superiority. Our source code is available at&#10;https://github.com/toannguyen1904/DeWi.&#10; | General | [Link](http://arxiv.org/abs/2409.10445v1) |&#10;| LLM as BT&#45;Planner: Leveraging LLMs for Behavior Tree Generation in Robot&#10; &#160;Task Planning | Jicong Ao, Fan Wu, Yansong Wu, Abdalla Swikir, Sami Haddadin | &#160;&#160;Robotic assembly tasks are open challenges due to the long task horizon and&#10;complex part relations. Behavior trees (BTs) are increasingly used in robot&#10;task planning for their modularity and flexibility, but manually designing them&#10;can be effort&#45;intensive. Large language models (LLMs) have recently been&#10;applied in robotic task planning for generating action sequences, but their&#10;ability to generate BTs has not been fully investigated. To this end, We&#10;propose LLM as BT&#45;planner, a novel framework to leverage LLMs for BT generation&#10;in robotic assembly task planning and execution. Four in&#45;context learning&#10;methods are introduced to utilize the natural language processing and inference&#10;capabilities of LLMs to produce task plans in BT format, reducing manual effort&#10;and ensuring robustness and comprehensibility. We also evaluate the performance&#10;of fine&#45;tuned, fewer&#45;parameter LLMs on the same tasks. Experiments in simulated&#10;and real&#45;world settings show that our framework enhances LLMs&#39; performance in&#10;BT generation, improving success rates in BT generation through in&#45;context&#10;learning and supervised fine&#45;tuning.&#10; | General | [Link](http://arxiv.org/abs/2409.10444v1) |&#10;| The James Webb Space Telescope Absolute Flux Calibration. II.&#10; &#160;Mid&#45;Infrared Instrument Imaging and Coronagraphy | Karl D. Gordon, G. C. Sloan, Macarena Garcia Marin, Mattia Libralato, George Rieke, Jonathan A. Aguilar, Ralph Bohlin, Misty Cracraft, Marjorie Decleir, Andras Gaspar, David R. Law, Alberto Noriega&#45;Crespo, Michael Regan | &#160;&#160;The absolute flux calibration of the Mid&#45;Infrared Instrument Imaging and&#10;Coronagraphy is based on observations of multiple stars taken during the first&#10;2.5 years of JWST operations. The observations were designed to ensure that the&#10;flux calibration is valid for a range of flux densities, different subarrays,&#10;and different types of stars. The flux calibration was measured by combining&#10;observed aperture photometry corrected to infinite aperture with predictions&#10;based on previous observations and models of stellar atmospheres. A subset of&#10;these observations were combined with model point&#45;spread&#45;functions to measure&#10;the corrections to infinite aperture. Variations in the calibration factor with&#10;time, flux density, background level, type of star, subarray, integration time,&#10;rate, and well depth were investigated, and the only significant variations&#10;were with time and subarray. Observations of the same star taken approximately&#10;every month revealed a modest time&#45;dependent response loss seen mainly at the&#10;longest wavelengths. This loss is well characterized by a decaying exponential&#10;with a time constant of ~200 days. After correcting for the response loss, the&#10;band&#45;dependent scatter around the corrected average (aka repeatability) was&#10;found to range from 0.1 to 1.2%. Signals in observations taken with different&#10;subarrays can be lower by up to 3.4% compared to FULL frame. After correcting&#10;for the time and subarray dependencies, the scatter in the calibration factors&#10;measured for individual stars ranges from 1 to 4% depending on the band. The&#10;formal uncertainties on the flux calibration averaged for all observations are&#10;0.3 to 1.0%, with longer&#45;wavelength bands generally having larger&#10;uncertainties.&#10; | General | [Link](http://arxiv.org/abs/2409.10443v1) |&#10;| CtRNet&#45;X: Camera&#45;to&#45;Robot Pose Estimation in Real&#45;world Conditions Using&#10; &#160;a Single Camera | Jingpei Lu, Zekai Liang, Tristin Xie, Florian Ritcher, Shan Lin, Sainan Liu, Michael C. Yip | &#160;&#160;Camera&#45;to&#45;robot calibration is crucial for vision&#45;based robot control and&#10;requires effort to make it accurate. Recent advancements in markerless pose&#10;estimation methods have eliminated the need for time&#45;consuming physical setups&#10;for camera&#45;to&#45;robot calibration. While the existing markerless pose estimation&#10;methods have demonstrated impressive accuracy without the need for cumbersome&#10;setups, they rely on the assumption that all the robot joints are visible&#10;within the camera&#39;s field of view. However, in practice, robots usually move in&#10;and out of view, and some portion of the robot may stay out&#45;of&#45;frame during the&#10;whole manipulation task due to real&#45;world constraints, leading to a lack of&#10;sufficient visual features and subsequent failure of these approaches. To&#10;address this challenge and enhance the applicability to vision&#45;based robot&#10;control, we propose a novel framework capable of estimating the robot pose with&#10;partially visible robot manipulators. Our approach leverages the&#10;Vision&#45;Language Models for fine&#45;grained robot components detection, and&#10;integrates it into a keypoint&#45;based pose estimation network, which enables more&#10;robust performance in varied operational conditions. The framework is evaluated&#10;on both public robot datasets and self&#45;collected partial&#45;view datasets to&#10;demonstrate our robustness and generalizability. As a result, this method is&#10;effective for robot pose estimation in a wider range of real&#45;world manipulation&#10;scenarios.&#10; | General | [Link](http://arxiv.org/abs/2409.10441v1) |&#10;| Successive topological phase transitions in two distinct spin&#45;flop&#10; &#160;phases on the honeycomb lattice | Xudong Li, Jize Zhao, Jinbin Li, Qiang Luo | &#160;&#160;The Kitaev magnets with bond&#45;dependent interactions have garnered&#10;considerable attention in recent years for their ability to harbor exotic&#10;phases and nontrivial excitations. The topological magnons, which are indicated&#10;by nonzero Chern number and thermal Hall conductivity, are proposed to&#10;partially explain thermal Hall measurements in real materials. Hitherto,&#10;topological magnons have been extensively explored when the magnetic field is&#10;normal to the honeycomb plane, but their topological characteristics are less&#10;studied in the presence of in&#45;plane magnetic field. Here, we study two distinct&#10;in&#45;plane field induced spin&#45;flop phases in the $Gamma$&#45;$Gamma&#39;$ model, both&#10;of which are off&#45;diagonal couplings that have intimate relation to the Kitaev&#10;interaction. The two spin&#45;flop phases are distinguished by their out&#45;of&#45;plane&#10;spin components which can be either antiparallel or parallel, thus dubbing&#10;antiferromagnetic (AFM) or ferromagnetic (FM) spin&#45;flop phases, respectively.&#10;We map out topological phase diagrams for both phases, revealing a rich pattern&#10;of the Chern number over exchange parameters and magnetic field. We&#10;analytically calculate the boundaries of topological phase transitions when the&#10;magnetic field is along the $a$ and $b$ directions. We find that the thermal&#10;Hall conductivity and its derivative display contrasting behaviors when&#10;crossing different topological phase transitions. The striking difference of&#10;the two phases lies in that when the magnetic field is along the $b$ direction,&#10;topological magnons are totally absent in the AFM spin&#45;flop phase, while they&#10;can survive in the FM analogue in certain parameter regions.&#10; | General | [Link](http://arxiv.org/abs/2409.10439v1) |&#10;| A functorial approach to $n$&#45;abelian categories | Vitor Gulisz | &#160;&#160;We develop a functorial approach to the study of $n$&#45;abelian categories by&#10;reformulating their axioms in terms of their categories of finitely presented&#10;functors. Such an approach allows the use of classical homological algebra and&#10;representation theory techniques to understand higher homological algebra. As&#10;an application, we present two possible generalizations of the axioms &quot;every&#10;monomorphism is a kernel&quot; and &quot;every epimorphism is a cokernel&quot; of an abelian&#10;category to $n$&#45;abelian categories. We also specialize our results to modules&#10;over rings, thereby describing when the category of finitely generated&#10;projective modules over a ring is $n$&#45;abelian. Moreover, we establish a&#10;correspondence for $n$&#45;abelian categories with additive generators, which&#10;extends the higher Auslander correspondence.&#10; | General | [Link](http://arxiv.org/abs/2409.10438v1) |&#10;| Color symmetry breaking in the Potts spin glass | Jean&#45;Christophe Mourrat | &#160;&#160;The Potts spin glass is an analogue of the Sherrington&#45;Kirkpatrick model in&#10;which each spin can take one of $kappa$ possible values, which we interpret as&#10;colors. It was suggested in arXiv:2310.06745 that the order parameter for this&#10;model is always invariant with respect to permutations of the colors. We show&#10;here that this is false whenever $kappa ge 58$.&#10; | General | [Link](http://arxiv.org/abs/2409.10437v1) |&#10;| Infector characteristics exposed by spatial analysis of SARS&#45;CoV&#45;2&#10; &#160;sequence and demographic data analysed at fine geographical scales | Anna Gama, Samantha Lycett, Will Harvey, Joseph Hughes, Sema Nickbakhsh, David L Robertson, Alison Smith Palmer, Anthony Wood, Rowland Kao | &#160;&#160;Characterising drivers of SARS&#45;CoV&#45;2 circulation is crucial for understanding&#10;COVID&#45;19 because of the severity of control measures adopted during the&#10;pandemic. Whole genome sequence data augmented with demographic metadata&#10;provides the best opportunity to do this. We use Random Forest Decision Tree&#10;models to analyse a combination of over 4000 SARS&#45;CoV2 sequences from a densely&#10;sampled, mixed urban and rural population (Tayside) in Scotland in the period&#10;from August 2020 to July 2021, with fine scale geographical and&#10;socio&#45;demographic metadata. Comparing periods in versus out of &quot;lockdown&quot;&#10;restrictions, we show using genetic distance relationships that individuals&#10;from more deprived areas are more likely to get infected during lockdown but&#10;less likely to spread the infection further. As disadvantaged communities were&#10;the most affected by both COVID&#45;19 and its restrictions, our finding has&#10;important implications for informing future approaches to control future&#10;pandemics driven by similar respiratory infections.&#10; | General | [Link](http://arxiv.org/abs/2409.10436v1) |&#10;| A study of pure multi&#45;strange hadrons production in Pb+Pb collisions at&#10; &#160;LHC energies using HYDJET++ model | Gauri Devi, B. K. Singh | &#160;&#160;For the present work, we have used the HYDJET++ model to explore the&#10;production of pure multi&#45;strange hadrons in Pb+Pb collisions at&#10;$sqrt{s_{NN}}$= 2.76 TeV and $sqrt{s_{NN}}$= 5.02 TeV collision energies,&#10;respectively. We have simulated the $p_{T}$&#45;spectra and elliptic flow ($v_{2}$)&#10;of $phi$&#45;meson and $Omega$&#45;baryons comparing our results with ALICE&#10;experimental data and several phenomenological models (HIJING/$Boverline{B}$,&#10;VISHNU, EPOS, AMPT, and Krakow) across various centrality intervals.&#10;Additionally, we have calculated the nuclear modification factors ($R_{AA}$ and&#10;$R_{CP}$), which provide a perception of jet quenching phenomena. Hence, our&#10;findings enable the study of the energy and system dependence of $phi$ and&#10;$Omega$ hadrons production over a wide range of ultra&#45;relativistic collision&#10;energies. We also present the particle ratios ($Omega/phi$,&#10;$overline{Omega}^{+}/Omega^{&#45;}$, $Omega/pi$, and $phi/pi$), offering&#10;insights on the strangeness enhancement and chemical properties of the medium&#10;at both LHC collision energies.&#10; | General | [Link](http://arxiv.org/abs/2409.10435v1) |&#10;| Magnetic metamaterials by ion&#45;implantation | Christina Vantaraki, Petter Strm, Tuan T. Tran, Matas P. Grassi, Giovanni Fevola, Michael Foerster, Jerzy T. Sadowski, Daniel Primetzhofer, Vassilios Kapaklis | &#160;&#160;We present a method for the additive fabrication of planar magnetic&#10;nanoarrays with minimal surface roughness. Synthesis is accomplished by&#10;combining electron&#45;beam lithography, used to generate nanometric patterned&#10;masks, with ion implantation in thin films. By implanting $^{56}$Fe$^{+}$ ions,&#10;we are able to introduce magnetic functionality in a controlled manner into&#10;continuous Pd thin films, achieving 3D spatial resolution down to a few tens of&#10;nanometers. Our results demonstrate the successful application of this&#10;technique in fabricating square artificial spin ice lattices, which exhibit&#10;well&#45;defined magnetization textures and interactions among the patterned&#10;magnetic elements.&#10; | General | [Link](http://arxiv.org/abs/2409.10433v1) |&#10;| Structure&#45;preserving learning for multi&#45;symplectic PDEs | Sleyman Yldz, Pawan Goyal, Peter Benner | &#160;&#160;This paper presents an energy&#45;preserving machine learning method for&#10;inferring reduced&#45;order models (ROMs) by exploiting the multi&#45;symplectic form&#10;of partial differential equations (PDEs). The vast majority of&#10;energy&#45;preserving reduced&#45;order methods use symplectic Galerkin projection to&#10;construct reduced&#45;order Hamiltonian models by projecting the full models onto a&#10;symplectic subspace. However, symplectic projection requires the existence of&#10;fully discrete operators, and in many cases, such as black&#45;box PDE solvers,&#10;these operators are inaccessible. In this work, we propose an energy&#45;preserving&#10;machine learning method that can infer the dynamics of the given PDE using data&#10;only, so that the proposed framework does not depend on the fully discrete&#10;operators. In this context, the proposed method is non&#45;intrusive. The proposed&#10;method is grey box in the sense that it requires only some basic knowledge of&#10;the multi&#45;symplectic model at the partial differential equation level. We prove&#10;that the proposed method satisfies spatially discrete local energy conservation&#10;and preserves the multi&#45;symplectic conservation laws. We test our method on the&#10;linear wave equation, the Korteweg&#45;de Vries equation, and the&#10;Zakharov&#45;Kuznetsov equation. We test the generalization of our learned models&#10;by testing them far outside the training time interval.&#10; | General | [Link](http://arxiv.org/abs/2409.10432v1) |&#10;| Hippocampal synchronization in a realistic CA1 neuron model | Alessandro Fiasconaro, Michele Migliore | &#160;&#160;This work delves into studying the synchronization in two realistic neuron&#10;models using Hodgkin&#45;Huxley dynamics. Unlike simplistic point&#45;like models,&#10;excitatory synapses are here randomly distributed along the dendrites,&#10;introducing strong stochastic contributions into their signal propagation. To&#10;focus on the role of different excitatory positions, we use two copies of the&#10;same neuron whose synapses are located at different distances from the soma and&#10;are exposed to identical Poissonian distributed current pulses. The&#10;synchronization is investigated through a specifically defined spiking&#10;correlation function, and its behavior is analyzed as a function of several&#10;parameters: inhibition weight, distance from the soma of one synaptic group,&#10;excitatory inactivation delay, and weight of the excitatory synapses.&#10; | General | [Link](http://arxiv.org/abs/2409.10431v1) |&#10;| Meta&#45;Whisper: Speech&#45;Based Meta&#45;ICL for ASR on Low&#45;Resource Languages | Ming&#45;Hao Hsu, Kuan Po Huang, Hung&#45;yi Lee | &#160;&#160;This paper presents Meta&#45;Whisper, a novel approach to improve automatic&#10;speech recognition (ASR) for low&#45;resource languages using the Whisper model. By&#10;leveraging Meta In&#45;Context Learning (Meta&#45;ICL) and a k&#45;Nearest Neighbors (KNN)&#10;algorithm for sample selection, Meta&#45;Whisper enhances Whisper&#39;s ability to&#10;recognize speech in unfamiliar languages without extensive fine&#45;tuning.&#10;Experiments on the ML&#45;SUPERB dataset show that Meta&#45;Whisper significantly&#10;reduces the Character Error Rate (CER) for low&#45;resource languages compared to&#10;the original Whisper model. This method offers a promising solution for&#10;developing more adaptable multilingual ASR systems, particularly for languages&#10;with limited resources.&#10; | General | [Link](http://arxiv.org/abs/2409.10429v1) |&#10;| User&#45;Authenticated Device&#45;Independent Quantum Secure Direct&#10; &#160;Communication Protocol | Nayana Das, Saikat Basu, Goutam Paul, Vijay S. Rao | &#160;&#160;Device&#45;Independent Quantum Secure Direct Communication (DI&#45;QSDC) enhances&#10;quantum cryptography by enabling secure message transmission without relying on&#10;the trustworthiness of the devices involved. This approach mitigates risks&#10;associated with compromised or untrusted devices, common in traditional quantum&#10;communication.&#10; &#160;In this paper, we propose the first of its kind DI&#45;QSDC protocol with user&#10;identity authentication. This ensures the authenticity of both the sender and&#10;receiver prior to message exchange. We then discuss the security of the&#10;proposed protocol against common attacks, demonstrating that no eavesdropper&#10;gains any information from either the quantum or the classical channel. Next,&#10;we implement the protocol on IBM&#39;s quantum hardware and evaluate its&#10;performance in a realistic noisy environment. Additionally, by simulating&#10;common attack models, we showcase that the protocol is secure against any&#10;eavesdropper in the channel. These findings highlight the protocol&#39;s robust&#10;security and practical feasibility for real&#45;world secure quantum communication.&#10; | General | [Link](http://arxiv.org/abs/2409.10427v1) |&#10;| Role of kinematic constraints in the time reversal symmetry breaking of&#10; &#160;a model active matter | Soumen Das, Shankar Ghosh, Tridib Sadhu, Juliane U Klamser | &#160;&#160;Active&#45;matter systems are inherently out&#45;of&#45;equilibrium and perform&#10;mechanical work by utilizing their internal energy sources. Breakdown of&#10;time&#45;reversal symmetry (BTRS) is a hallmark of such dissipative non&#45;equilibrium&#10;dynamics. We introduce a robust, experimentally accessible, noninvasive,&#10;quantitative measure of BTRS in terms of the Kullback&#45;Leibler divergence in&#10;collision events, demonstrated in our novel artificial active matter, comprised&#10;of battery&#45;powered spherical rolling robots whose energetics in different modes&#10;of motion can be measured with high precision. Our dimensionless measure&#10;characterizes how dissipation and internal energetics are influenced by&#10;kinematic constraints from interactions with the environment. We propose this&#10;measure of BTRS as an empirical estimate of the distance from equilibrium. An&#10;energetic insight into this departure of active matter from equilibrium comes&#10;from our demonstration of a non&#45;trivial fluctuation symmetry, which reveals a&#10;potentially universal thermodynamic characteristic of active energetics. As a&#10;many&#45;body consequence of BTRS in our experimental active system, we demonstrate&#10;the emergence of activity&#45;induced herding, which has no equilibrium analogue.&#10; | General | [Link](http://arxiv.org/abs/2409.10425v1) |&#10;| Unveiling V Modes: Enhancing CMB Sensitivity to BSM Physics with a&#10; &#160;Non&#45;Ideal Half&#45;Wave Plate | N. Raffuzzi, M. Lembo, S. Giardiello, M. Gerbino, M. Lattanzi, P. Natoli, L. Pagano | &#160;&#160;V&#45;mode polarization of the cosmic microwave background is expected to be&#10;vanishingly small in the $Lambda$CDM model and, hence, usually ignored.&#10;Nonetheless, several astrophysical effects, as well as beyond standard model&#10;physics could produce it at a detectable level. A realistic half&#45;wave plate &#45;&#10;an optical element commonly used in CMB experiments to modulate the polarized&#10;signal &#45; can provide sensitivity to V modes without significantly spoiling that&#10;to linear polarization. We assess this sensitivity for some new&#45;generation CMB&#10;experiments, such as the LiteBIRD satellite, the ground&#45;based Simons&#10;Observatory and a CMB&#45;S4&#45;like experiment. We forecast the efficiency of these&#10;experiments to constrain the phenomenology of certain classes of BSM models&#10;inducing mixing of linear polarization states and generation of V modes in the&#10;CMB. We find that new&#45;generation experiments can improve current limits by&#10;1&#45;to&#45;3 orders of magnitude, depending on the data combination. The inclusion of&#10;V&#45;mode information dramatically boosts the sensitivity to these BSM models.&#10; | General | [Link](http://arxiv.org/abs/2409.10424v1) |&#10;| Initial data for a deformed isolated horizon | Ale Flandera, David Kofro, Tom Ledvinka | &#160;&#160;Within the isolated horizon formalism, we investigate a static axisymmetric&#10;space&#45;time of a black hole influenced by matter in its neighborhood. To&#10;illustrate the role of ingredients and assumptions in this formalism, we first&#10;show how, in spherical symmetry, the field equations and gauge conditions imply&#10;the isolated horizon initial data leading to the Schwarzschild space&#45;time.&#10;Then, we construct the initial data for a static axisymmetric isolated horizon&#10;representing a deformed black hole. The space&#45;time description in the&#10;Bondi&#45;like coordinates is then found as a series expansion in the vicinity of&#10;the horizon. To graphically illustrate this construction, we also find a&#10;numerical solution for a black hole deformed by a particular analytic model of&#10;a thin accretion disk. We also discuss how an accretion disk affects the&#10;analytical properties of the horizon geometry.&#10; | General | [Link](http://arxiv.org/abs/2409.10423v1) |&#10;| Learning Semi&#45;Supervised Medical Image Segmentation from Spatial&#10; &#160;Registration | Qianying Liu, Paul Henderson, Xiao Gu, Hang Dai, Fani Deligianni | &#160;&#160;Semi&#45;supervised medical image segmentation has shown promise in training&#10;models with limited labeled data and abundant unlabeled data. However,&#10;state&#45;of&#45;the&#45;art methods ignore a potentially valuable source of unsupervised&#10;semantic information &#45;&#45; spatial registration transforms between image volumes.&#10;To address this, we propose CCT&#45;R, a contrastive cross&#45;teaching framework&#10;incorporating registration information. To leverage the semantic information&#10;available in registrations between volume pairs, CCT&#45;R incorporates two&#10;proposed modules: Registration Supervision Loss (RSL) and Registration&#45;Enhanced&#10;Positive Sampling (REPS). The RSL leverages segmentation knowledge derived from&#10;transforms between labeled and unlabeled volume pairs, providing an additional&#10;source of pseudo&#45;labels. REPS enhances contrastive learning by identifying&#10;anatomically&#45;corresponding positives across volumes using registration&#10;transforms. Experimental results on two challenging medical segmentation&#10;benchmarks demonstrate the effectiveness and superiority of CCT&#45;R across&#10;various semi&#45;supervised settings, with as few as one labeled case. Our code is&#10;available at&#10;https://github.com/kathyliu579/ContrastiveCross&#45;teachingWithRegistration.&#10; | General | [Link](http://arxiv.org/abs/2409.10422v1) |&#10;| Multidimensional Deconvolution with Profiling | Huanbiao Zhu, Krish Desai, Mikael Kuusela, Vinicius Mikuni, Benjamin Nachman, Larry Wasserman | &#160;&#160;In many experimental contexts, it is necessary to statistically remove the&#10;impact of instrumental effects in order to physically interpret measurements.&#10;This task has been extensively studied in particle physics, where the&#10;deconvolution task is called unfolding. A number of recent methods have shown&#10;how to perform high&#45;dimensional, unbinned unfolding using machine learning.&#10;However, one of the assumptions in all of these methods is that the detector&#10;response is accurately modeled in the Monte Carlo simulation. In practice, the&#10;detector response depends on a number of nuisance parameters that can be&#10;constrained with data. We propose a new algorithm called Profile OmniFold&#10;(POF), which works in a similar iterative manner as the OmniFold (OF) algorithm&#10;while being able to simultaneously profile the nuisance parameters. We&#10;illustrate the method with a Gaussian example as a proof of concept&#10;highlighting its promising capabilities.&#10; | General | [Link](http://arxiv.org/abs/2409.10421v1) |&#10;| HiFi&#45;CS: Towards Open Vocabulary Visual Grounding For Robotic Grasping&#10; &#160;Using Vision&#45;Language Models | Vineet Bhat, Prashanth Krishnamurthy, Ramesh Karri, Farshad Khorrami | &#160;&#160;Robots interacting with humans through natural language can unlock numerous&#10;applications such as Referring Grasp Synthesis (RGS). Given a text query, RGS&#10;determines a stable grasp pose to manipulate the referred object in the robot&#39;s&#10;workspace. RGS comprises two steps: visual grounding and grasp pose estimation.&#10;Recent studies leverage powerful Vision&#45;Language Models (VLMs) for visually&#10;grounding free&#45;flowing natural language in real&#45;world robotic execution.&#10;However, comparisons in complex, cluttered environments with multiple instances&#10;of the same object are lacking. This paper introduces HiFi&#45;CS, featuring&#10;hierarchical application of Featurewise Linear Modulation (FiLM) to fuse image&#10;and text embeddings, enhancing visual grounding for complex attribute rich text&#10;queries encountered in robotic grasping. Visual grounding associates an object&#10;in 2D/3D space with natural language input and is studied in two scenarios:&#10;Closed and Open Vocabulary. HiFi&#45;CS features a lightweight decoder combined&#10;with a frozen VLM and outperforms competitive baselines in closed vocabulary&#10;settings while being 100x smaller in size. Our model can effectively guide&#10;open&#45;set object detectors like GroundedSAM to enhance open&#45;vocabulary&#10;performance. We validate our approach through real&#45;world RGS experiments using&#10;a 7&#45;DOF robotic arm, achieving 90.33% visual grounding accuracy in 15 tabletop&#10;scenes. We include our codebase in the supplementary material.&#10; | General | [Link](http://arxiv.org/abs/2409.10419v1) |&#10;| X&#45;ray reverberation as an explanation for UV/optical variability in&#10; &#160;nearby Seyferts | M. Papoutsis, I. E. Papadakis, C. Panagiotou, M. Doviak, E. Kammoun | &#160;&#160;Active galactic nuclei (AGNs) are known to be variable across all&#10;wavelengths. Significant observational efforts have been invested in the last&#10;decade in studying their ultraviolet (UV) and optical variability. Long and&#10;densely sampled, multi&#45;wavelength monitoring campaigns of numerous Seyfert&#10;galaxies have been conducted with the aim of determining the X&#45;ray/UV/optical&#10;continuum time lags. Time&#45;lag studies can be used to constrain theoretical&#10;models. The observed time lags can be explained by thermal reprocessing of the&#10;X&#45;rays illuminating the accretion disc (known as the X&#45;ray reverberation&#10;model). However, the observed light curves contain more information that can be&#10;used to further constrain physical models. Our primary objective is to&#10;investigate whether, in addition to time lags, the X&#45;ray reverberation model&#10;can also explain the UV/optical variability amplitude of nearby Seyferts. To do&#10;this, we measured the excess variance of four sources (namely Mrk 509, NGC&#10;4151, NGC 2617, and Mrk 142) as a function of wavelength using data from&#10;archival long, multi&#45;wavelength campaigns with Swift, and ground&#45;based&#10;telescopes. We also computed the model excess variance in the case of the X&#45;ray&#10;reverberation model by determining the disc&#39;s transfer function and assuming a&#10;bending power law for the X&#45;ray power spectrum. We tested the validity of the&#10;model by comparing the measured and model variances for a range of accretion&#10;rates and X&#45;ray source heights. We conclude that the X&#45;ray thermal&#10;reverberation model can fit both the continuum, UV/optical time lags, as well&#10;as the variance in these AGNs, for the same physical parameters. Our results&#10;suggest that the accretion disc is constant and that all the observed&#10;UV/optical variations, on timescales of days and up to a few weeks, can be&#10;fully explained by the variable X&#45;rays as they illuminate the accretion disc.&#10; | General | [Link](http://arxiv.org/abs/2409.10417v1) |&#10;| Local central limit theorem for Mallows measure | Alexey Bufetov, Kailun Chen | &#160;&#160;We study the statistics of the Mallows measure on permutations in the limit&#10;pioneered by Starr (2009). Our main result is the local central limit theorem&#10;for its height function. We also re&#45;derive versions of the law of large numbers&#10;and the large deviation principle, obtain the standard central limit theorem&#10;from the local one, and establish a multi&#45;point version of the local central&#10;limit theorem.&#10; | General | [Link](http://arxiv.org/abs/2409.10415v1) |&#10;| On interactive anisotropic walks in two dimensions generated from a&#10; &#160;three state opinion dynamics model | Surajit Saha, Parongama Sen | &#160;&#160;A system of interacting walkers on a two&#45;dimensional space where the dynamics&#10;of each walker are governed by the opinions of agents of a three&#45;state opinion&#10;dynamics model are considered. Such walks, inspired by Ising&#45;like models and&#10;opinions dynamics models, are usually considered in one&#45;dimensional virtual&#10;spaces. Here, the mapping is done in such a way that the walk is directed along&#10;the $y$ axis while it can move either way along the $x$ axis. We explore the&#10;properties of such walks as the parameter representing the noise in the opinion&#10;dynamics model, responsible for a continuous phase transition, is varied. The&#10;walk features show marked differences as the system crosses the critical point.&#10;The bivariate distribution of the displacements below the critical point is a&#10;modified biased Gaussian function of x and y which is symmetric about the X&#10;axis.&#10; &#160;The marginal probability distributions can be extracted and the scaling forms&#10;of different quantities, showing power law behaviour, are obtained. The&#10;directed nature of the walk is reflected in the marginal distributions as well&#10;as in the exponents.&#10; | General | [Link](http://arxiv.org/abs/2409.10413v1) |&#10;| A Large&#45;Scale Privacy Assessment of Android Third&#45;Party SDKs | Mark Huasong Meng, Chuan Yan, Yun Hao, Qing Zhang, Zeyu Wang, Kailong Wang, Sin Gee Teo, Guangdong Bai, Jin Song Dong | &#160;&#160;Third&#45;party Software Development Kits (SDKs) are widely adopted in Android&#10;app development, to effortlessly accelerate development pipelines and enhance&#10;app functionality. However, this convenience raises substantial concerns about&#10;unauthorized access to users&#39; privacy&#45;sensitive information, which could be&#10;further abused for illegitimate purposes like user tracking or monetization.&#10;Our study offers a targeted analysis of user privacy protection among Android&#10;third&#45;party SDKs, filling a critical gap in the Android software supply chain.&#10;It focuses on two aspects of their privacy practices, including data&#10;exfiltration and behavior&#45;policy compliance (or privacy compliance), utilizing&#10;techniques of taint analysis and large language models. It covers 158&#10;widely&#45;used SDKs from two key SDK release platforms, the official one and a&#10;large alternative one. From them, we identified 338 instances of privacy data&#10;exfiltration. On the privacy compliance, our study reveals that more than 30%&#10;of the examined SDKs fail to provide a privacy policy to disclose their data&#10;handling practices. Among those that provide privacy policies, 37% of them&#10;over&#45;collect user data, and 88% falsely claim access to sensitive data. We&#10;revisit the latest versions of the SDKs after 12 months. Our analysis&#10;demonstrates a persistent lack of improvement in these concerning trends. Based&#10;on our findings, we propose three actionable recommendations to mitigate the&#10;privacy leakage risks and enhance privacy protection for Android users. Our&#10;research not only serves as an urgent call for industry attention but also&#10;provides crucial insights for future regulatory interventions.&#10; | General | [Link](http://arxiv.org/abs/2409.10411v1) |&#10;| A point process approach for the classification of noisy calcium imaging&#10; &#160;data | Arianna Burzacchi, Nicoletta D&#39;Angelo, David Payares&#45;Garcia, Jorge Mateu | &#160;&#160;We study noisy calcium imaging data, with a focus on the classification of&#10;spike traces. As raw traces obscure the true temporal structure of neuron&#39;s&#10;activity, we performed a tuned filtering of the calcium concentration using two&#10;methods: a biophysical model and a kernel mapping. The former characterizes&#10;spike trains related to a particular triggering event, while the latter filters&#10;out the signal and refines the selection of the underlying neuronal response.&#10;Transitioning from traditional time series analysis to point process theory,&#10;the study explores spike&#45;time distance metrics and point pattern prototypes to&#10;describe repeated observations. We assume that the analyzed neuron&#39;s firing&#10;events, i.e. spike occurrences, are temporal point process events. In&#10;particular, the study aims to categorize 47 point patterns by depth, assuming&#10;the similarity of spike occurrences within specific depth categories. The&#10;results highlight the pivotal roles of depth and stimuli in discerning diverse&#10;temporal structures of neuron firing events, confirming the point process&#10;approach based on prototype analysis is largely useful in the classification of&#10;spike traces.&#10; | General | [Link](http://arxiv.org/abs/2409.10409v1) |&#10;| Variational closures for composite homogenised fluid flows | Theo Diamantakis, Ruiao Hu | &#160;&#160;The Stochastic Advection by Lie Transport is a variational formulation of&#10;stochastic fluid dynamics introduced to model the effects of unresolved scales,&#10;whilst preserving the geometric structure of ideal fluid flows. In this work,&#10;we show that the SALT equations can arise from the decomposition of the fluid&#10;flow map into its mean and fluctuating components. The fluctuating component is&#10;realised as a prescribed stochastic diffeomorphism that introduces stochastic&#10;transport into the system and we construct it using homogenisation theory. The&#10;dynamics of the mean component are derived from a variational principle&#10;utilising particular forms of variations that preserve the composite structure&#10;of the flow. Using a new variational principle, we show that SALT equations can&#10;arise from random Lagrangians and are equivalent to random coefficient PDEs. We&#10;also demonstrate how to modify the composite flow and the associated&#10;variational principle to derive models inspired by the Lagrangian Averaged&#10;Euler&#45;Poincare (LAEP) theory.&#10; | General | [Link](http://arxiv.org/abs/2409.10408v1) |&#10;| Bitcoin Transaction Behavior Modeling Based on Balance Data | Yu Zhang, Claudio Tessone | &#160;&#160;When analyzing Bitcoin users&#39; balance distribution, we observed that it&#10;follows a log&#45;normal pattern. Drawing parallels from the successful application&#10;of Gibrat&#39;s law of proportional growth in explaining city size and word&#10;frequency distributions, we tested whether the same principle could account for&#10;the log&#45;normal distribution in Bitcoin balances. However, our calculations&#10;revealed that the exponent parameters in both the drift and variance terms&#10;deviate slightly from one. This suggests that Gibrat&#39;s proportional growth rule&#10;alone does not fully explain the log&#45;normal distribution observed in Bitcoin&#10;users&#39; balances. During our exploration, we discovered an intriguing&#10;phenomenon: Bitcoin users tend to fall into two distinct categories based on&#10;their behavior, which we refer to as ``poor&quot; and ``wealthy&quot; users. Poor users,&#10;who initially purchase only a small amount of Bitcoin, tend to buy more&#10;bitcoins first and then sell out all their holdings gradually over time. The&#10;certainty of selling all their coins is higher and higher with time. In&#10;contrast, wealthy users, who acquire a large amount of Bitcoin from the start,&#10;tend to sell off their holdings over time. The speed at which they sell their&#10;bitcoins is lower and lower over time and they will hold at least a small part&#10;of their initial holdings at last. Interestingly, the wealthier the user, the&#10;larger the proportion of their balance and the higher the certainty they tend&#10;to sell. This research provided an interesting perspective to explore bitcoin&#10;users&#39; behaviors which may apply to other finance markets.&#10; | General | [Link](http://arxiv.org/abs/2409.10407v1) |&#10;| Stochastic Data&#45;Driven Predictive Control: Chance&#45;Constraint&#10; &#160;Satisfaction with Identified Multi&#45;step Predictors | Haldun Balim, Andrea Carron, Melanie N. Zeilinger, Johannes Khler | &#160;&#160;We propose a novel data&#45;driven stochastic model predictive control framework&#10;for uncertain linear systems with noisy output measurements. Our approach&#10;leverages multi&#45;step predictors to efficiently propagate uncertainty, ensuring&#10;chance constraint satisfaction with minimal conservatism. In particular, we&#10;present a strategy to identify multi&#45;step predictors and quantify the&#10;associated uncertainty using a surrogate (data&#45;driven) state space model. Then,&#10;we utilize the derived distribution to formulate a constraint tightening that&#10;ensures chance constraint satisfaction. A numerical example highlights the&#10;reduced conservatism of handling parametric uncertainty in the proposed method&#10;compared to state&#45;of&#45;the&#45;art solutions.&#10; | General | [Link](http://arxiv.org/abs/2409.10405v1) |&#10;| A Knowledge&#45;Enhanced Disease Diagnosis Method Based on Prompt Learning&#10; &#160;and BERT Integration | Zhang Zheng | &#160;&#160;This paper proposes a knowledge&#45;enhanced disease diagnosis method based on a&#10;prompt learning framework. The method retrieves structured knowledge from&#10;external knowledge graphs related to clinical cases, encodes it, and injects it&#10;into the prompt templates to enhance the language model&#39;s understanding and&#10;reasoning capabilities for the task.We conducted experiments on three public&#10;datasets: CHIP&#45;CTC, IMCS&#45;V2&#45;NER, and KUAKE&#45;QTR. The results show that the&#10;proposed method significantly outperforms existing models across multiple&#10;evaluation metrics, with an F1 score improvement of 2.4% on the CHIP&#45;CTC&#10;dataset, 3.1% on the IMCS&#45;V2&#45;NER dataset,and 4.2% on the KUAKE&#45;QTR dataset.&#10;Additionally,ablation studies confirmed the critical role of the knowledge&#10;injection module,as the removal of this module resulted in a significant drop&#10;in F1 score. The experimental results demonstrate that the proposed method not&#10;only effectively improves the accuracy of disease diagnosis but also enhances&#10;the interpretability of the predictions, providing more reliable support and&#10;evidence for clinical diagnosis.&#10; | General | [Link](http://arxiv.org/abs/2409.10403v1) |&#10;| A Statistical Equilibrium Approach to Adam Smith&#39;s Labor Theory of Value | Ellis Scharfenaker, Bruno Theodosio, Duncan K. Foley | &#160;&#160;Adam Smith&#39;s inquiry into the emergence and stability of the&#10;self&#45;organization of the division of labor in commodity production and exchange&#10;is considered using statistical equilibrium methods from statistical physics.&#10;We develop a statistical equilibrium model of the distribution of independent&#10;direct producers in a hub&#45;and&#45;spoke framework that predicts both the center of&#10;gravity of producers across lines of production as well as the endogenous&#10;fluctuations between lines of production that arise from Smith&#39;s concept of&#10;&quot;perfect liberty&quot;. The ergodic distribution of producers implies a long&#45;run&#10;balancing of &quot;advantages to disadvantages&quot; across lines of employment and&#10;gravitation of market prices around Smith&#39;s natural prices.&#10; | General | [Link](http://arxiv.org/abs/2409.10402v1) |&#10;| Hydrodynamic mechanism for stable spindle positioning in meiosis II&#10; &#160;oocytes | Weida Liao, Eric Lauga | &#160;&#160;Cytoplasmic streaming, the persistent flow of fluid inside a cell, induces&#10;intracellular transport, which plays a key role in fundamental biological&#10;processes. In meiosis II mouse oocytes (developing egg cells) awaiting&#10;fertilisation, the spindle, which is the protein structure responsible for&#10;dividing genetic material in a cell, must maintain its position near the cell&#10;cortex (the thin actin network bound to the cell membrane) for many hours.&#10;However, the cytoplasmic streaming that accompanies this stable positioning&#10;would intuitively appear to destabilise the spindle position. Here, through a&#10;combination of numerical and analytical modelling, we reveal a new,&#10;hydrodynamic mechanism for stable spindle positioning beneath the cortical cap.&#10;We show that this stability depends critically on the spindle size and the&#10;active driving from the cortex, and demonstrate that stable spindle positioning&#10;can result purely from a hydrodynamic suction force exerted on the spindle by&#10;the cytoplasmic flow. Our findings show that local fluid dynamic forces can be&#10;sufficient to stabilise the spindle, explaining robustness against&#10;perturbations not only perpendicular but also parallel to the cortex. Our&#10;results shed light on the importance of cytoplasmic streaming in mammalian&#10;meiosis.&#10; | General | [Link](http://arxiv.org/abs/2409.10401v1) |&#10;| Sherpa: An Open Source Python Fitting Package | Aneta Siemiginowska, Douglas Burke, Hans Moritz Gnther, Nicholas P. Lee, Warren McLaughlin, David A. Principe, Harlan Cheer, Antonella Fruscione, Omar Laurino, Jonathan McDowell, Marie Terrell | &#160;&#160;We present an overview of Sherpa, an open source Python project, and discuss&#10;its development history, broad design concepts and capabilities. Sherpa&#10;contains powerful tools for combining parametric models into complex&#10;expressions that can be fit to data using a variety of statistics and&#10;optimization methods. It is easily extensible to include user&#45;defined models,&#10;statistics, and optimization methods. It provides a high&#45;level User Interface&#10;for interactive data&#45;analysis, such as within a Jupyter notebook, and it can&#10;also be used as a library component, providing fitting and modeling&#10;capabilities to an application. We include a few examples of Sherpa&#10;applications to multiwavelength astronomical data. The code is available&#10;GitHub: https://github.com/sherpa/sherpa&#10; | General | [Link](http://arxiv.org/abs/2409.10400v1) |&#10;| Minimally coupled $$&#45;exponential inflation with an $R^2$ term in&#10; &#160;the Palatini formulation | Nilay Bostan, Rafid H. Dejrah | &#160;&#160;We focus on the inflationary predictions of $beta$&#45;exponential potential&#10;models, in which the inflaton is a representation of the field delineating the&#10;size of extra&#45;dimension. Since it offers a well&#45;motivated starting point for&#10;the study of physics at very high energies, we incorporate an $R^2$ term in the&#10;Palatini gravity. In addition, afterward the inflation, the inflaton oscillates&#10;about the minimum of the inflation potential, and reheats the universe. This&#10;occurs during the reheating phase, at which the inflaton decays into the&#10;standard model particles, which fill the universe. We extend our examination by&#10;considering the reheating effects on inflationary observables by employing the&#10;different scenarios of the reheat temperature. Supposing the standard thermal&#10;history after inflation, we display the inflationary predictions, $n_s, r,&#10;mathrm{d}n_s/mathrm{d}&#10;n k$ of $beta$&#45;exponential potential with minimal&#10;coupling in Palatini $R^2$ gravity. Also, different kinds of constraints from a&#10;variety of observations, such as BICEP/Keck, Planck 2018, as well as future&#10;possible detectable sensitivities that might be reached by CMB experiments:&#10;CMB&#45;S4 and LiteBIRD are taken into account in this work. We indicate that our&#10;results are consistent with both the latest data and the future sensitivity&#10;forecasts of LiteBIRD/Planck and CMB&#45;S4. Finally, the results in this study&#10;highlight the viability of our model even in the case of the existence of more&#10;stringent constraints expected from future achievable confidence level limits.&#10; | General | [Link](http://arxiv.org/abs/2409.10398v1) |&#10;| Quantifying Observational Projection Effects with a Simulation&#45;based hot&#10; &#160;CGM model | Soumya Shreeram, Johan Comparat, Andrea Merloni, Yi Zhang, Gabriele Ponti, Kirpal Nandra, John ZuHone, Ilaria Marini, Stephan Vladutescu&#45;Zopp, Paola Popesso, Ruediger Pakmor, Riccardo Seppi, Celine Peroux, Daniele Sorini | &#160;&#160;The hot phase of the circumgalactic medium (CGM) allows us to probe the&#10;inflow and outflow of gas within a galaxy, which is responsible for dictating&#10;the evolution of the galaxy. Studying the hot CGM sheds light on a better&#10;understanding of gas physics, which is crucial to inform and constrain&#10;simulation models. With the recent advances in observational measurements&#10;probing the hot CGM in X&#45;rays and tSZ, we have a new avenue for widening our&#10;knowledge of gas physics and feedback by exploiting the information from&#10;current/future observations. In this paper, we use the TNG300 hydrodynamical&#10;simulations to build a fully self&#45;consistent forward model for the hot CGM. We&#10;construct a lightcone and generate mock X&#45;ray observations. We quantify the&#10;projection effects, namely the locally correlated large&#45;scale structure in&#10;X&#45;rays and the effect due to satellite galaxies misclassified as centrals which&#10;affects the measured hot CGM galactocentric profiles in stacking experiments.&#10;We present an analytical model that describes the intrinsic X&#45;ray surface&#10;brightness profile across the stellar and halo mass bins. The increasing&#10;stellar mass bins result in decreasing values of $beta$, the exponent&#10;quantifying the slope of the intrinsic galactocentric profiles. We carry&#10;forward the current state&#45;of&#45;the&#45;art by also showing the impact of the locally&#10;correlated environment on the measured X&#45;ray surface brightness profiles. We&#10;also present, for the first time, the effect of misclassified centrals in&#10;stacking experiments for three stellar mass bins: $10^{10.5&#45;11} M_odot$,&#10;$10^{11&#45;11.2} M_odot$, and $10^{11.2&#45;11.5} M_odot$. We find that the&#10;contaminating effect of the misclassified centrals on the stacked profiles&#10;increases when the stellar mass decreases.&#10; | General | [Link](http://arxiv.org/abs/2409.10397v1) |&#10;| MOST: MR reconstruction Optimization for multiple downStream Tasks via&#10; &#160;continual learning | Hwihun Jeong, Se Young Chun, Jongho Lee | &#160;&#160;Deep learning&#45;based Magnetic Resonance (MR) reconstruction methods have&#10;focused on generating high&#45;quality images but they often overlook the impact on&#10;downstream tasks (e.g., segmentation) that utilize the reconstructed images.&#10;Cascading separately trained reconstruction network and downstream task network&#10;has been shown to introduce performance degradation due to error propagation&#10;and domain gaps between training datasets. To mitigate this issue, downstream&#10;task&#45;oriented reconstruction optimization has been proposed for a single&#10;downstream task. Expanding this optimization to multi&#45;task scenarios is not&#10;straightforward. In this work, we extended this optimization to sequentially&#10;introduced multiple downstream tasks and demonstrated that a single MR&#10;reconstruction network can be optimized for multiple downstream tasks by&#10;deploying continual learning (MOST). MOST integrated techniques from&#10;replay&#45;based continual learning and image&#45;guided loss to overcome catastrophic&#10;forgetting. Comparative experiments demonstrated that MOST outperformed a&#10;reconstruction network without finetuning, a reconstruction network with&#10;na&quot;ive finetuning, and conventional continual learning methods. This&#10;advancement empowers the application of a single MR reconstruction network for&#10;multiple downstream tasks. The source code is available at:&#10;https://github.com/SNU&#45;LIST/MOST&#10; | General | [Link](http://arxiv.org/abs/2409.10394v1) |&#10;| Multicopy quantum state teleportation with application to storage and&#10; &#160;retrieval of quantum programs | Frdric Grosshans, Micha Horodecki, Mio Murao, Tomasz Mynik, Marco Tlio Quintino, Micha Studziski, Satoshi Yoshida | &#160;&#160;This work considers a teleportation task for Alice and Bob in a scenario&#10;where Bob cannot perform corrections. In particular, we analyse the task of&#10;textit{multicopy state teleportation}, where Alice has $k$ identical copies of&#10;an arbitrary unknown $d$&#45;dimensional qudit state $vertpsi&#13;angle$ to teleport&#10;a single copy of $vertpsi&#13;angle$ to Bob using a maximally entangled&#10;two&#45;qudit state shared between Alice and Bob without Bob&#39;s correction. Alice&#10;may perform a joint measurement on her half of the entangled state and the $k$&#10;copies of $vertpsi&#13;angle$. We prove that the maximal probability of success&#10;for teleporting the exact state $vertpsi&#13;angle$ to Bob is&#10;$p(d,k)=frac{k}{d(k&#45;1+d)}$ and present an explicit protocol to attain this&#10;performance. Then, by utilising $k$ copies of an arbitrary target state&#10;$vertpsi&#13;angle$, we show how the multicopy state teleportation protocol can&#10;be employed to enhance the success probability of storage and retrieval of&#10;quantum programs, which aims to universally retrieve the action of an arbitrary&#10;quantum channel that is stored in a state. Our proofs make use of group&#10;representation theory methods, which may find applications beyond the problems&#10;addressed in this work.&#10; | General | [Link](http://arxiv.org/abs/2409.10393v1) |&#10;| TPFL: Tsetlin&#45;Personalized Federated Learning with Confidence&#45;Based&#10; &#160;Clustering | Rasoul Jafari Gohari, Laya Aliahmadipour, Ezat Valipour | &#160;&#160;The world of Machine Learning (ML) has witnessed rapid changes in terms of&#10;new models and ways to process users data. The majority of work that has been&#10;done is focused on Deep Learning (DL) based approaches. However, with the&#10;emergence of new algorithms such as the Tsetlin Machine (TM) algorithm, there&#10;is growing interest in exploring alternative approaches that may offer unique&#10;advantages in certain domains or applications. One of these domains is&#10;Federated Learning (FL), in which users privacy is of utmost importance. Due to&#10;its novelty, FL has seen a surge in the incorporation of personalization&#10;techniques to enhance model accuracy while maintaining user privacy under&#10;personalized conditions. In this work, we propose a novel approach dubbed TPFL:&#10;Tsetlin&#45;Personalized Federated Learning, in which models are grouped into&#10;clusters based on their confidence towards a specific class. In this way,&#10;clustering can benefit from two key advantages. Firstly, clients share only&#10;what they are confident about, resulting in the elimination of wrongful weight&#10;aggregation among clients whose data for a specific class may have not been&#10;enough during the training. This phenomenon is prevalent when the data are&#10;non&#45;Independent and Identically Distributed (non&#45;IID). Secondly, by sharing&#10;only weights towards a specific class, communication cost is substantially&#10;reduced, making TPLF efficient in terms of both accuracy and communication&#10;cost. The results of TPFL demonstrated the highest accuracy on three different&#10;datasets; namely MNIST, FashionMNIST and FEMNIST.&#10; | General | [Link](http://arxiv.org/abs/2409.10392v1) |&#10;| Prompt&#45;and&#45;Transfer: Dynamic Class&#45;aware Enhancement for Few&#45;shot&#10; &#160;Segmentation | Hanbo Bi, Yingchao Feng, Wenhui Diao, Peijin Wang, Yongqiang Mao, Kun Fu, Hongqi Wang, Xian Sun | &#160;&#160;For more efficient generalization to unseen domains (classes), most Few&#45;shot&#10;Segmentation (FSS) would directly exploit pre&#45;trained encoders and only&#10;fine&#45;tune the decoder, especially in the current era of large models. However,&#10;such fixed feature encoders tend to be class&#45;agnostic, inevitably activating&#10;objects that are irrelevant to the target class. In contrast, humans can&#10;effortlessly focus on specific objects in the line of sight. This paper mimics&#10;the visual perception pattern of human beings and proposes a novel and powerful&#10;prompt&#45;driven scheme, called ``Prompt and Transfer&quot; (PAT), which constructs a&#10;dynamic class&#45;aware prompting paradigm to tune the encoder for focusing on the&#10;interested object (target class) in the current task. Three key points are&#10;elaborated to enhance the prompting: 1) Cross&#45;modal linguistic information is&#10;introduced to initialize prompts for each task. 2) Semantic Prompt Transfer&#10;(SPT) that precisely transfers the class&#45;specific semantics within the images&#10;to prompts. 3) Part Mask Generator (PMG) that works in conjunction with SPT to&#10;adaptively generate different but complementary part prompts for different&#10;individuals. Surprisingly, PAT achieves competitive performance on 4 different&#10;tasks including standard FSS, Cross&#45;domain FSS (e.g., CV, medical, and remote&#10;sensing domains), Weak&#45;label FSS, and Zero&#45;shot Segmentation, setting new&#10;state&#45;of&#45;the&#45;arts on 11 benchmarks.&#10; | General | [Link](http://arxiv.org/abs/2409.10389v1) |&#10;| Revising the Structure of Recurrent Neural Networks to Eliminate&#10; &#160;Numerical Derivatives in Forming Physics Informed Loss Terms with Respect to&#10; &#160;Time | Mahyar Jahani&#45;nasab, Mohamad Ali Bijarchi | &#160;&#160;Solving unsteady partial differential equations (PDEs) using recurrent neural&#10;networks (RNNs) typically requires numerical derivatives between each block of&#10;the RNN to form the physics informed loss function. However, this introduces&#10;the complexities of numerical derivatives into the training process of these&#10;models. In this study, we propose modifying the structure of the traditional&#10;RNN to enable the prediction of each block over a time interval, making it&#10;possible to calculate the derivative of the output with respect to time using&#10;the backpropagation algorithm. To achieve this, the time intervals of these&#10;blocks are overlapped, defining a mutual loss function between them.&#10;Additionally, the employment of conditional hidden states enables us to achieve&#10;a unique solution for each block. The forget factor is utilized to control the&#10;influence of the conditional hidden state on the prediction of the subsequent&#10;block. This new model, termed the Mutual Interval RNN (MI&#45;RNN), is applied to&#10;solve three different benchmarks: the Burgers equation, unsteady heat&#10;conduction in an irregular domain, and the Green vortex problem. Our results&#10;demonstrate that MI&#45;RNN can find the exact solution more accurately compared to&#10;existing RNN models. For instance, in the second problem, MI&#45;RNN achieved one&#10;order of magnitude less relative error compared to the RNN model with numerical&#10;derivatives.&#10; | General | [Link](http://arxiv.org/abs/2409.10388v1) |&#10;| Sharp decay rate for eigenfunctions of perturbed periodic Schrdinger&#10; &#160;operators | Wencai Liu, Rodrigo Matos, John N. Treuer | &#160;&#160;This paper investigates uniqueness results for perturbed periodic&#10;Schr&quot;odinger operators on $mathbb{Z}^d$. Specifically, we consider operators&#10;of the form $H = &#45;Delta + V + v$, where $Delta$ is the discrete Laplacian,&#10;$V: mathbb{Z}^d &#13;ightarrow mathbb{R}$ is a periodic potential, and $v:&#10;mathbb{Z}^d &#13;ightarrow mathbb{C}$ represents a decaying impurity. We&#10;establish quantitative conditions under which the equation $&#45;Delta u + V u + v&#10;u = &#10;ambda u$, for $&#10;ambda in mathbb{C}$, admits only the trivial solution&#10;$u equiv 0$. Key applications include the absence of embedded eigenvalues for&#10;operators with impurities decaying faster than any exponential function and the&#10;determination of sharp decay rates for eigenfunctions. Our findings extend&#10;previous works by providing precise decay conditions for impurities and&#10;analyzing different spectral regimes of $&#10;ambda$.&#10; | General | [Link](http://arxiv.org/abs/2409.10387v1) |&#10;| Mamba&#45;ST: State Space Model for Efficient Style Transfer | Filippo Botti, Alex Ergasti, Leonardo Rossi, Tomaso Fontanini, Claudio Ferrari, Massimo Bertozzi, Andrea Prati | &#160;&#160;The goal of style transfer is, given a content image and a style source,&#10;generating a new image preserving the content but with the artistic&#10;representation of the style source. Most of the state&#45;of&#45;the&#45;art architectures&#10;use transformers or diffusion&#45;based models to perform this task, despite the&#10;heavy computational burden that they require. In particular, transformers use&#10;self&#45; and cross&#45;attention layers which have large memory footprint, while&#10;diffusion models require high inference time. To overcome the above, this paper&#10;explores a novel design of Mamba, an emergent State&#45;Space Model (SSM), called&#10;Mamba&#45;ST, to perform style transfer. To do so, we adapt Mamba linear equation&#10;to simulate the behavior of cross&#45;attention layers, which are able to combine&#10;two separate embeddings into a single output, but drastically reducing memory&#10;usage and time complexity. We modified the Mamba&#39;s inner equations so to accept&#10;inputs from, and combine, two separate data streams. To the best of our&#10;knowledge, this is the first attempt to adapt the equations of SSMs to a vision&#10;task like style transfer without requiring any other module like&#10;cross&#45;attention or custom normalization layers. An extensive set of experiments&#10;demonstrates the superiority and efficiency of our method in performing style&#10;transfer compared to transformers and diffusion models. Results show improved&#10;quality in terms of both ArtFID and FID metrics. Code is available at&#10;https://github.com/FilippoBotti/MambaST.&#10; | General | [Link](http://arxiv.org/abs/2409.10385v1) |&#10;| Performance&#45;Portable Numerical Relativity with AthenaK | Hengrui Zhu, Jacob Fields, Francesco Zappa, David Radice, James Stone, Alireza Rashti, William Cook, Sebastiano Bernuzzi, Boris Daszuta | &#160;&#160;We present the numerical relativity module within AthenaK, an open source&#10;performance&#45;portable astrophysics code designed for exascale computing&#10;applications. This module employs the Z4c formulation to solve the Einstein&#10;equations. We demonstrate its accuracy through a series of standard numerical&#10;relativity tests, including convergence of the gravitational waveform from&#10;binary black hole coalescence. Furthermore, we conduct scaling tests on OLCF&#10;Frontier and NERSC Perlmutter, where AthenaK exhibits excellent weak scaling&#10;efficiency of 80% on up to 65,536 AMD MI250X GPUs on Frontier (relative to 4&#10;GPUs) and strong scaling efficiencies of 84% and 77% on AMD MI250X and NVIDIA&#10;A100 GPUs on Frontier and Perlmutter respectively. Additionally, we observe a&#10;significant performance boost, with two orders of magnitude speedup ($gtrsim&#10;200times$) on a GPU compared to a single CPU core, affirming that AthenaK is&#10;well&#45;suited for exascale computing, thereby expanding the potential for&#10;breakthroughs in numerical relativity research.&#10; | General | [Link](http://arxiv.org/abs/2409.10383v1) |&#10;| J&#45;UBIK: The JAX&#45;accelerated Universal Bayesian Imaging Kit | Vincent Eberle, Matteo Guardiani, Margret Westerkamp, Philipp Frank, Julian Rstig, Julia Stadler, Torsten A. Enlin | &#160;&#160;Many advances in astronomy and astrophysics originate from accurate images of&#10;the sky emission across multiple wavelengths. This often requires&#10;reconstructing spatially and spectrally correlated signals detected from&#10;multiple instruments. To facilitate the high&#45;fidelity imaging of these signals,&#10;we introduce the universal Bayesian imaging kit (UBIK). Specifically, we&#10;present J&#45;UBIK, a flexible and modular implementation leveraging the&#10;JAX&#45;accelerated NIFTy.re software as its backend. J&#45;UBIK streamlines the&#10;implementation of the key Bayesian inference components, providing for all the&#10;necessary steps of Bayesian imaging pipelines. First, it provides adaptable&#10;prior models for different sky realizations. Second, it includes likelihood&#10;models tailored to specific instruments. So far, the package includes three&#10;instruments: Chandra and eROSITA for X&#45;ray observations, and the James Webb&#10;Space Telescope (JWST) for the near&#45; and mid&#45;infrared. The aim is to expand&#10;this set in the future. Third, these models can be integrated with various&#10;inference and optimization schemes, such as maximum a posteriori estimation and&#10;variational inference. Explicit demos show how to integrate the individual&#10;modules into a full analysis pipeline. Overall, J&#45;UBIK enables efficient&#10;generation of high&#45;fidelity images via Bayesian pipelines that can be tailored&#10;to specific research objectives.&#10; | General | [Link](http://arxiv.org/abs/2409.10381v1) |&#10;| Thermolectricity in irradiated bilayer graphene flakes | Cynthia Ihuoma Osuala, Tanu Choudhary, Raju K. Biswas, Sudin Ganguly, Chunlei Qu, Santanu K. Maiti | &#160;&#160;We present a comprehensive study on enhancing the thermoelectric (TE)&#10;performance of bilayer graphene (BLG) through irradiation with arbitrarily&#10;polarized light, focusing on $AA$&#45; and $AB$&#45;stacked configurations with zigzag&#10;edges. Utilizing a combination of tight&#45;binding theory and density functional&#10;theory (DFT), we systematically analyze the impact of light irradiation on&#10;electronic and phononic transport properties. Light irradiation alters the&#10;electronic hopping parameters, creating an asymmetric transmission function,&#10;which significantly increases the Seebeck coefficient, thereby boosting the&#10;overall {it figure of merit} (FOM). For the phononic contribution, DFT&#10;calculations reveal that $AB$&#45;stacked BLG exhibits lower lattice thermal&#10;conductivity compared to $AA$&#45;stacked, attributed to enhanced anharmonic&#10;scattering and phonon group velocity. The combined analysis shows that FOM&#10;exceeds unity in both stacking types, with notable improvements near the&#10;irradiation&#45;induced gap. Additionally, we explore the dependence of FOM on the&#10;system dimensions and temperature, demonstrating that light&#45;irradiated BLG&#10;holds great promise for efficient thermoelectric energy conversion and waste&#10;heat recovery. Our results show favorable responses over a wide range of&#10;irradiation parameters. These findings provide crucial insights into optimizing&#10;BLG for advanced TE applications through light&#45;induced modifications.&#10; | General | [Link](http://arxiv.org/abs/2409.10380v1) |&#10;| Leveraging Joint Spectral and Spatial Learning with MAMBA for&#10; &#160;Multichannel Speech Enhancement | Wenze Ren, Haibin Wu, Yi&#45;Cheng Lin, Xuanjun Chen, Rong Chao, Kuo&#45;Hsuan Hung, You&#45;Jin Li, Wen&#45;Yuan Ting, Hsin&#45;Min Wang, Yu Tsao | &#160;&#160;In multichannel speech enhancement, effectively capturing spatial and&#10;spectral information across different microphones is crucial for noise&#10;reduction. Traditional methods, such as CNN or LSTM, attempt to model the&#10;temporal dynamics of full&#45;band and sub&#45;band spectral and spatial features.&#10;However, these approaches face limitations in fully modeling complex temporal&#10;dependencies, especially in dynamic acoustic environments. To overcome these&#10;challenges, we modify the current advanced model McNet by introducing an&#10;improved version of Mamba, a state&#45;space model, and further propose MCMamba.&#10;MCMamba has been completely reengineered to integrate full&#45;band and narrow&#45;band&#10;spatial information with sub&#45;band and full&#45;band spectral features, providing a&#10;more comprehensive approach to modeling spatial and spectral information. Our&#10;experimental results demonstrate that MCMamba significantly improves the&#10;modeling of spatial and spectral features in multichannel speech enhancement,&#10;outperforming McNet and achieving state&#45;of&#45;the&#45;art performance on the CHiME&#45;3&#10;dataset. Additionally, we find that Mamba performs exceptionally well in&#10;modeling spectral information.&#10; | General | [Link](http://arxiv.org/abs/2409.10376v1) |&#10;| Nonlinear Causality in Brain Networks: With Application to Motor Imagery&#10; &#160;vs Execution | Sipan Aslan, Hernando Ombao | &#160;&#160;One fundamental challenge of data&#45;driven analysis in neuroscience is modeling&#10;causal interactions and exploring the connectivity of nodes in a brain network.&#10;Various statistical methods, relying on various perspectives and employing&#10;different data modalities, are being developed to examine and comprehend the&#10;underlying causal structures inherent to brain dynamics. This study introduces&#10;a novel statistical approach, TAR4C, to dissect causal interactions in&#10;multichannel EEG recordings. TAR4C uses the threshold autoregressive model to&#10;describe the causal interaction between nodes or clusters of nodes in a brain&#10;network. The perspective involves testing whether one node, which may represent&#10;a brain region, can control the dynamics of the other. The node that has such&#10;an impact on the other is called a threshold variable and can be classified as&#10;a causative because its functionality is the leading source operating as an&#10;instantaneous switching mechanism that regulates the time&#45;varying&#10;autoregressive structure of the other. This statistical concept is commonly&#10;referred to as threshold non&#45;linearity. Once threshold non&#45;linearity has been&#10;verified between a pair of nodes, the subsequent essential facet of TAR&#10;modeling is to assess the predictive ability of the causal node for the current&#10;activity on the other and represent causal interactions in autoregressive&#10;terms. This predictive ability is what underlies Granger causality. The TAR4C&#10;approach can discover non&#45;linear and time&#45;dependent causal interactions without&#10;negating the G&#45;causality perspective. The efficacy of the proposed approach is&#10;exemplified by analyzing the EEG signals recorded during the motor&#10;movement/imagery experiment. The similarities and differences between the&#10;causal interactions manifesting during the execution and the imagery of a given&#10;motor movement are demonstrated by analyzing EEG recordings from multiple&#10;subjects.&#10; | General | [Link](http://arxiv.org/abs/2409.10374v1) |&#10;| Instigating Cooperation among LLM Agents Using Adaptive Information&#10; &#160;Modulation | Qiliang Chen, &#160;Alireza, &#160;Ilami, Nunzio Lore, Babak Heydari | &#160;&#160;This paper introduces a novel framework combining LLM agents as proxies for&#10;human strategic behavior with reinforcement learning (RL) to engage these&#10;agents in evolving strategic interactions within team environments. Our&#10;approach extends traditional agent&#45;based simulations by using strategic LLM&#10;agents (SLA) and introducing dynamic and adaptive governance through a&#10;pro&#45;social promoting RL agent (PPA) that modulates information access across&#10;agents in a network, optimizing social welfare and promoting pro&#45;social&#10;behavior. Through validation in iterative games, including the prisoner&#10;dilemma, we demonstrate that SLA agents exhibit nuanced strategic adaptations.&#10;The PPA agent effectively learns to adjust information transparency, resulting&#10;in enhanced cooperation rates. This framework offers significant insights into&#10;AI&#45;mediated social dynamics, contributing to the deployment of AI in real&#45;world&#10;team settings.&#10; | General | [Link](http://arxiv.org/abs/2409.10372v1) |&#10;| Learning Gentle Grasping from Human&#45;Free Force Control Demonstration | Mingxuan Li, Lunwei Zhang, Tiemin Li, Yao Jiang | &#160;&#160;Humans can steadily and gently grasp unfamiliar objects based on tactile&#10;perception. Robots still face challenges in achieving similar performance due&#10;to the difficulty of learning accurate grasp&#45;force predictions and force&#10;control strategies that can be generalized from limited data. In this article,&#10;we propose an approach for learning grasping from ideal force control&#10;demonstrations, to achieve similar performance of human hands with limited data&#10;size. Our approach utilizes objects with known contact characteristics to&#10;automatically generate reference force curves without human demonstrations. In&#10;addition, we design the dual convolutional neural networks (Dual&#45;CNN)&#10;architecture which incorporating a physics&#45;based mechanics module for learning&#10;target grasping force predictions from demonstrations. The described method can&#10;be effectively applied in vision&#45;based tactile sensors and enables gentle and&#10;stable grasping of objects from the ground. The described prediction model and&#10;grasping strategy were validated in offline evaluations and online experiments,&#10;and the accuracy and generalizability were demonstrated.&#10; | General | [Link](http://arxiv.org/abs/2409.10371v1) |&#10;| Uncovering the Mechanism of Hepatotoxiciy of PFAS Targeting L&#45;FABP Using&#10; &#160;GCN and Computational Modeling | Lucas Jividen, Tibo Duran, Xi&#45;Zhi Niu, Jun Bai | &#160;&#160;Per&#45; and polyfluoroalkyl substances (PFAS) are persistent environmental&#10;pollutants with known toxicity and bioaccumulation issues. Their widespread&#10;industrial use and resistance to degradation have led to global environmental&#10;contamination and significant health concerns. While a minority of PFAS have&#10;been extensively studied, the toxicity of many PFAS remains poorly understood&#10;due to limited direct toxicological data. This study advances the predictive&#10;modeling of PFAS toxicity by combining semi&#45;supervised graph convolutional&#10;networks (GCNs) with molecular descriptors and fingerprints. We propose a novel&#10;approach to enhance the prediction of PFAS binding affinities by isolating&#10;molecular fingerprints to construct graphs where then descriptors are set as&#10;the node features. This approach specifically captures the structural,&#10;physicochemical, and topological features of PFAS without overfitting due to an&#10;abundance of features. Unsupervised clustering then identifies representative&#10;compounds for detailed binding studies. Our results provide a more accurate&#10;ability to estimate PFAS hepatotoxicity to provide guidance in chemical&#10;discovery of new PFAS and the development of new safety regulations.&#10; | General | [Link](http://arxiv.org/abs/2409.10370v1) |&#10;| Stochastic Control of UAVs: An Optimal Tradeoff between Performance,&#10; &#160;Flight Smoothness and Control Effort | George Rapakoulias, Panagiotis Tsiotras | &#160;&#160;Safe and accurate control of unmanned aerial vehicles in the presence of&#10;winds is a challenging control problem due to the hard&#45;to&#45;model and highly&#10;stochastic nature of the disturbance forces acting upon the vehicle. To meet&#10;performance constraints, state&#45;of&#45;the&#45;art control methods such as Incremental&#10;Nonlinear Dynamic Inversion (INDI) or other adaptive control techniques require&#10;high control gains to mitigate the effects of uncertainty entering the system.&#10;While achieving good tracking performance, IDNI requires excessive control&#10;effort, results in high actuator strain, and reduced flight smoothness due to&#10;constant and aggressive corrective actions commanded by the controller. In this&#10;paper, we propose a novel control architecture that allows the user to&#10;systematically address the trade&#45;off between high authority control and&#10;performance constraint satisfaction. Our approach consists of two parts. To&#10;cancel out biases introduced by unmodelled aerodynamic effects we propose a&#10;hybrid, model&#45;based disturbance force estimator augmented with a neural&#10;network, that can adapt to external wind conditions using a Kalman Filter. We&#10;then utilize state&#45;of&#45;the&#45;art results from Covariance Steering theory, which&#10;offers a principled way of controlling the uncertainty of the tracking error&#10;dynamics. We first analyze the properties of the combined system and then&#10;provide extensive experimental results to verify the advantages of the proposed&#10;approach over existing methods&#10; | General | [Link](http://arxiv.org/abs/2409.10369v1) |&#10;| Integrated nowcasting of convective precipitation with Transformer&#45;based&#10; &#160;models using multi&#45;source data | alar Kk, Aitor Atencia, Markus Dabernig | &#160;&#160;Precipitation nowcasting is crucial for mitigating the impacts of severe&#10;weather events and supporting daily activities. Conventional models&#10;predominantly relying on radar data have limited performance in predicting&#10;cases with complex temporal features such as convection initiation,&#10;highlighting the need to integrate data from other sources for more&#10;comprehensive nowcasting. Unlike physics&#45;based models, machine learning&#10;(ML)&#45;based models offer promising solutions for efficiently integrating large&#10;volumes of diverse data. We present EF4INCA, a spatiotemporal Transformer model&#10;for precipitation nowcasting that integrates satellite&#45; and ground&#45;based&#10;observations with numerical weather prediction outputs. EF4INCA provides&#10;high&#45;resolution forecasts over Austria, accurately predicting the location and&#10;shape of precipitation fields with a spatial resolution of 1 kilometre and a&#10;temporal resolution of 5 minutes, up to 90 minutes ahead. Our evaluation shows&#10;that EF4INCA outperforms conventional nowcasting models, including the&#10;operational model of Austria, particularly in scenarios with complex temporal&#10;features such as convective initiation and rapid weather changes. EF4INCA&#10;maintains higher accuracy in location forecasting but generates smoother fields&#10;at later prediction times compared to traditional models. Interpretation of our&#10;model showed that precipitation products and SEVIRI infrared channels CH7 and&#10;CH9 are the most important data streams. These results underscore the&#10;importance of combining data from different domains, including physics&#45;based&#10;model products, with ML approaches. Our study highlights the robustness of&#10;EF4INCA and its potential for improved precipitation nowcasting. We provide&#10;access to our code repository, model weights, and the dataset curated for&#10;benchmarking, facilitating further development and application.&#10; | General | [Link](http://arxiv.org/abs/2409.10367v1) |&#10;&#10;">
<polygon fill="#ddfff7" stroke="#00ff00" stroke-width="3" points="2375,-874 2263,-874 2263,-850 2375,-850 2387,-862 2375,-874"/>
<text font-weight="bold" text-anchor="middle" x="2325" y="-858.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Code Execution</text>
</a>
</g>
</g>
<!-- 1726553894.222013&#45;&gt;139922633387152_5 -->
<g id="edge75" class="edge">
<title>1726553894.222013&#45;&gt;139922633387152_5</title>
<path fill="none" stroke="#00ff00" d="M2325,-833.73C2325,-824.06 2325,-813.17 2325,-803.48"/>
<polygon fill="#00ff00" stroke="#00ff00" points="2321.5,-833.8 2325,-843.8 2328.5,-833.8 2321.5,-833.8"/>
<polygon fill="#00ff00" stroke="#00ff00" points="2328.5,-803.18 2325,-793.18 2321.5,-803.18 2328.5,-803.18"/>
<text text-anchor="middle" x="2353.5" y="-814.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">Success</text>
</g>
<!-- 139922670162320_6 -->
<g id="node69" class="node">
<title>139922670162320_6</title>
<ellipse fill="#faf4d0" stroke="#c7c19d" stroke-width="3" cx="2504" cy="-528" rx="55.49" ry="18"/>
<text text-anchor="middle" x="2504" y="-524.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Admin (6)</text>
</g>
<!-- 139922752308304_6&#45;&gt;139922670162320_6 -->
<g id="edge77" class="edge">
<title>139922752308304_6&#45;&gt;139922670162320_6</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M2344.93,-600.89C2365.01,-595.33 2387.44,-588.02 2407,-579 2418.08,-573.89 2419.35,-569.96 2430,-564 2440.46,-558.15 2452.05,-552.36 2462.9,-547.22"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2464.61,-550.29 2472.2,-542.89 2461.65,-543.94 2464.61,-550.29"/>
<g id="a_edge77&#45;label"><a xlink:title="exitcode: 0 (execution succeeded)&#10;Code output: &#10;| Title | Authors | Abstract | Domain | Source URL |&#10;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#10;| The VIRUS&#45;dE Survey I: Stars in dwarf elliptical galaxies &#45; 3D dynamics&#10; &#160;and radially resolved stellar initial mass functions | Mathias Lipka, Jens Thomas, Roberto Saglia, Ralf Bender, Maximilian Fabricius, Gary J. Hill, Matthias Kluge, Martin Landriau, Ximena Mazzalay, Eva Noyola, Taniya Parikh, Jan Snigula | &#160;&#160;We analyse the stellar structure of a sample of dwarf ellipticals (dE)&#10;inhabiting various environments within the Virgo cluster. Integral&#45;field&#10;observations with a high spectral resolution allow us to robustly determine&#10;their low velocity dispersions ($sim25$ km s$^{&#45;1}$) and higher&#45;order&#10;kinematic moments out to the half&#45;light radius. We find the dEs exhibit a&#10;diversity in ages with the younger dEs being less enhanced than the older,&#10;suggesting a complex star formation history for those dEs that recently entered&#10;Virgo while others have been quenched shortly after reionization.&#10;Orbit&#45;superposition modeling allowed us to recover viewing angles, stellar&#10;mass&#45;to&#45;light ratios (with gradients), as well as the intrinsic orbit&#10;structure. We find that the angular momentum of the dEs is strongly suppressed&#10;compared to ordinary early&#45;type galaxies and correlates with the environment.&#10;Flattened dEs are so because of a suppressed kinetic energy perpendicular to&#10;their equatorial plane. Combining population and dynamical modeling results, we&#10;find an age&#45;dependent stellar initial mass function (IMF) or, alternatively,&#10;evidence for a more extended star formation history for those galaxies that&#10;have had higher initial mass and/or inhabited lower density environments. dEs&#10;appear to have a spatially homogeneous stellar structure but the state they&#10;were `frozen&#39; in as they stopped forming stars varies dramatically according to&#10;their initial conditions.&#10; | General | [Link](http://arxiv.org/abs/2409.10518v1) |&#10;| RetrievalAttention: Accelerating Long&#45;Context LLM Inference via Vector&#10; &#160;Retrieval | Di Liu, Meng Chen, Baotong Lu, Huiqiang Jiang, Zhenhua Han, Qianxi Zhang, Qi Chen, Chengruidong Zhang, Bailu Ding, Kai Zhang, Chen Chen, Fan Yang, Yuqing Yang, Lili Qiu | &#160;&#160;Transformer&#45;based large Language Models (LLMs) become increasingly important&#10;in various domains. However, the quadratic time complexity of attention&#10;operation poses a significant challenge for scaling to longer contexts due to&#10;the extremely high inference latency and GPU memory consumption for caching&#10;key&#45;value (KV) vectors. This paper proposes RetrievalAttention, a training&#45;free&#10;approach to accelerate attention computation. To leverage the dynamic sparse&#10;property of attention, RetrievalAttention builds approximate nearest neighbor&#10;search (ANNS) indexes upon KV vectors in CPU memory and retrieves the most&#10;relevant ones via vector search during generation. Due to the&#10;out&#45;of&#45;distribution (OOD) between query vectors and key vectors, off&#45;the&#45;shelf&#10;ANNS indexes still need to scan O(N) (usually 30% of all keys) data for&#10;accurate retrieval, which fails to exploit the high sparsity.&#10;RetrievalAttention first identifies the OOD challenge of ANNS&#45;based attention,&#10;and addresses it via an attention&#45;aware vector search algorithm that can adapt&#10;to queries and only access 1&#45;&#45;3% of data, thus achieving a sub&#45;linear time&#10;complexity. RetrievalAttention greatly reduces the inference cost of&#10;long&#45;context LLM with much lower GPU memory requirements while maintaining the&#10;model accuracy. Especially, RetrievalAttention only needs 16GB GPU memory for&#10;serving 128K tokens in LLMs with 8B parameters, which is capable of generating&#10;one token in 0.188 seconds on a single NVIDIA RTX4090 (24GB).&#10; | General | [Link](http://arxiv.org/abs/2409.10516v1) |&#10;| An Efficient Self&#45;Learning Framework For Interactive Spoken Dialog&#10; &#160;Systems | Hitesh Tulsiani, David M. Chan, Shalini Ghosh, Garima Lalwani, Prabhat Pandey, Ankish Bansal, Sri Garimella, Ariya Rastrow, Bjrn Hoffmeister | &#160;&#160;Dialog systems, such as voice assistants, are expected to engage with users&#10;in complex, evolving conversations. Unfortunately, traditional automatic speech&#10;recognition (ASR) systems deployed in such applications are usually trained to&#10;recognize each turn independently and lack the ability to adapt to the&#10;conversational context or incorporate user feedback. In this work, we introduce&#10;a general framework for ASR in dialog systems that can go beyond learning from&#10;single&#45;turn utterances and learn over time how to adapt to both explicit&#10;supervision and implicit user feedback present in multi&#45;turn conversations. We&#10;accomplish that by leveraging advances in student&#45;teacher learning and&#10;context&#45;aware dialog processing, and designing contrastive self&#45;supervision&#10;approaches with Ohm, a new online hard&#45;negative mining approach. We show that&#10;leveraging our new framework compared to traditional training leads to relative&#10;WER reductions of close to 10% in real&#45;world dialog systems, and up to 26% on&#10;public synthetic data.&#10; | General | [Link](http://arxiv.org/abs/2409.10515v1) |&#10;| Constraints on axions from patchy screening of the cosmic microwave&#10; &#160;background | Samuel Goldstein, Fiona McCarthy, Cristina Mondino, J. Colin Hill, Junwu Huang, Matthew C. Johnson | &#160;&#160;The resonant conversion of cosmic microwave background (CMB) photons into&#10;axions within large&#45;scale structure induces an anisotropic spectral distortion&#10;in CMB temperature maps. Applying state&#45;of&#45;the&#45;art foreground cleaning&#10;techniques to $textit{Planck}$ CMB observations, we construct maps of&#10;axion&#45;induced &quot;patchy screening&quot; of the CMB. We cross&#45;correlate these maps with&#10;data from the $textit{unWISE}$ galaxy survey and find no evidence of axions.&#10;We constrain the axion&#45;photon coupling, $g_{agammagamma} &#10;esssim 2 times&#10;10^{&#45;12}~{&#13;m GeV}^{&#45;1}$, at the 95% confidence level for axion masses in the&#10;range $10^{&#45;13}~{&#13;m eV} &#10;esssim m_a &#10;esssim 10^{&#45;12}~{&#13;m eV}$. These&#10;constraints are competitive with the tightest astrophysical axion limits in&#10;this mass range and are inferred from robust population&#45;level statistics, which&#10;makes them complementary to existing searches that rely on modeling of&#10;individual systems.&#10; | General | [Link](http://arxiv.org/abs/2409.10514v1) |&#10;| Weak Superimposed Codes of Improved Asymptotic Rate and Their Randomized&#10; &#160;Construction | Yu Tsunoda, Yuichiro Fujiwara | &#160;&#160;Weak superimposed codes are combinatorial structures related closely to&#10;generalized cover&#45;free families, superimposed codes, and disjunct matrices in&#10;that they are only required to satisfy similar but less stringent conditions.&#10;This class of codes may also be seen as a stricter variant of what are known as&#10;locally thin families in combinatorics. Originally, weak superimposed codes&#10;were introduced in the context of multimedia content protection against illegal&#10;distribution of copies under the assumption that a coalition of malicious users&#10;may employ the averaging attack with adversarial noise. As in many other kinds&#10;of codes in information theory, it is of interest and importance in the study&#10;of weak superimposed codes to find the highest achievable rate in the&#10;asymptotic regime and give an efficient construction that produces an infinite&#10;sequence of codes that achieve it. Here, we prove a tighter lower bound than&#10;the sharpest known one on the rate of optimal weak superimposed codes and give&#10;a polynomial&#45;time randomized construction algorithm for codes that&#10;asymptotically attain our improved bound with high probability. Our&#10;probabilistic approach is versatile and applicable to many other related codes&#10;and arrays.&#10; | General | [Link](http://arxiv.org/abs/2409.10511v1) |&#10;| Pennsieve &#45; A Collaborative Platform for Translational Neuroscience and&#10; &#160;Beyond | Zack Goldblum, Zhongchuan Xu, Haoer Shi, Patryk Orzechowski, Jamaal Spence, Kathryn A Davis, Brian Litt, Nishant Sinha, Joost Wagenaar | &#160;&#160;The exponential growth of neuroscientific data necessitates platforms that&#10;facilitate data management and multidisciplinary collaboration. In this paper,&#10;we introduce Pennsieve &#45; an open&#45;source, cloud&#45;based scientific data management&#10;platform built to meet these needs. Pennsieve supports complex multimodal&#10;datasets and provides tools for data visualization and analyses. It takes a&#10;comprehensive approach to data integration, enabling researchers to define&#10;custom metadata schemas and utilize advanced tools to filter and query their&#10;data. Pennsieve&#39;s modular architecture allows external applications to extend&#10;its capabilities, and collaborative workspaces with peer&#45;reviewed data&#10;publishing mechanisms promote high&#45;quality datasets optimized for downstream&#10;analysis, both in the cloud and on&#45;premises.&#10; &#160;Pennsieve forms the core for major neuroscience research programs including&#10;the NIH SPARC Initiative, NIH HEAL Initiative&#39;s PRECISION Human Pain Network,&#10;and NIH HEAL RE&#45;JOIN Initiative. It serves more than 80 research groups&#10;worldwide, along with several large&#45;scale, inter&#45;institutional projects at&#10;clinical sites through the University of Pennsylvania. Underpinning the&#10;SPARC.Science, Epilepsy.Science, and Pennsieve Discover portals, Pennsieve&#10;stores over 125 TB of scientific data, with 35 TB of data publicly available&#10;across more than 350 high&#45;impact datasets. It adheres to the findable,&#10;accessible, interoperable, and reusable (FAIR) principles of data sharing and&#10;is recognized as one of the NIH&#45;approved Data Repositories. By facilitating&#10;scientific data management, discovery, and analysis, Pennsieve fosters a robust&#10;and collaborative research ecosystem for neuroscience and beyond.&#10; | General | [Link](http://arxiv.org/abs/2409.10509v1) |&#10;| General&#45;relativistic resistive&#45;magnetohydrodynamics simulations of&#10; &#160;self&#45;consistent magnetized rotating neutron stars | Patrick Chi&#45;Kit Cheong, Antonios Tsokaros, Milton Ruiz, Fabrizio Venturi, Juno Chun Lung Chan, Anson Ka Long Yip, Koji Uryu | &#160;&#160;We present the first general&#45;relativistic resistive magnetohydrodynamics&#10;simulations of self&#45;consistent, rotating neutron stars with mixed poloidal and&#10;toroidal magnetic fields. Specifically, we investigate the role of resistivity&#10;in the dynamical evolution of neutron stars over a period of up to 100 ms and&#10;its effects on their quasi&#45;equilibrium configurations. Our results demonstrate&#10;that resistivity can significantly influence the development of&#10;magnetohydrodynamic instabilities, resulting in markedly different magnetic&#10;field geometries. Additionally, resistivity suppresses the growth of these&#10;instabilities, leading to a reduction in the amplitude of emitted gravitational&#10;waves. Despite the variations in magnetic field geometries, the ratio of&#10;poloidal to toroidal field energies remains consistently 9:1 throughout the&#10;simulations, for the models we investigated.&#10; | General | [Link](http://arxiv.org/abs/2409.10508v1) |&#10;| Beth&#45;Uhlenbeck equation for the thermodynamics of fluctuations in a&#10; &#160;generalised 2+1D Gross&#45;Neveu model | Biplab Mahato, David Blaschke, Dietmar Ebert | &#160;&#160;We study a generalised version of Gross&#45;Neveu model in 2+1 dimensions. The&#10;model is inspired from graphene which shows a linear dispersion relation near&#10;the Dirac points. The phase structure and the thermodynamic properties in the&#10;mean field approximation have been studied before. Here we go beyond the mean&#10;field level by deriving a Beth&#45;Uhlenbeck equation for Gaussian fluctuations,&#10;solutions of which we explore numerically, for the first time including their&#10;momentum dependence. We discuss the excitonic mass, fluctuation pressure and&#10;phase shifts. We also perform a comparison with the NJL model in 3+1 dimension&#10;and discuss its implication for graphene.&#10; | General | [Link](http://arxiv.org/abs/2409.10507v1) |&#10;| Context&#45;aware Code Segmentation for C&#45;to&#45;Rust Translation using Large&#10; &#160;Language Models | Momoko Shiraishi, Takahiro Shinagawa | &#160;&#160;There is strong motivation to translate C code into Rust code due to the&#10;continuing threat of memory safety vulnerabilities in existing C programs and&#10;the significant attention paid to Rust as an alternative to the C language.&#10;While large language models (LLMs) show promise for automating this translation&#10;by generating more natural and safer code than rule&#45;based methods, previous&#10;studies have shown that LLM&#45;generated Rust code often fails to compile, even&#10;for relatively small C programs, due to significant differences between the two&#10;languages and context window limitations. We propose an LLM&#45;based translation&#10;scheme that improves the success rate of translating large&#45;scale C code into&#10;compilable Rust code. Our approach involves three key techniques: (1)&#10;pre&#45;processing the C code to better align its structure and expressions with&#10;Rust, (2) segmenting the code into optimally sized translation units to avoid&#10;exceeding the LLM&#39;s context window limits, and (3) iteratively compiling and&#10;repairing errors while maintaining consistency between translation units using&#10;context&#45;supplementing prompts. Compilation success is an essential first step&#10;in achieving functional equivalence, as only compilable code can be further&#10;tested. In experiments with 20 benchmark C programs, including those exceeding&#10;4 kilo lines of code, we successfully translated all programs into compilable&#10;Rust code without losing corresponding parts of the original code.&#10; | General | [Link](http://arxiv.org/abs/2409.10506v1) |&#10;| Machine Learning Optimization of non&#45;Kasha Behavior and of Transient&#10; &#160;Dynamics in Model Retinal Isomerization | Davinder Singh, Chern Chuang, Paul Brumer | &#160;&#160;Designing a model of retinal isomerization in Rhodopsin, the first step in&#10;vision, that accounts for both experimental transient and stationary state&#10;observables is challenging. Here, multi&#45;objective Bayesian optimization is&#10;employed to refine the parameters of a minimal two&#45;state&#45;two&#45;mode (TM) model&#10;describing the photoisomerization of retinal in Rhodopsin. With an appropriate&#10;selection of objectives, the optimized retinal model predicts excitation&#10;wavelength&#45;dependent fluorescence spectra that closely align with&#10;experimentally observed non&#45;Kasha behavior in the non&#45;equilibrium steady state.&#10;Further, adjustments to the potential energy surface within the TM model reduce&#10;the discrepancies across the time domain. Overall, agreement with experimental&#10;data is excellent.&#10; | General | [Link](http://arxiv.org/abs/2409.10505v1) |&#10;| DILA: Dictionary Label Attention for Mechanistic Interpretability in&#10; &#160;High&#45;dimensional Multi&#45;label Medical Coding Prediction | John Wu, David Wu, Jimeng Sun | &#160;&#160;Predicting high&#45;dimensional or extreme multilabels, such as in medical&#10;coding, requires both accuracy and interpretability. Existing works often rely&#10;on local interpretability methods, failing to provide comprehensive&#10;explanations of the overall mechanism behind each label prediction within a&#10;multilabel set. We propose a mechanistic interpretability module called&#10;DIctionary Label Attention (method) that disentangles uninterpretable dense&#10;embeddings into a sparse embedding space, where each nonzero element (a&#10;dictionary feature) represents a globally learned medical concept. Through&#10;human evaluations, we show that our sparse embeddings are more human&#10;understandable than its dense counterparts by at least 50 percent. Our&#10;automated dictionary feature identification pipeline, leveraging large language&#10;models (LLMs), uncovers thousands of learned medical concepts by examining and&#10;summarizing the highest activating tokens for each dictionary feature. We&#10;represent the relationships between dictionary features and medical codes&#10;through a sparse interpretable matrix, enhancing the mechanistic and global&#10;understanding of the model&#39;s predictions while maintaining competitive&#10;performance and scalability without extensive human annotation.&#10; | General | [Link](http://arxiv.org/abs/2409.10504v1) |&#10;| Causal Language Modeling Can Elicit Search and Reasoning Capabilities on&#10; &#160;Logic Puzzles | Kulin Shah, Nishanth Dikkala, Xin Wang, Rina Panigrahy | &#160;&#160;Causal language modeling using the Transformer architecture has yielded&#10;remarkable capabilities in Large Language Models (LLMs) over the last few&#10;years. However, the extent to which fundamental search and reasoning&#10;capabilities emerged within LLMs remains a topic of ongoing debate. In this&#10;work, we study if causal language modeling can learn a complex task such as&#10;solving Sudoku puzzles. To solve a Sudoku, the model is first required to&#10;search over all empty cells of the puzzle to decide on a cell to fill and then&#10;apply an appropriate strategy to fill the decided cell. Sometimes, the&#10;application of a strategy only results in thinning down the possible values in&#10;a cell rather than concluding the exact value of the cell. In such cases,&#10;multiple strategies are applied one after the other to fill a single cell. We&#10;observe that Transformer models trained on this synthetic task can indeed learn&#10;to solve Sudokus (our model solves $94.21%$ of the puzzles fully correctly)&#10;when trained on a logical sequence of steps taken by a solver. We find that&#10;training Transformers with the logical sequence of steps is necessary and&#10;without such training, they fail to learn Sudoku. We also extend our analysis&#10;to Zebra puzzles (known as Einstein puzzles) and show that the model solves&#10;$92.04 %$ of the puzzles fully correctly. In addition, we study the internal&#10;representations of the trained Transformer and find that through linear&#10;probing, we can decode information about the set of possible values in any&#10;given cell from them, pointing to the presence of a strong reasoning engine&#10;implicit in the Transformer weights.&#10; | General | [Link](http://arxiv.org/abs/2409.10502v1) |&#10;| Alignment with nonlinear velocity couplings: collision&#45;avoidance and&#10; &#160;micro&#45;to&#45;macro mean&#45;field limits | Young&#45;Pil Choi, Micha Fabisiak, Jan Peszek | &#160;&#160;We investigate the pressureless fractional Euler&#45;alignment system with&#10;nonlinear velocity couplings, referred to as the $p$&#45;Euler&#45;alignment system.&#10;This model features a nonlinear velocity alignment force, interpreted as a&#10;density&#45;weighted fractional $p$&#45;Laplacian when the singularity parameter&#10;$alpha$ exceeds the spatial dimension $d$. Our primary goal is to establish&#10;the existence of solutions for strongly singular interactions ($alpha ge d$)&#10;and compactly supported initial conditions. We construct solutions as&#10;mean&#45;field limits of empirical measures from a kinetic variant of the&#10;$p$&#45;Euler&#45;alignment system. Specifically, we show that a sequence of empirical&#10;measures converges to a finite Radon measure, whose local density and velocity&#10;satisfy the $p$&#45;Euler&#45;alignment system. Our results are the first to prove the&#10;existence of solutions to this system in multi&#45;dimensional settings without&#10;significant initial data restrictions, covering both nonlinear ($p&gt;2$) and&#10;linear ($p=2$) cases. Additionally, we establish global existence, uniqueness,&#10;and collision avoidance for the corresponding particle ODE system under&#10;non&#45;collisional initial conditions, extending previous results for $1 &#10;e p &#10;e&#10;alpha + 2$. This analysis supports our mean&#45;field limit argument and&#10;contributes to understanding alignment models with singular communication.&#10; | General | [Link](http://arxiv.org/abs/2409.10501v1) |&#10;| Focus diverse phase retrieval test results on broadband continuous&#10; &#160;wavefront sensing in space telescope applications | Hyukmo Kang, Kyle Van Gorkom, Meghdoot Biswas, Daewook Kim, Ewan S. Douglas | &#160;&#160;Continuous wavefront sensing benefits space observatories in on&#45;orbit optical&#10;performance maintenance. To measure the phase of a wavefront, phase retrieval&#10;is an attractive technique as it uses multiple point spread function (PSF)&#10;images that are acquired by the telescope itself without extra metrology&#10;systems nor complicated calibration. The focus diverse phase retrieval utilizes&#10;PSFs from predetermined defocused positions to enhance the dynamic range of the&#10;algorithm. We describe an updated visible light active optics testbed with the&#10;addition of a linear motorized focus stage. The performance of the phase&#10;retrieval algorithm in broadband is tested under various cases. While broadband&#10;pass filters have advantages in higher signal&#45;to&#45;noise ratio (SNR), the&#10;performance of phase retrieval can be restricted due to blurred image caused by&#10;diffraction and increased computing cost. We used multiple bandpass filters (10&#10;nm, 88 nm, and 150 nm) and investigated effects of bandwidth on the accuracy&#10;and required image acquisition conditions such as SNR, reaching accuracies&#10;below 20 nm RMS wavefront error at the widest bandwidth. We also investigated&#10;the dynamic range of the phase retrieval algorithm depending on the bandwidth&#10;and required amount of defocus to expand dynamic range. Finally, we simulated&#10;the continuous wavefront sensing and correction loop with a range of&#10;statistically generated representative telescope disturbance time series to&#10;test for edge cases.&#10; | General | [Link](http://arxiv.org/abs/2409.10500v1) |&#10;| The role of higher&#45;order terms in trapped&#45;ion quantum computing with&#10; &#160;magnetic gradient induced coupling | Sebastian Nagies, Kevin T. Geier, Javed Akram, Junichi Okamoto, Dimitris Badounas, Christof Wunderlich, Michael Johanning, Philipp Hauke | &#160;&#160;Trapped&#45;ion hardware based on the Magnetic Gradient Induced Coupling (MAGIC)&#10;scheme is emerging as a promising platform for quantum computing. Nevertheless,&#10;in this (as in any other) quantum&#45;computing platform, many technical questions&#10;still have to be resolved before large&#45;scale and error&#45;tolerant applications&#10;are possible. In this work, we present a thorough discussion of the&#10;contribution of higher&#45;order terms to the MAGIC setup, which can occur due to&#10;anharmonicities in the external potential of the ion crystal (e.g., through&#10;Coulomb repulsion) or through curvature of the applied magnetic field. These&#10;terms take the form of three&#45;spin couplings as well as diverse terms that&#10;couple spins to phonons. We find that most of these are negligible in realistic&#10;situations, with only two contributions that need careful attention. First,&#10;there are parasitic longitudinal fields whose strength increases with chain&#10;length, but which can easily be compensated by a microwave detuning. Second,&#10;anharmonicities of the Coulomb interaction can lead to well&#45;known two&#45;to&#45;one&#10;conversions of phonon excitations, which can be avoided if the phonons are&#10;ground&#45;state cooled. Our detailed analysis constitutes an important&#10;contribution on the way of making magnetic&#45;gradient trapped&#45;ion quantum&#10;technology fit for large&#45;scale applications, and it may inspire new ways to&#10;purposefully design interaction terms.&#10; | General | [Link](http://arxiv.org/abs/2409.10498v1) |&#10;| MusicLIME: Explainable Multimodal Music Understanding | Theodoros Sotirou, Vassilis Lyberatos, Orfeas Menis Mastromichalakis, Giorgos Stamou | &#160;&#160;Multimodal models are critical for music understanding tasks, as they capture&#10;the complex interplay between audio and lyrics. However, as these models become&#10;more prevalent, the need for explainability grows&#45;understanding how these&#10;systems make decisions is vital for ensuring fairness, reducing bias, and&#10;fostering trust. In this paper, we introduce MusicLIME, a model&#45;agnostic&#10;feature importance explanation method designed for multimodal music models.&#10;Unlike traditional unimodal methods, which analyze each modality separately&#10;without considering the interaction between them, often leading to incomplete&#10;or misleading explanations, MusicLIME reveals how audio and lyrical features&#10;interact and contribute to predictions, providing a holistic view of the&#10;model&#39;s decision&#45;making. Additionally, we enhance local explanations by&#10;aggregating them into global explanations, giving users a broader perspective&#10;of model behavior. Through this work, we contribute to improving the&#10;interpretability of multimodal music models, empowering users to make informed&#10;choices, and fostering more equitable, fair, and transparent music&#10;understanding systems.&#10; | General | [Link](http://arxiv.org/abs/2409.10496v1) |&#10;| Incorporating Classifier&#45;Free Guidance in Diffusion Model&#45;Based&#10; &#160;Recommendation | Noah Buchanan, Susan Gauch, Quan Mai | &#160;&#160;This paper presents a diffusion&#45;based recommender system that incorporates&#10;classifier&#45;free guidance. Most current recommender systems provide&#10;recommendations using conventional methods such as collaborative or&#10;content&#45;based filtering. Diffusion is a new approach to generative AI that&#10;improves on previous generative AI approaches such as Variational Autoencoders&#10;(VAEs) and Generative Adversarial Networks (GANs). We incorporate diffusion in&#10;a recommender system that mirrors the sequence users take when browsing and&#10;rating items. Although a few current recommender systems incorporate diffusion,&#10;they do not incorporate classifier&#45;free guidance, a new innovation in diffusion&#10;models as a whole. In this paper, we present a diffusion recommender system&#10;that augments the underlying recommender system model for improved performance&#10;and also incorporates classifier&#45;free guidance. Our findings show improvements&#10;over state&#45;of&#45;the&#45;art recommender systems for most metrics for several&#10;recommendation tasks on a variety of datasets. In particular, our approach&#10;demonstrates the potential to provide better recommendations when data is&#10;sparse.&#10; | General | [Link](http://arxiv.org/abs/2409.10494v1) |&#10;| Renormalization of the Einstein&#45;Cartan Theory in First&#45;Order Form | F. T. Brandt, J. Frenkel, S. Martins&#45;Filho, D. G. C. McKeon | &#160;&#160;We examine the Einstein&#45;Cartan (EC) theory in first&#45;order form, which has a&#10;diffeomorphism as well as a local Lorentz invariance. We study the&#10;renormalizability of this theory in the framework of the Batalin&#45;Vilkovisky&#10;formalism, which allows for a gauge invariant renormalization. Using the&#10;background field method, we discuss the gauge invariance of the background&#10;effective action and analyze the Ward identities which reflect the symmetries&#10;of the EC theory. As an application, we compute, in a general background gauge,&#10;the self&#45;energy of the tetrad field at one&#45;loop order.&#10; | General | [Link](http://arxiv.org/abs/2409.10493v1) |&#10;| What we can learn from the angular differential rates (only) in&#10; &#160;semileptonic $B to D^* ell _ell$ decays | G. Martinelli, S. Simula, L. Vittorio | &#160;&#160;We present a new, simple approach to the study of semileptonic $B to D^*&#10;ell &#10;u_ell$ decays based on the angular distributions of the final state&#10;particles only. Our approach is model independent and never requires the&#10;knowledge of $vert V_{cb}vert$. By studying such distributions in the case of&#10;light leptons, a comparison between results from different data sets from the&#10;Belle and BelleII Collaborations and between data and Standard Model&#10;calculations is also given for several interesting quantities. A good&#10;consistency is observed between some of the experimental results and the&#10;theoretical predictions.&#10; | General | [Link](http://arxiv.org/abs/2409.10492v1) |&#10;| Code Vulnerability Detection: A Comparative Analysis of Emerging Large&#10; &#160;Language Models | Shaznin Sultana, Sadia Afreen, Nasir U. Eisty | &#160;&#160;The growing trend of vulnerability issues in software development as a result&#10;of a large dependence on open&#45;source projects has received considerable&#10;attention recently. This paper investigates the effectiveness of Large Language&#10;Models (LLMs) in identifying vulnerabilities within codebases, with a focus on&#10;the latest advancements in LLM technology. Through a comparative analysis, we&#10;assess the performance of emerging LLMs, specifically Llama, CodeLlama, Gemma,&#10;and CodeGemma, alongside established state&#45;of&#45;the&#45;art models such as BERT,&#10;RoBERTa, and GPT&#45;3. Our study aims to shed light on the capabilities of LLMs in&#10;vulnerability detection, contributing to the enhancement of software security&#10;practices across diverse open&#45;source repositories. We observe that CodeGemma&#10;achieves the highest F1&#45;score of 58 and a Recall of 87, amongst the recent&#10;additions of large language models to detect software security vulnerabilities.&#10; | General | [Link](http://arxiv.org/abs/2409.10490v1) |&#10;| Flash STU: Fast Spectral Transform Units | Y. Isabel Liu, Windsor Nguyen, Yagiz Devre, Evan Dogariu, Anirudha Majumdar, Elad Hazan | &#160;&#160;This paper describes an efficient, open source PyTorch implementation of the&#10;Spectral Transform Unit. We investigate sequence prediction tasks over several&#10;modalities including language, robotics, and simulated dynamical systems. We&#10;find that for the same parameter count, the STU and its variants outperform the&#10;Transformer as well as other leading state space models across various&#10;modalities.&#10; | General | [Link](http://arxiv.org/abs/2409.10489v1) |&#10;| Do Pre&#45;trained Vision&#45;Language Models Encode Object States? | Kaleb Newman, Shijie Wang, Yuan Zang, David Heffren, Chen Sun | &#160;&#160;For a vision&#45;language model (VLM) to understand the physical world, such as&#10;cause and effect, a first step is to capture the temporal dynamics of the&#10;visual world, for example how the physical states of objects evolve over time&#10;(e.g. a whole apple into a sliced apple). Our paper aims to investigate if VLMs&#10;pre&#45;trained on web&#45;scale data learn to encode object states, which can be&#10;extracted with zero&#45;shot text prompts. We curate an object state recognition&#10;dataset ChangeIt&#45;Frames, and evaluate nine open&#45;source VLMs, including models&#10;trained with contrastive and generative objectives. We observe that while these&#10;state&#45;of&#45;the&#45;art vision&#45;language models can reliably perform object&#10;recognition, they consistently fail to accurately distinguish the objects&#39;&#10;physical states. Through extensive experiments, we identify three areas for&#10;improvements for VLMs to better encode object states, namely the quality of&#10;object localization, the architecture to bind concepts to objects, and the&#10;objective to learn discriminative visual and language encoders on object&#10;states. Data and code are released.&#10; | General | [Link](http://arxiv.org/abs/2409.10488v1) |&#10;| A Host Galaxy Morphology Link Between Quasi&#45;Periodic Eruptions and Tidal&#10; &#160;Disruption Events | Olivier Gilbert, John J. Ruan, Michael Eracleous, Daryl Haggard, Jessie C. Runnoe | &#160;&#160;The physical processes that produce X&#45;ray Quasi&#45;Periodic Eruptions (QPEs)&#10;recently discovered from the nuclei of several low&#45;redshift galaxies are&#10;mysterious. Several pieces of observational evidence strongly suggest a link&#10;between QPEs and Tidal Disruption Events (TDE). Previous studies also reveal&#10;that the morphologies of TDE host galaxies are highly concentrated, with high&#10;Sersic indicies, bulge&#45;to&#45;total light (B/T) ratios, and stellar surface mass&#10;densities relative to the broader galaxy population. We use these distinctive&#10;properties to test the link between QPEs and TDEs, by comparing these&#10;parameters of QPE host galaxies to TDE host galaxies. We employ archival Legacy&#10;Survey images of a sample of 9 QPE host galaxies and a sample of 13 TDE host&#10;galaxies, and model their surface brightness profiles. We show that QPE host&#10;galaxies have high Sersic indices of ~3, high B/T ratios of ~0.5, and high&#10;surface mass densities of ~10^10 Msun kpc^&#45;2. These properties are similar to&#10;TDE host galaxies, but are in strong contrast to a mass&#45; and redshift&#45;matched&#10;control sample of galaxies. We also find tentative evidence that the central&#10;black holes in both QPE and TDE host galaxies are undermassive relative to&#10;their stellar mass. The morphological similarities between QPE and TDE host&#10;galaxies at the population level add to the mounting evidence of a physical&#10;link between these phenomena, and favor QPE models that also invoke TDEs.&#10; | General | [Link](http://arxiv.org/abs/2409.10486v1) |&#10;| Tuning the Rate of Tightly Packed Systems To Produce Planet Occurrence&#10; &#160;Trends with Galactic Height | Sarah Ballard | &#160;&#160;The formation of planetary systems has historically been considered in&#10;isolation, decoupled from processes on galactic scales. Recent findings&#10;employing data from ESA&#39;s Gaia mission challenge this narrative, identifying&#10;trends in planet occurrence with galactic kinematics and stellar age. The&#10;findings indicate changes in planet occurrence over and above the predicted&#10;changes from metallicity variation within the Milky Way, so that changes to&#10;stellar metallicity alone (long understood to be deterministic in planet&#10;outcomes) cannot explain the trends entirely. The scope of potential factors&#10;influencing planet formation has grown progressively wider, with accompanying&#10;theoretical support for galactic&#45;scale influences upon planet formation. In&#10;this manuscript, we investigate specifically how changes to the rate of Systems&#10;of Tightly&#45;packed Inner Planets (STIPs) could manifest as a trend in planet&#10;occurrence with galactic height. We focus our study upon M dwarf planetary&#10;systems for two reasons: first, they host STIPs at high rates, and secondly,&#10;their longevity makes them useful probes for kinematic trends over Gyr. We&#10;consider two models for a varying STIP rate: one in which STIP likelihood is&#10;determined by stellar age alone, irrespective of galactic time, and another in&#10;which the STIP likelihood suddenly increased in recent galactic history. Both&#10;models, which impose a higher STIP likelihood among younger stars, produce a&#10;negative gradient in planet occurrence with increasing height from the galactic&#10;midplane. We find that a step function model in which STIP likelihood increased&#10;by a factor of several ~a few Gyr ago resembles an observed trend among FGK&#10;dwarfs. We consider plausible physical mechanisms that could mimic the&#10;hypothesized model, given known links between STIP occurrence and other stellar&#10;and planetary properties.&#10; | General | [Link](http://arxiv.org/abs/2409.10485v1) |&#10;| XLM for Autonomous Driving Systems: A Comprehensive Review | Sonda Fourati, Wael Jaafar, Noura Baccar, Safwan Alfattani | &#160;&#160;Large Language Models (LLMs) have showcased remarkable proficiency in various&#10;information&#45;processing tasks. These tasks span from extracting data and&#10;summarizing literature to generating content, predictive modeling,&#10;decision&#45;making, and system controls. Moreover, Vision Large Models (VLMs) and&#10;Multimodal LLMs (MLLMs), which represent the next generation of language&#10;models, a.k.a., XLMs, can combine and integrate many data modalities with the&#10;strength of language understanding, thus advancing several information&#45;based&#10;systems, such as Autonomous Driving Systems (ADS). Indeed, by combining&#10;language communication with multimodal sensory inputs, e.g., panoramic images&#10;and LiDAR or radar data, accurate driving actions can be taken. In this&#10;context, we provide in this survey paper a comprehensive overview of the&#10;potential of XLMs towards achieving autonomous driving. Specifically, we review&#10;the relevant literature on ADS and XLMs, including their architectures, tools,&#10;and frameworks. Then, we detail the proposed approaches to deploy XLMs for&#10;autonomous driving solutions. Finally, we provide the related challenges to XLM&#10;deployment for ADS and point to future research directions aiming to enable XLM&#10;adoption in future ADS frameworks.&#10; | General | [Link](http://arxiv.org/abs/2409.10484v1) |&#10;| Efficient polarizable QM/MM using the direct reaction field Hamiltonian&#10; &#160;with electrostatic potential fitted multipole operators | Thomas P. Fay, Nicolas Ferr, Miquel Huix&#45;Rotllant | &#160;&#160;Electronic polarization and dispersion are decisive actors in determining&#10;interaction energies between molecules. These interactions have a particularly&#10;profound effect on excitation energies of molecules in complex environments,&#10;especially when the excitation involves a significant degree of charge&#10;reorganisation. The direct reaction field (DRF) approach, which has seen a&#10;recent revival of interest, provides a powerful framework for describing these&#10;interactions in quantum mechanics/molecular mechanics (QM/MM) models of&#10;systems, where a small subsystem of interest is described using quantum&#10;chemical methods and the remainder is treated with a simple MM force field. In&#10;this paper we show how the DRF approach can be combined with the electrostatic&#10;potential fitted (ESPF) multipole operator description of the QM region charge&#10;density, which reduces the scaling $mathcal{O}(N_mathrm{MM}^3)$ of the method&#10;with MM system to $mathcal{O}(N_mathrm{MM}^2)$. We also show how the DRF&#10;approach can be combined with fluctuating charge descriptions of the&#10;polarizable environment, as well as previously used atom&#45;centred&#10;dipole&#45;polarizability based models. We further show that the ESPF&#45;DRF method&#10;provides an accurate description of molecular interactions in both ground and&#10;excited electronic states of the QM system and apply it to predict the gas to&#10;aqueous solution solvatochromic shifts in the UV/visible absorption spectrum of&#10;acrolein.&#10; | General | [Link](http://arxiv.org/abs/2409.10483v1) |&#10;| Schrodinger&#39;s Memory: Large Language Models | Wei Wang, Qing Li | &#160;&#160;Memory is the foundation of LLMs&#39; functionality, yet past research has lacked&#10;an in&#45;depth exploration of their memory capabilities and underlying theory. In&#10;this paper, we apply UAT theory to explain the memory mechanism of LLMs and&#10;propose a new approach for evaluating LLM performance by comparing the memory&#10;capacities of different models. Through extensive experiments, we validate our&#10;theory and the memory abilities of LLMs. Finally, we compare the capabilities&#10;of the human brain and LLMs, highlighting both their similarities and&#10;differences in terms of working mechanisms.&#10; | General | [Link](http://arxiv.org/abs/2409.10482v1) |&#10;| Exploring 3D Face Reconstruction and Fusion Methods for Face&#10; &#160;Verification: A Case&#45;Study in Video Surveillance | Simone Maurizio La Cava, Sara Concas, Ruben Tolosana, Roberto Casula, Giulia Orr, Martin Drahansky, Julian Fierrez, Gian Luca Marcialis | &#160;&#160;3D face reconstruction (3DFR) algorithms are based on specific assumptions&#10;tailored to distinct application scenarios. These assumptions limit their use&#10;when acquisition conditions, such as the subject&#39;s distance from the camera or&#10;the camera&#39;s characteristics, are different than expected, as typically happens&#10;in video surveillance. Additionally, 3DFR algorithms follow various strategies&#10;to address the reconstruction of a 3D shape from 2D data, such as statistical&#10;model fitting, photometric stereo, or deep learning. In the present study, we&#10;explore the application of three 3DFR algorithms representative of the SOTA,&#10;employing each one as the template set generator for a face verification&#10;system. The scores provided by each system are combined by score&#45;level fusion.&#10;We show that the complementarity induced by different 3DFR algorithms improves&#10;performance when tests are conducted at never&#45;seen&#45;before distances from the&#10;camera and camera characteristics (cross&#45;distance and cross&#45;camera settings),&#10;thus encouraging further investigations on multiple 3DFR&#45;based approaches.&#10; | General | [Link](http://arxiv.org/abs/2409.10481v1) |&#10;| Addressing misspecification in contextual optimization | Omar Bennouna, Jiawei Zhang, Saurabh Amin, Asuman Ozdaglar | &#160;&#160;We study a linear contextual optimization problem where a decision maker has&#10;access to historical data and contextual features to learn a cost prediction&#10;model aimed at minimizing decision error. We adopt the predict&#45;then&#45;optimize&#10;framework for this analysis. Given that perfect model alignment with reality is&#10;often unrealistic in practice, we focus on scenarios where the chosen&#10;hypothesis set is misspecified. In this context, it remains unclear whether&#10;current contextual optimization approaches can effectively address such model&#10;misspecification. In this paper, we present a novel integrated learning and&#10;optimization approach designed to tackle model misspecification in contextual&#10;optimization. This approach offers theoretical generalizability, tractability,&#10;and optimality guarantees, along with strong practical performance. Our method&#10;involves minimizing a tractable surrogate loss that aligns with the performance&#10;value from cost vector predictions, regardless of whether the model&#10;misspecified or not, and can be optimized in reasonable time. To our knowledge,&#10;no previous work has provided an approach with such guarantees in the context&#10;of model misspecification.&#10; | General | [Link](http://arxiv.org/abs/2409.10479v1) |&#10;| Local SGD for Near&#45;Quadratic Problems: Improving Convergence under&#10; &#160;Unconstrained Noise Conditions | Andrey Sadchikov, Savelii Chezhegov, Aleksandr Beznosikov, Alexander Gasnikov | &#160;&#160;Distributed optimization plays an important role in modern large&#45;scale&#10;machine learning and data processing systems by optimizing the utilization of&#10;computational resources. One of the classical and popular approaches is Local&#10;Stochastic Gradient Descent (Local SGD), characterized by multiple local&#10;updates before averaging, which is particularly useful in distributed&#10;environments to reduce communication bottlenecks and improve scalability. A&#10;typical feature of this method is the dependence on the frequency of&#10;communications. But in the case of a quadratic target function with homogeneous&#10;data distribution over all devices, the influence of frequency of&#10;communications vanishes. As a natural consequence, subsequent studies include&#10;the assumption of a Lipschitz Hessian, as this indicates the similarity of the&#10;optimized function to a quadratic one to some extent. However, in order to&#10;extend the completeness of the Local SGD theory and unlock its potential, in&#10;this paper we abandon the Lipschitz Hessian assumption by introducing a new&#10;concept of $textit{approximate quadraticity}$. This assumption gives a new&#10;perspective on problems that have near quadratic properties. In addition,&#10;existing theoretical analyses of Local SGD often assume bounded variance. We,&#10;in turn, consider the unbounded noise condition, which allows us to broaden the&#10;class of studied problems.&#10; | General | [Link](http://arxiv.org/abs/2409.10478v1) |&#10;| SimInversion: A Simple Framework for Inversion&#45;Based Text&#45;to&#45;Image&#10; &#160;Editing | Qi Qian, Haiyang Xu, Ming Yan, Juhua Hu | &#160;&#160;Diffusion models demonstrate impressive image generation performance with&#10;text guidance. Inspired by the learning process of diffusion, existing images&#10;can be edited according to text by DDIM inversion. However, the vanilla DDIM&#10;inversion is not optimized for classifier&#45;free guidance and the accumulated&#10;error will result in the undesired performance. While many algorithms are&#10;developed to improve the framework of DDIM inversion for editing, in this work,&#10;we investigate the approximation error in DDIM inversion and propose to&#10;disentangle the guidance scale for the source and target branches to reduce the&#10;error while keeping the original framework. Moreover, a better guidance scale&#10;(i.e., 0.5) than default settings can be derived theoretically. Experiments on&#10;PIE&#45;Bench show that our proposal can improve the performance of DDIM inversion&#10;dramatically without sacrificing efficiency.&#10; | General | [Link](http://arxiv.org/abs/2409.10476v1) |&#10;| Leadership and Engagement Dynamics in Legislative Twitter Networks:&#10; &#160;Statistical Analysis and Modeling | Carolina Luque, Juan Sosa | &#160;&#160;In this manuscript, we analyze the interaction network on Twitter among&#10;members of the 117th U.S. Congress to assess the visibility of political&#10;leaders and explore how systemic properties and node attributes influence the&#10;formation of legislative connections. We employ descriptive social network&#10;statistical methods, the exponential random graph model (ERGM), and the&#10;stochastic block model (SBM) to evaluate the relative impact of network&#10;systemic properties, as well as institutional and personal traits, on the&#10;generation of online relationships among legislators. Our findings reveal that&#10;legislative networks on social media platforms like Twitter tend to reinforce&#10;the leadership of dominant political actors rather than diminishing their&#10;influence. However, we identify that these leadership roles can manifest in&#10;various forms. Additionally, we highlight that online connections within&#10;legislative networks are influenced by both the systemic properties of the&#10;network and institutional characteristics.&#10; | General | [Link](http://arxiv.org/abs/2409.10475v1) |&#10;| MacDiff: Unified Skeleton Modeling with Masked Conditional Diffusion | Lehong Wu, Lilang Lin, Jiahang Zhang, Yiyang Ma, Jiaying Liu | &#160;&#160;Self&#45;supervised learning has proved effective for skeleton&#45;based human action&#10;understanding. However, previous works either rely on contrastive learning that&#10;suffers false negative problems or are based on reconstruction that learns too&#10;much unessential low&#45;level clues, leading to limited representations for&#10;downstream tasks. Recently, great advances have been made in generative&#10;learning, which is naturally a challenging yet meaningful pretext task to model&#10;the general underlying data distributions. However, the representation learning&#10;capacity of generative models is under&#45;explored, especially for the skeletons&#10;with spacial sparsity and temporal redundancy. To this end, we propose Masked&#10;Conditional Diffusion (MacDiff) as a unified framework for human skeleton&#10;modeling. For the first time, we leverage diffusion models as effective&#10;skeleton representation learners. Specifically, we train a diffusion decoder&#10;conditioned on the representations extracted by a semantic encoder. Random&#10;masking is applied to encoder inputs to introduce a information bottleneck and&#10;remove redundancy of skeletons. Furthermore, we theoretically demonstrate that&#10;our generative objective involves the contrastive learning objective which&#10;aligns the masked and noisy views. Meanwhile, it also enforces the&#10;representation to complement for the noisy view, leading to better&#10;generalization performance. MacDiff achieves state&#45;of&#45;the&#45;art performance on&#10;representation learning benchmarks while maintaining the competence for&#10;generative tasks. Moreover, we leverage the diffusion model for data&#10;augmentation, significantly enhancing the fine&#45;tuning performance in scenarios&#10;with scarce labeled data. Our project is available at&#10;https://lehongwu.github.io/ECCV24MacDiff/.&#10; | General | [Link](http://arxiv.org/abs/2409.10473v1) |&#10;| Towards Semantic Versioning of Open Pre&#45;trained Language Model Releases&#10; &#160;on Hugging Face | Adekunle Ajibode, Abdul Ali Bangash, Filipe Roseiro Cogo, Bram Adams, Ahmed E. Hassan | &#160;&#160;The proliferation of open Pre&#45;trained Language Models (PTLMs) on model&#10;registry platforms like Hugging Face (HF) presents both opportunities and&#10;challenges for companies building products around them. Similar to traditional&#10;software dependencies, PTLMs continue to evolve after a release. However, the&#10;current state of release practices of PTLMs on model registry platforms are&#10;plagued by a variety of inconsistencies, such as ambiguous naming conventions&#10;and inaccessible model training documentation. Given the knowledge gap on&#10;current PTLM release practices, our empirical study uses a mixed&#45;methods&#10;approach to analyze the releases of 52,227 PTLMs on the most well&#45;known model&#10;registry, HF. Our results reveal 148 different naming practices for PTLM&#10;releases, with 40.87% of changes to model weight files not represented in the&#10;adopted name&#45;based versioning practice or their documentation. In addition, we&#10;identified that the 52,227 PTLMs are derived from only 299 different base&#10;models (the modified original models used to create 52,227 PTLMs), with&#10;Fine&#45;tuning and Quantization being the most prevalent modification methods&#10;applied to these base models. Significant gaps in release transparency, in&#10;terms of training dataset specifications and model card availability, still&#10;exist, highlighting the need for standardized documentation. While we&#10;identified a model naming practice explicitly differentiating between major and&#10;minor PTLM releases, we did not find any significant difference in the types of&#10;changes that went into either type of releases, suggesting that major/minor&#10;version numbers for PTLMs often are chosen arbitrarily. Our findings provide&#10;valuable insights to improve PTLM release practices, nudging the field towards&#10;more formal semantic versioning practices.&#10; | General | [Link](http://arxiv.org/abs/2409.10472v1) |&#10;| Real&#45;Time Whole&#45;Body Control of Legged Robots with Model&#45;Predictive Path&#10; &#160;Integral Control | Juan Alvarez&#45;Padilla, John Z. Zhang, Sofia Kwok, John M. Dolan, Zachary Manchester | &#160;&#160;This paper presents a system for enabling real&#45;time synthesis of whole&#45;body&#10;locomotion and manipulation policies for real&#45;world legged robots. Motivated by&#10;recent advancements in robot simulation, we leverage the efficient&#10;parallelization capabilities of the MuJoCo simulator to achieve fast sampling&#10;over the robot state and action trajectories. Our results show surprisingly&#10;effective real&#45;world locomotion and manipulation capabilities with a very&#10;simple control strategy. We demonstrate our approach on several hardware and&#10;simulation experiments: robust locomotion over flat and uneven terrains,&#10;climbing over a box whose height is comparable to the robot, and pushing a box&#10;to a goal position. To our knowledge, this is the first successful deployment&#10;of whole&#45;body sampling&#45;based MPC on real&#45;world legged robot hardware.&#10;Experiment videos and code can be found at: https://whole&#45;body&#45;mppi.github.io/&#10; | General | [Link](http://arxiv.org/abs/2409.10469v1) |&#10;| Assortativity in sympatric speciation and species classification | Joao U. F. Lizarraga, Flavia M. D. Marquitti, Marcus A. M. de Aguiar | &#160;&#160;We investigate the role of assortative mating in speciation using the&#10;sympatric model of Derrida and Higgs. The model explores the idea that genetic&#10;differences create incompatibilities between individuals, preventing mating if&#10;the number of such differences is too large. Speciation, however, only happens&#10;in this mating system if the number of genes is large. Here we show that&#10;speciation with small genome sizes can occur if assortative mating is&#10;introduced. In our model individuals are represented by three chromosomes: one&#10;responsible for reproductive compatibility, one for coding the trait on which&#10;assortativity will operate, and a neutral chromosome. Reproduction is possible&#10;if individuals are genetically similar with respect to the first chromosome,&#10;but among these compatible mating partners, the one with the most similar trait&#10;coded by the second chromosome is selected. We show that this type of&#10;assortativity facilitates speciation, which can happen with a small number of&#10;genes in the first chromosome. Species, classified according to reproductive&#10;isolation, dictated by the first chromosome, can display different traits&#10;values, as measured by the second and the third chromosomes. Therefore, species&#10;can also be identified based on similarity of the neutral trait, which works as&#10;a proxy for reproductive isolation.&#10; | General | [Link](http://arxiv.org/abs/2409.10466v1) |&#10;| A stabilized total pressure&#45;formulation of the Biot&#39;s poroelasticity&#10; &#160;equations in frequency domain: numerical analysis and applications | Cristian Crcamo, Alfonso Caiazzo, Felipe Galarce, Joaqun Mura | &#160;&#160;This work focuses on the numerical solution of the dynamics of a poroelastic&#10;material in the frequency domain. We provide a detailed stability analysis&#10;based on the application of the Fredholm alternative in the continuous case,&#10;considering a total pressure formulation of the Biot&#39;s equations. In the&#10;discrete setting, we propose a stabilized equal order finite element method&#10;complemented by an additional pressure stabilization to enhance the robustness&#10;of the numerical scheme with respect to the fluid permeability. Utilizing the&#10;Fredholm alternative, we extend the well&#45;posedness results to the discrete&#10;setting, obtaining theoretical optimal convergence for the case of linear&#10;finite elements. We present different numerical experiments to validate the&#10;proposed method. First, we consider model problems with known analytic&#10;solutions in two and three dimensions. As next, we show that the method is&#10;robust for a wide range of permeabilities, including the case of discontinuous&#10;coefficients. Lastly, we show the application for the simulation of brain&#10;elastography on a realistic brain geometry obtained from medical imaging.&#10; | General | [Link](http://arxiv.org/abs/2409.10465v1) |&#10;| New Direct Sum Tests | Alek Westover, Edward Yu, Kai Zheng | &#160;&#160;A function $f:[n]^{d} to mathbb{F}_2$ is a defn{direct sum} if there are&#10;functions $L_i:[n]to mathbb{F}_2$ such that ${f(x) = sum_{i}L_i(x_i)}$. In&#10;this work we give multiple results related to the property testing of direct&#10;sums.&#10; &#160;Our first result concerns a test proposed by Dinur and Golubev in 2019. We&#10;call their test the Diamond test and show that it is indeed a direct sum&#10;tester. More specifically, we show that if a function $f$ is $epsilon$&#45;far&#10;from being a direct sum function, then the Diamond test rejects $f$ with&#10;probability at least $Omega_{n,epsilon}(1)$. Even in the case of $n = 2$, the&#10;Diamond test is, to the best of our knowledge, novel and yields a new tester&#10;for the classic property of affinity.&#10; &#160;Apart from the Diamond test, we also analyze a broad family of direct sum&#10;tests, which at a high level, run an arbitrary affinity test on the restriction&#10;of $f$ to a random hypercube inside of $[n]^d$. This family of tests includes&#10;the direct sum test analyzed in cite{di19}, but does not include the Diamond&#10;test. As an application of our result, we obtain a direct sum test which works&#10;in the online adversary model of cite{KRV}.&#10; &#160;Finally, we also discuss a Fourier analytic interpretation of the diamond&#10;tester in the $n=2$ case, as well as prove local correction results for direct&#10;sum as conjectured by Dinur and Golubev.&#10; | General | [Link](http://arxiv.org/abs/2409.10464v1) |&#10;| Kolmogorov&#45;Arnold Networks in Low&#45;Data Regimes: A Comparative Study with&#10; &#160;Multilayer Perceptrons | Farhad Pourkamali&#45;Anaraki | &#160;&#160;Multilayer Perceptrons (MLPs) have long been a cornerstone in deep learning,&#10;known for their capacity to model complex relationships. Recently,&#10;Kolmogorov&#45;Arnold Networks (KANs) have emerged as a compelling alternative,&#10;utilizing highly flexible learnable activation functions directly on network&#10;edges, a departure from the neuron&#45;centric approach of MLPs. However, KANs&#10;significantly increase the number of learnable parameters, raising concerns&#10;about their effectiveness in data&#45;scarce environments. This paper presents a&#10;comprehensive comparative study of MLPs and KANs from both algorithmic and&#10;experimental perspectives, with a focus on low&#45;data regimes. We introduce an&#10;effective technique for designing MLPs with unique, parameterized activation&#10;functions for each neuron, enabling a more balanced comparison with KANs. Using&#10;empirical evaluations on simulated data and two real&#45;world data sets from&#10;medicine and engineering, we explore the trade&#45;offs between model complexity&#10;and accuracy, with particular attention to the role of network depth. Our&#10;findings show that MLPs with individualized activation functions achieve&#10;significantly higher predictive accuracy with only a modest increase in&#10;parameters, especially when the sample size is limited to around one hundred.&#10;For example, in a three&#45;class classification problem within additive&#10;manufacturing, MLPs achieve a median accuracy of 0.91, significantly&#10;outperforming KANs, which only reach a median accuracy of 0.53 with default&#10;hyperparameters. These results offer valuable insights into the impact of&#10;activation function selection in neural networks.&#10; | General | [Link](http://arxiv.org/abs/2409.10463v1) |&#10;| Effects of synapse location, delay and background stochastic activity on&#10; &#160;synchronising hippocampal CA1 neurons | Alessandro Fiasconaro, Michele Migliore | &#160;&#160;We study the synchronisation of neurons in a realistic model under the&#10;Hodgkin&#45;Huxley dynamics. To focus on the role of the different locations of the&#10;excitatory synapses, we use two identical neurons where the set of input&#10;signals is grouped at two different distances from the soma. The system is&#10;intended to represent a CA1 hippocampal neuron in which the synapses arriving&#10;from the CA3 neurons of the trisynaptic pathway appear to be localised in the&#10;apical dendritic region and are, in principle, either proximal or distal to the&#10;soma. Synchronisation is studied using a specifically defined spiking&#10;correlation function as a function of various parameters such as the distance&#10;from the soma of one of the synaptic groups, the inhibition weight and the&#10;associated activation delay. We found that the neurons&#39; spiking activity&#10;depends nonmonotonically on the relative dendritic location of the synapses and&#10;their inhibitory weight, whereas the synchronisation measure always decreases&#10;with inhibition, and strongly depends on its activation time delay. The&#10;background activity on the somas results essentially independent on the&#10;fluctuation intensity and strongly support the importance of the balance&#10;between inhibition and excitation for neuronal synchronization.&#10; | General | [Link](http://arxiv.org/abs/2409.10460v1) |&#10;| Efficiently Crowdsourcing Visual Importance with Punch&#45;Hole Annotation | Minsuk Chang, Soohyun Lee, Aeri Cho, Hyeon Jeon, Seokhyeon Park, Cindy Xiong Bearfield, Jinwook Seo | &#160;&#160;We introduce a novel crowdsourcing method for identifying important areas in&#10;graphical images through punch&#45;hole labeling. Traditional methods, such as gaze&#10;trackers and mouse&#45;based annotations, which generate continuous data, can be&#10;impractical in crowdsourcing scenarios. They require many participants, and the&#10;outcome data can be noisy. In contrast, our method first segments the graphical&#10;image with a grid and drops a portion of the patches (punch holes). Then, we&#10;iteratively ask the labeler to validate each annotation with holes, narrowing&#10;down the annotation only having the most important area. This approach aims to&#10;reduce annotation noise in crowdsourcing by standardizing the annotations while&#10;enhancing labeling efficiency and reliability. Preliminary findings from&#10;fundamental charts demonstrate that punch&#45;hole labeling can effectively&#10;pinpoint critical regions. This also highlights its potential for broader&#10;application in visualization research, particularly in studying large&#45;scale&#10;users&#39; graphical perception. Our future work aims to enhance the algorithm to&#10;achieve faster labeling speed and prove its utility through large&#45;scale&#10;experiments.&#10; | General | [Link](http://arxiv.org/abs/2409.10459v1) |&#10;| Full distribution of local observables in an exactly solvable current&#10; &#160;carrying steady states of a driven XXZ chain | Sandipan Manna, G J Sreejith | &#160;&#160;Current carrying steady states of interacting spins chains exhibit rich&#10;structures generated through an interplay of current induced correlations and&#10;energetic constraints from the Hamiltonian. The XXZ spin chain when coupled to&#10;maximally polarizing Lindblad terms admits an exact solution in a matrix&#10;product state (MPS) form. We use this exact solution to study the correlations&#10;and distributions of simple local spin observables in the non equilibrium&#10;steady state (NESS). We present exact expressions for spin correlators, entropy&#10;per site, cumulant generating functions for distributions of local observables&#10;in the XX limit (Ising anisotropy $Delta=0$). Further, we use the exact MPS&#10;solution in systems with $Delta&gt;0$, to numerically exactly calculate the&#10;entropy, correlations, as well as distributions of spin observables in blocks&#10;as large as $nsim 200$ sites allowing an estimation of the rate functions. The&#10;$z$ magnetization distribution is consistant with short range spin correlations&#10;in the $z$ direction while the $x$&#45;magnetization shows a double peak structure&#10;at larger $Delta$ suggesting short range ferromagnetic ordering. We find that&#10;the distribution of $z$&#45;magnetization sharpens for parameters where the current&#10;is maximized.&#10; | General | [Link](http://arxiv.org/abs/2409.10458v1) |&#10;| Mean Residual Life Ageing Intensity Function | Ashutosh Singh, Ishapathik Das, Asok Kumar Nanda, Sumen Sen | &#160;&#160;The ageing intensity function is a powerful analytical tool that provides&#10;valuable insights into the ageing process across diverse domains such as&#10;reliability engineering, actuarial science, and healthcare. Its applications&#10;continue to expand as researchers delve deeper into understanding the complex&#10;dynamics of ageing and its implications for society. One common approach to&#10;defining the ageing intensity function is through the hazard rate or failure&#10;rate function, extensively explored in scholarly literature. Equally&#10;significant to the hazard rate function is the mean residual life function,&#10;which plays a crucial role in analyzing the ageing patterns exhibited by units&#10;or components. This article introduces the mean residual life ageing intensity&#10;(MRLAI) function to delve into component ageing behaviours across various&#10;distributions. Additionally, we scrutinize the closure properties of the MRLAI&#10;function across different reliability operations. Furthermore, a new order&#10;termed the mean residual life ageing intensity order is defined to analyze the&#10;ageing behaviour of a system, and the closure property of this order under&#10;various reliability operations is discussed.&#10; | General | [Link](http://arxiv.org/abs/2409.10456v1) |&#10;| Quantile Fourier regressions for decision making under uncertainty | Arash Khojaste, Geoffrey Pritchard, Golbon Zakeri | &#160;&#160;Weconsider Markov decision processes arising from a Markov model of an&#10;underlying natural phenomenon. Such phenomena are usually periodic (e.g.&#10;annual) in time, and so the Markov processes modelling them must be&#10;time&#45;inhomogeneous, with cyclostationary rather than stationary behaviour. We&#10;describe a technique for constructing such processes that allows for periodic&#10;variations both in the values taken by the process and in the serial dependence&#10;structure. We include two illustrative numerical examples: a hydropower&#10;scheduling problem and a model of offshore wind power integration.&#10; | General | [Link](http://arxiv.org/abs/2409.10455v1) |&#10;| The Debiased Near&#45;Earth Object Population from ATLAS Telescopes | Rogerio Deienno, Larry Denneau, David Nesvorn, David Vokrouhlick, William F. Bottke, Robert Jedicke, Shantanu Naidu, Steven R. Chesley, Davide Farnocchia, Paul W. Chodas | &#160;&#160;This work is dedicated to debias the Near&#45;Earth Objects (NEO) population&#10;based on observations from the Asteroid Terrestrial&#45;impact Last Alert System&#10;(ATLAS) telescopes. We have applied similar methods used to develop the&#10;recently released NEO model generator (NEOMOD), once debiasing the NEO&#10;population using data from Catalina Sky Survey (CSS) G96 telescope. ATLAS is&#10;composed of four different telescopes. We first analyzed observational data&#10;from each of all four telescopes separately and later combined them. Our&#10;results highlight main differences between CSS and ATLAS, e.g., sky coverage&#10;and survey power at debiasing the NEO population. ATLAS has a much larger sky&#10;coverage than CSS, allowing it to find bright NEOs that would be constantly&#10;&quot;hiding&quot; from CSS. Consequently, ATLAS is more powerful than CSS at debiasing&#10;the NEO population for H $&#10;esssim$ 19. With its intrinsically greater&#10;sensitivity and emphasis on observing near opposition, CSS excels in the&#10;debiasing of smaller objects. ATLAS, as an all sky survey designed to find&#10;imminent hazardous objects, necessarily spends a significant fraction of time&#10;looking at places on the sky where objects do not appear, reducing its power&#10;for debiasing the population of small objects. We estimate a NEO population&#10;completeness of $approx$ 88%$^{+3%}_{&#45;2%}$ for H $&lt;$ 17.75 and $approx$&#10;36%$^{+1%}_{&#45;1%}$ for H $&lt;$ 22.25. Those numbers are similar to previous&#10;estimates (within error bars for H $&lt;$ 17.75) from CSS, yet, around 3% and 8%&#10;smaller at their face values, respectively. We also confirm previous finding&#10;that the $&#10;u_6$ secular resonance is the main source of small and faint NEOs&#10;at H = 28, whereas the 3:1 mean motion resonance with Jupiter dominates for&#10;larger and brighter NEOs at H = 15.&#10; | General | [Link](http://arxiv.org/abs/2409.10453v1) |&#10;| Signed Graph Autoencoder for Explainable and Polarization&#45;Aware Network&#10; &#160;Embeddings | Nikolaos Nakis, Chrysoula Kosma, Giannis Nikolentzos, Michalis Chatzianastasis, Iakovos Evdaimon, Michalis Vazirgiannis | &#160;&#160;Autoencoders based on Graph Neural Networks (GNNs) have garnered significant&#10;attention in recent years for their ability to extract informative latent&#10;representations, characterizing the structure of complex topologies, such as&#10;graphs. Despite the prevalence of Graph Autoencoders, there has been limited&#10;focus on developing and evaluating explainable neural&#45;based graph generative&#10;models specifically designed for signed networks. To address this gap, we&#10;propose the Signed Graph Archetypal Autoencoder (SGAAE) framework. SGAAE&#10;extracts node&#45;level representations that express node memberships over distinct&#10;extreme profiles, referred to as archetypes, within the network. This is&#10;achieved by projecting the graph onto a learned polytope, which governs its&#10;polarization. The framework employs a recently proposed likelihood for&#10;analyzing signed networks based on the Skellam distribution, combined with&#10;relational archetypal analysis and GNNs. Our experimental evaluation&#10;demonstrates the SGAAEs&#39; capability to successfully infer node memberships over&#10;the different underlying latent structures while extracting competing&#10;communities formed through the participation of the opposing views in the&#10;network. Additionally, we introduce the 2&#45;level network polarization problem&#10;and show how SGAAE is able to characterize such a setting. The proposed model&#10;achieves high performance in different tasks of signed link prediction across&#10;four real&#45;world datasets, outperforming several baseline models.&#10; | General | [Link](http://arxiv.org/abs/2409.10452v1) |&#10;| Why you should also use OLS estimation of tail exponents | Thiago Trafane Oliveira Santos, Daniel Oliveira Cajueiro | &#160;&#160;Even though practitioners often estimate Pareto exponents running OLS&#10;rank&#45;size regressions, the usual recommendation is to use the Hill MLE with a&#10;small&#45;sample correction instead, due to its unbiasedness and efficiency. In&#10;this paper, we advocate that you should also apply OLS in empirical&#10;applications. On the one hand, we demonstrate that, with a small&#45;sample&#10;correction, the OLS estimator is also unbiased. On the other hand, we show that&#10;the MLE assigns significantly greater weight to smaller observations. This&#10;suggests that the OLS estimator may outperform the MLE in cases where the&#10;distribution is (i) strictly Pareto but only in the upper tail or (ii)&#10;regularly varying rather than strictly Pareto. We substantiate our theoretical&#10;findings with Monte Carlo simulations and real&#45;world applications,&#10;demonstrating the practical relevance of the OLS method in estimating tail&#10;exponents.&#10; | General | [Link](http://arxiv.org/abs/2409.10448v1) |&#10;| Hydrodynamic hovering of swimming bacteria above surfaces | Pyae Hein Htet, Debasish Das, Eric Lauga | &#160;&#160;Flagellated bacteria are hydrodynamically attracted to rigid walls, yet past&#10;work shows a &#39;hovering&#39; state where they swim stably at a finite height above&#10;surfaces. We use numerics and theory to reveal the physical origin of hovering.&#10;Simulations first show that hovering requires an elongated cell body and&#10;results from a tilt away from the wall. Theoretical models then identify two&#10;essential asymmetries: the response of width&#45;asymmetric cells to active flows&#10;created by length&#45;asymmetric cells. A minimal model reconciles near and&#10;far&#45;field hydrodynamics, capturing all key features of hovering.&#10; | General | [Link](http://arxiv.org/abs/2409.10447v1) |&#10;| KoroT&#45;3E: A Personalized Musical Mnemonics Tool for Enhancing Memory&#10; &#160;Retention of Complex Computer Science Concepts | Xiangzhe Yuan, Jiajun Wang, Siying Hu, Andrew Cheung, Zhicong Lu | &#160;&#160;As the demand for computer science (CS) skills grows, mastering foundational&#10;concepts is crucial yet challenging for novice learners. To address this&#10;challenge, we present KoroT&#45;3E, an AI&#45;based system that creates personalized&#10;musical mnemonics to enhance both memory retention and understanding of&#10;concepts in CS. KoroT&#45;3E enables users to transform complex concepts into&#10;memorable lyrics and compose melodies that suit their musical preferences. We&#10;conducted semi&#45;structured interviews (n=12) to investigate why novice learners&#10;find it challenging to memorize and understand CS concepts. The findings,&#10;combined with constructivist learning theory, established our initial design,&#10;which was then refined following consultations with CS education experts. An&#10;empirical experiment(n=36) showed that those using KoroT&#45;3E (n=18)&#10;significantly outperformed the control group (n=18), with improved memory&#10;efficiency, increased motivation, and a positive learning experience. These&#10;findings demonstrate the effectiveness of integrating multimodal generative AI&#10;into CS education to create personalized and interactive learning experiences.&#10; | General | [Link](http://arxiv.org/abs/2409.10446v1) |&#10;| Deep&#45;Wide Learning Assistance for Insect Pest Classification | Toan Nguyen, Huy Nguyen, Huy Ung, Hieu Ung, Binh Nguyen | &#160;&#160;Accurate insect pest recognition plays a critical role in agriculture. It is&#10;a challenging problem due to the intricate characteristics of insects. In this&#10;paper, we present DeWi, novel learning assistance for insect pest&#10;classification. With a one&#45;stage and alternating training strategy, DeWi&#10;simultaneously improves several Convolutional Neural Networks in two&#10;perspectives: discrimination (by optimizing a triplet margin loss in a&#10;supervised training manner) and generalization (via data augmentation). From&#10;that, DeWi can learn discriminative and in&#45;depth features of insect pests&#10;(deep) yet still generalize well to a large number of insect categories (wide).&#10;Experimental results show that DeWi achieves the highest performances on two&#10;insect pest classification benchmarks (76.44% accuracy on the IP102 dataset&#10;and 99.79% accuracy on the D0 dataset, respectively). In addition, extensive&#10;evaluations and ablation studies are conducted to thoroughly investigate our&#10;DeWi and demonstrate its superiority. Our source code is available at&#10;https://github.com/toannguyen1904/DeWi.&#10; | General | [Link](http://arxiv.org/abs/2409.10445v1) |&#10;| LLM as BT&#45;Planner: Leveraging LLMs for Behavior Tree Generation in Robot&#10; &#160;Task Planning | Jicong Ao, Fan Wu, Yansong Wu, Abdalla Swikir, Sami Haddadin | &#160;&#160;Robotic assembly tasks are open challenges due to the long task horizon and&#10;complex part relations. Behavior trees (BTs) are increasingly used in robot&#10;task planning for their modularity and flexibility, but manually designing them&#10;can be effort&#45;intensive. Large language models (LLMs) have recently been&#10;applied in robotic task planning for generating action sequences, but their&#10;ability to generate BTs has not been fully investigated. To this end, We&#10;propose LLM as BT&#45;planner, a novel framework to leverage LLMs for BT generation&#10;in robotic assembly task planning and execution. Four in&#45;context learning&#10;methods are introduced to utilize the natural language processing and inference&#10;capabilities of LLMs to produce task plans in BT format, reducing manual effort&#10;and ensuring robustness and comprehensibility. We also evaluate the performance&#10;of fine&#45;tuned, fewer&#45;parameter LLMs on the same tasks. Experiments in simulated&#10;and real&#45;world settings show that our framework enhances LLMs&#39; performance in&#10;BT generation, improving success rates in BT generation through in&#45;context&#10;learning and supervised fine&#45;tuning.&#10; | General | [Link](http://arxiv.org/abs/2409.10444v1) |&#10;| The James Webb Space Telescope Absolute Flux Calibration. II.&#10; &#160;Mid&#45;Infrared Instrument Imaging and Coronagraphy | Karl D. Gordon, G. C. Sloan, Macarena Garcia Marin, Mattia Libralato, George Rieke, Jonathan A. Aguilar, Ralph Bohlin, Misty Cracraft, Marjorie Decleir, Andras Gaspar, David R. Law, Alberto Noriega&#45;Crespo, Michael Regan | &#160;&#160;The absolute flux calibration of the Mid&#45;Infrared Instrument Imaging and&#10;Coronagraphy is based on observations of multiple stars taken during the first&#10;2.5 years of JWST operations. The observations were designed to ensure that the&#10;flux calibration is valid for a range of flux densities, different subarrays,&#10;and different types of stars. The flux calibration was measured by combining&#10;observed aperture photometry corrected to infinite aperture with predictions&#10;based on previous observations and models of stellar atmospheres. A subset of&#10;these observations were combined with model point&#45;spread&#45;functions to measure&#10;the corrections to infinite aperture. Variations in the calibration factor with&#10;time, flux density, background level, type of star, subarray, integration time,&#10;rate, and well depth were investigated, and the only significant variations&#10;were with time and subarray. Observations of the same star taken approximately&#10;every month revealed a modest time&#45;dependent response loss seen mainly at the&#10;longest wavelengths. This loss is well characterized by a decaying exponential&#10;with a time constant of ~200 days. After correcting for the response loss, the&#10;band&#45;dependent scatter around the corrected average (aka repeatability) was&#10;found to range from 0.1 to 1.2%. Signals in observations taken with different&#10;subarrays can be lower by up to 3.4% compared to FULL frame. After correcting&#10;for the time and subarray dependencies, the scatter in the calibration factors&#10;measured for individual stars ranges from 1 to 4% depending on the band. The&#10;formal uncertainties on the flux calibration averaged for all observations are&#10;0.3 to 1.0%, with longer&#45;wavelength bands generally having larger&#10;uncertainties.&#10; | General | [Link](http://arxiv.org/abs/2409.10443v1) |&#10;| CtRNet&#45;X: Camera&#45;to&#45;Robot Pose Estimation in Real&#45;world Conditions Using&#10; &#160;a Single Camera | Jingpei Lu, Zekai Liang, Tristin Xie, Florian Ritcher, Shan Lin, Sainan Liu, Michael C. Yip | &#160;&#160;Camera&#45;to&#45;robot calibration is crucial for vision&#45;based robot control and&#10;requires effort to make it accurate. Recent advancements in markerless pose&#10;estimation methods have eliminated the need for time&#45;consuming physical setups&#10;for camera&#45;to&#45;robot calibration. While the existing markerless pose estimation&#10;methods have demonstrated impressive accuracy without the need for cumbersome&#10;setups, they rely on the assumption that all the robot joints are visible&#10;within the camera&#39;s field of view. However, in practice, robots usually move in&#10;and out of view, and some portion of the robot may stay out&#45;of&#45;frame during the&#10;whole manipulation task due to real&#45;world constraints, leading to a lack of&#10;sufficient visual features and subsequent failure of these approaches. To&#10;address this challenge and enhance the applicability to vision&#45;based robot&#10;control, we propose a novel framework capable of estimating the robot pose with&#10;partially visible robot manipulators. Our approach leverages the&#10;Vision&#45;Language Models for fine&#45;grained robot components detection, and&#10;integrates it into a keypoint&#45;based pose estimation network, which enables more&#10;robust performance in varied operational conditions. The framework is evaluated&#10;on both public robot datasets and self&#45;collected partial&#45;view datasets to&#10;demonstrate our robustness and generalizability. As a result, this method is&#10;effective for robot pose estimation in a wider range of real&#45;world manipulation&#10;scenarios.&#10; | General | [Link](http://arxiv.org/abs/2409.10441v1) |&#10;| Successive topological phase transitions in two distinct spin&#45;flop&#10; &#160;phases on the honeycomb lattice | Xudong Li, Jize Zhao, Jinbin Li, Qiang Luo | &#160;&#160;The Kitaev magnets with bond&#45;dependent interactions have garnered&#10;considerable attention in recent years for their ability to harbor exotic&#10;phases and nontrivial excitations. The topological magnons, which are indicated&#10;by nonzero Chern number and thermal Hall conductivity, are proposed to&#10;partially explain thermal Hall measurements in real materials. Hitherto,&#10;topological magnons have been extensively explored when the magnetic field is&#10;normal to the honeycomb plane, but their topological characteristics are less&#10;studied in the presence of in&#45;plane magnetic field. Here, we study two distinct&#10;in&#45;plane field induced spin&#45;flop phases in the $Gamma$&#45;$Gamma&#39;$ model, both&#10;of which are off&#45;diagonal couplings that have intimate relation to the Kitaev&#10;interaction. The two spin&#45;flop phases are distinguished by their out&#45;of&#45;plane&#10;spin components which can be either antiparallel or parallel, thus dubbing&#10;antiferromagnetic (AFM) or ferromagnetic (FM) spin&#45;flop phases, respectively.&#10;We map out topological phase diagrams for both phases, revealing a rich pattern&#10;of the Chern number over exchange parameters and magnetic field. We&#10;analytically calculate the boundaries of topological phase transitions when the&#10;magnetic field is along the $a$ and $b$ directions. We find that the thermal&#10;Hall conductivity and its derivative display contrasting behaviors when&#10;crossing different topological phase transitions. The striking difference of&#10;the two phases lies in that when the magnetic field is along the $b$ direction,&#10;topological magnons are totally absent in the AFM spin&#45;flop phase, while they&#10;can survive in the FM analogue in certain parameter regions.&#10; | General | [Link](http://arxiv.org/abs/2409.10439v1) |&#10;| A functorial approach to $n$&#45;abelian categories | Vitor Gulisz | &#160;&#160;We develop a functorial approach to the study of $n$&#45;abelian categories by&#10;reformulating their axioms in terms of their categories of finitely presented&#10;functors. Such an approach allows the use of classical homological algebra and&#10;representation theory techniques to understand higher homological algebra. As&#10;an application, we present two possible generalizations of the axioms &quot;every&#10;monomorphism is a kernel&quot; and &quot;every epimorphism is a cokernel&quot; of an abelian&#10;category to $n$&#45;abelian categories. We also specialize our results to modules&#10;over rings, thereby describing when the category of finitely generated&#10;projective modules over a ring is $n$&#45;abelian. Moreover, we establish a&#10;correspondence for $n$&#45;abelian categories with additive generators, which&#10;extends the higher Auslander correspondence.&#10; | General | [Link](http://arxiv.org/abs/2409.10438v1) |&#10;| Color symmetry breaking in the Potts spin glass | Jean&#45;Christophe Mourrat | &#160;&#160;The Potts spin glass is an analogue of the Sherrington&#45;Kirkpatrick model in&#10;which each spin can take one of $kappa$ possible values, which we interpret as&#10;colors. It was suggested in arXiv:2310.06745 that the order parameter for this&#10;model is always invariant with respect to permutations of the colors. We show&#10;here that this is false whenever $kappa ge 58$.&#10; | General | [Link](http://arxiv.org/abs/2409.10437v1) |&#10;| Infector characteristics exposed by spatial analysis of SARS&#45;CoV&#45;2&#10; &#160;sequence and demographic data analysed at fine geographical scales | Anna Gama, Samantha Lycett, Will Harvey, Joseph Hughes, Sema Nickbakhsh, David L Robertson, Alison Smith Palmer, Anthony Wood, Rowland Kao | &#160;&#160;Characterising drivers of SARS&#45;CoV&#45;2 circulation is crucial for understanding&#10;COVID&#45;19 because of the severity of control measures adopted during the&#10;pandemic. Whole genome sequence data augmented with demographic metadata&#10;provides the best opportunity to do this. We use Random Forest Decision Tree&#10;models to analyse a combination of over 4000 SARS&#45;CoV2 sequences from a densely&#10;sampled, mixed urban and rural population (Tayside) in Scotland in the period&#10;from August 2020 to July 2021, with fine scale geographical and&#10;socio&#45;demographic metadata. Comparing periods in versus out of &quot;lockdown&quot;&#10;restrictions, we show using genetic distance relationships that individuals&#10;from more deprived areas are more likely to get infected during lockdown but&#10;less likely to spread the infection further. As disadvantaged communities were&#10;the most affected by both COVID&#45;19 and its restrictions, our finding has&#10;important implications for informing future approaches to control future&#10;pandemics driven by similar respiratory infections.&#10; | General | [Link](http://arxiv.org/abs/2409.10436v1) |&#10;| A study of pure multi&#45;strange hadrons production in Pb+Pb collisions at&#10; &#160;LHC energies using HYDJET++ model | Gauri Devi, B. K. Singh | &#160;&#160;For the present work, we have used the HYDJET++ model to explore the&#10;production of pure multi&#45;strange hadrons in Pb+Pb collisions at&#10;$sqrt{s_{NN}}$= 2.76 TeV and $sqrt{s_{NN}}$= 5.02 TeV collision energies,&#10;respectively. We have simulated the $p_{T}$&#45;spectra and elliptic flow ($v_{2}$)&#10;of $phi$&#45;meson and $Omega$&#45;baryons comparing our results with ALICE&#10;experimental data and several phenomenological models (HIJING/$Boverline{B}$,&#10;VISHNU, EPOS, AMPT, and Krakow) across various centrality intervals.&#10;Additionally, we have calculated the nuclear modification factors ($R_{AA}$ and&#10;$R_{CP}$), which provide a perception of jet quenching phenomena. Hence, our&#10;findings enable the study of the energy and system dependence of $phi$ and&#10;$Omega$ hadrons production over a wide range of ultra&#45;relativistic collision&#10;energies. We also present the particle ratios ($Omega/phi$,&#10;$overline{Omega}^{+}/Omega^{&#45;}$, $Omega/pi$, and $phi/pi$), offering&#10;insights on the strangeness enhancement and chemical properties of the medium&#10;at both LHC collision energies.&#10; | General | [Link](http://arxiv.org/abs/2409.10435v1) |&#10;| Magnetic metamaterials by ion&#45;implantation | Christina Vantaraki, Petter Strm, Tuan T. Tran, Matas P. Grassi, Giovanni Fevola, Michael Foerster, Jerzy T. Sadowski, Daniel Primetzhofer, Vassilios Kapaklis | &#160;&#160;We present a method for the additive fabrication of planar magnetic&#10;nanoarrays with minimal surface roughness. Synthesis is accomplished by&#10;combining electron&#45;beam lithography, used to generate nanometric patterned&#10;masks, with ion implantation in thin films. By implanting $^{56}$Fe$^{+}$ ions,&#10;we are able to introduce magnetic functionality in a controlled manner into&#10;continuous Pd thin films, achieving 3D spatial resolution down to a few tens of&#10;nanometers. Our results demonstrate the successful application of this&#10;technique in fabricating square artificial spin ice lattices, which exhibit&#10;well&#45;defined magnetization textures and interactions among the patterned&#10;magnetic elements.&#10; | General | [Link](http://arxiv.org/abs/2409.10433v1) |&#10;| Structure&#45;preserving learning for multi&#45;symplectic PDEs | Sleyman Yldz, Pawan Goyal, Peter Benner | &#160;&#160;This paper presents an energy&#45;preserving machine learning method for&#10;inferring reduced&#45;order models (ROMs) by exploiting the multi&#45;symplectic form&#10;of partial differential equations (PDEs). The vast majority of&#10;energy&#45;preserving reduced&#45;order methods use symplectic Galerkin projection to&#10;construct reduced&#45;order Hamiltonian models by projecting the full models onto a&#10;symplectic subspace. However, symplectic projection requires the existence of&#10;fully discrete operators, and in many cases, such as black&#45;box PDE solvers,&#10;these operators are inaccessible. In this work, we propose an energy&#45;preserving&#10;machine learning method that can infer the dynamics of the given PDE using data&#10;only, so that the proposed framework does not depend on the fully discrete&#10;operators. In this context, the proposed method is non&#45;intrusive. The proposed&#10;method is grey box in the sense that it requires only some basic knowledge of&#10;the multi&#45;symplectic model at the partial differential equation level. We prove&#10;that the proposed method satisfies spatially discrete local energy conservation&#10;and preserves the multi&#45;symplectic conservation laws. We test our method on the&#10;linear wave equation, the Korteweg&#45;de Vries equation, and the&#10;Zakharov&#45;Kuznetsov equation. We test the generalization of our learned models&#10;by testing them far outside the training time interval.&#10; | General | [Link](http://arxiv.org/abs/2409.10432v1) |&#10;| Hippocampal synchronization in a realistic CA1 neuron model | Alessandro Fiasconaro, Michele Migliore | &#160;&#160;This work delves into studying the synchronization in two realistic neuron&#10;models using Hodgkin&#45;Huxley dynamics. Unlike simplistic point&#45;like models,&#10;excitatory synapses are here randomly distributed along the dendrites,&#10;introducing strong stochastic contributions into their signal propagation. To&#10;focus on the role of different excitatory positions, we use two copies of the&#10;same neuron whose synapses are located at different distances from the soma and&#10;are exposed to identical Poissonian distributed current pulses. The&#10;synchronization is investigated through a specifically defined spiking&#10;correlation function, and its behavior is analyzed as a function of several&#10;parameters: inhibition weight, distance from the soma of one synaptic group,&#10;excitatory inactivation delay, and weight of the excitatory synapses.&#10; | General | [Link](http://arxiv.org/abs/2409.10431v1) |&#10;| Meta&#45;Whisper: Speech&#45;Based Meta&#45;ICL for ASR on Low&#45;Resource Languages | Ming&#45;Hao Hsu, Kuan Po Huang, Hung&#45;yi Lee | &#160;&#160;This paper presents Meta&#45;Whisper, a novel approach to improve automatic&#10;speech recognition (ASR) for low&#45;resource languages using the Whisper model. By&#10;leveraging Meta In&#45;Context Learning (Meta&#45;ICL) and a k&#45;Nearest Neighbors (KNN)&#10;algorithm for sample selection, Meta&#45;Whisper enhances Whisper&#39;s ability to&#10;recognize speech in unfamiliar languages without extensive fine&#45;tuning.&#10;Experiments on the ML&#45;SUPERB dataset show that Meta&#45;Whisper significantly&#10;reduces the Character Error Rate (CER) for low&#45;resource languages compared to&#10;the original Whisper model. This method offers a promising solution for&#10;developing more adaptable multilingual ASR systems, particularly for languages&#10;with limited resources.&#10; | General | [Link](http://arxiv.org/abs/2409.10429v1) |&#10;| User&#45;Authenticated Device&#45;Independent Quantum Secure Direct&#10; &#160;Communication Protocol | Nayana Das, Saikat Basu, Goutam Paul, Vijay S. Rao | &#160;&#160;Device&#45;Independent Quantum Secure Direct Communication (DI&#45;QSDC) enhances&#10;quantum cryptography by enabling secure message transmission without relying on&#10;the trustworthiness of the devices involved. This approach mitigates risks&#10;associated with compromised or untrusted devices, common in traditional quantum&#10;communication.&#10; &#160;In this paper, we propose the first of its kind DI&#45;QSDC protocol with user&#10;identity authentication. This ensures the authenticity of both the sender and&#10;receiver prior to message exchange. We then discuss the security of the&#10;proposed protocol against common attacks, demonstrating that no eavesdropper&#10;gains any information from either the quantum or the classical channel. Next,&#10;we implement the protocol on IBM&#39;s quantum hardware and evaluate its&#10;performance in a realistic noisy environment. Additionally, by simulating&#10;common attack models, we showcase that the protocol is secure against any&#10;eavesdropper in the channel. These findings highlight the protocol&#39;s robust&#10;security and practical feasibility for real&#45;world secure quantum communication.&#10; | General | [Link](http://arxiv.org/abs/2409.10427v1) |&#10;| Role of kinematic constraints in the time reversal symmetry breaking of&#10; &#160;a model active matter | Soumen Das, Shankar Ghosh, Tridib Sadhu, Juliane U Klamser | &#160;&#160;Active&#45;matter systems are inherently out&#45;of&#45;equilibrium and perform&#10;mechanical work by utilizing their internal energy sources. Breakdown of&#10;time&#45;reversal symmetry (BTRS) is a hallmark of such dissipative non&#45;equilibrium&#10;dynamics. We introduce a robust, experimentally accessible, noninvasive,&#10;quantitative measure of BTRS in terms of the Kullback&#45;Leibler divergence in&#10;collision events, demonstrated in our novel artificial active matter, comprised&#10;of battery&#45;powered spherical rolling robots whose energetics in different modes&#10;of motion can be measured with high precision. Our dimensionless measure&#10;characterizes how dissipation and internal energetics are influenced by&#10;kinematic constraints from interactions with the environment. We propose this&#10;measure of BTRS as an empirical estimate of the distance from equilibrium. An&#10;energetic insight into this departure of active matter from equilibrium comes&#10;from our demonstration of a non&#45;trivial fluctuation symmetry, which reveals a&#10;potentially universal thermodynamic characteristic of active energetics. As a&#10;many&#45;body consequence of BTRS in our experimental active system, we demonstrate&#10;the emergence of activity&#45;induced herding, which has no equilibrium analogue.&#10; | General | [Link](http://arxiv.org/abs/2409.10425v1) |&#10;| Unveiling V Modes: Enhancing CMB Sensitivity to BSM Physics with a&#10; &#160;Non&#45;Ideal Half&#45;Wave Plate | N. Raffuzzi, M. Lembo, S. Giardiello, M. Gerbino, M. Lattanzi, P. Natoli, L. Pagano | &#160;&#160;V&#45;mode polarization of the cosmic microwave background is expected to be&#10;vanishingly small in the $Lambda$CDM model and, hence, usually ignored.&#10;Nonetheless, several astrophysical effects, as well as beyond standard model&#10;physics could produce it at a detectable level. A realistic half&#45;wave plate &#45;&#10;an optical element commonly used in CMB experiments to modulate the polarized&#10;signal &#45; can provide sensitivity to V modes without significantly spoiling that&#10;to linear polarization. We assess this sensitivity for some new&#45;generation CMB&#10;experiments, such as the LiteBIRD satellite, the ground&#45;based Simons&#10;Observatory and a CMB&#45;S4&#45;like experiment. We forecast the efficiency of these&#10;experiments to constrain the phenomenology of certain classes of BSM models&#10;inducing mixing of linear polarization states and generation of V modes in the&#10;CMB. We find that new&#45;generation experiments can improve current limits by&#10;1&#45;to&#45;3 orders of magnitude, depending on the data combination. The inclusion of&#10;V&#45;mode information dramatically boosts the sensitivity to these BSM models.&#10; | General | [Link](http://arxiv.org/abs/2409.10424v1) |&#10;| Initial data for a deformed isolated horizon | Ale Flandera, David Kofro, Tom Ledvinka | &#160;&#160;Within the isolated horizon formalism, we investigate a static axisymmetric&#10;space&#45;time of a black hole influenced by matter in its neighborhood. To&#10;illustrate the role of ingredients and assumptions in this formalism, we first&#10;show how, in spherical symmetry, the field equations and gauge conditions imply&#10;the isolated horizon initial data leading to the Schwarzschild space&#45;time.&#10;Then, we construct the initial data for a static axisymmetric isolated horizon&#10;representing a deformed black hole. The space&#45;time description in the&#10;Bondi&#45;like coordinates is then found as a series expansion in the vicinity of&#10;the horizon. To graphically illustrate this construction, we also find a&#10;numerical solution for a black hole deformed by a particular analytic model of&#10;a thin accretion disk. We also discuss how an accretion disk affects the&#10;analytical properties of the horizon geometry.&#10; | General | [Link](http://arxiv.org/abs/2409.10423v1) |&#10;| Learning Semi&#45;Supervised Medical Image Segmentation from Spatial&#10; &#160;Registration | Qianying Liu, Paul Henderson, Xiao Gu, Hang Dai, Fani Deligianni | &#160;&#160;Semi&#45;supervised medical image segmentation has shown promise in training&#10;models with limited labeled data and abundant unlabeled data. However,&#10;state&#45;of&#45;the&#45;art methods ignore a potentially valuable source of unsupervised&#10;semantic information &#45;&#45; spatial registration transforms between image volumes.&#10;To address this, we propose CCT&#45;R, a contrastive cross&#45;teaching framework&#10;incorporating registration information. To leverage the semantic information&#10;available in registrations between volume pairs, CCT&#45;R incorporates two&#10;proposed modules: Registration Supervision Loss (RSL) and Registration&#45;Enhanced&#10;Positive Sampling (REPS). The RSL leverages segmentation knowledge derived from&#10;transforms between labeled and unlabeled volume pairs, providing an additional&#10;source of pseudo&#45;labels. REPS enhances contrastive learning by identifying&#10;anatomically&#45;corresponding positives across volumes using registration&#10;transforms. Experimental results on two challenging medical segmentation&#10;benchmarks demonstrate the effectiveness and superiority of CCT&#45;R across&#10;various semi&#45;supervised settings, with as few as one labeled case. Our code is&#10;available at&#10;https://github.com/kathyliu579/ContrastiveCross&#45;teachingWithRegistration.&#10; | General | [Link](http://arxiv.org/abs/2409.10422v1) |&#10;| Multidimensional Deconvolution with Profiling | Huanbiao Zhu, Krish Desai, Mikael Kuusela, Vinicius Mikuni, Benjamin Nachman, Larry Wasserman | &#160;&#160;In many experimental contexts, it is necessary to statistically remove the&#10;impact of instrumental effects in order to physically interpret measurements.&#10;This task has been extensively studied in particle physics, where the&#10;deconvolution task is called unfolding. A number of recent methods have shown&#10;how to perform high&#45;dimensional, unbinned unfolding using machine learning.&#10;However, one of the assumptions in all of these methods is that the detector&#10;response is accurately modeled in the Monte Carlo simulation. In practice, the&#10;detector response depends on a number of nuisance parameters that can be&#10;constrained with data. We propose a new algorithm called Profile OmniFold&#10;(POF), which works in a similar iterative manner as the OmniFold (OF) algorithm&#10;while being able to simultaneously profile the nuisance parameters. We&#10;illustrate the method with a Gaussian example as a proof of concept&#10;highlighting its promising capabilities.&#10; | General | [Link](http://arxiv.org/abs/2409.10421v1) |&#10;| HiFi&#45;CS: Towards Open Vocabulary Visual Grounding For Robotic Grasping&#10; &#160;Using Vision&#45;Language Models | Vineet Bhat, Prashanth Krishnamurthy, Ramesh Karri, Farshad Khorrami | &#160;&#160;Robots interacting with humans through natural language can unlock numerous&#10;applications such as Referring Grasp Synthesis (RGS). Given a text query, RGS&#10;determines a stable grasp pose to manipulate the referred object in the robot&#39;s&#10;workspace. RGS comprises two steps: visual grounding and grasp pose estimation.&#10;Recent studies leverage powerful Vision&#45;Language Models (VLMs) for visually&#10;grounding free&#45;flowing natural language in real&#45;world robotic execution.&#10;However, comparisons in complex, cluttered environments with multiple instances&#10;of the same object are lacking. This paper introduces HiFi&#45;CS, featuring&#10;hierarchical application of Featurewise Linear Modulation (FiLM) to fuse image&#10;and text embeddings, enhancing visual grounding for complex attribute rich text&#10;queries encountered in robotic grasping. Visual grounding associates an object&#10;in 2D/3D space with natural language input and is studied in two scenarios:&#10;Closed and Open Vocabulary. HiFi&#45;CS features a lightweight decoder combined&#10;with a frozen VLM and outperforms competitive baselines in closed vocabulary&#10;settings while being 100x smaller in size. Our model can effectively guide&#10;open&#45;set object detectors like GroundedSAM to enhance open&#45;vocabulary&#10;performance. We validate our approach through real&#45;world RGS experiments using&#10;a 7&#45;DOF robotic arm, achieving 90.33% visual grounding accuracy in 15 tabletop&#10;scenes. We include our codebase in the supplementary material.&#10; | General | [Link](http://arxiv.org/abs/2409.10419v1) |&#10;| X&#45;ray reverberation as an explanation for UV/optical variability in&#10; &#160;nearby Seyferts | M. Papoutsis, I. E. Papadakis, C. Panagiotou, M. Doviak, E. Kammoun | &#160;&#160;Active galactic nuclei (AGNs) are known to be variable across all&#10;wavelengths. Significant observational efforts have been invested in the last&#10;decade in studying their ultraviolet (UV) and optical variability. Long and&#10;densely sampled, multi&#45;wavelength monitoring campaigns of numerous Seyfert&#10;galaxies have been conducted with the aim of determining the X&#45;ray/UV/optical&#10;continuum time lags. Time&#45;lag studies can be used to constrain theoretical&#10;models. The observed time lags can be explained by thermal reprocessing of the&#10;X&#45;rays illuminating the accretion disc (known as the X&#45;ray reverberation&#10;model). However, the observed light curves contain more information that can be&#10;used to further constrain physical models. Our primary objective is to&#10;investigate whether, in addition to time lags, the X&#45;ray reverberation model&#10;can also explain the UV/optical variability amplitude of nearby Seyferts. To do&#10;this, we measured the excess variance of four sources (namely Mrk 509, NGC&#10;4151, NGC 2617, and Mrk 142) as a function of wavelength using data from&#10;archival long, multi&#45;wavelength campaigns with Swift, and ground&#45;based&#10;telescopes. We also computed the model excess variance in the case of the X&#45;ray&#10;reverberation model by determining the disc&#39;s transfer function and assuming a&#10;bending power law for the X&#45;ray power spectrum. We tested the validity of the&#10;model by comparing the measured and model variances for a range of accretion&#10;rates and X&#45;ray source heights. We conclude that the X&#45;ray thermal&#10;reverberation model can fit both the continuum, UV/optical time lags, as well&#10;as the variance in these AGNs, for the same physical parameters. Our results&#10;suggest that the accretion disc is constant and that all the observed&#10;UV/optical variations, on timescales of days and up to a few weeks, can be&#10;fully explained by the variable X&#45;rays as they illuminate the accretion disc.&#10; | General | [Link](http://arxiv.org/abs/2409.10417v1) |&#10;| Local central limit theorem for Mallows measure | Alexey Bufetov, Kailun Chen | &#160;&#160;We study the statistics of the Mallows measure on permutations in the limit&#10;pioneered by Starr (2009). Our main result is the local central limit theorem&#10;for its height function. We also re&#45;derive versions of the law of large numbers&#10;and the large deviation principle, obtain the standard central limit theorem&#10;from the local one, and establish a multi&#45;point version of the local central&#10;limit theorem.&#10; | General | [Link](http://arxiv.org/abs/2409.10415v1) |&#10;| On interactive anisotropic walks in two dimensions generated from a&#10; &#160;three state opinion dynamics model | Surajit Saha, Parongama Sen | &#160;&#160;A system of interacting walkers on a two&#45;dimensional space where the dynamics&#10;of each walker are governed by the opinions of agents of a three&#45;state opinion&#10;dynamics model are considered. Such walks, inspired by Ising&#45;like models and&#10;opinions dynamics models, are usually considered in one&#45;dimensional virtual&#10;spaces. Here, the mapping is done in such a way that the walk is directed along&#10;the $y$ axis while it can move either way along the $x$ axis. We explore the&#10;properties of such walks as the parameter representing the noise in the opinion&#10;dynamics model, responsible for a continuous phase transition, is varied. The&#10;walk features show marked differences as the system crosses the critical point.&#10;The bivariate distribution of the displacements below the critical point is a&#10;modified biased Gaussian function of x and y which is symmetric about the X&#10;axis.&#10; &#160;The marginal probability distributions can be extracted and the scaling forms&#10;of different quantities, showing power law behaviour, are obtained. The&#10;directed nature of the walk is reflected in the marginal distributions as well&#10;as in the exponents.&#10; | General | [Link](http://arxiv.org/abs/2409.10413v1) |&#10;| A Large&#45;Scale Privacy Assessment of Android Third&#45;Party SDKs | Mark Huasong Meng, Chuan Yan, Yun Hao, Qing Zhang, Zeyu Wang, Kailong Wang, Sin Gee Teo, Guangdong Bai, Jin Song Dong | &#160;&#160;Third&#45;party Software Development Kits (SDKs) are widely adopted in Android&#10;app development, to effortlessly accelerate development pipelines and enhance&#10;app functionality. However, this convenience raises substantial concerns about&#10;unauthorized access to users&#39; privacy&#45;sensitive information, which could be&#10;further abused for illegitimate purposes like user tracking or monetization.&#10;Our study offers a targeted analysis of user privacy protection among Android&#10;third&#45;party SDKs, filling a critical gap in the Android software supply chain.&#10;It focuses on two aspects of their privacy practices, including data&#10;exfiltration and behavior&#45;policy compliance (or privacy compliance), utilizing&#10;techniques of taint analysis and large language models. It covers 158&#10;widely&#45;used SDKs from two key SDK release platforms, the official one and a&#10;large alternative one. From them, we identified 338 instances of privacy data&#10;exfiltration. On the privacy compliance, our study reveals that more than 30%&#10;of the examined SDKs fail to provide a privacy policy to disclose their data&#10;handling practices. Among those that provide privacy policies, 37% of them&#10;over&#45;collect user data, and 88% falsely claim access to sensitive data. We&#10;revisit the latest versions of the SDKs after 12 months. Our analysis&#10;demonstrates a persistent lack of improvement in these concerning trends. Based&#10;on our findings, we propose three actionable recommendations to mitigate the&#10;privacy leakage risks and enhance privacy protection for Android users. Our&#10;research not only serves as an urgent call for industry attention but also&#10;provides crucial insights for future regulatory interventions.&#10; | General | [Link](http://arxiv.org/abs/2409.10411v1) |&#10;| A point process approach for the classification of noisy calcium imaging&#10; &#160;data | Arianna Burzacchi, Nicoletta D&#39;Angelo, David Payares&#45;Garcia, Jorge Mateu | &#160;&#160;We study noisy calcium imaging data, with a focus on the classification of&#10;spike traces. As raw traces obscure the true temporal structure of neuron&#39;s&#10;activity, we performed a tuned filtering of the calcium concentration using two&#10;methods: a biophysical model and a kernel mapping. The former characterizes&#10;spike trains related to a particular triggering event, while the latter filters&#10;out the signal and refines the selection of the underlying neuronal response.&#10;Transitioning from traditional time series analysis to point process theory,&#10;the study explores spike&#45;time distance metrics and point pattern prototypes to&#10;describe repeated observations. We assume that the analyzed neuron&#39;s firing&#10;events, i.e. spike occurrences, are temporal point process events. In&#10;particular, the study aims to categorize 47 point patterns by depth, assuming&#10;the similarity of spike occurrences within specific depth categories. The&#10;results highlight the pivotal roles of depth and stimuli in discerning diverse&#10;temporal structures of neuron firing events, confirming the point process&#10;approach based on prototype analysis is largely useful in the classification of&#10;spike traces.&#10; | General | [Link](http://arxiv.org/abs/2409.10409v1) |&#10;| Variational closures for composite homogenised fluid flows | Theo Diamantakis, Ruiao Hu | &#160;&#160;The Stochastic Advection by Lie Transport is a variational formulation of&#10;stochastic fluid dynamics introduced to model the effects of unresolved scales,&#10;whilst preserving the geometric structure of ideal fluid flows. In this work,&#10;we show that the SALT equations can arise from the decomposition of the fluid&#10;flow map into its mean and fluctuating components. The fluctuating component is&#10;realised as a prescribed stochastic diffeomorphism that introduces stochastic&#10;transport into the system and we construct it using homogenisation theory. The&#10;dynamics of the mean component are derived from a variational principle&#10;utilising particular forms of variations that preserve the composite structure&#10;of the flow. Using a new variational principle, we show that SALT equations can&#10;arise from random Lagrangians and are equivalent to random coefficient PDEs. We&#10;also demonstrate how to modify the composite flow and the associated&#10;variational principle to derive models inspired by the Lagrangian Averaged&#10;Euler&#45;Poincare (LAEP) theory.&#10; | General | [Link](http://arxiv.org/abs/2409.10408v1) |&#10;| Bitcoin Transaction Behavior Modeling Based on Balance Data | Yu Zhang, Claudio Tessone | &#160;&#160;When analyzing Bitcoin users&#39; balance distribution, we observed that it&#10;follows a log&#45;normal pattern. Drawing parallels from the successful application&#10;of Gibrat&#39;s law of proportional growth in explaining city size and word&#10;frequency distributions, we tested whether the same principle could account for&#10;the log&#45;normal distribution in Bitcoin balances. However, our calculations&#10;revealed that the exponent parameters in both the drift and variance terms&#10;deviate slightly from one. This suggests that Gibrat&#39;s proportional growth rule&#10;alone does not fully explain the log&#45;normal distribution observed in Bitcoin&#10;users&#39; balances. During our exploration, we discovered an intriguing&#10;phenomenon: Bitcoin users tend to fall into two distinct categories based on&#10;their behavior, which we refer to as ``poor&quot; and ``wealthy&quot; users. Poor users,&#10;who initially purchase only a small amount of Bitcoin, tend to buy more&#10;bitcoins first and then sell out all their holdings gradually over time. The&#10;certainty of selling all their coins is higher and higher with time. In&#10;contrast, wealthy users, who acquire a large amount of Bitcoin from the start,&#10;tend to sell off their holdings over time. The speed at which they sell their&#10;bitcoins is lower and lower over time and they will hold at least a small part&#10;of their initial holdings at last. Interestingly, the wealthier the user, the&#10;larger the proportion of their balance and the higher the certainty they tend&#10;to sell. This research provided an interesting perspective to explore bitcoin&#10;users&#39; behaviors which may apply to other finance markets.&#10; | General | [Link](http://arxiv.org/abs/2409.10407v1) |&#10;| Stochastic Data&#45;Driven Predictive Control: Chance&#45;Constraint&#10; &#160;Satisfaction with Identified Multi&#45;step Predictors | Haldun Balim, Andrea Carron, Melanie N. Zeilinger, Johannes Khler | &#160;&#160;We propose a novel data&#45;driven stochastic model predictive control framework&#10;for uncertain linear systems with noisy output measurements. Our approach&#10;leverages multi&#45;step predictors to efficiently propagate uncertainty, ensuring&#10;chance constraint satisfaction with minimal conservatism. In particular, we&#10;present a strategy to identify multi&#45;step predictors and quantify the&#10;associated uncertainty using a surrogate (data&#45;driven) state space model. Then,&#10;we utilize the derived distribution to formulate a constraint tightening that&#10;ensures chance constraint satisfaction. A numerical example highlights the&#10;reduced conservatism of handling parametric uncertainty in the proposed method&#10;compared to state&#45;of&#45;the&#45;art solutions.&#10; | General | [Link](http://arxiv.org/abs/2409.10405v1) |&#10;| A Knowledge&#45;Enhanced Disease Diagnosis Method Based on Prompt Learning&#10; &#160;and BERT Integration | Zhang Zheng | &#160;&#160;This paper proposes a knowledge&#45;enhanced disease diagnosis method based on a&#10;prompt learning framework. The method retrieves structured knowledge from&#10;external knowledge graphs related to clinical cases, encodes it, and injects it&#10;into the prompt templates to enhance the language model&#39;s understanding and&#10;reasoning capabilities for the task.We conducted experiments on three public&#10;datasets: CHIP&#45;CTC, IMCS&#45;V2&#45;NER, and KUAKE&#45;QTR. The results show that the&#10;proposed method significantly outperforms existing models across multiple&#10;evaluation metrics, with an F1 score improvement of 2.4% on the CHIP&#45;CTC&#10;dataset, 3.1% on the IMCS&#45;V2&#45;NER dataset,and 4.2% on the KUAKE&#45;QTR dataset.&#10;Additionally,ablation studies confirmed the critical role of the knowledge&#10;injection module,as the removal of this module resulted in a significant drop&#10;in F1 score. The experimental results demonstrate that the proposed method not&#10;only effectively improves the accuracy of disease diagnosis but also enhances&#10;the interpretability of the predictions, providing more reliable support and&#10;evidence for clinical diagnosis.&#10; | General | [Link](http://arxiv.org/abs/2409.10403v1) |&#10;| A Statistical Equilibrium Approach to Adam Smith&#39;s Labor Theory of Value | Ellis Scharfenaker, Bruno Theodosio, Duncan K. Foley | &#160;&#160;Adam Smith&#39;s inquiry into the emergence and stability of the&#10;self&#45;organization of the division of labor in commodity production and exchange&#10;is considered using statistical equilibrium methods from statistical physics.&#10;We develop a statistical equilibrium model of the distribution of independent&#10;direct producers in a hub&#45;and&#45;spoke framework that predicts both the center of&#10;gravity of producers across lines of production as well as the endogenous&#10;fluctuations between lines of production that arise from Smith&#39;s concept of&#10;&quot;perfect liberty&quot;. The ergodic distribution of producers implies a long&#45;run&#10;balancing of &quot;advantages to disadvantages&quot; across lines of employment and&#10;gravitation of market prices around Smith&#39;s natural prices.&#10; | General | [Link](http://arxiv.org/abs/2409.10402v1) |&#10;| Hydrodynamic mechanism for stable spindle positioning in meiosis II&#10; &#160;oocytes | Weida Liao, Eric Lauga | &#160;&#160;Cytoplasmic streaming, the persistent flow of fluid inside a cell, induces&#10;intracellular transport, which plays a key role in fundamental biological&#10;processes. In meiosis II mouse oocytes (developing egg cells) awaiting&#10;fertilisation, the spindle, which is the protein structure responsible for&#10;dividing genetic material in a cell, must maintain its position near the cell&#10;cortex (the thin actin network bound to the cell membrane) for many hours.&#10;However, the cytoplasmic streaming that accompanies this stable positioning&#10;would intuitively appear to destabilise the spindle position. Here, through a&#10;combination of numerical and analytical modelling, we reveal a new,&#10;hydrodynamic mechanism for stable spindle positioning beneath the cortical cap.&#10;We show that this stability depends critically on the spindle size and the&#10;active driving from the cortex, and demonstrate that stable spindle positioning&#10;can result purely from a hydrodynamic suction force exerted on the spindle by&#10;the cytoplasmic flow. Our findings show that local fluid dynamic forces can be&#10;sufficient to stabilise the spindle, explaining robustness against&#10;perturbations not only perpendicular but also parallel to the cortex. Our&#10;results shed light on the importance of cytoplasmic streaming in mammalian&#10;meiosis.&#10; | General | [Link](http://arxiv.org/abs/2409.10401v1) |&#10;| Sherpa: An Open Source Python Fitting Package | Aneta Siemiginowska, Douglas Burke, Hans Moritz Gnther, Nicholas P. Lee, Warren McLaughlin, David A. Principe, Harlan Cheer, Antonella Fruscione, Omar Laurino, Jonathan McDowell, Marie Terrell | &#160;&#160;We present an overview of Sherpa, an open source Python project, and discuss&#10;its development history, broad design concepts and capabilities. Sherpa&#10;contains powerful tools for combining parametric models into complex&#10;expressions that can be fit to data using a variety of statistics and&#10;optimization methods. It is easily extensible to include user&#45;defined models,&#10;statistics, and optimization methods. It provides a high&#45;level User Interface&#10;for interactive data&#45;analysis, such as within a Jupyter notebook, and it can&#10;also be used as a library component, providing fitting and modeling&#10;capabilities to an application. We include a few examples of Sherpa&#10;applications to multiwavelength astronomical data. The code is available&#10;GitHub: https://github.com/sherpa/sherpa&#10; | General | [Link](http://arxiv.org/abs/2409.10400v1) |&#10;| Minimally coupled $$&#45;exponential inflation with an $R^2$ term in&#10; &#160;the Palatini formulation | Nilay Bostan, Rafid H. Dejrah | &#160;&#160;We focus on the inflationary predictions of $beta$&#45;exponential potential&#10;models, in which the inflaton is a representation of the field delineating the&#10;size of extra&#45;dimension. Since it offers a well&#45;motivated starting point for&#10;the study of physics at very high energies, we incorporate an $R^2$ term in the&#10;Palatini gravity. In addition, afterward the inflation, the inflaton oscillates&#10;about the minimum of the inflation potential, and reheats the universe. This&#10;occurs during the reheating phase, at which the inflaton decays into the&#10;standard model particles, which fill the universe. We extend our examination by&#10;considering the reheating effects on inflationary observables by employing the&#10;different scenarios of the reheat temperature. Supposing the standard thermal&#10;history after inflation, we display the inflationary predictions, $n_s, r,&#10;mathrm{d}n_s/mathrm{d}&#10;n k$ of $beta$&#45;exponential potential with minimal&#10;coupling in Palatini $R^2$ gravity. Also, different kinds of constraints from a&#10;variety of observations, such as BICEP/Keck, Planck 2018, as well as future&#10;possible detectable sensitivities that might be reached by CMB experiments:&#10;CMB&#45;S4 and LiteBIRD are taken into account in this work. We indicate that our&#10;results are consistent with both the latest data and the future sensitivity&#10;forecasts of LiteBIRD/Planck and CMB&#45;S4. Finally, the results in this study&#10;highlight the viability of our model even in the case of the existence of more&#10;stringent constraints expected from future achievable confidence level limits.&#10; | General | [Link](http://arxiv.org/abs/2409.10398v1) |&#10;| Quantifying Observational Projection Effects with a Simulation&#45;based hot&#10; &#160;CGM model | Soumya Shreeram, Johan Comparat, Andrea Merloni, Yi Zhang, Gabriele Ponti, Kirpal Nandra, John ZuHone, Ilaria Marini, Stephan Vladutescu&#45;Zopp, Paola Popesso, Ruediger Pakmor, Riccardo Seppi, Celine Peroux, Daniele Sorini | &#160;&#160;The hot phase of the circumgalactic medium (CGM) allows us to probe the&#10;inflow and outflow of gas within a galaxy, which is responsible for dictating&#10;the evolution of the galaxy. Studying the hot CGM sheds light on a better&#10;understanding of gas physics, which is crucial to inform and constrain&#10;simulation models. With the recent advances in observational measurements&#10;probing the hot CGM in X&#45;rays and tSZ, we have a new avenue for widening our&#10;knowledge of gas physics and feedback by exploiting the information from&#10;current/future observations. In this paper, we use the TNG300 hydrodynamical&#10;simulations to build a fully self&#45;consistent forward model for the hot CGM. We&#10;construct a lightcone and generate mock X&#45;ray observations. We quantify the&#10;projection effects, namely the locally correlated large&#45;scale structure in&#10;X&#45;rays and the effect due to satellite galaxies misclassified as centrals which&#10;affects the measured hot CGM galactocentric profiles in stacking experiments.&#10;We present an analytical model that describes the intrinsic X&#45;ray surface&#10;brightness profile across the stellar and halo mass bins. The increasing&#10;stellar mass bins result in decreasing values of $beta$, the exponent&#10;quantifying the slope of the intrinsic galactocentric profiles. We carry&#10;forward the current state&#45;of&#45;the&#45;art by also showing the impact of the locally&#10;correlated environment on the measured X&#45;ray surface brightness profiles. We&#10;also present, for the first time, the effect of misclassified centrals in&#10;stacking experiments for three stellar mass bins: $10^{10.5&#45;11} M_odot$,&#10;$10^{11&#45;11.2} M_odot$, and $10^{11.2&#45;11.5} M_odot$. We find that the&#10;contaminating effect of the misclassified centrals on the stacked profiles&#10;increases when the stellar mass decreases.&#10; | General | [Link](http://arxiv.org/abs/2409.10397v1) |&#10;| MOST: MR reconstruction Optimization for multiple downStream Tasks via&#10; &#160;continual learning | Hwihun Jeong, Se Young Chun, Jongho Lee | &#160;&#160;Deep learning&#45;based Magnetic Resonance (MR) reconstruction methods have&#10;focused on generating high&#45;quality images but they often overlook the impact on&#10;downstream tasks (e.g., segmentation) that utilize the reconstructed images.&#10;Cascading separately trained reconstruction network and downstream task network&#10;has been shown to introduce performance degradation due to error propagation&#10;and domain gaps between training datasets. To mitigate this issue, downstream&#10;task&#45;oriented reconstruction optimization has been proposed for a single&#10;downstream task. Expanding this optimization to multi&#45;task scenarios is not&#10;straightforward. In this work, we extended this optimization to sequentially&#10;introduced multiple downstream tasks and demonstrated that a single MR&#10;reconstruction network can be optimized for multiple downstream tasks by&#10;deploying continual learning (MOST). MOST integrated techniques from&#10;replay&#45;based continual learning and image&#45;guided loss to overcome catastrophic&#10;forgetting. Comparative experiments demonstrated that MOST outperformed a&#10;reconstruction network without finetuning, a reconstruction network with&#10;na&quot;ive finetuning, and conventional continual learning methods. This&#10;advancement empowers the application of a single MR reconstruction network for&#10;multiple downstream tasks. The source code is available at:&#10;https://github.com/SNU&#45;LIST/MOST&#10; | General | [Link](http://arxiv.org/abs/2409.10394v1) |&#10;| Multicopy quantum state teleportation with application to storage and&#10; &#160;retrieval of quantum programs | Frdric Grosshans, Micha Horodecki, Mio Murao, Tomasz Mynik, Marco Tlio Quintino, Micha Studziski, Satoshi Yoshida | &#160;&#160;This work considers a teleportation task for Alice and Bob in a scenario&#10;where Bob cannot perform corrections. In particular, we analyse the task of&#10;textit{multicopy state teleportation}, where Alice has $k$ identical copies of&#10;an arbitrary unknown $d$&#45;dimensional qudit state $vertpsi&#13;angle$ to teleport&#10;a single copy of $vertpsi&#13;angle$ to Bob using a maximally entangled&#10;two&#45;qudit state shared between Alice and Bob without Bob&#39;s correction. Alice&#10;may perform a joint measurement on her half of the entangled state and the $k$&#10;copies of $vertpsi&#13;angle$. We prove that the maximal probability of success&#10;for teleporting the exact state $vertpsi&#13;angle$ to Bob is&#10;$p(d,k)=frac{k}{d(k&#45;1+d)}$ and present an explicit protocol to attain this&#10;performance. Then, by utilising $k$ copies of an arbitrary target state&#10;$vertpsi&#13;angle$, we show how the multicopy state teleportation protocol can&#10;be employed to enhance the success probability of storage and retrieval of&#10;quantum programs, which aims to universally retrieve the action of an arbitrary&#10;quantum channel that is stored in a state. Our proofs make use of group&#10;representation theory methods, which may find applications beyond the problems&#10;addressed in this work.&#10; | General | [Link](http://arxiv.org/abs/2409.10393v1) |&#10;| TPFL: Tsetlin&#45;Personalized Federated Learning with Confidence&#45;Based&#10; &#160;Clustering | Rasoul Jafari Gohari, Laya Aliahmadipour, Ezat Valipour | &#160;&#160;The world of Machine Learning (ML) has witnessed rapid changes in terms of&#10;new models and ways to process users data. The majority of work that has been&#10;done is focused on Deep Learning (DL) based approaches. However, with the&#10;emergence of new algorithms such as the Tsetlin Machine (TM) algorithm, there&#10;is growing interest in exploring alternative approaches that may offer unique&#10;advantages in certain domains or applications. One of these domains is&#10;Federated Learning (FL), in which users privacy is of utmost importance. Due to&#10;its novelty, FL has seen a surge in the incorporation of personalization&#10;techniques to enhance model accuracy while maintaining user privacy under&#10;personalized conditions. In this work, we propose a novel approach dubbed TPFL:&#10;Tsetlin&#45;Personalized Federated Learning, in which models are grouped into&#10;clusters based on their confidence towards a specific class. In this way,&#10;clustering can benefit from two key advantages. Firstly, clients share only&#10;what they are confident about, resulting in the elimination of wrongful weight&#10;aggregation among clients whose data for a specific class may have not been&#10;enough during the training. This phenomenon is prevalent when the data are&#10;non&#45;Independent and Identically Distributed (non&#45;IID). Secondly, by sharing&#10;only weights towards a specific class, communication cost is substantially&#10;reduced, making TPLF efficient in terms of both accuracy and communication&#10;cost. The results of TPFL demonstrated the highest accuracy on three different&#10;datasets; namely MNIST, FashionMNIST and FEMNIST.&#10; | General | [Link](http://arxiv.org/abs/2409.10392v1) |&#10;| Prompt&#45;and&#45;Transfer: Dynamic Class&#45;aware Enhancement for Few&#45;shot&#10; &#160;Segmentation | Hanbo Bi, Yingchao Feng, Wenhui Diao, Peijin Wang, Yongqiang Mao, Kun Fu, Hongqi Wang, Xian Sun | &#160;&#160;For more efficient generalization to unseen domains (classes), most Few&#45;shot&#10;Segmentation (FSS) would directly exploit pre&#45;trained encoders and only&#10;fine&#45;tune the decoder, especially in the current era of large models. However,&#10;such fixed feature encoders tend to be class&#45;agnostic, inevitably activating&#10;objects that are irrelevant to the target class. In contrast, humans can&#10;effortlessly focus on specific objects in the line of sight. This paper mimics&#10;the visual perception pattern of human beings and proposes a novel and powerful&#10;prompt&#45;driven scheme, called ``Prompt and Transfer&quot; (PAT), which constructs a&#10;dynamic class&#45;aware prompting paradigm to tune the encoder for focusing on the&#10;interested object (target class) in the current task. Three key points are&#10;elaborated to enhance the prompting: 1) Cross&#45;modal linguistic information is&#10;introduced to initialize prompts for each task. 2) Semantic Prompt Transfer&#10;(SPT) that precisely transfers the class&#45;specific semantics within the images&#10;to prompts. 3) Part Mask Generator (PMG) that works in conjunction with SPT to&#10;adaptively generate different but complementary part prompts for different&#10;individuals. Surprisingly, PAT achieves competitive performance on 4 different&#10;tasks including standard FSS, Cross&#45;domain FSS (e.g., CV, medical, and remote&#10;sensing domains), Weak&#45;label FSS, and Zero&#45;shot Segmentation, setting new&#10;state&#45;of&#45;the&#45;arts on 11 benchmarks.&#10; | General | [Link](http://arxiv.org/abs/2409.10389v1) |&#10;| Revising the Structure of Recurrent Neural Networks to Eliminate&#10; &#160;Numerical Derivatives in Forming Physics Informed Loss Terms with Respect to&#10; &#160;Time | Mahyar Jahani&#45;nasab, Mohamad Ali Bijarchi | &#160;&#160;Solving unsteady partial differential equations (PDEs) using recurrent neural&#10;networks (RNNs) typically requires numerical derivatives between each block of&#10;the RNN to form the physics informed loss function. However, this introduces&#10;the complexities of numerical derivatives into the training process of these&#10;models. In this study, we propose modifying the structure of the traditional&#10;RNN to enable the prediction of each block over a time interval, making it&#10;possible to calculate the derivative of the output with respect to time using&#10;the backpropagation algorithm. To achieve this, the time intervals of these&#10;blocks are overlapped, defining a mutual loss function between them.&#10;Additionally, the employment of conditional hidden states enables us to achieve&#10;a unique solution for each block. The forget factor is utilized to control the&#10;influence of the conditional hidden state on the prediction of the subsequent&#10;block. This new model, termed the Mutual Interval RNN (MI&#45;RNN), is applied to&#10;solve three different benchmarks: the Burgers equation, unsteady heat&#10;conduction in an irregular domain, and the Green vortex problem. Our results&#10;demonstrate that MI&#45;RNN can find the exact solution more accurately compared to&#10;existing RNN models. For instance, in the second problem, MI&#45;RNN achieved one&#10;order of magnitude less relative error compared to the RNN model with numerical&#10;derivatives.&#10; | General | [Link](http://arxiv.org/abs/2409.10388v1) |&#10;| Sharp decay rate for eigenfunctions of perturbed periodic Schrdinger&#10; &#160;operators | Wencai Liu, Rodrigo Matos, John N. Treuer | &#160;&#160;This paper investigates uniqueness results for perturbed periodic&#10;Schr&quot;odinger operators on $mathbb{Z}^d$. Specifically, we consider operators&#10;of the form $H = &#45;Delta + V + v$, where $Delta$ is the discrete Laplacian,&#10;$V: mathbb{Z}^d &#13;ightarrow mathbb{R}$ is a periodic potential, and $v:&#10;mathbb{Z}^d &#13;ightarrow mathbb{C}$ represents a decaying impurity. We&#10;establish quantitative conditions under which the equation $&#45;Delta u + V u + v&#10;u = &#10;ambda u$, for $&#10;ambda in mathbb{C}$, admits only the trivial solution&#10;$u equiv 0$. Key applications include the absence of embedded eigenvalues for&#10;operators with impurities decaying faster than any exponential function and the&#10;determination of sharp decay rates for eigenfunctions. Our findings extend&#10;previous works by providing precise decay conditions for impurities and&#10;analyzing different spectral regimes of $&#10;ambda$.&#10; | General | [Link](http://arxiv.org/abs/2409.10387v1) |&#10;| Mamba&#45;ST: State Space Model for Efficient Style Transfer | Filippo Botti, Alex Ergasti, Leonardo Rossi, Tomaso Fontanini, Claudio Ferrari, Massimo Bertozzi, Andrea Prati | &#160;&#160;The goal of style transfer is, given a content image and a style source,&#10;generating a new image preserving the content but with the artistic&#10;representation of the style source. Most of the state&#45;of&#45;the&#45;art architectures&#10;use transformers or diffusion&#45;based models to perform this task, despite the&#10;heavy computational burden that they require. In particular, transformers use&#10;self&#45; and cross&#45;attention layers which have large memory footprint, while&#10;diffusion models require high inference time. To overcome the above, this paper&#10;explores a novel design of Mamba, an emergent State&#45;Space Model (SSM), called&#10;Mamba&#45;ST, to perform style transfer. To do so, we adapt Mamba linear equation&#10;to simulate the behavior of cross&#45;attention layers, which are able to combine&#10;two separate embeddings into a single output, but drastically reducing memory&#10;usage and time complexity. We modified the Mamba&#39;s inner equations so to accept&#10;inputs from, and combine, two separate data streams. To the best of our&#10;knowledge, this is the first attempt to adapt the equations of SSMs to a vision&#10;task like style transfer without requiring any other module like&#10;cross&#45;attention or custom normalization layers. An extensive set of experiments&#10;demonstrates the superiority and efficiency of our method in performing style&#10;transfer compared to transformers and diffusion models. Results show improved&#10;quality in terms of both ArtFID and FID metrics. Code is available at&#10;https://github.com/FilippoBotti/MambaST.&#10; | General | [Link](http://arxiv.org/abs/2409.10385v1) |&#10;| Performance&#45;Portable Numerical Relativity with AthenaK | Hengrui Zhu, Jacob Fields, Francesco Zappa, David Radice, James Stone, Alireza Rashti, William Cook, Sebastiano Bernuzzi, Boris Daszuta | &#160;&#160;We present the numerical relativity module within AthenaK, an open source&#10;performance&#45;portable astrophysics code designed for exascale computing&#10;applications. This module employs the Z4c formulation to solve the Einstein&#10;equations. We demonstrate its accuracy through a series of standard numerical&#10;relativity tests, including convergence of the gravitational waveform from&#10;binary black hole coalescence. Furthermore, we conduct scaling tests on OLCF&#10;Frontier and NERSC Perlmutter, where AthenaK exhibits excellent weak scaling&#10;efficiency of 80% on up to 65,536 AMD MI250X GPUs on Frontier (relative to 4&#10;GPUs) and strong scaling efficiencies of 84% and 77% on AMD MI250X and NVIDIA&#10;A100 GPUs on Frontier and Perlmutter respectively. Additionally, we observe a&#10;significant performance boost, with two orders of magnitude speedup ($gtrsim&#10;200times$) on a GPU compared to a single CPU core, affirming that AthenaK is&#10;well&#45;suited for exascale computing, thereby expanding the potential for&#10;breakthroughs in numerical relativity research.&#10; | General | [Link](http://arxiv.org/abs/2409.10383v1) |&#10;| J&#45;UBIK: The JAX&#45;accelerated Universal Bayesian Imaging Kit | Vincent Eberle, Matteo Guardiani, Margret Westerkamp, Philipp Frank, Julian Rstig, Julia Stadler, Torsten A. Enlin | &#160;&#160;Many advances in astronomy and astrophysics originate from accurate images of&#10;the sky emission across multiple wavelengths. This often requires&#10;reconstructing spatially and spectrally correlated signals detected from&#10;multiple instruments. To facilitate the high&#45;fidelity imaging of these signals,&#10;we introduce the universal Bayesian imaging kit (UBIK). Specifically, we&#10;present J&#45;UBIK, a flexible and modular implementation leveraging the&#10;JAX&#45;accelerated NIFTy.re software as its backend. J&#45;UBIK streamlines the&#10;implementation of the key Bayesian inference components, providing for all the&#10;necessary steps of Bayesian imaging pipelines. First, it provides adaptable&#10;prior models for different sky realizations. Second, it includes likelihood&#10;models tailored to specific instruments. So far, the package includes three&#10;instruments: Chandra and eROSITA for X&#45;ray observations, and the James Webb&#10;Space Telescope (JWST) for the near&#45; and mid&#45;infrared. The aim is to expand&#10;this set in the future. Third, these models can be integrated with various&#10;inference and optimization schemes, such as maximum a posteriori estimation and&#10;variational inference. Explicit demos show how to integrate the individual&#10;modules into a full analysis pipeline. Overall, J&#45;UBIK enables efficient&#10;generation of high&#45;fidelity images via Bayesian pipelines that can be tailored&#10;to specific research objectives.&#10; | General | [Link](http://arxiv.org/abs/2409.10381v1) |&#10;| Thermolectricity in irradiated bilayer graphene flakes | Cynthia Ihuoma Osuala, Tanu Choudhary, Raju K. Biswas, Sudin Ganguly, Chunlei Qu, Santanu K. Maiti | &#160;&#160;We present a comprehensive study on enhancing the thermoelectric (TE)&#10;performance of bilayer graphene (BLG) through irradiation with arbitrarily&#10;polarized light, focusing on $AA$&#45; and $AB$&#45;stacked configurations with zigzag&#10;edges. Utilizing a combination of tight&#45;binding theory and density functional&#10;theory (DFT), we systematically analyze the impact of light irradiation on&#10;electronic and phononic transport properties. Light irradiation alters the&#10;electronic hopping parameters, creating an asymmetric transmission function,&#10;which significantly increases the Seebeck coefficient, thereby boosting the&#10;overall {it figure of merit} (FOM). For the phononic contribution, DFT&#10;calculations reveal that $AB$&#45;stacked BLG exhibits lower lattice thermal&#10;conductivity compared to $AA$&#45;stacked, attributed to enhanced anharmonic&#10;scattering and phonon group velocity. The combined analysis shows that FOM&#10;exceeds unity in both stacking types, with notable improvements near the&#10;irradiation&#45;induced gap. Additionally, we explore the dependence of FOM on the&#10;system dimensions and temperature, demonstrating that light&#45;irradiated BLG&#10;holds great promise for efficient thermoelectric energy conversion and waste&#10;heat recovery. Our results show favorable responses over a wide range of&#10;irradiation parameters. These findings provide crucial insights into optimizing&#10;BLG for advanced TE applications through light&#45;induced modifications.&#10; | General | [Link](http://arxiv.org/abs/2409.10380v1) |&#10;| Leveraging Joint Spectral and Spatial Learning with MAMBA for&#10; &#160;Multichannel Speech Enhancement | Wenze Ren, Haibin Wu, Yi&#45;Cheng Lin, Xuanjun Chen, Rong Chao, Kuo&#45;Hsuan Hung, You&#45;Jin Li, Wen&#45;Yuan Ting, Hsin&#45;Min Wang, Yu Tsao | &#160;&#160;In multichannel speech enhancement, effectively capturing spatial and&#10;spectral information across different microphones is crucial for noise&#10;reduction. Traditional methods, such as CNN or LSTM, attempt to model the&#10;temporal dynamics of full&#45;band and sub&#45;band spectral and spatial features.&#10;However, these approaches face limitations in fully modeling complex temporal&#10;dependencies, especially in dynamic acoustic environments. To overcome these&#10;challenges, we modify the current advanced model McNet by introducing an&#10;improved version of Mamba, a state&#45;space model, and further propose MCMamba.&#10;MCMamba has been completely reengineered to integrate full&#45;band and narrow&#45;band&#10;spatial information with sub&#45;band and full&#45;band spectral features, providing a&#10;more comprehensive approach to modeling spatial and spectral information. Our&#10;experimental results demonstrate that MCMamba significantly improves the&#10;modeling of spatial and spectral features in multichannel speech enhancement,&#10;outperforming McNet and achieving state&#45;of&#45;the&#45;art performance on the CHiME&#45;3&#10;dataset. Additionally, we find that Mamba performs exceptionally well in&#10;modeling spectral information.&#10; | General | [Link](http://arxiv.org/abs/2409.10376v1) |&#10;| Nonlinear Causality in Brain Networks: With Application to Motor Imagery&#10; &#160;vs Execution | Sipan Aslan, Hernando Ombao | &#160;&#160;One fundamental challenge of data&#45;driven analysis in neuroscience is modeling&#10;causal interactions and exploring the connectivity of nodes in a brain network.&#10;Various statistical methods, relying on various perspectives and employing&#10;different data modalities, are being developed to examine and comprehend the&#10;underlying causal structures inherent to brain dynamics. This study introduces&#10;a novel statistical approach, TAR4C, to dissect causal interactions in&#10;multichannel EEG recordings. TAR4C uses the threshold autoregressive model to&#10;describe the causal interaction between nodes or clusters of nodes in a brain&#10;network. The perspective involves testing whether one node, which may represent&#10;a brain region, can control the dynamics of the other. The node that has such&#10;an impact on the other is called a threshold variable and can be classified as&#10;a causative because its functionality is the leading source operating as an&#10;instantaneous switching mechanism that regulates the time&#45;varying&#10;autoregressive structure of the other. This statistical concept is commonly&#10;referred to as threshold non&#45;linearity. Once threshold non&#45;linearity has been&#10;verified between a pair of nodes, the subsequent essential facet of TAR&#10;modeling is to assess the predictive ability of the causal node for the current&#10;activity on the other and represent causal interactions in autoregressive&#10;terms. This predictive ability is what underlies Granger causality. The TAR4C&#10;approach can discover non&#45;linear and time&#45;dependent causal interactions without&#10;negating the G&#45;causality perspective. The efficacy of the proposed approach is&#10;exemplified by analyzing the EEG signals recorded during the motor&#10;movement/imagery experiment. The similarities and differences between the&#10;causal interactions manifesting during the execution and the imagery of a given&#10;motor movement are demonstrated by analyzing EEG recordings from multiple&#10;subjects.&#10; | General | [Link](http://arxiv.org/abs/2409.10374v1) |&#10;| Instigating Cooperation among LLM Agents Using Adaptive Information&#10; &#160;Modulation | Qiliang Chen, &#160;Alireza, &#160;Ilami, Nunzio Lore, Babak Heydari | &#160;&#160;This paper introduces a novel framework combining LLM agents as proxies for&#10;human strategic behavior with reinforcement learning (RL) to engage these&#10;agents in evolving strategic interactions within team environments. Our&#10;approach extends traditional agent&#45;based simulations by using strategic LLM&#10;agents (SLA) and introducing dynamic and adaptive governance through a&#10;pro&#45;social promoting RL agent (PPA) that modulates information access across&#10;agents in a network, optimizing social welfare and promoting pro&#45;social&#10;behavior. Through validation in iterative games, including the prisoner&#10;dilemma, we demonstrate that SLA agents exhibit nuanced strategic adaptations.&#10;The PPA agent effectively learns to adjust information transparency, resulting&#10;in enhanced cooperation rates. This framework offers significant insights into&#10;AI&#45;mediated social dynamics, contributing to the deployment of AI in real&#45;world&#10;team settings.&#10; | General | [Link](http://arxiv.org/abs/2409.10372v1) |&#10;| Learning Gentle Grasping from Human&#45;Free Force Control Demonstration | Mingxuan Li, Lunwei Zhang, Tiemin Li, Yao Jiang | &#160;&#160;Humans can steadily and gently grasp unfamiliar objects based on tactile&#10;perception. Robots still face challenges in achieving similar performance due&#10;to the difficulty of learning accurate grasp&#45;force predictions and force&#10;control strategies that can be generalized from limited data. In this article,&#10;we propose an approach for learning grasping from ideal force control&#10;demonstrations, to achieve similar performance of human hands with limited data&#10;size. Our approach utilizes objects with known contact characteristics to&#10;automatically generate reference force curves without human demonstrations. In&#10;addition, we design the dual convolutional neural networks (Dual&#45;CNN)&#10;architecture which incorporating a physics&#45;based mechanics module for learning&#10;target grasping force predictions from demonstrations. The described method can&#10;be effectively applied in vision&#45;based tactile sensors and enables gentle and&#10;stable grasping of objects from the ground. The described prediction model and&#10;grasping strategy were validated in offline evaluations and online experiments,&#10;and the accuracy and generalizability were demonstrated.&#10; | General | [Link](http://arxiv.org/abs/2409.10371v1) |&#10;| Uncovering the Mechanism of Hepatotoxiciy of PFAS Targeting L&#45;FABP Using&#10; &#160;GCN and Computational Modeling | Lucas Jividen, Tibo Duran, Xi&#45;Zhi Niu, Jun Bai | &#160;&#160;Per&#45; and polyfluoroalkyl substances (PFAS) are persistent environmental&#10;pollutants with known toxicity and bioaccumulation issues. Their widespread&#10;industrial use and resistance to degradation have led to global environmental&#10;contamination and significant health concerns. While a minority of PFAS have&#10;been extensively studied, the toxicity of many PFAS remains poorly understood&#10;due to limited direct toxicological data. This study advances the predictive&#10;modeling of PFAS toxicity by combining semi&#45;supervised graph convolutional&#10;networks (GCNs) with molecular descriptors and fingerprints. We propose a novel&#10;approach to enhance the prediction of PFAS binding affinities by isolating&#10;molecular fingerprints to construct graphs where then descriptors are set as&#10;the node features. This approach specifically captures the structural,&#10;physicochemical, and topological features of PFAS without overfitting due to an&#10;abundance of features. Unsupervised clustering then identifies representative&#10;compounds for detailed binding studies. Our results provide a more accurate&#10;ability to estimate PFAS hepatotoxicity to provide guidance in chemical&#10;discovery of new PFAS and the development of new safety regulations.&#10; | General | [Link](http://arxiv.org/abs/2409.10370v1) |&#10;| Stochastic Control of UAVs: An Optimal Tradeoff between Performance,&#10; &#160;Flight Smoothness and Control Effort | George Rapakoulias, Panagiotis Tsiotras | &#160;&#160;Safe and accurate control of unmanned aerial vehicles in the presence of&#10;winds is a challenging control problem due to the hard&#45;to&#45;model and highly&#10;stochastic nature of the disturbance forces acting upon the vehicle. To meet&#10;performance constraints, state&#45;of&#45;the&#45;art control methods such as Incremental&#10;Nonlinear Dynamic Inversion (INDI) or other adaptive control techniques require&#10;high control gains to mitigate the effects of uncertainty entering the system.&#10;While achieving good tracking performance, IDNI requires excessive control&#10;effort, results in high actuator strain, and reduced flight smoothness due to&#10;constant and aggressive corrective actions commanded by the controller. In this&#10;paper, we propose a novel control architecture that allows the user to&#10;systematically address the trade&#45;off between high authority control and&#10;performance constraint satisfaction. Our approach consists of two parts. To&#10;cancel out biases introduced by unmodelled aerodynamic effects we propose a&#10;hybrid, model&#45;based disturbance force estimator augmented with a neural&#10;network, that can adapt to external wind conditions using a Kalman Filter. We&#10;then utilize state&#45;of&#45;the&#45;art results from Covariance Steering theory, which&#10;offers a principled way of controlling the uncertainty of the tracking error&#10;dynamics. We first analyze the properties of the combined system and then&#10;provide extensive experimental results to verify the advantages of the proposed&#10;approach over existing methods&#10; | General | [Link](http://arxiv.org/abs/2409.10369v1) |&#10;| Integrated nowcasting of convective precipitation with Transformer&#45;based&#10; &#160;models using multi&#45;source data | alar Kk, Aitor Atencia, Markus Dabernig | &#160;&#160;Precipitation nowcasting is crucial for mitigating the impacts of severe&#10;weather events and supporting daily activities. Conventional models&#10;predominantly relying on radar data have limited performance in predicting&#10;cases with complex temporal features such as convection initiation,&#10;highlighting the need to integrate data from other sources for more&#10;comprehensive nowcasting. Unlike physics&#45;based models, machine learning&#10;(ML)&#45;based models offer promising solutions for efficiently integrating large&#10;volumes of diverse data. We present EF4INCA, a spatiotemporal Transformer model&#10;for precipitation nowcasting that integrates satellite&#45; and ground&#45;based&#10;observations with numerical weather prediction outputs. EF4INCA provides&#10;high&#45;resolution forecasts over Austria, accurately predicting the location and&#10;shape of precipitation fields with a spatial resolution of 1 kilometre and a&#10;temporal resolution of 5 minutes, up to 90 minutes ahead. Our evaluation shows&#10;that EF4INCA outperforms conventional nowcasting models, including the&#10;operational model of Austria, particularly in scenarios with complex temporal&#10;features such as convective initiation and rapid weather changes. EF4INCA&#10;maintains higher accuracy in location forecasting but generates smoother fields&#10;at later prediction times compared to traditional models. Interpretation of our&#10;model showed that precipitation products and SEVIRI infrared channels CH7 and&#10;CH9 are the most important data streams. These results underscore the&#10;importance of combining data from different domains, including physics&#45;based&#10;model products, with ML approaches. Our study highlights the robustness of&#10;EF4INCA and its potential for improved precipitation nowcasting. We provide&#10;access to our code repository, model weights, and the dataset curated for&#10;benchmarking, facilitating further development and application.&#10; | General | [Link](http://arxiv.org/abs/2409.10367v1) |&#10;&#10;">
<text font-weight="bold" text-anchor="middle" x="2494" y="-567.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922636535504_5 -->
<g id="node70" class="node">
<title>139922636535504_5</title>
<ellipse fill="#c0dfb7" stroke="#8dac84" stroke-width="3" cx="2644" cy="-528" rx="66.89" ry="18"/>
<text text-anchor="middle" x="2644" y="-524.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Engineer (5)</text>
</g>
<!-- 139922752308304_6&#45;&gt;139922636535504_5 -->
<g id="edge78" class="edge">
<title>139922752308304_6&#45;&gt;139922636535504_5</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M2378.25,-612.35C2431.89,-608.93 2500.46,-600.23 2558,-579 2569.45,-574.78 2570.55,-570.3 2581,-564 2589.11,-559.11 2597.92,-554.06 2606.32,-549.36"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2608.17,-552.34 2615.22,-544.43 2604.77,-546.22 2608.17,-552.34"/>
<g id="a_edge78&#45;label"><a xlink:title="exitcode: 0 (execution succeeded)&#10;Code output: &#10;| Title | Authors | Abstract | Domain | Source URL |&#10;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#10;| The VIRUS&#45;dE Survey I: Stars in dwarf elliptical galaxies &#45; 3D dynamics&#10; &#160;and radially resolved stellar initial mass functions | Mathias Lipka, Jens Thomas, Roberto Saglia, Ralf Bender, Maximilian Fabricius, Gary J. Hill, Matthias Kluge, Martin Landriau, Ximena Mazzalay, Eva Noyola, Taniya Parikh, Jan Snigula | &#160;&#160;We analyse the stellar structure of a sample of dwarf ellipticals (dE)&#10;inhabiting various environments within the Virgo cluster. Integral&#45;field&#10;observations with a high spectral resolution allow us to robustly determine&#10;their low velocity dispersions ($sim25$ km s$^{&#45;1}$) and higher&#45;order&#10;kinematic moments out to the half&#45;light radius. We find the dEs exhibit a&#10;diversity in ages with the younger dEs being less enhanced than the older,&#10;suggesting a complex star formation history for those dEs that recently entered&#10;Virgo while others have been quenched shortly after reionization.&#10;Orbit&#45;superposition modeling allowed us to recover viewing angles, stellar&#10;mass&#45;to&#45;light ratios (with gradients), as well as the intrinsic orbit&#10;structure. We find that the angular momentum of the dEs is strongly suppressed&#10;compared to ordinary early&#45;type galaxies and correlates with the environment.&#10;Flattened dEs are so because of a suppressed kinetic energy perpendicular to&#10;their equatorial plane. Combining population and dynamical modeling results, we&#10;find an age&#45;dependent stellar initial mass function (IMF) or, alternatively,&#10;evidence for a more extended star formation history for those galaxies that&#10;have had higher initial mass and/or inhabited lower density environments. dEs&#10;appear to have a spatially homogeneous stellar structure but the state they&#10;were `frozen&#39; in as they stopped forming stars varies dramatically according to&#10;their initial conditions.&#10; | General | [Link](http://arxiv.org/abs/2409.10518v1) |&#10;| RetrievalAttention: Accelerating Long&#45;Context LLM Inference via Vector&#10; &#160;Retrieval | Di Liu, Meng Chen, Baotong Lu, Huiqiang Jiang, Zhenhua Han, Qianxi Zhang, Qi Chen, Chengruidong Zhang, Bailu Ding, Kai Zhang, Chen Chen, Fan Yang, Yuqing Yang, Lili Qiu | &#160;&#160;Transformer&#45;based large Language Models (LLMs) become increasingly important&#10;in various domains. However, the quadratic time complexity of attention&#10;operation poses a significant challenge for scaling to longer contexts due to&#10;the extremely high inference latency and GPU memory consumption for caching&#10;key&#45;value (KV) vectors. This paper proposes RetrievalAttention, a training&#45;free&#10;approach to accelerate attention computation. To leverage the dynamic sparse&#10;property of attention, RetrievalAttention builds approximate nearest neighbor&#10;search (ANNS) indexes upon KV vectors in CPU memory and retrieves the most&#10;relevant ones via vector search during generation. Due to the&#10;out&#45;of&#45;distribution (OOD) between query vectors and key vectors, off&#45;the&#45;shelf&#10;ANNS indexes still need to scan O(N) (usually 30% of all keys) data for&#10;accurate retrieval, which fails to exploit the high sparsity.&#10;RetrievalAttention first identifies the OOD challenge of ANNS&#45;based attention,&#10;and addresses it via an attention&#45;aware vector search algorithm that can adapt&#10;to queries and only access 1&#45;&#45;3% of data, thus achieving a sub&#45;linear time&#10;complexity. RetrievalAttention greatly reduces the inference cost of&#10;long&#45;context LLM with much lower GPU memory requirements while maintaining the&#10;model accuracy. Especially, RetrievalAttention only needs 16GB GPU memory for&#10;serving 128K tokens in LLMs with 8B parameters, which is capable of generating&#10;one token in 0.188 seconds on a single NVIDIA RTX4090 (24GB).&#10; | General | [Link](http://arxiv.org/abs/2409.10516v1) |&#10;| An Efficient Self&#45;Learning Framework For Interactive Spoken Dialog&#10; &#160;Systems | Hitesh Tulsiani, David M. Chan, Shalini Ghosh, Garima Lalwani, Prabhat Pandey, Ankish Bansal, Sri Garimella, Ariya Rastrow, Bjrn Hoffmeister | &#160;&#160;Dialog systems, such as voice assistants, are expected to engage with users&#10;in complex, evolving conversations. Unfortunately, traditional automatic speech&#10;recognition (ASR) systems deployed in such applications are usually trained to&#10;recognize each turn independently and lack the ability to adapt to the&#10;conversational context or incorporate user feedback. In this work, we introduce&#10;a general framework for ASR in dialog systems that can go beyond learning from&#10;single&#45;turn utterances and learn over time how to adapt to both explicit&#10;supervision and implicit user feedback present in multi&#45;turn conversations. We&#10;accomplish that by leveraging advances in student&#45;teacher learning and&#10;context&#45;aware dialog processing, and designing contrastive self&#45;supervision&#10;approaches with Ohm, a new online hard&#45;negative mining approach. We show that&#10;leveraging our new framework compared to traditional training leads to relative&#10;WER reductions of close to 10% in real&#45;world dialog systems, and up to 26% on&#10;public synthetic data.&#10; | General | [Link](http://arxiv.org/abs/2409.10515v1) |&#10;| Constraints on axions from patchy screening of the cosmic microwave&#10; &#160;background | Samuel Goldstein, Fiona McCarthy, Cristina Mondino, J. Colin Hill, Junwu Huang, Matthew C. Johnson | &#160;&#160;The resonant conversion of cosmic microwave background (CMB) photons into&#10;axions within large&#45;scale structure induces an anisotropic spectral distortion&#10;in CMB temperature maps. Applying state&#45;of&#45;the&#45;art foreground cleaning&#10;techniques to $textit{Planck}$ CMB observations, we construct maps of&#10;axion&#45;induced &quot;patchy screening&quot; of the CMB. We cross&#45;correlate these maps with&#10;data from the $textit{unWISE}$ galaxy survey and find no evidence of axions.&#10;We constrain the axion&#45;photon coupling, $g_{agammagamma} &#10;esssim 2 times&#10;10^{&#45;12}~{&#13;m GeV}^{&#45;1}$, at the 95% confidence level for axion masses in the&#10;range $10^{&#45;13}~{&#13;m eV} &#10;esssim m_a &#10;esssim 10^{&#45;12}~{&#13;m eV}$. These&#10;constraints are competitive with the tightest astrophysical axion limits in&#10;this mass range and are inferred from robust population&#45;level statistics, which&#10;makes them complementary to existing searches that rely on modeling of&#10;individual systems.&#10; | General | [Link](http://arxiv.org/abs/2409.10514v1) |&#10;| Weak Superimposed Codes of Improved Asymptotic Rate and Their Randomized&#10; &#160;Construction | Yu Tsunoda, Yuichiro Fujiwara | &#160;&#160;Weak superimposed codes are combinatorial structures related closely to&#10;generalized cover&#45;free families, superimposed codes, and disjunct matrices in&#10;that they are only required to satisfy similar but less stringent conditions.&#10;This class of codes may also be seen as a stricter variant of what are known as&#10;locally thin families in combinatorics. Originally, weak superimposed codes&#10;were introduced in the context of multimedia content protection against illegal&#10;distribution of copies under the assumption that a coalition of malicious users&#10;may employ the averaging attack with adversarial noise. As in many other kinds&#10;of codes in information theory, it is of interest and importance in the study&#10;of weak superimposed codes to find the highest achievable rate in the&#10;asymptotic regime and give an efficient construction that produces an infinite&#10;sequence of codes that achieve it. Here, we prove a tighter lower bound than&#10;the sharpest known one on the rate of optimal weak superimposed codes and give&#10;a polynomial&#45;time randomized construction algorithm for codes that&#10;asymptotically attain our improved bound with high probability. Our&#10;probabilistic approach is versatile and applicable to many other related codes&#10;and arrays.&#10; | General | [Link](http://arxiv.org/abs/2409.10511v1) |&#10;| Pennsieve &#45; A Collaborative Platform for Translational Neuroscience and&#10; &#160;Beyond | Zack Goldblum, Zhongchuan Xu, Haoer Shi, Patryk Orzechowski, Jamaal Spence, Kathryn A Davis, Brian Litt, Nishant Sinha, Joost Wagenaar | &#160;&#160;The exponential growth of neuroscientific data necessitates platforms that&#10;facilitate data management and multidisciplinary collaboration. In this paper,&#10;we introduce Pennsieve &#45; an open&#45;source, cloud&#45;based scientific data management&#10;platform built to meet these needs. Pennsieve supports complex multimodal&#10;datasets and provides tools for data visualization and analyses. It takes a&#10;comprehensive approach to data integration, enabling researchers to define&#10;custom metadata schemas and utilize advanced tools to filter and query their&#10;data. Pennsieve&#39;s modular architecture allows external applications to extend&#10;its capabilities, and collaborative workspaces with peer&#45;reviewed data&#10;publishing mechanisms promote high&#45;quality datasets optimized for downstream&#10;analysis, both in the cloud and on&#45;premises.&#10; &#160;Pennsieve forms the core for major neuroscience research programs including&#10;the NIH SPARC Initiative, NIH HEAL Initiative&#39;s PRECISION Human Pain Network,&#10;and NIH HEAL RE&#45;JOIN Initiative. It serves more than 80 research groups&#10;worldwide, along with several large&#45;scale, inter&#45;institutional projects at&#10;clinical sites through the University of Pennsylvania. Underpinning the&#10;SPARC.Science, Epilepsy.Science, and Pennsieve Discover portals, Pennsieve&#10;stores over 125 TB of scientific data, with 35 TB of data publicly available&#10;across more than 350 high&#45;impact datasets. It adheres to the findable,&#10;accessible, interoperable, and reusable (FAIR) principles of data sharing and&#10;is recognized as one of the NIH&#45;approved Data Repositories. By facilitating&#10;scientific data management, discovery, and analysis, Pennsieve fosters a robust&#10;and collaborative research ecosystem for neuroscience and beyond.&#10; | General | [Link](http://arxiv.org/abs/2409.10509v1) |&#10;| General&#45;relativistic resistive&#45;magnetohydrodynamics simulations of&#10; &#160;self&#45;consistent magnetized rotating neutron stars | Patrick Chi&#45;Kit Cheong, Antonios Tsokaros, Milton Ruiz, Fabrizio Venturi, Juno Chun Lung Chan, Anson Ka Long Yip, Koji Uryu | &#160;&#160;We present the first general&#45;relativistic resistive magnetohydrodynamics&#10;simulations of self&#45;consistent, rotating neutron stars with mixed poloidal and&#10;toroidal magnetic fields. Specifically, we investigate the role of resistivity&#10;in the dynamical evolution of neutron stars over a period of up to 100 ms and&#10;its effects on their quasi&#45;equilibrium configurations. Our results demonstrate&#10;that resistivity can significantly influence the development of&#10;magnetohydrodynamic instabilities, resulting in markedly different magnetic&#10;field geometries. Additionally, resistivity suppresses the growth of these&#10;instabilities, leading to a reduction in the amplitude of emitted gravitational&#10;waves. Despite the variations in magnetic field geometries, the ratio of&#10;poloidal to toroidal field energies remains consistently 9:1 throughout the&#10;simulations, for the models we investigated.&#10; | General | [Link](http://arxiv.org/abs/2409.10508v1) |&#10;| Beth&#45;Uhlenbeck equation for the thermodynamics of fluctuations in a&#10; &#160;generalised 2+1D Gross&#45;Neveu model | Biplab Mahato, David Blaschke, Dietmar Ebert | &#160;&#160;We study a generalised version of Gross&#45;Neveu model in 2+1 dimensions. The&#10;model is inspired from graphene which shows a linear dispersion relation near&#10;the Dirac points. The phase structure and the thermodynamic properties in the&#10;mean field approximation have been studied before. Here we go beyond the mean&#10;field level by deriving a Beth&#45;Uhlenbeck equation for Gaussian fluctuations,&#10;solutions of which we explore numerically, for the first time including their&#10;momentum dependence. We discuss the excitonic mass, fluctuation pressure and&#10;phase shifts. We also perform a comparison with the NJL model in 3+1 dimension&#10;and discuss its implication for graphene.&#10; | General | [Link](http://arxiv.org/abs/2409.10507v1) |&#10;| Context&#45;aware Code Segmentation for C&#45;to&#45;Rust Translation using Large&#10; &#160;Language Models | Momoko Shiraishi, Takahiro Shinagawa | &#160;&#160;There is strong motivation to translate C code into Rust code due to the&#10;continuing threat of memory safety vulnerabilities in existing C programs and&#10;the significant attention paid to Rust as an alternative to the C language.&#10;While large language models (LLMs) show promise for automating this translation&#10;by generating more natural and safer code than rule&#45;based methods, previous&#10;studies have shown that LLM&#45;generated Rust code often fails to compile, even&#10;for relatively small C programs, due to significant differences between the two&#10;languages and context window limitations. We propose an LLM&#45;based translation&#10;scheme that improves the success rate of translating large&#45;scale C code into&#10;compilable Rust code. Our approach involves three key techniques: (1)&#10;pre&#45;processing the C code to better align its structure and expressions with&#10;Rust, (2) segmenting the code into optimally sized translation units to avoid&#10;exceeding the LLM&#39;s context window limits, and (3) iteratively compiling and&#10;repairing errors while maintaining consistency between translation units using&#10;context&#45;supplementing prompts. Compilation success is an essential first step&#10;in achieving functional equivalence, as only compilable code can be further&#10;tested. In experiments with 20 benchmark C programs, including those exceeding&#10;4 kilo lines of code, we successfully translated all programs into compilable&#10;Rust code without losing corresponding parts of the original code.&#10; | General | [Link](http://arxiv.org/abs/2409.10506v1) |&#10;| Machine Learning Optimization of non&#45;Kasha Behavior and of Transient&#10; &#160;Dynamics in Model Retinal Isomerization | Davinder Singh, Chern Chuang, Paul Brumer | &#160;&#160;Designing a model of retinal isomerization in Rhodopsin, the first step in&#10;vision, that accounts for both experimental transient and stationary state&#10;observables is challenging. Here, multi&#45;objective Bayesian optimization is&#10;employed to refine the parameters of a minimal two&#45;state&#45;two&#45;mode (TM) model&#10;describing the photoisomerization of retinal in Rhodopsin. With an appropriate&#10;selection of objectives, the optimized retinal model predicts excitation&#10;wavelength&#45;dependent fluorescence spectra that closely align with&#10;experimentally observed non&#45;Kasha behavior in the non&#45;equilibrium steady state.&#10;Further, adjustments to the potential energy surface within the TM model reduce&#10;the discrepancies across the time domain. Overall, agreement with experimental&#10;data is excellent.&#10; | General | [Link](http://arxiv.org/abs/2409.10505v1) |&#10;| DILA: Dictionary Label Attention for Mechanistic Interpretability in&#10; &#160;High&#45;dimensional Multi&#45;label Medical Coding Prediction | John Wu, David Wu, Jimeng Sun | &#160;&#160;Predicting high&#45;dimensional or extreme multilabels, such as in medical&#10;coding, requires both accuracy and interpretability. Existing works often rely&#10;on local interpretability methods, failing to provide comprehensive&#10;explanations of the overall mechanism behind each label prediction within a&#10;multilabel set. We propose a mechanistic interpretability module called&#10;DIctionary Label Attention (method) that disentangles uninterpretable dense&#10;embeddings into a sparse embedding space, where each nonzero element (a&#10;dictionary feature) represents a globally learned medical concept. Through&#10;human evaluations, we show that our sparse embeddings are more human&#10;understandable than its dense counterparts by at least 50 percent. Our&#10;automated dictionary feature identification pipeline, leveraging large language&#10;models (LLMs), uncovers thousands of learned medical concepts by examining and&#10;summarizing the highest activating tokens for each dictionary feature. We&#10;represent the relationships between dictionary features and medical codes&#10;through a sparse interpretable matrix, enhancing the mechanistic and global&#10;understanding of the model&#39;s predictions while maintaining competitive&#10;performance and scalability without extensive human annotation.&#10; | General | [Link](http://arxiv.org/abs/2409.10504v1) |&#10;| Causal Language Modeling Can Elicit Search and Reasoning Capabilities on&#10; &#160;Logic Puzzles | Kulin Shah, Nishanth Dikkala, Xin Wang, Rina Panigrahy | &#160;&#160;Causal language modeling using the Transformer architecture has yielded&#10;remarkable capabilities in Large Language Models (LLMs) over the last few&#10;years. However, the extent to which fundamental search and reasoning&#10;capabilities emerged within LLMs remains a topic of ongoing debate. In this&#10;work, we study if causal language modeling can learn a complex task such as&#10;solving Sudoku puzzles. To solve a Sudoku, the model is first required to&#10;search over all empty cells of the puzzle to decide on a cell to fill and then&#10;apply an appropriate strategy to fill the decided cell. Sometimes, the&#10;application of a strategy only results in thinning down the possible values in&#10;a cell rather than concluding the exact value of the cell. In such cases,&#10;multiple strategies are applied one after the other to fill a single cell. We&#10;observe that Transformer models trained on this synthetic task can indeed learn&#10;to solve Sudokus (our model solves $94.21%$ of the puzzles fully correctly)&#10;when trained on a logical sequence of steps taken by a solver. We find that&#10;training Transformers with the logical sequence of steps is necessary and&#10;without such training, they fail to learn Sudoku. We also extend our analysis&#10;to Zebra puzzles (known as Einstein puzzles) and show that the model solves&#10;$92.04 %$ of the puzzles fully correctly. In addition, we study the internal&#10;representations of the trained Transformer and find that through linear&#10;probing, we can decode information about the set of possible values in any&#10;given cell from them, pointing to the presence of a strong reasoning engine&#10;implicit in the Transformer weights.&#10; | General | [Link](http://arxiv.org/abs/2409.10502v1) |&#10;| Alignment with nonlinear velocity couplings: collision&#45;avoidance and&#10; &#160;micro&#45;to&#45;macro mean&#45;field limits | Young&#45;Pil Choi, Micha Fabisiak, Jan Peszek | &#160;&#160;We investigate the pressureless fractional Euler&#45;alignment system with&#10;nonlinear velocity couplings, referred to as the $p$&#45;Euler&#45;alignment system.&#10;This model features a nonlinear velocity alignment force, interpreted as a&#10;density&#45;weighted fractional $p$&#45;Laplacian when the singularity parameter&#10;$alpha$ exceeds the spatial dimension $d$. Our primary goal is to establish&#10;the existence of solutions for strongly singular interactions ($alpha ge d$)&#10;and compactly supported initial conditions. We construct solutions as&#10;mean&#45;field limits of empirical measures from a kinetic variant of the&#10;$p$&#45;Euler&#45;alignment system. Specifically, we show that a sequence of empirical&#10;measures converges to a finite Radon measure, whose local density and velocity&#10;satisfy the $p$&#45;Euler&#45;alignment system. Our results are the first to prove the&#10;existence of solutions to this system in multi&#45;dimensional settings without&#10;significant initial data restrictions, covering both nonlinear ($p&gt;2$) and&#10;linear ($p=2$) cases. Additionally, we establish global existence, uniqueness,&#10;and collision avoidance for the corresponding particle ODE system under&#10;non&#45;collisional initial conditions, extending previous results for $1 &#10;e p &#10;e&#10;alpha + 2$. This analysis supports our mean&#45;field limit argument and&#10;contributes to understanding alignment models with singular communication.&#10; | General | [Link](http://arxiv.org/abs/2409.10501v1) |&#10;| Focus diverse phase retrieval test results on broadband continuous&#10; &#160;wavefront sensing in space telescope applications | Hyukmo Kang, Kyle Van Gorkom, Meghdoot Biswas, Daewook Kim, Ewan S. Douglas | &#160;&#160;Continuous wavefront sensing benefits space observatories in on&#45;orbit optical&#10;performance maintenance. To measure the phase of a wavefront, phase retrieval&#10;is an attractive technique as it uses multiple point spread function (PSF)&#10;images that are acquired by the telescope itself without extra metrology&#10;systems nor complicated calibration. The focus diverse phase retrieval utilizes&#10;PSFs from predetermined defocused positions to enhance the dynamic range of the&#10;algorithm. We describe an updated visible light active optics testbed with the&#10;addition of a linear motorized focus stage. The performance of the phase&#10;retrieval algorithm in broadband is tested under various cases. While broadband&#10;pass filters have advantages in higher signal&#45;to&#45;noise ratio (SNR), the&#10;performance of phase retrieval can be restricted due to blurred image caused by&#10;diffraction and increased computing cost. We used multiple bandpass filters (10&#10;nm, 88 nm, and 150 nm) and investigated effects of bandwidth on the accuracy&#10;and required image acquisition conditions such as SNR, reaching accuracies&#10;below 20 nm RMS wavefront error at the widest bandwidth. We also investigated&#10;the dynamic range of the phase retrieval algorithm depending on the bandwidth&#10;and required amount of defocus to expand dynamic range. Finally, we simulated&#10;the continuous wavefront sensing and correction loop with a range of&#10;statistically generated representative telescope disturbance time series to&#10;test for edge cases.&#10; | General | [Link](http://arxiv.org/abs/2409.10500v1) |&#10;| The role of higher&#45;order terms in trapped&#45;ion quantum computing with&#10; &#160;magnetic gradient induced coupling | Sebastian Nagies, Kevin T. Geier, Javed Akram, Junichi Okamoto, Dimitris Badounas, Christof Wunderlich, Michael Johanning, Philipp Hauke | &#160;&#160;Trapped&#45;ion hardware based on the Magnetic Gradient Induced Coupling (MAGIC)&#10;scheme is emerging as a promising platform for quantum computing. Nevertheless,&#10;in this (as in any other) quantum&#45;computing platform, many technical questions&#10;still have to be resolved before large&#45;scale and error&#45;tolerant applications&#10;are possible. In this work, we present a thorough discussion of the&#10;contribution of higher&#45;order terms to the MAGIC setup, which can occur due to&#10;anharmonicities in the external potential of the ion crystal (e.g., through&#10;Coulomb repulsion) or through curvature of the applied magnetic field. These&#10;terms take the form of three&#45;spin couplings as well as diverse terms that&#10;couple spins to phonons. We find that most of these are negligible in realistic&#10;situations, with only two contributions that need careful attention. First,&#10;there are parasitic longitudinal fields whose strength increases with chain&#10;length, but which can easily be compensated by a microwave detuning. Second,&#10;anharmonicities of the Coulomb interaction can lead to well&#45;known two&#45;to&#45;one&#10;conversions of phonon excitations, which can be avoided if the phonons are&#10;ground&#45;state cooled. Our detailed analysis constitutes an important&#10;contribution on the way of making magnetic&#45;gradient trapped&#45;ion quantum&#10;technology fit for large&#45;scale applications, and it may inspire new ways to&#10;purposefully design interaction terms.&#10; | General | [Link](http://arxiv.org/abs/2409.10498v1) |&#10;| MusicLIME: Explainable Multimodal Music Understanding | Theodoros Sotirou, Vassilis Lyberatos, Orfeas Menis Mastromichalakis, Giorgos Stamou | &#160;&#160;Multimodal models are critical for music understanding tasks, as they capture&#10;the complex interplay between audio and lyrics. However, as these models become&#10;more prevalent, the need for explainability grows&#45;understanding how these&#10;systems make decisions is vital for ensuring fairness, reducing bias, and&#10;fostering trust. In this paper, we introduce MusicLIME, a model&#45;agnostic&#10;feature importance explanation method designed for multimodal music models.&#10;Unlike traditional unimodal methods, which analyze each modality separately&#10;without considering the interaction between them, often leading to incomplete&#10;or misleading explanations, MusicLIME reveals how audio and lyrical features&#10;interact and contribute to predictions, providing a holistic view of the&#10;model&#39;s decision&#45;making. Additionally, we enhance local explanations by&#10;aggregating them into global explanations, giving users a broader perspective&#10;of model behavior. Through this work, we contribute to improving the&#10;interpretability of multimodal music models, empowering users to make informed&#10;choices, and fostering more equitable, fair, and transparent music&#10;understanding systems.&#10; | General | [Link](http://arxiv.org/abs/2409.10496v1) |&#10;| Incorporating Classifier&#45;Free Guidance in Diffusion Model&#45;Based&#10; &#160;Recommendation | Noah Buchanan, Susan Gauch, Quan Mai | &#160;&#160;This paper presents a diffusion&#45;based recommender system that incorporates&#10;classifier&#45;free guidance. Most current recommender systems provide&#10;recommendations using conventional methods such as collaborative or&#10;content&#45;based filtering. Diffusion is a new approach to generative AI that&#10;improves on previous generative AI approaches such as Variational Autoencoders&#10;(VAEs) and Generative Adversarial Networks (GANs). We incorporate diffusion in&#10;a recommender system that mirrors the sequence users take when browsing and&#10;rating items. Although a few current recommender systems incorporate diffusion,&#10;they do not incorporate classifier&#45;free guidance, a new innovation in diffusion&#10;models as a whole. In this paper, we present a diffusion recommender system&#10;that augments the underlying recommender system model for improved performance&#10;and also incorporates classifier&#45;free guidance. Our findings show improvements&#10;over state&#45;of&#45;the&#45;art recommender systems for most metrics for several&#10;recommendation tasks on a variety of datasets. In particular, our approach&#10;demonstrates the potential to provide better recommendations when data is&#10;sparse.&#10; | General | [Link](http://arxiv.org/abs/2409.10494v1) |&#10;| Renormalization of the Einstein&#45;Cartan Theory in First&#45;Order Form | F. T. Brandt, J. Frenkel, S. Martins&#45;Filho, D. G. C. McKeon | &#160;&#160;We examine the Einstein&#45;Cartan (EC) theory in first&#45;order form, which has a&#10;diffeomorphism as well as a local Lorentz invariance. We study the&#10;renormalizability of this theory in the framework of the Batalin&#45;Vilkovisky&#10;formalism, which allows for a gauge invariant renormalization. Using the&#10;background field method, we discuss the gauge invariance of the background&#10;effective action and analyze the Ward identities which reflect the symmetries&#10;of the EC theory. As an application, we compute, in a general background gauge,&#10;the self&#45;energy of the tetrad field at one&#45;loop order.&#10; | General | [Link](http://arxiv.org/abs/2409.10493v1) |&#10;| What we can learn from the angular differential rates (only) in&#10; &#160;semileptonic $B to D^* ell _ell$ decays | G. Martinelli, S. Simula, L. Vittorio | &#160;&#160;We present a new, simple approach to the study of semileptonic $B to D^*&#10;ell &#10;u_ell$ decays based on the angular distributions of the final state&#10;particles only. Our approach is model independent and never requires the&#10;knowledge of $vert V_{cb}vert$. By studying such distributions in the case of&#10;light leptons, a comparison between results from different data sets from the&#10;Belle and BelleII Collaborations and between data and Standard Model&#10;calculations is also given for several interesting quantities. A good&#10;consistency is observed between some of the experimental results and the&#10;theoretical predictions.&#10; | General | [Link](http://arxiv.org/abs/2409.10492v1) |&#10;| Code Vulnerability Detection: A Comparative Analysis of Emerging Large&#10; &#160;Language Models | Shaznin Sultana, Sadia Afreen, Nasir U. Eisty | &#160;&#160;The growing trend of vulnerability issues in software development as a result&#10;of a large dependence on open&#45;source projects has received considerable&#10;attention recently. This paper investigates the effectiveness of Large Language&#10;Models (LLMs) in identifying vulnerabilities within codebases, with a focus on&#10;the latest advancements in LLM technology. Through a comparative analysis, we&#10;assess the performance of emerging LLMs, specifically Llama, CodeLlama, Gemma,&#10;and CodeGemma, alongside established state&#45;of&#45;the&#45;art models such as BERT,&#10;RoBERTa, and GPT&#45;3. Our study aims to shed light on the capabilities of LLMs in&#10;vulnerability detection, contributing to the enhancement of software security&#10;practices across diverse open&#45;source repositories. We observe that CodeGemma&#10;achieves the highest F1&#45;score of 58 and a Recall of 87, amongst the recent&#10;additions of large language models to detect software security vulnerabilities.&#10; | General | [Link](http://arxiv.org/abs/2409.10490v1) |&#10;| Flash STU: Fast Spectral Transform Units | Y. Isabel Liu, Windsor Nguyen, Yagiz Devre, Evan Dogariu, Anirudha Majumdar, Elad Hazan | &#160;&#160;This paper describes an efficient, open source PyTorch implementation of the&#10;Spectral Transform Unit. We investigate sequence prediction tasks over several&#10;modalities including language, robotics, and simulated dynamical systems. We&#10;find that for the same parameter count, the STU and its variants outperform the&#10;Transformer as well as other leading state space models across various&#10;modalities.&#10; | General | [Link](http://arxiv.org/abs/2409.10489v1) |&#10;| Do Pre&#45;trained Vision&#45;Language Models Encode Object States? | Kaleb Newman, Shijie Wang, Yuan Zang, David Heffren, Chen Sun | &#160;&#160;For a vision&#45;language model (VLM) to understand the physical world, such as&#10;cause and effect, a first step is to capture the temporal dynamics of the&#10;visual world, for example how the physical states of objects evolve over time&#10;(e.g. a whole apple into a sliced apple). Our paper aims to investigate if VLMs&#10;pre&#45;trained on web&#45;scale data learn to encode object states, which can be&#10;extracted with zero&#45;shot text prompts. We curate an object state recognition&#10;dataset ChangeIt&#45;Frames, and evaluate nine open&#45;source VLMs, including models&#10;trained with contrastive and generative objectives. We observe that while these&#10;state&#45;of&#45;the&#45;art vision&#45;language models can reliably perform object&#10;recognition, they consistently fail to accurately distinguish the objects&#39;&#10;physical states. Through extensive experiments, we identify three areas for&#10;improvements for VLMs to better encode object states, namely the quality of&#10;object localization, the architecture to bind concepts to objects, and the&#10;objective to learn discriminative visual and language encoders on object&#10;states. Data and code are released.&#10; | General | [Link](http://arxiv.org/abs/2409.10488v1) |&#10;| A Host Galaxy Morphology Link Between Quasi&#45;Periodic Eruptions and Tidal&#10; &#160;Disruption Events | Olivier Gilbert, John J. Ruan, Michael Eracleous, Daryl Haggard, Jessie C. Runnoe | &#160;&#160;The physical processes that produce X&#45;ray Quasi&#45;Periodic Eruptions (QPEs)&#10;recently discovered from the nuclei of several low&#45;redshift galaxies are&#10;mysterious. Several pieces of observational evidence strongly suggest a link&#10;between QPEs and Tidal Disruption Events (TDE). Previous studies also reveal&#10;that the morphologies of TDE host galaxies are highly concentrated, with high&#10;Sersic indicies, bulge&#45;to&#45;total light (B/T) ratios, and stellar surface mass&#10;densities relative to the broader galaxy population. We use these distinctive&#10;properties to test the link between QPEs and TDEs, by comparing these&#10;parameters of QPE host galaxies to TDE host galaxies. We employ archival Legacy&#10;Survey images of a sample of 9 QPE host galaxies and a sample of 13 TDE host&#10;galaxies, and model their surface brightness profiles. We show that QPE host&#10;galaxies have high Sersic indices of ~3, high B/T ratios of ~0.5, and high&#10;surface mass densities of ~10^10 Msun kpc^&#45;2. These properties are similar to&#10;TDE host galaxies, but are in strong contrast to a mass&#45; and redshift&#45;matched&#10;control sample of galaxies. We also find tentative evidence that the central&#10;black holes in both QPE and TDE host galaxies are undermassive relative to&#10;their stellar mass. The morphological similarities between QPE and TDE host&#10;galaxies at the population level add to the mounting evidence of a physical&#10;link between these phenomena, and favor QPE models that also invoke TDEs.&#10; | General | [Link](http://arxiv.org/abs/2409.10486v1) |&#10;| Tuning the Rate of Tightly Packed Systems To Produce Planet Occurrence&#10; &#160;Trends with Galactic Height | Sarah Ballard | &#160;&#160;The formation of planetary systems has historically been considered in&#10;isolation, decoupled from processes on galactic scales. Recent findings&#10;employing data from ESA&#39;s Gaia mission challenge this narrative, identifying&#10;trends in planet occurrence with galactic kinematics and stellar age. The&#10;findings indicate changes in planet occurrence over and above the predicted&#10;changes from metallicity variation within the Milky Way, so that changes to&#10;stellar metallicity alone (long understood to be deterministic in planet&#10;outcomes) cannot explain the trends entirely. The scope of potential factors&#10;influencing planet formation has grown progressively wider, with accompanying&#10;theoretical support for galactic&#45;scale influences upon planet formation. In&#10;this manuscript, we investigate specifically how changes to the rate of Systems&#10;of Tightly&#45;packed Inner Planets (STIPs) could manifest as a trend in planet&#10;occurrence with galactic height. We focus our study upon M dwarf planetary&#10;systems for two reasons: first, they host STIPs at high rates, and secondly,&#10;their longevity makes them useful probes for kinematic trends over Gyr. We&#10;consider two models for a varying STIP rate: one in which STIP likelihood is&#10;determined by stellar age alone, irrespective of galactic time, and another in&#10;which the STIP likelihood suddenly increased in recent galactic history. Both&#10;models, which impose a higher STIP likelihood among younger stars, produce a&#10;negative gradient in planet occurrence with increasing height from the galactic&#10;midplane. We find that a step function model in which STIP likelihood increased&#10;by a factor of several ~a few Gyr ago resembles an observed trend among FGK&#10;dwarfs. We consider plausible physical mechanisms that could mimic the&#10;hypothesized model, given known links between STIP occurrence and other stellar&#10;and planetary properties.&#10; | General | [Link](http://arxiv.org/abs/2409.10485v1) |&#10;| XLM for Autonomous Driving Systems: A Comprehensive Review | Sonda Fourati, Wael Jaafar, Noura Baccar, Safwan Alfattani | &#160;&#160;Large Language Models (LLMs) have showcased remarkable proficiency in various&#10;information&#45;processing tasks. These tasks span from extracting data and&#10;summarizing literature to generating content, predictive modeling,&#10;decision&#45;making, and system controls. Moreover, Vision Large Models (VLMs) and&#10;Multimodal LLMs (MLLMs), which represent the next generation of language&#10;models, a.k.a., XLMs, can combine and integrate many data modalities with the&#10;strength of language understanding, thus advancing several information&#45;based&#10;systems, such as Autonomous Driving Systems (ADS). Indeed, by combining&#10;language communication with multimodal sensory inputs, e.g., panoramic images&#10;and LiDAR or radar data, accurate driving actions can be taken. In this&#10;context, we provide in this survey paper a comprehensive overview of the&#10;potential of XLMs towards achieving autonomous driving. Specifically, we review&#10;the relevant literature on ADS and XLMs, including their architectures, tools,&#10;and frameworks. Then, we detail the proposed approaches to deploy XLMs for&#10;autonomous driving solutions. Finally, we provide the related challenges to XLM&#10;deployment for ADS and point to future research directions aiming to enable XLM&#10;adoption in future ADS frameworks.&#10; | General | [Link](http://arxiv.org/abs/2409.10484v1) |&#10;| Efficient polarizable QM/MM using the direct reaction field Hamiltonian&#10; &#160;with electrostatic potential fitted multipole operators | Thomas P. Fay, Nicolas Ferr, Miquel Huix&#45;Rotllant | &#160;&#160;Electronic polarization and dispersion are decisive actors in determining&#10;interaction energies between molecules. These interactions have a particularly&#10;profound effect on excitation energies of molecules in complex environments,&#10;especially when the excitation involves a significant degree of charge&#10;reorganisation. The direct reaction field (DRF) approach, which has seen a&#10;recent revival of interest, provides a powerful framework for describing these&#10;interactions in quantum mechanics/molecular mechanics (QM/MM) models of&#10;systems, where a small subsystem of interest is described using quantum&#10;chemical methods and the remainder is treated with a simple MM force field. In&#10;this paper we show how the DRF approach can be combined with the electrostatic&#10;potential fitted (ESPF) multipole operator description of the QM region charge&#10;density, which reduces the scaling $mathcal{O}(N_mathrm{MM}^3)$ of the method&#10;with MM system to $mathcal{O}(N_mathrm{MM}^2)$. We also show how the DRF&#10;approach can be combined with fluctuating charge descriptions of the&#10;polarizable environment, as well as previously used atom&#45;centred&#10;dipole&#45;polarizability based models. We further show that the ESPF&#45;DRF method&#10;provides an accurate description of molecular interactions in both ground and&#10;excited electronic states of the QM system and apply it to predict the gas to&#10;aqueous solution solvatochromic shifts in the UV/visible absorption spectrum of&#10;acrolein.&#10; | General | [Link](http://arxiv.org/abs/2409.10483v1) |&#10;| Schrodinger&#39;s Memory: Large Language Models | Wei Wang, Qing Li | &#160;&#160;Memory is the foundation of LLMs&#39; functionality, yet past research has lacked&#10;an in&#45;depth exploration of their memory capabilities and underlying theory. In&#10;this paper, we apply UAT theory to explain the memory mechanism of LLMs and&#10;propose a new approach for evaluating LLM performance by comparing the memory&#10;capacities of different models. Through extensive experiments, we validate our&#10;theory and the memory abilities of LLMs. Finally, we compare the capabilities&#10;of the human brain and LLMs, highlighting both their similarities and&#10;differences in terms of working mechanisms.&#10; | General | [Link](http://arxiv.org/abs/2409.10482v1) |&#10;| Exploring 3D Face Reconstruction and Fusion Methods for Face&#10; &#160;Verification: A Case&#45;Study in Video Surveillance | Simone Maurizio La Cava, Sara Concas, Ruben Tolosana, Roberto Casula, Giulia Orr, Martin Drahansky, Julian Fierrez, Gian Luca Marcialis | &#160;&#160;3D face reconstruction (3DFR) algorithms are based on specific assumptions&#10;tailored to distinct application scenarios. These assumptions limit their use&#10;when acquisition conditions, such as the subject&#39;s distance from the camera or&#10;the camera&#39;s characteristics, are different than expected, as typically happens&#10;in video surveillance. Additionally, 3DFR algorithms follow various strategies&#10;to address the reconstruction of a 3D shape from 2D data, such as statistical&#10;model fitting, photometric stereo, or deep learning. In the present study, we&#10;explore the application of three 3DFR algorithms representative of the SOTA,&#10;employing each one as the template set generator for a face verification&#10;system. The scores provided by each system are combined by score&#45;level fusion.&#10;We show that the complementarity induced by different 3DFR algorithms improves&#10;performance when tests are conducted at never&#45;seen&#45;before distances from the&#10;camera and camera characteristics (cross&#45;distance and cross&#45;camera settings),&#10;thus encouraging further investigations on multiple 3DFR&#45;based approaches.&#10; | General | [Link](http://arxiv.org/abs/2409.10481v1) |&#10;| Addressing misspecification in contextual optimization | Omar Bennouna, Jiawei Zhang, Saurabh Amin, Asuman Ozdaglar | &#160;&#160;We study a linear contextual optimization problem where a decision maker has&#10;access to historical data and contextual features to learn a cost prediction&#10;model aimed at minimizing decision error. We adopt the predict&#45;then&#45;optimize&#10;framework for this analysis. Given that perfect model alignment with reality is&#10;often unrealistic in practice, we focus on scenarios where the chosen&#10;hypothesis set is misspecified. In this context, it remains unclear whether&#10;current contextual optimization approaches can effectively address such model&#10;misspecification. In this paper, we present a novel integrated learning and&#10;optimization approach designed to tackle model misspecification in contextual&#10;optimization. This approach offers theoretical generalizability, tractability,&#10;and optimality guarantees, along with strong practical performance. Our method&#10;involves minimizing a tractable surrogate loss that aligns with the performance&#10;value from cost vector predictions, regardless of whether the model&#10;misspecified or not, and can be optimized in reasonable time. To our knowledge,&#10;no previous work has provided an approach with such guarantees in the context&#10;of model misspecification.&#10; | General | [Link](http://arxiv.org/abs/2409.10479v1) |&#10;| Local SGD for Near&#45;Quadratic Problems: Improving Convergence under&#10; &#160;Unconstrained Noise Conditions | Andrey Sadchikov, Savelii Chezhegov, Aleksandr Beznosikov, Alexander Gasnikov | &#160;&#160;Distributed optimization plays an important role in modern large&#45;scale&#10;machine learning and data processing systems by optimizing the utilization of&#10;computational resources. One of the classical and popular approaches is Local&#10;Stochastic Gradient Descent (Local SGD), characterized by multiple local&#10;updates before averaging, which is particularly useful in distributed&#10;environments to reduce communication bottlenecks and improve scalability. A&#10;typical feature of this method is the dependence on the frequency of&#10;communications. But in the case of a quadratic target function with homogeneous&#10;data distribution over all devices, the influence of frequency of&#10;communications vanishes. As a natural consequence, subsequent studies include&#10;the assumption of a Lipschitz Hessian, as this indicates the similarity of the&#10;optimized function to a quadratic one to some extent. However, in order to&#10;extend the completeness of the Local SGD theory and unlock its potential, in&#10;this paper we abandon the Lipschitz Hessian assumption by introducing a new&#10;concept of $textit{approximate quadraticity}$. This assumption gives a new&#10;perspective on problems that have near quadratic properties. In addition,&#10;existing theoretical analyses of Local SGD often assume bounded variance. We,&#10;in turn, consider the unbounded noise condition, which allows us to broaden the&#10;class of studied problems.&#10; | General | [Link](http://arxiv.org/abs/2409.10478v1) |&#10;| SimInversion: A Simple Framework for Inversion&#45;Based Text&#45;to&#45;Image&#10; &#160;Editing | Qi Qian, Haiyang Xu, Ming Yan, Juhua Hu | &#160;&#160;Diffusion models demonstrate impressive image generation performance with&#10;text guidance. Inspired by the learning process of diffusion, existing images&#10;can be edited according to text by DDIM inversion. However, the vanilla DDIM&#10;inversion is not optimized for classifier&#45;free guidance and the accumulated&#10;error will result in the undesired performance. While many algorithms are&#10;developed to improve the framework of DDIM inversion for editing, in this work,&#10;we investigate the approximation error in DDIM inversion and propose to&#10;disentangle the guidance scale for the source and target branches to reduce the&#10;error while keeping the original framework. Moreover, a better guidance scale&#10;(i.e., 0.5) than default settings can be derived theoretically. Experiments on&#10;PIE&#45;Bench show that our proposal can improve the performance of DDIM inversion&#10;dramatically without sacrificing efficiency.&#10; | General | [Link](http://arxiv.org/abs/2409.10476v1) |&#10;| Leadership and Engagement Dynamics in Legislative Twitter Networks:&#10; &#160;Statistical Analysis and Modeling | Carolina Luque, Juan Sosa | &#160;&#160;In this manuscript, we analyze the interaction network on Twitter among&#10;members of the 117th U.S. Congress to assess the visibility of political&#10;leaders and explore how systemic properties and node attributes influence the&#10;formation of legislative connections. We employ descriptive social network&#10;statistical methods, the exponential random graph model (ERGM), and the&#10;stochastic block model (SBM) to evaluate the relative impact of network&#10;systemic properties, as well as institutional and personal traits, on the&#10;generation of online relationships among legislators. Our findings reveal that&#10;legislative networks on social media platforms like Twitter tend to reinforce&#10;the leadership of dominant political actors rather than diminishing their&#10;influence. However, we identify that these leadership roles can manifest in&#10;various forms. Additionally, we highlight that online connections within&#10;legislative networks are influenced by both the systemic properties of the&#10;network and institutional characteristics.&#10; | General | [Link](http://arxiv.org/abs/2409.10475v1) |&#10;| MacDiff: Unified Skeleton Modeling with Masked Conditional Diffusion | Lehong Wu, Lilang Lin, Jiahang Zhang, Yiyang Ma, Jiaying Liu | &#160;&#160;Self&#45;supervised learning has proved effective for skeleton&#45;based human action&#10;understanding. However, previous works either rely on contrastive learning that&#10;suffers false negative problems or are based on reconstruction that learns too&#10;much unessential low&#45;level clues, leading to limited representations for&#10;downstream tasks. Recently, great advances have been made in generative&#10;learning, which is naturally a challenging yet meaningful pretext task to model&#10;the general underlying data distributions. However, the representation learning&#10;capacity of generative models is under&#45;explored, especially for the skeletons&#10;with spacial sparsity and temporal redundancy. To this end, we propose Masked&#10;Conditional Diffusion (MacDiff) as a unified framework for human skeleton&#10;modeling. For the first time, we leverage diffusion models as effective&#10;skeleton representation learners. Specifically, we train a diffusion decoder&#10;conditioned on the representations extracted by a semantic encoder. Random&#10;masking is applied to encoder inputs to introduce a information bottleneck and&#10;remove redundancy of skeletons. Furthermore, we theoretically demonstrate that&#10;our generative objective involves the contrastive learning objective which&#10;aligns the masked and noisy views. Meanwhile, it also enforces the&#10;representation to complement for the noisy view, leading to better&#10;generalization performance. MacDiff achieves state&#45;of&#45;the&#45;art performance on&#10;representation learning benchmarks while maintaining the competence for&#10;generative tasks. Moreover, we leverage the diffusion model for data&#10;augmentation, significantly enhancing the fine&#45;tuning performance in scenarios&#10;with scarce labeled data. Our project is available at&#10;https://lehongwu.github.io/ECCV24MacDiff/.&#10; | General | [Link](http://arxiv.org/abs/2409.10473v1) |&#10;| Towards Semantic Versioning of Open Pre&#45;trained Language Model Releases&#10; &#160;on Hugging Face | Adekunle Ajibode, Abdul Ali Bangash, Filipe Roseiro Cogo, Bram Adams, Ahmed E. Hassan | &#160;&#160;The proliferation of open Pre&#45;trained Language Models (PTLMs) on model&#10;registry platforms like Hugging Face (HF) presents both opportunities and&#10;challenges for companies building products around them. Similar to traditional&#10;software dependencies, PTLMs continue to evolve after a release. However, the&#10;current state of release practices of PTLMs on model registry platforms are&#10;plagued by a variety of inconsistencies, such as ambiguous naming conventions&#10;and inaccessible model training documentation. Given the knowledge gap on&#10;current PTLM release practices, our empirical study uses a mixed&#45;methods&#10;approach to analyze the releases of 52,227 PTLMs on the most well&#45;known model&#10;registry, HF. Our results reveal 148 different naming practices for PTLM&#10;releases, with 40.87% of changes to model weight files not represented in the&#10;adopted name&#45;based versioning practice or their documentation. In addition, we&#10;identified that the 52,227 PTLMs are derived from only 299 different base&#10;models (the modified original models used to create 52,227 PTLMs), with&#10;Fine&#45;tuning and Quantization being the most prevalent modification methods&#10;applied to these base models. Significant gaps in release transparency, in&#10;terms of training dataset specifications and model card availability, still&#10;exist, highlighting the need for standardized documentation. While we&#10;identified a model naming practice explicitly differentiating between major and&#10;minor PTLM releases, we did not find any significant difference in the types of&#10;changes that went into either type of releases, suggesting that major/minor&#10;version numbers for PTLMs often are chosen arbitrarily. Our findings provide&#10;valuable insights to improve PTLM release practices, nudging the field towards&#10;more formal semantic versioning practices.&#10; | General | [Link](http://arxiv.org/abs/2409.10472v1) |&#10;| Real&#45;Time Whole&#45;Body Control of Legged Robots with Model&#45;Predictive Path&#10; &#160;Integral Control | Juan Alvarez&#45;Padilla, John Z. Zhang, Sofia Kwok, John M. Dolan, Zachary Manchester | &#160;&#160;This paper presents a system for enabling real&#45;time synthesis of whole&#45;body&#10;locomotion and manipulation policies for real&#45;world legged robots. Motivated by&#10;recent advancements in robot simulation, we leverage the efficient&#10;parallelization capabilities of the MuJoCo simulator to achieve fast sampling&#10;over the robot state and action trajectories. Our results show surprisingly&#10;effective real&#45;world locomotion and manipulation capabilities with a very&#10;simple control strategy. We demonstrate our approach on several hardware and&#10;simulation experiments: robust locomotion over flat and uneven terrains,&#10;climbing over a box whose height is comparable to the robot, and pushing a box&#10;to a goal position. To our knowledge, this is the first successful deployment&#10;of whole&#45;body sampling&#45;based MPC on real&#45;world legged robot hardware.&#10;Experiment videos and code can be found at: https://whole&#45;body&#45;mppi.github.io/&#10; | General | [Link](http://arxiv.org/abs/2409.10469v1) |&#10;| Assortativity in sympatric speciation and species classification | Joao U. F. Lizarraga, Flavia M. D. Marquitti, Marcus A. M. de Aguiar | &#160;&#160;We investigate the role of assortative mating in speciation using the&#10;sympatric model of Derrida and Higgs. The model explores the idea that genetic&#10;differences create incompatibilities between individuals, preventing mating if&#10;the number of such differences is too large. Speciation, however, only happens&#10;in this mating system if the number of genes is large. Here we show that&#10;speciation with small genome sizes can occur if assortative mating is&#10;introduced. In our model individuals are represented by three chromosomes: one&#10;responsible for reproductive compatibility, one for coding the trait on which&#10;assortativity will operate, and a neutral chromosome. Reproduction is possible&#10;if individuals are genetically similar with respect to the first chromosome,&#10;but among these compatible mating partners, the one with the most similar trait&#10;coded by the second chromosome is selected. We show that this type of&#10;assortativity facilitates speciation, which can happen with a small number of&#10;genes in the first chromosome. Species, classified according to reproductive&#10;isolation, dictated by the first chromosome, can display different traits&#10;values, as measured by the second and the third chromosomes. Therefore, species&#10;can also be identified based on similarity of the neutral trait, which works as&#10;a proxy for reproductive isolation.&#10; | General | [Link](http://arxiv.org/abs/2409.10466v1) |&#10;| A stabilized total pressure&#45;formulation of the Biot&#39;s poroelasticity&#10; &#160;equations in frequency domain: numerical analysis and applications | Cristian Crcamo, Alfonso Caiazzo, Felipe Galarce, Joaqun Mura | &#160;&#160;This work focuses on the numerical solution of the dynamics of a poroelastic&#10;material in the frequency domain. We provide a detailed stability analysis&#10;based on the application of the Fredholm alternative in the continuous case,&#10;considering a total pressure formulation of the Biot&#39;s equations. In the&#10;discrete setting, we propose a stabilized equal order finite element method&#10;complemented by an additional pressure stabilization to enhance the robustness&#10;of the numerical scheme with respect to the fluid permeability. Utilizing the&#10;Fredholm alternative, we extend the well&#45;posedness results to the discrete&#10;setting, obtaining theoretical optimal convergence for the case of linear&#10;finite elements. We present different numerical experiments to validate the&#10;proposed method. First, we consider model problems with known analytic&#10;solutions in two and three dimensions. As next, we show that the method is&#10;robust for a wide range of permeabilities, including the case of discontinuous&#10;coefficients. Lastly, we show the application for the simulation of brain&#10;elastography on a realistic brain geometry obtained from medical imaging.&#10; | General | [Link](http://arxiv.org/abs/2409.10465v1) |&#10;| New Direct Sum Tests | Alek Westover, Edward Yu, Kai Zheng | &#160;&#160;A function $f:[n]^{d} to mathbb{F}_2$ is a defn{direct sum} if there are&#10;functions $L_i:[n]to mathbb{F}_2$ such that ${f(x) = sum_{i}L_i(x_i)}$. In&#10;this work we give multiple results related to the property testing of direct&#10;sums.&#10; &#160;Our first result concerns a test proposed by Dinur and Golubev in 2019. We&#10;call their test the Diamond test and show that it is indeed a direct sum&#10;tester. More specifically, we show that if a function $f$ is $epsilon$&#45;far&#10;from being a direct sum function, then the Diamond test rejects $f$ with&#10;probability at least $Omega_{n,epsilon}(1)$. Even in the case of $n = 2$, the&#10;Diamond test is, to the best of our knowledge, novel and yields a new tester&#10;for the classic property of affinity.&#10; &#160;Apart from the Diamond test, we also analyze a broad family of direct sum&#10;tests, which at a high level, run an arbitrary affinity test on the restriction&#10;of $f$ to a random hypercube inside of $[n]^d$. This family of tests includes&#10;the direct sum test analyzed in cite{di19}, but does not include the Diamond&#10;test. As an application of our result, we obtain a direct sum test which works&#10;in the online adversary model of cite{KRV}.&#10; &#160;Finally, we also discuss a Fourier analytic interpretation of the diamond&#10;tester in the $n=2$ case, as well as prove local correction results for direct&#10;sum as conjectured by Dinur and Golubev.&#10; | General | [Link](http://arxiv.org/abs/2409.10464v1) |&#10;| Kolmogorov&#45;Arnold Networks in Low&#45;Data Regimes: A Comparative Study with&#10; &#160;Multilayer Perceptrons | Farhad Pourkamali&#45;Anaraki | &#160;&#160;Multilayer Perceptrons (MLPs) have long been a cornerstone in deep learning,&#10;known for their capacity to model complex relationships. Recently,&#10;Kolmogorov&#45;Arnold Networks (KANs) have emerged as a compelling alternative,&#10;utilizing highly flexible learnable activation functions directly on network&#10;edges, a departure from the neuron&#45;centric approach of MLPs. However, KANs&#10;significantly increase the number of learnable parameters, raising concerns&#10;about their effectiveness in data&#45;scarce environments. This paper presents a&#10;comprehensive comparative study of MLPs and KANs from both algorithmic and&#10;experimental perspectives, with a focus on low&#45;data regimes. We introduce an&#10;effective technique for designing MLPs with unique, parameterized activation&#10;functions for each neuron, enabling a more balanced comparison with KANs. Using&#10;empirical evaluations on simulated data and two real&#45;world data sets from&#10;medicine and engineering, we explore the trade&#45;offs between model complexity&#10;and accuracy, with particular attention to the role of network depth. Our&#10;findings show that MLPs with individualized activation functions achieve&#10;significantly higher predictive accuracy with only a modest increase in&#10;parameters, especially when the sample size is limited to around one hundred.&#10;For example, in a three&#45;class classification problem within additive&#10;manufacturing, MLPs achieve a median accuracy of 0.91, significantly&#10;outperforming KANs, which only reach a median accuracy of 0.53 with default&#10;hyperparameters. These results offer valuable insights into the impact of&#10;activation function selection in neural networks.&#10; | General | [Link](http://arxiv.org/abs/2409.10463v1) |&#10;| Effects of synapse location, delay and background stochastic activity on&#10; &#160;synchronising hippocampal CA1 neurons | Alessandro Fiasconaro, Michele Migliore | &#160;&#160;We study the synchronisation of neurons in a realistic model under the&#10;Hodgkin&#45;Huxley dynamics. To focus on the role of the different locations of the&#10;excitatory synapses, we use two identical neurons where the set of input&#10;signals is grouped at two different distances from the soma. The system is&#10;intended to represent a CA1 hippocampal neuron in which the synapses arriving&#10;from the CA3 neurons of the trisynaptic pathway appear to be localised in the&#10;apical dendritic region and are, in principle, either proximal or distal to the&#10;soma. Synchronisation is studied using a specifically defined spiking&#10;correlation function as a function of various parameters such as the distance&#10;from the soma of one of the synaptic groups, the inhibition weight and the&#10;associated activation delay. We found that the neurons&#39; spiking activity&#10;depends nonmonotonically on the relative dendritic location of the synapses and&#10;their inhibitory weight, whereas the synchronisation measure always decreases&#10;with inhibition, and strongly depends on its activation time delay. The&#10;background activity on the somas results essentially independent on the&#10;fluctuation intensity and strongly support the importance of the balance&#10;between inhibition and excitation for neuronal synchronization.&#10; | General | [Link](http://arxiv.org/abs/2409.10460v1) |&#10;| Efficiently Crowdsourcing Visual Importance with Punch&#45;Hole Annotation | Minsuk Chang, Soohyun Lee, Aeri Cho, Hyeon Jeon, Seokhyeon Park, Cindy Xiong Bearfield, Jinwook Seo | &#160;&#160;We introduce a novel crowdsourcing method for identifying important areas in&#10;graphical images through punch&#45;hole labeling. Traditional methods, such as gaze&#10;trackers and mouse&#45;based annotations, which generate continuous data, can be&#10;impractical in crowdsourcing scenarios. They require many participants, and the&#10;outcome data can be noisy. In contrast, our method first segments the graphical&#10;image with a grid and drops a portion of the patches (punch holes). Then, we&#10;iteratively ask the labeler to validate each annotation with holes, narrowing&#10;down the annotation only having the most important area. This approach aims to&#10;reduce annotation noise in crowdsourcing by standardizing the annotations while&#10;enhancing labeling efficiency and reliability. Preliminary findings from&#10;fundamental charts demonstrate that punch&#45;hole labeling can effectively&#10;pinpoint critical regions. This also highlights its potential for broader&#10;application in visualization research, particularly in studying large&#45;scale&#10;users&#39; graphical perception. Our future work aims to enhance the algorithm to&#10;achieve faster labeling speed and prove its utility through large&#45;scale&#10;experiments.&#10; | General | [Link](http://arxiv.org/abs/2409.10459v1) |&#10;| Full distribution of local observables in an exactly solvable current&#10; &#160;carrying steady states of a driven XXZ chain | Sandipan Manna, G J Sreejith | &#160;&#160;Current carrying steady states of interacting spins chains exhibit rich&#10;structures generated through an interplay of current induced correlations and&#10;energetic constraints from the Hamiltonian. The XXZ spin chain when coupled to&#10;maximally polarizing Lindblad terms admits an exact solution in a matrix&#10;product state (MPS) form. We use this exact solution to study the correlations&#10;and distributions of simple local spin observables in the non equilibrium&#10;steady state (NESS). We present exact expressions for spin correlators, entropy&#10;per site, cumulant generating functions for distributions of local observables&#10;in the XX limit (Ising anisotropy $Delta=0$). Further, we use the exact MPS&#10;solution in systems with $Delta&gt;0$, to numerically exactly calculate the&#10;entropy, correlations, as well as distributions of spin observables in blocks&#10;as large as $nsim 200$ sites allowing an estimation of the rate functions. The&#10;$z$ magnetization distribution is consistant with short range spin correlations&#10;in the $z$ direction while the $x$&#45;magnetization shows a double peak structure&#10;at larger $Delta$ suggesting short range ferromagnetic ordering. We find that&#10;the distribution of $z$&#45;magnetization sharpens for parameters where the current&#10;is maximized.&#10; | General | [Link](http://arxiv.org/abs/2409.10458v1) |&#10;| Mean Residual Life Ageing Intensity Function | Ashutosh Singh, Ishapathik Das, Asok Kumar Nanda, Sumen Sen | &#160;&#160;The ageing intensity function is a powerful analytical tool that provides&#10;valuable insights into the ageing process across diverse domains such as&#10;reliability engineering, actuarial science, and healthcare. Its applications&#10;continue to expand as researchers delve deeper into understanding the complex&#10;dynamics of ageing and its implications for society. One common approach to&#10;defining the ageing intensity function is through the hazard rate or failure&#10;rate function, extensively explored in scholarly literature. Equally&#10;significant to the hazard rate function is the mean residual life function,&#10;which plays a crucial role in analyzing the ageing patterns exhibited by units&#10;or components. This article introduces the mean residual life ageing intensity&#10;(MRLAI) function to delve into component ageing behaviours across various&#10;distributions. Additionally, we scrutinize the closure properties of the MRLAI&#10;function across different reliability operations. Furthermore, a new order&#10;termed the mean residual life ageing intensity order is defined to analyze the&#10;ageing behaviour of a system, and the closure property of this order under&#10;various reliability operations is discussed.&#10; | General | [Link](http://arxiv.org/abs/2409.10456v1) |&#10;| Quantile Fourier regressions for decision making under uncertainty | Arash Khojaste, Geoffrey Pritchard, Golbon Zakeri | &#160;&#160;Weconsider Markov decision processes arising from a Markov model of an&#10;underlying natural phenomenon. Such phenomena are usually periodic (e.g.&#10;annual) in time, and so the Markov processes modelling them must be&#10;time&#45;inhomogeneous, with cyclostationary rather than stationary behaviour. We&#10;describe a technique for constructing such processes that allows for periodic&#10;variations both in the values taken by the process and in the serial dependence&#10;structure. We include two illustrative numerical examples: a hydropower&#10;scheduling problem and a model of offshore wind power integration.&#10; | General | [Link](http://arxiv.org/abs/2409.10455v1) |&#10;| The Debiased Near&#45;Earth Object Population from ATLAS Telescopes | Rogerio Deienno, Larry Denneau, David Nesvorn, David Vokrouhlick, William F. Bottke, Robert Jedicke, Shantanu Naidu, Steven R. Chesley, Davide Farnocchia, Paul W. Chodas | &#160;&#160;This work is dedicated to debias the Near&#45;Earth Objects (NEO) population&#10;based on observations from the Asteroid Terrestrial&#45;impact Last Alert System&#10;(ATLAS) telescopes. We have applied similar methods used to develop the&#10;recently released NEO model generator (NEOMOD), once debiasing the NEO&#10;population using data from Catalina Sky Survey (CSS) G96 telescope. ATLAS is&#10;composed of four different telescopes. We first analyzed observational data&#10;from each of all four telescopes separately and later combined them. Our&#10;results highlight main differences between CSS and ATLAS, e.g., sky coverage&#10;and survey power at debiasing the NEO population. ATLAS has a much larger sky&#10;coverage than CSS, allowing it to find bright NEOs that would be constantly&#10;&quot;hiding&quot; from CSS. Consequently, ATLAS is more powerful than CSS at debiasing&#10;the NEO population for H $&#10;esssim$ 19. With its intrinsically greater&#10;sensitivity and emphasis on observing near opposition, CSS excels in the&#10;debiasing of smaller objects. ATLAS, as an all sky survey designed to find&#10;imminent hazardous objects, necessarily spends a significant fraction of time&#10;looking at places on the sky where objects do not appear, reducing its power&#10;for debiasing the population of small objects. We estimate a NEO population&#10;completeness of $approx$ 88%$^{+3%}_{&#45;2%}$ for H $&lt;$ 17.75 and $approx$&#10;36%$^{+1%}_{&#45;1%}$ for H $&lt;$ 22.25. Those numbers are similar to previous&#10;estimates (within error bars for H $&lt;$ 17.75) from CSS, yet, around 3% and 8%&#10;smaller at their face values, respectively. We also confirm previous finding&#10;that the $&#10;u_6$ secular resonance is the main source of small and faint NEOs&#10;at H = 28, whereas the 3:1 mean motion resonance with Jupiter dominates for&#10;larger and brighter NEOs at H = 15.&#10; | General | [Link](http://arxiv.org/abs/2409.10453v1) |&#10;| Signed Graph Autoencoder for Explainable and Polarization&#45;Aware Network&#10; &#160;Embeddings | Nikolaos Nakis, Chrysoula Kosma, Giannis Nikolentzos, Michalis Chatzianastasis, Iakovos Evdaimon, Michalis Vazirgiannis | &#160;&#160;Autoencoders based on Graph Neural Networks (GNNs) have garnered significant&#10;attention in recent years for their ability to extract informative latent&#10;representations, characterizing the structure of complex topologies, such as&#10;graphs. Despite the prevalence of Graph Autoencoders, there has been limited&#10;focus on developing and evaluating explainable neural&#45;based graph generative&#10;models specifically designed for signed networks. To address this gap, we&#10;propose the Signed Graph Archetypal Autoencoder (SGAAE) framework. SGAAE&#10;extracts node&#45;level representations that express node memberships over distinct&#10;extreme profiles, referred to as archetypes, within the network. This is&#10;achieved by projecting the graph onto a learned polytope, which governs its&#10;polarization. The framework employs a recently proposed likelihood for&#10;analyzing signed networks based on the Skellam distribution, combined with&#10;relational archetypal analysis and GNNs. Our experimental evaluation&#10;demonstrates the SGAAEs&#39; capability to successfully infer node memberships over&#10;the different underlying latent structures while extracting competing&#10;communities formed through the participation of the opposing views in the&#10;network. Additionally, we introduce the 2&#45;level network polarization problem&#10;and show how SGAAE is able to characterize such a setting. The proposed model&#10;achieves high performance in different tasks of signed link prediction across&#10;four real&#45;world datasets, outperforming several baseline models.&#10; | General | [Link](http://arxiv.org/abs/2409.10452v1) |&#10;| Why you should also use OLS estimation of tail exponents | Thiago Trafane Oliveira Santos, Daniel Oliveira Cajueiro | &#160;&#160;Even though practitioners often estimate Pareto exponents running OLS&#10;rank&#45;size regressions, the usual recommendation is to use the Hill MLE with a&#10;small&#45;sample correction instead, due to its unbiasedness and efficiency. In&#10;this paper, we advocate that you should also apply OLS in empirical&#10;applications. On the one hand, we demonstrate that, with a small&#45;sample&#10;correction, the OLS estimator is also unbiased. On the other hand, we show that&#10;the MLE assigns significantly greater weight to smaller observations. This&#10;suggests that the OLS estimator may outperform the MLE in cases where the&#10;distribution is (i) strictly Pareto but only in the upper tail or (ii)&#10;regularly varying rather than strictly Pareto. We substantiate our theoretical&#10;findings with Monte Carlo simulations and real&#45;world applications,&#10;demonstrating the practical relevance of the OLS method in estimating tail&#10;exponents.&#10; | General | [Link](http://arxiv.org/abs/2409.10448v1) |&#10;| Hydrodynamic hovering of swimming bacteria above surfaces | Pyae Hein Htet, Debasish Das, Eric Lauga | &#160;&#160;Flagellated bacteria are hydrodynamically attracted to rigid walls, yet past&#10;work shows a &#39;hovering&#39; state where they swim stably at a finite height above&#10;surfaces. We use numerics and theory to reveal the physical origin of hovering.&#10;Simulations first show that hovering requires an elongated cell body and&#10;results from a tilt away from the wall. Theoretical models then identify two&#10;essential asymmetries: the response of width&#45;asymmetric cells to active flows&#10;created by length&#45;asymmetric cells. A minimal model reconciles near and&#10;far&#45;field hydrodynamics, capturing all key features of hovering.&#10; | General | [Link](http://arxiv.org/abs/2409.10447v1) |&#10;| KoroT&#45;3E: A Personalized Musical Mnemonics Tool for Enhancing Memory&#10; &#160;Retention of Complex Computer Science Concepts | Xiangzhe Yuan, Jiajun Wang, Siying Hu, Andrew Cheung, Zhicong Lu | &#160;&#160;As the demand for computer science (CS) skills grows, mastering foundational&#10;concepts is crucial yet challenging for novice learners. To address this&#10;challenge, we present KoroT&#45;3E, an AI&#45;based system that creates personalized&#10;musical mnemonics to enhance both memory retention and understanding of&#10;concepts in CS. KoroT&#45;3E enables users to transform complex concepts into&#10;memorable lyrics and compose melodies that suit their musical preferences. We&#10;conducted semi&#45;structured interviews (n=12) to investigate why novice learners&#10;find it challenging to memorize and understand CS concepts. The findings,&#10;combined with constructivist learning theory, established our initial design,&#10;which was then refined following consultations with CS education experts. An&#10;empirical experiment(n=36) showed that those using KoroT&#45;3E (n=18)&#10;significantly outperformed the control group (n=18), with improved memory&#10;efficiency, increased motivation, and a positive learning experience. These&#10;findings demonstrate the effectiveness of integrating multimodal generative AI&#10;into CS education to create personalized and interactive learning experiences.&#10; | General | [Link](http://arxiv.org/abs/2409.10446v1) |&#10;| Deep&#45;Wide Learning Assistance for Insect Pest Classification | Toan Nguyen, Huy Nguyen, Huy Ung, Hieu Ung, Binh Nguyen | &#160;&#160;Accurate insect pest recognition plays a critical role in agriculture. It is&#10;a challenging problem due to the intricate characteristics of insects. In this&#10;paper, we present DeWi, novel learning assistance for insect pest&#10;classification. With a one&#45;stage and alternating training strategy, DeWi&#10;simultaneously improves several Convolutional Neural Networks in two&#10;perspectives: discrimination (by optimizing a triplet margin loss in a&#10;supervised training manner) and generalization (via data augmentation). From&#10;that, DeWi can learn discriminative and in&#45;depth features of insect pests&#10;(deep) yet still generalize well to a large number of insect categories (wide).&#10;Experimental results show that DeWi achieves the highest performances on two&#10;insect pest classification benchmarks (76.44% accuracy on the IP102 dataset&#10;and 99.79% accuracy on the D0 dataset, respectively). In addition, extensive&#10;evaluations and ablation studies are conducted to thoroughly investigate our&#10;DeWi and demonstrate its superiority. Our source code is available at&#10;https://github.com/toannguyen1904/DeWi.&#10; | General | [Link](http://arxiv.org/abs/2409.10445v1) |&#10;| LLM as BT&#45;Planner: Leveraging LLMs for Behavior Tree Generation in Robot&#10; &#160;Task Planning | Jicong Ao, Fan Wu, Yansong Wu, Abdalla Swikir, Sami Haddadin | &#160;&#160;Robotic assembly tasks are open challenges due to the long task horizon and&#10;complex part relations. Behavior trees (BTs) are increasingly used in robot&#10;task planning for their modularity and flexibility, but manually designing them&#10;can be effort&#45;intensive. Large language models (LLMs) have recently been&#10;applied in robotic task planning for generating action sequences, but their&#10;ability to generate BTs has not been fully investigated. To this end, We&#10;propose LLM as BT&#45;planner, a novel framework to leverage LLMs for BT generation&#10;in robotic assembly task planning and execution. Four in&#45;context learning&#10;methods are introduced to utilize the natural language processing and inference&#10;capabilities of LLMs to produce task plans in BT format, reducing manual effort&#10;and ensuring robustness and comprehensibility. We also evaluate the performance&#10;of fine&#45;tuned, fewer&#45;parameter LLMs on the same tasks. Experiments in simulated&#10;and real&#45;world settings show that our framework enhances LLMs&#39; performance in&#10;BT generation, improving success rates in BT generation through in&#45;context&#10;learning and supervised fine&#45;tuning.&#10; | General | [Link](http://arxiv.org/abs/2409.10444v1) |&#10;| The James Webb Space Telescope Absolute Flux Calibration. II.&#10; &#160;Mid&#45;Infrared Instrument Imaging and Coronagraphy | Karl D. Gordon, G. C. Sloan, Macarena Garcia Marin, Mattia Libralato, George Rieke, Jonathan A. Aguilar, Ralph Bohlin, Misty Cracraft, Marjorie Decleir, Andras Gaspar, David R. Law, Alberto Noriega&#45;Crespo, Michael Regan | &#160;&#160;The absolute flux calibration of the Mid&#45;Infrared Instrument Imaging and&#10;Coronagraphy is based on observations of multiple stars taken during the first&#10;2.5 years of JWST operations. The observations were designed to ensure that the&#10;flux calibration is valid for a range of flux densities, different subarrays,&#10;and different types of stars. The flux calibration was measured by combining&#10;observed aperture photometry corrected to infinite aperture with predictions&#10;based on previous observations and models of stellar atmospheres. A subset of&#10;these observations were combined with model point&#45;spread&#45;functions to measure&#10;the corrections to infinite aperture. Variations in the calibration factor with&#10;time, flux density, background level, type of star, subarray, integration time,&#10;rate, and well depth were investigated, and the only significant variations&#10;were with time and subarray. Observations of the same star taken approximately&#10;every month revealed a modest time&#45;dependent response loss seen mainly at the&#10;longest wavelengths. This loss is well characterized by a decaying exponential&#10;with a time constant of ~200 days. After correcting for the response loss, the&#10;band&#45;dependent scatter around the corrected average (aka repeatability) was&#10;found to range from 0.1 to 1.2%. Signals in observations taken with different&#10;subarrays can be lower by up to 3.4% compared to FULL frame. After correcting&#10;for the time and subarray dependencies, the scatter in the calibration factors&#10;measured for individual stars ranges from 1 to 4% depending on the band. The&#10;formal uncertainties on the flux calibration averaged for all observations are&#10;0.3 to 1.0%, with longer&#45;wavelength bands generally having larger&#10;uncertainties.&#10; | General | [Link](http://arxiv.org/abs/2409.10443v1) |&#10;| CtRNet&#45;X: Camera&#45;to&#45;Robot Pose Estimation in Real&#45;world Conditions Using&#10; &#160;a Single Camera | Jingpei Lu, Zekai Liang, Tristin Xie, Florian Ritcher, Shan Lin, Sainan Liu, Michael C. Yip | &#160;&#160;Camera&#45;to&#45;robot calibration is crucial for vision&#45;based robot control and&#10;requires effort to make it accurate. Recent advancements in markerless pose&#10;estimation methods have eliminated the need for time&#45;consuming physical setups&#10;for camera&#45;to&#45;robot calibration. While the existing markerless pose estimation&#10;methods have demonstrated impressive accuracy without the need for cumbersome&#10;setups, they rely on the assumption that all the robot joints are visible&#10;within the camera&#39;s field of view. However, in practice, robots usually move in&#10;and out of view, and some portion of the robot may stay out&#45;of&#45;frame during the&#10;whole manipulation task due to real&#45;world constraints, leading to a lack of&#10;sufficient visual features and subsequent failure of these approaches. To&#10;address this challenge and enhance the applicability to vision&#45;based robot&#10;control, we propose a novel framework capable of estimating the robot pose with&#10;partially visible robot manipulators. Our approach leverages the&#10;Vision&#45;Language Models for fine&#45;grained robot components detection, and&#10;integrates it into a keypoint&#45;based pose estimation network, which enables more&#10;robust performance in varied operational conditions. The framework is evaluated&#10;on both public robot datasets and self&#45;collected partial&#45;view datasets to&#10;demonstrate our robustness and generalizability. As a result, this method is&#10;effective for robot pose estimation in a wider range of real&#45;world manipulation&#10;scenarios.&#10; | General | [Link](http://arxiv.org/abs/2409.10441v1) |&#10;| Successive topological phase transitions in two distinct spin&#45;flop&#10; &#160;phases on the honeycomb lattice | Xudong Li, Jize Zhao, Jinbin Li, Qiang Luo | &#160;&#160;The Kitaev magnets with bond&#45;dependent interactions have garnered&#10;considerable attention in recent years for their ability to harbor exotic&#10;phases and nontrivial excitations. The topological magnons, which are indicated&#10;by nonzero Chern number and thermal Hall conductivity, are proposed to&#10;partially explain thermal Hall measurements in real materials. Hitherto,&#10;topological magnons have been extensively explored when the magnetic field is&#10;normal to the honeycomb plane, but their topological characteristics are less&#10;studied in the presence of in&#45;plane magnetic field. Here, we study two distinct&#10;in&#45;plane field induced spin&#45;flop phases in the $Gamma$&#45;$Gamma&#39;$ model, both&#10;of which are off&#45;diagonal couplings that have intimate relation to the Kitaev&#10;interaction. The two spin&#45;flop phases are distinguished by their out&#45;of&#45;plane&#10;spin components which can be either antiparallel or parallel, thus dubbing&#10;antiferromagnetic (AFM) or ferromagnetic (FM) spin&#45;flop phases, respectively.&#10;We map out topological phase diagrams for both phases, revealing a rich pattern&#10;of the Chern number over exchange parameters and magnetic field. We&#10;analytically calculate the boundaries of topological phase transitions when the&#10;magnetic field is along the $a$ and $b$ directions. We find that the thermal&#10;Hall conductivity and its derivative display contrasting behaviors when&#10;crossing different topological phase transitions. The striking difference of&#10;the two phases lies in that when the magnetic field is along the $b$ direction,&#10;topological magnons are totally absent in the AFM spin&#45;flop phase, while they&#10;can survive in the FM analogue in certain parameter regions.&#10; | General | [Link](http://arxiv.org/abs/2409.10439v1) |&#10;| A functorial approach to $n$&#45;abelian categories | Vitor Gulisz | &#160;&#160;We develop a functorial approach to the study of $n$&#45;abelian categories by&#10;reformulating their axioms in terms of their categories of finitely presented&#10;functors. Such an approach allows the use of classical homological algebra and&#10;representation theory techniques to understand higher homological algebra. As&#10;an application, we present two possible generalizations of the axioms &quot;every&#10;monomorphism is a kernel&quot; and &quot;every epimorphism is a cokernel&quot; of an abelian&#10;category to $n$&#45;abelian categories. We also specialize our results to modules&#10;over rings, thereby describing when the category of finitely generated&#10;projective modules over a ring is $n$&#45;abelian. Moreover, we establish a&#10;correspondence for $n$&#45;abelian categories with additive generators, which&#10;extends the higher Auslander correspondence.&#10; | General | [Link](http://arxiv.org/abs/2409.10438v1) |&#10;| Color symmetry breaking in the Potts spin glass | Jean&#45;Christophe Mourrat | &#160;&#160;The Potts spin glass is an analogue of the Sherrington&#45;Kirkpatrick model in&#10;which each spin can take one of $kappa$ possible values, which we interpret as&#10;colors. It was suggested in arXiv:2310.06745 that the order parameter for this&#10;model is always invariant with respect to permutations of the colors. We show&#10;here that this is false whenever $kappa ge 58$.&#10; | General | [Link](http://arxiv.org/abs/2409.10437v1) |&#10;| Infector characteristics exposed by spatial analysis of SARS&#45;CoV&#45;2&#10; &#160;sequence and demographic data analysed at fine geographical scales | Anna Gama, Samantha Lycett, Will Harvey, Joseph Hughes, Sema Nickbakhsh, David L Robertson, Alison Smith Palmer, Anthony Wood, Rowland Kao | &#160;&#160;Characterising drivers of SARS&#45;CoV&#45;2 circulation is crucial for understanding&#10;COVID&#45;19 because of the severity of control measures adopted during the&#10;pandemic. Whole genome sequence data augmented with demographic metadata&#10;provides the best opportunity to do this. We use Random Forest Decision Tree&#10;models to analyse a combination of over 4000 SARS&#45;CoV2 sequences from a densely&#10;sampled, mixed urban and rural population (Tayside) in Scotland in the period&#10;from August 2020 to July 2021, with fine scale geographical and&#10;socio&#45;demographic metadata. Comparing periods in versus out of &quot;lockdown&quot;&#10;restrictions, we show using genetic distance relationships that individuals&#10;from more deprived areas are more likely to get infected during lockdown but&#10;less likely to spread the infection further. As disadvantaged communities were&#10;the most affected by both COVID&#45;19 and its restrictions, our finding has&#10;important implications for informing future approaches to control future&#10;pandemics driven by similar respiratory infections.&#10; | General | [Link](http://arxiv.org/abs/2409.10436v1) |&#10;| A study of pure multi&#45;strange hadrons production in Pb+Pb collisions at&#10; &#160;LHC energies using HYDJET++ model | Gauri Devi, B. K. Singh | &#160;&#160;For the present work, we have used the HYDJET++ model to explore the&#10;production of pure multi&#45;strange hadrons in Pb+Pb collisions at&#10;$sqrt{s_{NN}}$= 2.76 TeV and $sqrt{s_{NN}}$= 5.02 TeV collision energies,&#10;respectively. We have simulated the $p_{T}$&#45;spectra and elliptic flow ($v_{2}$)&#10;of $phi$&#45;meson and $Omega$&#45;baryons comparing our results with ALICE&#10;experimental data and several phenomenological models (HIJING/$Boverline{B}$,&#10;VISHNU, EPOS, AMPT, and Krakow) across various centrality intervals.&#10;Additionally, we have calculated the nuclear modification factors ($R_{AA}$ and&#10;$R_{CP}$), which provide a perception of jet quenching phenomena. Hence, our&#10;findings enable the study of the energy and system dependence of $phi$ and&#10;$Omega$ hadrons production over a wide range of ultra&#45;relativistic collision&#10;energies. We also present the particle ratios ($Omega/phi$,&#10;$overline{Omega}^{+}/Omega^{&#45;}$, $Omega/pi$, and $phi/pi$), offering&#10;insights on the strangeness enhancement and chemical properties of the medium&#10;at both LHC collision energies.&#10; | General | [Link](http://arxiv.org/abs/2409.10435v1) |&#10;| Magnetic metamaterials by ion&#45;implantation | Christina Vantaraki, Petter Strm, Tuan T. Tran, Matas P. Grassi, Giovanni Fevola, Michael Foerster, Jerzy T. Sadowski, Daniel Primetzhofer, Vassilios Kapaklis | &#160;&#160;We present a method for the additive fabrication of planar magnetic&#10;nanoarrays with minimal surface roughness. Synthesis is accomplished by&#10;combining electron&#45;beam lithography, used to generate nanometric patterned&#10;masks, with ion implantation in thin films. By implanting $^{56}$Fe$^{+}$ ions,&#10;we are able to introduce magnetic functionality in a controlled manner into&#10;continuous Pd thin films, achieving 3D spatial resolution down to a few tens of&#10;nanometers. Our results demonstrate the successful application of this&#10;technique in fabricating square artificial spin ice lattices, which exhibit&#10;well&#45;defined magnetization textures and interactions among the patterned&#10;magnetic elements.&#10; | General | [Link](http://arxiv.org/abs/2409.10433v1) |&#10;| Structure&#45;preserving learning for multi&#45;symplectic PDEs | Sleyman Yldz, Pawan Goyal, Peter Benner | &#160;&#160;This paper presents an energy&#45;preserving machine learning method for&#10;inferring reduced&#45;order models (ROMs) by exploiting the multi&#45;symplectic form&#10;of partial differential equations (PDEs). The vast majority of&#10;energy&#45;preserving reduced&#45;order methods use symplectic Galerkin projection to&#10;construct reduced&#45;order Hamiltonian models by projecting the full models onto a&#10;symplectic subspace. However, symplectic projection requires the existence of&#10;fully discrete operators, and in many cases, such as black&#45;box PDE solvers,&#10;these operators are inaccessible. In this work, we propose an energy&#45;preserving&#10;machine learning method that can infer the dynamics of the given PDE using data&#10;only, so that the proposed framework does not depend on the fully discrete&#10;operators. In this context, the proposed method is non&#45;intrusive. The proposed&#10;method is grey box in the sense that it requires only some basic knowledge of&#10;the multi&#45;symplectic model at the partial differential equation level. We prove&#10;that the proposed method satisfies spatially discrete local energy conservation&#10;and preserves the multi&#45;symplectic conservation laws. We test our method on the&#10;linear wave equation, the Korteweg&#45;de Vries equation, and the&#10;Zakharov&#45;Kuznetsov equation. We test the generalization of our learned models&#10;by testing them far outside the training time interval.&#10; | General | [Link](http://arxiv.org/abs/2409.10432v1) |&#10;| Hippocampal synchronization in a realistic CA1 neuron model | Alessandro Fiasconaro, Michele Migliore | &#160;&#160;This work delves into studying the synchronization in two realistic neuron&#10;models using Hodgkin&#45;Huxley dynamics. Unlike simplistic point&#45;like models,&#10;excitatory synapses are here randomly distributed along the dendrites,&#10;introducing strong stochastic contributions into their signal propagation. To&#10;focus on the role of different excitatory positions, we use two copies of the&#10;same neuron whose synapses are located at different distances from the soma and&#10;are exposed to identical Poissonian distributed current pulses. The&#10;synchronization is investigated through a specifically defined spiking&#10;correlation function, and its behavior is analyzed as a function of several&#10;parameters: inhibition weight, distance from the soma of one synaptic group,&#10;excitatory inactivation delay, and weight of the excitatory synapses.&#10; | General | [Link](http://arxiv.org/abs/2409.10431v1) |&#10;| Meta&#45;Whisper: Speech&#45;Based Meta&#45;ICL for ASR on Low&#45;Resource Languages | Ming&#45;Hao Hsu, Kuan Po Huang, Hung&#45;yi Lee | &#160;&#160;This paper presents Meta&#45;Whisper, a novel approach to improve automatic&#10;speech recognition (ASR) for low&#45;resource languages using the Whisper model. By&#10;leveraging Meta In&#45;Context Learning (Meta&#45;ICL) and a k&#45;Nearest Neighbors (KNN)&#10;algorithm for sample selection, Meta&#45;Whisper enhances Whisper&#39;s ability to&#10;recognize speech in unfamiliar languages without extensive fine&#45;tuning.&#10;Experiments on the ML&#45;SUPERB dataset show that Meta&#45;Whisper significantly&#10;reduces the Character Error Rate (CER) for low&#45;resource languages compared to&#10;the original Whisper model. This method offers a promising solution for&#10;developing more adaptable multilingual ASR systems, particularly for languages&#10;with limited resources.&#10; | General | [Link](http://arxiv.org/abs/2409.10429v1) |&#10;| User&#45;Authenticated Device&#45;Independent Quantum Secure Direct&#10; &#160;Communication Protocol | Nayana Das, Saikat Basu, Goutam Paul, Vijay S. Rao | &#160;&#160;Device&#45;Independent Quantum Secure Direct Communication (DI&#45;QSDC) enhances&#10;quantum cryptography by enabling secure message transmission without relying on&#10;the trustworthiness of the devices involved. This approach mitigates risks&#10;associated with compromised or untrusted devices, common in traditional quantum&#10;communication.&#10; &#160;In this paper, we propose the first of its kind DI&#45;QSDC protocol with user&#10;identity authentication. This ensures the authenticity of both the sender and&#10;receiver prior to message exchange. We then discuss the security of the&#10;proposed protocol against common attacks, demonstrating that no eavesdropper&#10;gains any information from either the quantum or the classical channel. Next,&#10;we implement the protocol on IBM&#39;s quantum hardware and evaluate its&#10;performance in a realistic noisy environment. Additionally, by simulating&#10;common attack models, we showcase that the protocol is secure against any&#10;eavesdropper in the channel. These findings highlight the protocol&#39;s robust&#10;security and practical feasibility for real&#45;world secure quantum communication.&#10; | General | [Link](http://arxiv.org/abs/2409.10427v1) |&#10;| Role of kinematic constraints in the time reversal symmetry breaking of&#10; &#160;a model active matter | Soumen Das, Shankar Ghosh, Tridib Sadhu, Juliane U Klamser | &#160;&#160;Active&#45;matter systems are inherently out&#45;of&#45;equilibrium and perform&#10;mechanical work by utilizing their internal energy sources. Breakdown of&#10;time&#45;reversal symmetry (BTRS) is a hallmark of such dissipative non&#45;equilibrium&#10;dynamics. We introduce a robust, experimentally accessible, noninvasive,&#10;quantitative measure of BTRS in terms of the Kullback&#45;Leibler divergence in&#10;collision events, demonstrated in our novel artificial active matter, comprised&#10;of battery&#45;powered spherical rolling robots whose energetics in different modes&#10;of motion can be measured with high precision. Our dimensionless measure&#10;characterizes how dissipation and internal energetics are influenced by&#10;kinematic constraints from interactions with the environment. We propose this&#10;measure of BTRS as an empirical estimate of the distance from equilibrium. An&#10;energetic insight into this departure of active matter from equilibrium comes&#10;from our demonstration of a non&#45;trivial fluctuation symmetry, which reveals a&#10;potentially universal thermodynamic characteristic of active energetics. As a&#10;many&#45;body consequence of BTRS in our experimental active system, we demonstrate&#10;the emergence of activity&#45;induced herding, which has no equilibrium analogue.&#10; | General | [Link](http://arxiv.org/abs/2409.10425v1) |&#10;| Unveiling V Modes: Enhancing CMB Sensitivity to BSM Physics with a&#10; &#160;Non&#45;Ideal Half&#45;Wave Plate | N. Raffuzzi, M. Lembo, S. Giardiello, M. Gerbino, M. Lattanzi, P. Natoli, L. Pagano | &#160;&#160;V&#45;mode polarization of the cosmic microwave background is expected to be&#10;vanishingly small in the $Lambda$CDM model and, hence, usually ignored.&#10;Nonetheless, several astrophysical effects, as well as beyond standard model&#10;physics could produce it at a detectable level. A realistic half&#45;wave plate &#45;&#10;an optical element commonly used in CMB experiments to modulate the polarized&#10;signal &#45; can provide sensitivity to V modes without significantly spoiling that&#10;to linear polarization. We assess this sensitivity for some new&#45;generation CMB&#10;experiments, such as the LiteBIRD satellite, the ground&#45;based Simons&#10;Observatory and a CMB&#45;S4&#45;like experiment. We forecast the efficiency of these&#10;experiments to constrain the phenomenology of certain classes of BSM models&#10;inducing mixing of linear polarization states and generation of V modes in the&#10;CMB. We find that new&#45;generation experiments can improve current limits by&#10;1&#45;to&#45;3 orders of magnitude, depending on the data combination. The inclusion of&#10;V&#45;mode information dramatically boosts the sensitivity to these BSM models.&#10; | General | [Link](http://arxiv.org/abs/2409.10424v1) |&#10;| Initial data for a deformed isolated horizon | Ale Flandera, David Kofro, Tom Ledvinka | &#160;&#160;Within the isolated horizon formalism, we investigate a static axisymmetric&#10;space&#45;time of a black hole influenced by matter in its neighborhood. To&#10;illustrate the role of ingredients and assumptions in this formalism, we first&#10;show how, in spherical symmetry, the field equations and gauge conditions imply&#10;the isolated horizon initial data leading to the Schwarzschild space&#45;time.&#10;Then, we construct the initial data for a static axisymmetric isolated horizon&#10;representing a deformed black hole. The space&#45;time description in the&#10;Bondi&#45;like coordinates is then found as a series expansion in the vicinity of&#10;the horizon. To graphically illustrate this construction, we also find a&#10;numerical solution for a black hole deformed by a particular analytic model of&#10;a thin accretion disk. We also discuss how an accretion disk affects the&#10;analytical properties of the horizon geometry.&#10; | General | [Link](http://arxiv.org/abs/2409.10423v1) |&#10;| Learning Semi&#45;Supervised Medical Image Segmentation from Spatial&#10; &#160;Registration | Qianying Liu, Paul Henderson, Xiao Gu, Hang Dai, Fani Deligianni | &#160;&#160;Semi&#45;supervised medical image segmentation has shown promise in training&#10;models with limited labeled data and abundant unlabeled data. However,&#10;state&#45;of&#45;the&#45;art methods ignore a potentially valuable source of unsupervised&#10;semantic information &#45;&#45; spatial registration transforms between image volumes.&#10;To address this, we propose CCT&#45;R, a contrastive cross&#45;teaching framework&#10;incorporating registration information. To leverage the semantic information&#10;available in registrations between volume pairs, CCT&#45;R incorporates two&#10;proposed modules: Registration Supervision Loss (RSL) and Registration&#45;Enhanced&#10;Positive Sampling (REPS). The RSL leverages segmentation knowledge derived from&#10;transforms between labeled and unlabeled volume pairs, providing an additional&#10;source of pseudo&#45;labels. REPS enhances contrastive learning by identifying&#10;anatomically&#45;corresponding positives across volumes using registration&#10;transforms. Experimental results on two challenging medical segmentation&#10;benchmarks demonstrate the effectiveness and superiority of CCT&#45;R across&#10;various semi&#45;supervised settings, with as few as one labeled case. Our code is&#10;available at&#10;https://github.com/kathyliu579/ContrastiveCross&#45;teachingWithRegistration.&#10; | General | [Link](http://arxiv.org/abs/2409.10422v1) |&#10;| Multidimensional Deconvolution with Profiling | Huanbiao Zhu, Krish Desai, Mikael Kuusela, Vinicius Mikuni, Benjamin Nachman, Larry Wasserman | &#160;&#160;In many experimental contexts, it is necessary to statistically remove the&#10;impact of instrumental effects in order to physically interpret measurements.&#10;This task has been extensively studied in particle physics, where the&#10;deconvolution task is called unfolding. A number of recent methods have shown&#10;how to perform high&#45;dimensional, unbinned unfolding using machine learning.&#10;However, one of the assumptions in all of these methods is that the detector&#10;response is accurately modeled in the Monte Carlo simulation. In practice, the&#10;detector response depends on a number of nuisance parameters that can be&#10;constrained with data. We propose a new algorithm called Profile OmniFold&#10;(POF), which works in a similar iterative manner as the OmniFold (OF) algorithm&#10;while being able to simultaneously profile the nuisance parameters. We&#10;illustrate the method with a Gaussian example as a proof of concept&#10;highlighting its promising capabilities.&#10; | General | [Link](http://arxiv.org/abs/2409.10421v1) |&#10;| HiFi&#45;CS: Towards Open Vocabulary Visual Grounding For Robotic Grasping&#10; &#160;Using Vision&#45;Language Models | Vineet Bhat, Prashanth Krishnamurthy, Ramesh Karri, Farshad Khorrami | &#160;&#160;Robots interacting with humans through natural language can unlock numerous&#10;applications such as Referring Grasp Synthesis (RGS). Given a text query, RGS&#10;determines a stable grasp pose to manipulate the referred object in the robot&#39;s&#10;workspace. RGS comprises two steps: visual grounding and grasp pose estimation.&#10;Recent studies leverage powerful Vision&#45;Language Models (VLMs) for visually&#10;grounding free&#45;flowing natural language in real&#45;world robotic execution.&#10;However, comparisons in complex, cluttered environments with multiple instances&#10;of the same object are lacking. This paper introduces HiFi&#45;CS, featuring&#10;hierarchical application of Featurewise Linear Modulation (FiLM) to fuse image&#10;and text embeddings, enhancing visual grounding for complex attribute rich text&#10;queries encountered in robotic grasping. Visual grounding associates an object&#10;in 2D/3D space with natural language input and is studied in two scenarios:&#10;Closed and Open Vocabulary. HiFi&#45;CS features a lightweight decoder combined&#10;with a frozen VLM and outperforms competitive baselines in closed vocabulary&#10;settings while being 100x smaller in size. Our model can effectively guide&#10;open&#45;set object detectors like GroundedSAM to enhance open&#45;vocabulary&#10;performance. We validate our approach through real&#45;world RGS experiments using&#10;a 7&#45;DOF robotic arm, achieving 90.33% visual grounding accuracy in 15 tabletop&#10;scenes. We include our codebase in the supplementary material.&#10; | General | [Link](http://arxiv.org/abs/2409.10419v1) |&#10;| X&#45;ray reverberation as an explanation for UV/optical variability in&#10; &#160;nearby Seyferts | M. Papoutsis, I. E. Papadakis, C. Panagiotou, M. Doviak, E. Kammoun | &#160;&#160;Active galactic nuclei (AGNs) are known to be variable across all&#10;wavelengths. Significant observational efforts have been invested in the last&#10;decade in studying their ultraviolet (UV) and optical variability. Long and&#10;densely sampled, multi&#45;wavelength monitoring campaigns of numerous Seyfert&#10;galaxies have been conducted with the aim of determining the X&#45;ray/UV/optical&#10;continuum time lags. Time&#45;lag studies can be used to constrain theoretical&#10;models. The observed time lags can be explained by thermal reprocessing of the&#10;X&#45;rays illuminating the accretion disc (known as the X&#45;ray reverberation&#10;model). However, the observed light curves contain more information that can be&#10;used to further constrain physical models. Our primary objective is to&#10;investigate whether, in addition to time lags, the X&#45;ray reverberation model&#10;can also explain the UV/optical variability amplitude of nearby Seyferts. To do&#10;this, we measured the excess variance of four sources (namely Mrk 509, NGC&#10;4151, NGC 2617, and Mrk 142) as a function of wavelength using data from&#10;archival long, multi&#45;wavelength campaigns with Swift, and ground&#45;based&#10;telescopes. We also computed the model excess variance in the case of the X&#45;ray&#10;reverberation model by determining the disc&#39;s transfer function and assuming a&#10;bending power law for the X&#45;ray power spectrum. We tested the validity of the&#10;model by comparing the measured and model variances for a range of accretion&#10;rates and X&#45;ray source heights. We conclude that the X&#45;ray thermal&#10;reverberation model can fit both the continuum, UV/optical time lags, as well&#10;as the variance in these AGNs, for the same physical parameters. Our results&#10;suggest that the accretion disc is constant and that all the observed&#10;UV/optical variations, on timescales of days and up to a few weeks, can be&#10;fully explained by the variable X&#45;rays as they illuminate the accretion disc.&#10; | General | [Link](http://arxiv.org/abs/2409.10417v1) |&#10;| Local central limit theorem for Mallows measure | Alexey Bufetov, Kailun Chen | &#160;&#160;We study the statistics of the Mallows measure on permutations in the limit&#10;pioneered by Starr (2009). Our main result is the local central limit theorem&#10;for its height function. We also re&#45;derive versions of the law of large numbers&#10;and the large deviation principle, obtain the standard central limit theorem&#10;from the local one, and establish a multi&#45;point version of the local central&#10;limit theorem.&#10; | General | [Link](http://arxiv.org/abs/2409.10415v1) |&#10;| On interactive anisotropic walks in two dimensions generated from a&#10; &#160;three state opinion dynamics model | Surajit Saha, Parongama Sen | &#160;&#160;A system of interacting walkers on a two&#45;dimensional space where the dynamics&#10;of each walker are governed by the opinions of agents of a three&#45;state opinion&#10;dynamics model are considered. Such walks, inspired by Ising&#45;like models and&#10;opinions dynamics models, are usually considered in one&#45;dimensional virtual&#10;spaces. Here, the mapping is done in such a way that the walk is directed along&#10;the $y$ axis while it can move either way along the $x$ axis. We explore the&#10;properties of such walks as the parameter representing the noise in the opinion&#10;dynamics model, responsible for a continuous phase transition, is varied. The&#10;walk features show marked differences as the system crosses the critical point.&#10;The bivariate distribution of the displacements below the critical point is a&#10;modified biased Gaussian function of x and y which is symmetric about the X&#10;axis.&#10; &#160;The marginal probability distributions can be extracted and the scaling forms&#10;of different quantities, showing power law behaviour, are obtained. The&#10;directed nature of the walk is reflected in the marginal distributions as well&#10;as in the exponents.&#10; | General | [Link](http://arxiv.org/abs/2409.10413v1) |&#10;| A Large&#45;Scale Privacy Assessment of Android Third&#45;Party SDKs | Mark Huasong Meng, Chuan Yan, Yun Hao, Qing Zhang, Zeyu Wang, Kailong Wang, Sin Gee Teo, Guangdong Bai, Jin Song Dong | &#160;&#160;Third&#45;party Software Development Kits (SDKs) are widely adopted in Android&#10;app development, to effortlessly accelerate development pipelines and enhance&#10;app functionality. However, this convenience raises substantial concerns about&#10;unauthorized access to users&#39; privacy&#45;sensitive information, which could be&#10;further abused for illegitimate purposes like user tracking or monetization.&#10;Our study offers a targeted analysis of user privacy protection among Android&#10;third&#45;party SDKs, filling a critical gap in the Android software supply chain.&#10;It focuses on two aspects of their privacy practices, including data&#10;exfiltration and behavior&#45;policy compliance (or privacy compliance), utilizing&#10;techniques of taint analysis and large language models. It covers 158&#10;widely&#45;used SDKs from two key SDK release platforms, the official one and a&#10;large alternative one. From them, we identified 338 instances of privacy data&#10;exfiltration. On the privacy compliance, our study reveals that more than 30%&#10;of the examined SDKs fail to provide a privacy policy to disclose their data&#10;handling practices. Among those that provide privacy policies, 37% of them&#10;over&#45;collect user data, and 88% falsely claim access to sensitive data. We&#10;revisit the latest versions of the SDKs after 12 months. Our analysis&#10;demonstrates a persistent lack of improvement in these concerning trends. Based&#10;on our findings, we propose three actionable recommendations to mitigate the&#10;privacy leakage risks and enhance privacy protection for Android users. Our&#10;research not only serves as an urgent call for industry attention but also&#10;provides crucial insights for future regulatory interventions.&#10; | General | [Link](http://arxiv.org/abs/2409.10411v1) |&#10;| A point process approach for the classification of noisy calcium imaging&#10; &#160;data | Arianna Burzacchi, Nicoletta D&#39;Angelo, David Payares&#45;Garcia, Jorge Mateu | &#160;&#160;We study noisy calcium imaging data, with a focus on the classification of&#10;spike traces. As raw traces obscure the true temporal structure of neuron&#39;s&#10;activity, we performed a tuned filtering of the calcium concentration using two&#10;methods: a biophysical model and a kernel mapping. The former characterizes&#10;spike trains related to a particular triggering event, while the latter filters&#10;out the signal and refines the selection of the underlying neuronal response.&#10;Transitioning from traditional time series analysis to point process theory,&#10;the study explores spike&#45;time distance metrics and point pattern prototypes to&#10;describe repeated observations. We assume that the analyzed neuron&#39;s firing&#10;events, i.e. spike occurrences, are temporal point process events. In&#10;particular, the study aims to categorize 47 point patterns by depth, assuming&#10;the similarity of spike occurrences within specific depth categories. The&#10;results highlight the pivotal roles of depth and stimuli in discerning diverse&#10;temporal structures of neuron firing events, confirming the point process&#10;approach based on prototype analysis is largely useful in the classification of&#10;spike traces.&#10; | General | [Link](http://arxiv.org/abs/2409.10409v1) |&#10;| Variational closures for composite homogenised fluid flows | Theo Diamantakis, Ruiao Hu | &#160;&#160;The Stochastic Advection by Lie Transport is a variational formulation of&#10;stochastic fluid dynamics introduced to model the effects of unresolved scales,&#10;whilst preserving the geometric structure of ideal fluid flows. In this work,&#10;we show that the SALT equations can arise from the decomposition of the fluid&#10;flow map into its mean and fluctuating components. The fluctuating component is&#10;realised as a prescribed stochastic diffeomorphism that introduces stochastic&#10;transport into the system and we construct it using homogenisation theory. The&#10;dynamics of the mean component are derived from a variational principle&#10;utilising particular forms of variations that preserve the composite structure&#10;of the flow. Using a new variational principle, we show that SALT equations can&#10;arise from random Lagrangians and are equivalent to random coefficient PDEs. We&#10;also demonstrate how to modify the composite flow and the associated&#10;variational principle to derive models inspired by the Lagrangian Averaged&#10;Euler&#45;Poincare (LAEP) theory.&#10; | General | [Link](http://arxiv.org/abs/2409.10408v1) |&#10;| Bitcoin Transaction Behavior Modeling Based on Balance Data | Yu Zhang, Claudio Tessone | &#160;&#160;When analyzing Bitcoin users&#39; balance distribution, we observed that it&#10;follows a log&#45;normal pattern. Drawing parallels from the successful application&#10;of Gibrat&#39;s law of proportional growth in explaining city size and word&#10;frequency distributions, we tested whether the same principle could account for&#10;the log&#45;normal distribution in Bitcoin balances. However, our calculations&#10;revealed that the exponent parameters in both the drift and variance terms&#10;deviate slightly from one. This suggests that Gibrat&#39;s proportional growth rule&#10;alone does not fully explain the log&#45;normal distribution observed in Bitcoin&#10;users&#39; balances. During our exploration, we discovered an intriguing&#10;phenomenon: Bitcoin users tend to fall into two distinct categories based on&#10;their behavior, which we refer to as ``poor&quot; and ``wealthy&quot; users. Poor users,&#10;who initially purchase only a small amount of Bitcoin, tend to buy more&#10;bitcoins first and then sell out all their holdings gradually over time. The&#10;certainty of selling all their coins is higher and higher with time. In&#10;contrast, wealthy users, who acquire a large amount of Bitcoin from the start,&#10;tend to sell off their holdings over time. The speed at which they sell their&#10;bitcoins is lower and lower over time and they will hold at least a small part&#10;of their initial holdings at last. Interestingly, the wealthier the user, the&#10;larger the proportion of their balance and the higher the certainty they tend&#10;to sell. This research provided an interesting perspective to explore bitcoin&#10;users&#39; behaviors which may apply to other finance markets.&#10; | General | [Link](http://arxiv.org/abs/2409.10407v1) |&#10;| Stochastic Data&#45;Driven Predictive Control: Chance&#45;Constraint&#10; &#160;Satisfaction with Identified Multi&#45;step Predictors | Haldun Balim, Andrea Carron, Melanie N. Zeilinger, Johannes Khler | &#160;&#160;We propose a novel data&#45;driven stochastic model predictive control framework&#10;for uncertain linear systems with noisy output measurements. Our approach&#10;leverages multi&#45;step predictors to efficiently propagate uncertainty, ensuring&#10;chance constraint satisfaction with minimal conservatism. In particular, we&#10;present a strategy to identify multi&#45;step predictors and quantify the&#10;associated uncertainty using a surrogate (data&#45;driven) state space model. Then,&#10;we utilize the derived distribution to formulate a constraint tightening that&#10;ensures chance constraint satisfaction. A numerical example highlights the&#10;reduced conservatism of handling parametric uncertainty in the proposed method&#10;compared to state&#45;of&#45;the&#45;art solutions.&#10; | General | [Link](http://arxiv.org/abs/2409.10405v1) |&#10;| A Knowledge&#45;Enhanced Disease Diagnosis Method Based on Prompt Learning&#10; &#160;and BERT Integration | Zhang Zheng | &#160;&#160;This paper proposes a knowledge&#45;enhanced disease diagnosis method based on a&#10;prompt learning framework. The method retrieves structured knowledge from&#10;external knowledge graphs related to clinical cases, encodes it, and injects it&#10;into the prompt templates to enhance the language model&#39;s understanding and&#10;reasoning capabilities for the task.We conducted experiments on three public&#10;datasets: CHIP&#45;CTC, IMCS&#45;V2&#45;NER, and KUAKE&#45;QTR. The results show that the&#10;proposed method significantly outperforms existing models across multiple&#10;evaluation metrics, with an F1 score improvement of 2.4% on the CHIP&#45;CTC&#10;dataset, 3.1% on the IMCS&#45;V2&#45;NER dataset,and 4.2% on the KUAKE&#45;QTR dataset.&#10;Additionally,ablation studies confirmed the critical role of the knowledge&#10;injection module,as the removal of this module resulted in a significant drop&#10;in F1 score. The experimental results demonstrate that the proposed method not&#10;only effectively improves the accuracy of disease diagnosis but also enhances&#10;the interpretability of the predictions, providing more reliable support and&#10;evidence for clinical diagnosis.&#10; | General | [Link](http://arxiv.org/abs/2409.10403v1) |&#10;| A Statistical Equilibrium Approach to Adam Smith&#39;s Labor Theory of Value | Ellis Scharfenaker, Bruno Theodosio, Duncan K. Foley | &#160;&#160;Adam Smith&#39;s inquiry into the emergence and stability of the&#10;self&#45;organization of the division of labor in commodity production and exchange&#10;is considered using statistical equilibrium methods from statistical physics.&#10;We develop a statistical equilibrium model of the distribution of independent&#10;direct producers in a hub&#45;and&#45;spoke framework that predicts both the center of&#10;gravity of producers across lines of production as well as the endogenous&#10;fluctuations between lines of production that arise from Smith&#39;s concept of&#10;&quot;perfect liberty&quot;. The ergodic distribution of producers implies a long&#45;run&#10;balancing of &quot;advantages to disadvantages&quot; across lines of employment and&#10;gravitation of market prices around Smith&#39;s natural prices.&#10; | General | [Link](http://arxiv.org/abs/2409.10402v1) |&#10;| Hydrodynamic mechanism for stable spindle positioning in meiosis II&#10; &#160;oocytes | Weida Liao, Eric Lauga | &#160;&#160;Cytoplasmic streaming, the persistent flow of fluid inside a cell, induces&#10;intracellular transport, which plays a key role in fundamental biological&#10;processes. In meiosis II mouse oocytes (developing egg cells) awaiting&#10;fertilisation, the spindle, which is the protein structure responsible for&#10;dividing genetic material in a cell, must maintain its position near the cell&#10;cortex (the thin actin network bound to the cell membrane) for many hours.&#10;However, the cytoplasmic streaming that accompanies this stable positioning&#10;would intuitively appear to destabilise the spindle position. Here, through a&#10;combination of numerical and analytical modelling, we reveal a new,&#10;hydrodynamic mechanism for stable spindle positioning beneath the cortical cap.&#10;We show that this stability depends critically on the spindle size and the&#10;active driving from the cortex, and demonstrate that stable spindle positioning&#10;can result purely from a hydrodynamic suction force exerted on the spindle by&#10;the cytoplasmic flow. Our findings show that local fluid dynamic forces can be&#10;sufficient to stabilise the spindle, explaining robustness against&#10;perturbations not only perpendicular but also parallel to the cortex. Our&#10;results shed light on the importance of cytoplasmic streaming in mammalian&#10;meiosis.&#10; | General | [Link](http://arxiv.org/abs/2409.10401v1) |&#10;| Sherpa: An Open Source Python Fitting Package | Aneta Siemiginowska, Douglas Burke, Hans Moritz Gnther, Nicholas P. Lee, Warren McLaughlin, David A. Principe, Harlan Cheer, Antonella Fruscione, Omar Laurino, Jonathan McDowell, Marie Terrell | &#160;&#160;We present an overview of Sherpa, an open source Python project, and discuss&#10;its development history, broad design concepts and capabilities. Sherpa&#10;contains powerful tools for combining parametric models into complex&#10;expressions that can be fit to data using a variety of statistics and&#10;optimization methods. It is easily extensible to include user&#45;defined models,&#10;statistics, and optimization methods. It provides a high&#45;level User Interface&#10;for interactive data&#45;analysis, such as within a Jupyter notebook, and it can&#10;also be used as a library component, providing fitting and modeling&#10;capabilities to an application. We include a few examples of Sherpa&#10;applications to multiwavelength astronomical data. The code is available&#10;GitHub: https://github.com/sherpa/sherpa&#10; | General | [Link](http://arxiv.org/abs/2409.10400v1) |&#10;| Minimally coupled $$&#45;exponential inflation with an $R^2$ term in&#10; &#160;the Palatini formulation | Nilay Bostan, Rafid H. Dejrah | &#160;&#160;We focus on the inflationary predictions of $beta$&#45;exponential potential&#10;models, in which the inflaton is a representation of the field delineating the&#10;size of extra&#45;dimension. Since it offers a well&#45;motivated starting point for&#10;the study of physics at very high energies, we incorporate an $R^2$ term in the&#10;Palatini gravity. In addition, afterward the inflation, the inflaton oscillates&#10;about the minimum of the inflation potential, and reheats the universe. This&#10;occurs during the reheating phase, at which the inflaton decays into the&#10;standard model particles, which fill the universe. We extend our examination by&#10;considering the reheating effects on inflationary observables by employing the&#10;different scenarios of the reheat temperature. Supposing the standard thermal&#10;history after inflation, we display the inflationary predictions, $n_s, r,&#10;mathrm{d}n_s/mathrm{d}&#10;n k$ of $beta$&#45;exponential potential with minimal&#10;coupling in Palatini $R^2$ gravity. Also, different kinds of constraints from a&#10;variety of observations, such as BICEP/Keck, Planck 2018, as well as future&#10;possible detectable sensitivities that might be reached by CMB experiments:&#10;CMB&#45;S4 and LiteBIRD are taken into account in this work. We indicate that our&#10;results are consistent with both the latest data and the future sensitivity&#10;forecasts of LiteBIRD/Planck and CMB&#45;S4. Finally, the results in this study&#10;highlight the viability of our model even in the case of the existence of more&#10;stringent constraints expected from future achievable confidence level limits.&#10; | General | [Link](http://arxiv.org/abs/2409.10398v1) |&#10;| Quantifying Observational Projection Effects with a Simulation&#45;based hot&#10; &#160;CGM model | Soumya Shreeram, Johan Comparat, Andrea Merloni, Yi Zhang, Gabriele Ponti, Kirpal Nandra, John ZuHone, Ilaria Marini, Stephan Vladutescu&#45;Zopp, Paola Popesso, Ruediger Pakmor, Riccardo Seppi, Celine Peroux, Daniele Sorini | &#160;&#160;The hot phase of the circumgalactic medium (CGM) allows us to probe the&#10;inflow and outflow of gas within a galaxy, which is responsible for dictating&#10;the evolution of the galaxy. Studying the hot CGM sheds light on a better&#10;understanding of gas physics, which is crucial to inform and constrain&#10;simulation models. With the recent advances in observational measurements&#10;probing the hot CGM in X&#45;rays and tSZ, we have a new avenue for widening our&#10;knowledge of gas physics and feedback by exploiting the information from&#10;current/future observations. In this paper, we use the TNG300 hydrodynamical&#10;simulations to build a fully self&#45;consistent forward model for the hot CGM. We&#10;construct a lightcone and generate mock X&#45;ray observations. We quantify the&#10;projection effects, namely the locally correlated large&#45;scale structure in&#10;X&#45;rays and the effect due to satellite galaxies misclassified as centrals which&#10;affects the measured hot CGM galactocentric profiles in stacking experiments.&#10;We present an analytical model that describes the intrinsic X&#45;ray surface&#10;brightness profile across the stellar and halo mass bins. The increasing&#10;stellar mass bins result in decreasing values of $beta$, the exponent&#10;quantifying the slope of the intrinsic galactocentric profiles. We carry&#10;forward the current state&#45;of&#45;the&#45;art by also showing the impact of the locally&#10;correlated environment on the measured X&#45;ray surface brightness profiles. We&#10;also present, for the first time, the effect of misclassified centrals in&#10;stacking experiments for three stellar mass bins: $10^{10.5&#45;11} M_odot$,&#10;$10^{11&#45;11.2} M_odot$, and $10^{11.2&#45;11.5} M_odot$. We find that the&#10;contaminating effect of the misclassified centrals on the stacked profiles&#10;increases when the stellar mass decreases.&#10; | General | [Link](http://arxiv.org/abs/2409.10397v1) |&#10;| MOST: MR reconstruction Optimization for multiple downStream Tasks via&#10; &#160;continual learning | Hwihun Jeong, Se Young Chun, Jongho Lee | &#160;&#160;Deep learning&#45;based Magnetic Resonance (MR) reconstruction methods have&#10;focused on generating high&#45;quality images but they often overlook the impact on&#10;downstream tasks (e.g., segmentation) that utilize the reconstructed images.&#10;Cascading separately trained reconstruction network and downstream task network&#10;has been shown to introduce performance degradation due to error propagation&#10;and domain gaps between training datasets. To mitigate this issue, downstream&#10;task&#45;oriented reconstruction optimization has been proposed for a single&#10;downstream task. Expanding this optimization to multi&#45;task scenarios is not&#10;straightforward. In this work, we extended this optimization to sequentially&#10;introduced multiple downstream tasks and demonstrated that a single MR&#10;reconstruction network can be optimized for multiple downstream tasks by&#10;deploying continual learning (MOST). MOST integrated techniques from&#10;replay&#45;based continual learning and image&#45;guided loss to overcome catastrophic&#10;forgetting. Comparative experiments demonstrated that MOST outperformed a&#10;reconstruction network without finetuning, a reconstruction network with&#10;na&quot;ive finetuning, and conventional continual learning methods. This&#10;advancement empowers the application of a single MR reconstruction network for&#10;multiple downstream tasks. The source code is available at:&#10;https://github.com/SNU&#45;LIST/MOST&#10; | General | [Link](http://arxiv.org/abs/2409.10394v1) |&#10;| Multicopy quantum state teleportation with application to storage and&#10; &#160;retrieval of quantum programs | Frdric Grosshans, Micha Horodecki, Mio Murao, Tomasz Mynik, Marco Tlio Quintino, Micha Studziski, Satoshi Yoshida | &#160;&#160;This work considers a teleportation task for Alice and Bob in a scenario&#10;where Bob cannot perform corrections. In particular, we analyse the task of&#10;textit{multicopy state teleportation}, where Alice has $k$ identical copies of&#10;an arbitrary unknown $d$&#45;dimensional qudit state $vertpsi&#13;angle$ to teleport&#10;a single copy of $vertpsi&#13;angle$ to Bob using a maximally entangled&#10;two&#45;qudit state shared between Alice and Bob without Bob&#39;s correction. Alice&#10;may perform a joint measurement on her half of the entangled state and the $k$&#10;copies of $vertpsi&#13;angle$. We prove that the maximal probability of success&#10;for teleporting the exact state $vertpsi&#13;angle$ to Bob is&#10;$p(d,k)=frac{k}{d(k&#45;1+d)}$ and present an explicit protocol to attain this&#10;performance. Then, by utilising $k$ copies of an arbitrary target state&#10;$vertpsi&#13;angle$, we show how the multicopy state teleportation protocol can&#10;be employed to enhance the success probability of storage and retrieval of&#10;quantum programs, which aims to universally retrieve the action of an arbitrary&#10;quantum channel that is stored in a state. Our proofs make use of group&#10;representation theory methods, which may find applications beyond the problems&#10;addressed in this work.&#10; | General | [Link](http://arxiv.org/abs/2409.10393v1) |&#10;| TPFL: Tsetlin&#45;Personalized Federated Learning with Confidence&#45;Based&#10; &#160;Clustering | Rasoul Jafari Gohari, Laya Aliahmadipour, Ezat Valipour | &#160;&#160;The world of Machine Learning (ML) has witnessed rapid changes in terms of&#10;new models and ways to process users data. The majority of work that has been&#10;done is focused on Deep Learning (DL) based approaches. However, with the&#10;emergence of new algorithms such as the Tsetlin Machine (TM) algorithm, there&#10;is growing interest in exploring alternative approaches that may offer unique&#10;advantages in certain domains or applications. One of these domains is&#10;Federated Learning (FL), in which users privacy is of utmost importance. Due to&#10;its novelty, FL has seen a surge in the incorporation of personalization&#10;techniques to enhance model accuracy while maintaining user privacy under&#10;personalized conditions. In this work, we propose a novel approach dubbed TPFL:&#10;Tsetlin&#45;Personalized Federated Learning, in which models are grouped into&#10;clusters based on their confidence towards a specific class. In this way,&#10;clustering can benefit from two key advantages. Firstly, clients share only&#10;what they are confident about, resulting in the elimination of wrongful weight&#10;aggregation among clients whose data for a specific class may have not been&#10;enough during the training. This phenomenon is prevalent when the data are&#10;non&#45;Independent and Identically Distributed (non&#45;IID). Secondly, by sharing&#10;only weights towards a specific class, communication cost is substantially&#10;reduced, making TPLF efficient in terms of both accuracy and communication&#10;cost. The results of TPFL demonstrated the highest accuracy on three different&#10;datasets; namely MNIST, FashionMNIST and FEMNIST.&#10; | General | [Link](http://arxiv.org/abs/2409.10392v1) |&#10;| Prompt&#45;and&#45;Transfer: Dynamic Class&#45;aware Enhancement for Few&#45;shot&#10; &#160;Segmentation | Hanbo Bi, Yingchao Feng, Wenhui Diao, Peijin Wang, Yongqiang Mao, Kun Fu, Hongqi Wang, Xian Sun | &#160;&#160;For more efficient generalization to unseen domains (classes), most Few&#45;shot&#10;Segmentation (FSS) would directly exploit pre&#45;trained encoders and only&#10;fine&#45;tune the decoder, especially in the current era of large models. However,&#10;such fixed feature encoders tend to be class&#45;agnostic, inevitably activating&#10;objects that are irrelevant to the target class. In contrast, humans can&#10;effortlessly focus on specific objects in the line of sight. This paper mimics&#10;the visual perception pattern of human beings and proposes a novel and powerful&#10;prompt&#45;driven scheme, called ``Prompt and Transfer&quot; (PAT), which constructs a&#10;dynamic class&#45;aware prompting paradigm to tune the encoder for focusing on the&#10;interested object (target class) in the current task. Three key points are&#10;elaborated to enhance the prompting: 1) Cross&#45;modal linguistic information is&#10;introduced to initialize prompts for each task. 2) Semantic Prompt Transfer&#10;(SPT) that precisely transfers the class&#45;specific semantics within the images&#10;to prompts. 3) Part Mask Generator (PMG) that works in conjunction with SPT to&#10;adaptively generate different but complementary part prompts for different&#10;individuals. Surprisingly, PAT achieves competitive performance on 4 different&#10;tasks including standard FSS, Cross&#45;domain FSS (e.g., CV, medical, and remote&#10;sensing domains), Weak&#45;label FSS, and Zero&#45;shot Segmentation, setting new&#10;state&#45;of&#45;the&#45;arts on 11 benchmarks.&#10; | General | [Link](http://arxiv.org/abs/2409.10389v1) |&#10;| Revising the Structure of Recurrent Neural Networks to Eliminate&#10; &#160;Numerical Derivatives in Forming Physics Informed Loss Terms with Respect to&#10; &#160;Time | Mahyar Jahani&#45;nasab, Mohamad Ali Bijarchi | &#160;&#160;Solving unsteady partial differential equations (PDEs) using recurrent neural&#10;networks (RNNs) typically requires numerical derivatives between each block of&#10;the RNN to form the physics informed loss function. However, this introduces&#10;the complexities of numerical derivatives into the training process of these&#10;models. In this study, we propose modifying the structure of the traditional&#10;RNN to enable the prediction of each block over a time interval, making it&#10;possible to calculate the derivative of the output with respect to time using&#10;the backpropagation algorithm. To achieve this, the time intervals of these&#10;blocks are overlapped, defining a mutual loss function between them.&#10;Additionally, the employment of conditional hidden states enables us to achieve&#10;a unique solution for each block. The forget factor is utilized to control the&#10;influence of the conditional hidden state on the prediction of the subsequent&#10;block. This new model, termed the Mutual Interval RNN (MI&#45;RNN), is applied to&#10;solve three different benchmarks: the Burgers equation, unsteady heat&#10;conduction in an irregular domain, and the Green vortex problem. Our results&#10;demonstrate that MI&#45;RNN can find the exact solution more accurately compared to&#10;existing RNN models. For instance, in the second problem, MI&#45;RNN achieved one&#10;order of magnitude less relative error compared to the RNN model with numerical&#10;derivatives.&#10; | General | [Link](http://arxiv.org/abs/2409.10388v1) |&#10;| Sharp decay rate for eigenfunctions of perturbed periodic Schrdinger&#10; &#160;operators | Wencai Liu, Rodrigo Matos, John N. Treuer | &#160;&#160;This paper investigates uniqueness results for perturbed periodic&#10;Schr&quot;odinger operators on $mathbb{Z}^d$. Specifically, we consider operators&#10;of the form $H = &#45;Delta + V + v$, where $Delta$ is the discrete Laplacian,&#10;$V: mathbb{Z}^d &#13;ightarrow mathbb{R}$ is a periodic potential, and $v:&#10;mathbb{Z}^d &#13;ightarrow mathbb{C}$ represents a decaying impurity. We&#10;establish quantitative conditions under which the equation $&#45;Delta u + V u + v&#10;u = &#10;ambda u$, for $&#10;ambda in mathbb{C}$, admits only the trivial solution&#10;$u equiv 0$. Key applications include the absence of embedded eigenvalues for&#10;operators with impurities decaying faster than any exponential function and the&#10;determination of sharp decay rates for eigenfunctions. Our findings extend&#10;previous works by providing precise decay conditions for impurities and&#10;analyzing different spectral regimes of $&#10;ambda$.&#10; | General | [Link](http://arxiv.org/abs/2409.10387v1) |&#10;| Mamba&#45;ST: State Space Model for Efficient Style Transfer | Filippo Botti, Alex Ergasti, Leonardo Rossi, Tomaso Fontanini, Claudio Ferrari, Massimo Bertozzi, Andrea Prati | &#160;&#160;The goal of style transfer is, given a content image and a style source,&#10;generating a new image preserving the content but with the artistic&#10;representation of the style source. Most of the state&#45;of&#45;the&#45;art architectures&#10;use transformers or diffusion&#45;based models to perform this task, despite the&#10;heavy computational burden that they require. In particular, transformers use&#10;self&#45; and cross&#45;attention layers which have large memory footprint, while&#10;diffusion models require high inference time. To overcome the above, this paper&#10;explores a novel design of Mamba, an emergent State&#45;Space Model (SSM), called&#10;Mamba&#45;ST, to perform style transfer. To do so, we adapt Mamba linear equation&#10;to simulate the behavior of cross&#45;attention layers, which are able to combine&#10;two separate embeddings into a single output, but drastically reducing memory&#10;usage and time complexity. We modified the Mamba&#39;s inner equations so to accept&#10;inputs from, and combine, two separate data streams. To the best of our&#10;knowledge, this is the first attempt to adapt the equations of SSMs to a vision&#10;task like style transfer without requiring any other module like&#10;cross&#45;attention or custom normalization layers. An extensive set of experiments&#10;demonstrates the superiority and efficiency of our method in performing style&#10;transfer compared to transformers and diffusion models. Results show improved&#10;quality in terms of both ArtFID and FID metrics. Code is available at&#10;https://github.com/FilippoBotti/MambaST.&#10; | General | [Link](http://arxiv.org/abs/2409.10385v1) |&#10;| Performance&#45;Portable Numerical Relativity with AthenaK | Hengrui Zhu, Jacob Fields, Francesco Zappa, David Radice, James Stone, Alireza Rashti, William Cook, Sebastiano Bernuzzi, Boris Daszuta | &#160;&#160;We present the numerical relativity module within AthenaK, an open source&#10;performance&#45;portable astrophysics code designed for exascale computing&#10;applications. This module employs the Z4c formulation to solve the Einstein&#10;equations. We demonstrate its accuracy through a series of standard numerical&#10;relativity tests, including convergence of the gravitational waveform from&#10;binary black hole coalescence. Furthermore, we conduct scaling tests on OLCF&#10;Frontier and NERSC Perlmutter, where AthenaK exhibits excellent weak scaling&#10;efficiency of 80% on up to 65,536 AMD MI250X GPUs on Frontier (relative to 4&#10;GPUs) and strong scaling efficiencies of 84% and 77% on AMD MI250X and NVIDIA&#10;A100 GPUs on Frontier and Perlmutter respectively. Additionally, we observe a&#10;significant performance boost, with two orders of magnitude speedup ($gtrsim&#10;200times$) on a GPU compared to a single CPU core, affirming that AthenaK is&#10;well&#45;suited for exascale computing, thereby expanding the potential for&#10;breakthroughs in numerical relativity research.&#10; | General | [Link](http://arxiv.org/abs/2409.10383v1) |&#10;| J&#45;UBIK: The JAX&#45;accelerated Universal Bayesian Imaging Kit | Vincent Eberle, Matteo Guardiani, Margret Westerkamp, Philipp Frank, Julian Rstig, Julia Stadler, Torsten A. Enlin | &#160;&#160;Many advances in astronomy and astrophysics originate from accurate images of&#10;the sky emission across multiple wavelengths. This often requires&#10;reconstructing spatially and spectrally correlated signals detected from&#10;multiple instruments. To facilitate the high&#45;fidelity imaging of these signals,&#10;we introduce the universal Bayesian imaging kit (UBIK). Specifically, we&#10;present J&#45;UBIK, a flexible and modular implementation leveraging the&#10;JAX&#45;accelerated NIFTy.re software as its backend. J&#45;UBIK streamlines the&#10;implementation of the key Bayesian inference components, providing for all the&#10;necessary steps of Bayesian imaging pipelines. First, it provides adaptable&#10;prior models for different sky realizations. Second, it includes likelihood&#10;models tailored to specific instruments. So far, the package includes three&#10;instruments: Chandra and eROSITA for X&#45;ray observations, and the James Webb&#10;Space Telescope (JWST) for the near&#45; and mid&#45;infrared. The aim is to expand&#10;this set in the future. Third, these models can be integrated with various&#10;inference and optimization schemes, such as maximum a posteriori estimation and&#10;variational inference. Explicit demos show how to integrate the individual&#10;modules into a full analysis pipeline. Overall, J&#45;UBIK enables efficient&#10;generation of high&#45;fidelity images via Bayesian pipelines that can be tailored&#10;to specific research objectives.&#10; | General | [Link](http://arxiv.org/abs/2409.10381v1) |&#10;| Thermolectricity in irradiated bilayer graphene flakes | Cynthia Ihuoma Osuala, Tanu Choudhary, Raju K. Biswas, Sudin Ganguly, Chunlei Qu, Santanu K. Maiti | &#160;&#160;We present a comprehensive study on enhancing the thermoelectric (TE)&#10;performance of bilayer graphene (BLG) through irradiation with arbitrarily&#10;polarized light, focusing on $AA$&#45; and $AB$&#45;stacked configurations with zigzag&#10;edges. Utilizing a combination of tight&#45;binding theory and density functional&#10;theory (DFT), we systematically analyze the impact of light irradiation on&#10;electronic and phononic transport properties. Light irradiation alters the&#10;electronic hopping parameters, creating an asymmetric transmission function,&#10;which significantly increases the Seebeck coefficient, thereby boosting the&#10;overall {it figure of merit} (FOM). For the phononic contribution, DFT&#10;calculations reveal that $AB$&#45;stacked BLG exhibits lower lattice thermal&#10;conductivity compared to $AA$&#45;stacked, attributed to enhanced anharmonic&#10;scattering and phonon group velocity. The combined analysis shows that FOM&#10;exceeds unity in both stacking types, with notable improvements near the&#10;irradiation&#45;induced gap. Additionally, we explore the dependence of FOM on the&#10;system dimensions and temperature, demonstrating that light&#45;irradiated BLG&#10;holds great promise for efficient thermoelectric energy conversion and waste&#10;heat recovery. Our results show favorable responses over a wide range of&#10;irradiation parameters. These findings provide crucial insights into optimizing&#10;BLG for advanced TE applications through light&#45;induced modifications.&#10; | General | [Link](http://arxiv.org/abs/2409.10380v1) |&#10;| Leveraging Joint Spectral and Spatial Learning with MAMBA for&#10; &#160;Multichannel Speech Enhancement | Wenze Ren, Haibin Wu, Yi&#45;Cheng Lin, Xuanjun Chen, Rong Chao, Kuo&#45;Hsuan Hung, You&#45;Jin Li, Wen&#45;Yuan Ting, Hsin&#45;Min Wang, Yu Tsao | &#160;&#160;In multichannel speech enhancement, effectively capturing spatial and&#10;spectral information across different microphones is crucial for noise&#10;reduction. Traditional methods, such as CNN or LSTM, attempt to model the&#10;temporal dynamics of full&#45;band and sub&#45;band spectral and spatial features.&#10;However, these approaches face limitations in fully modeling complex temporal&#10;dependencies, especially in dynamic acoustic environments. To overcome these&#10;challenges, we modify the current advanced model McNet by introducing an&#10;improved version of Mamba, a state&#45;space model, and further propose MCMamba.&#10;MCMamba has been completely reengineered to integrate full&#45;band and narrow&#45;band&#10;spatial information with sub&#45;band and full&#45;band spectral features, providing a&#10;more comprehensive approach to modeling spatial and spectral information. Our&#10;experimental results demonstrate that MCMamba significantly improves the&#10;modeling of spatial and spectral features in multichannel speech enhancement,&#10;outperforming McNet and achieving state&#45;of&#45;the&#45;art performance on the CHiME&#45;3&#10;dataset. Additionally, we find that Mamba performs exceptionally well in&#10;modeling spectral information.&#10; | General | [Link](http://arxiv.org/abs/2409.10376v1) |&#10;| Nonlinear Causality in Brain Networks: With Application to Motor Imagery&#10; &#160;vs Execution | Sipan Aslan, Hernando Ombao | &#160;&#160;One fundamental challenge of data&#45;driven analysis in neuroscience is modeling&#10;causal interactions and exploring the connectivity of nodes in a brain network.&#10;Various statistical methods, relying on various perspectives and employing&#10;different data modalities, are being developed to examine and comprehend the&#10;underlying causal structures inherent to brain dynamics. This study introduces&#10;a novel statistical approach, TAR4C, to dissect causal interactions in&#10;multichannel EEG recordings. TAR4C uses the threshold autoregressive model to&#10;describe the causal interaction between nodes or clusters of nodes in a brain&#10;network. The perspective involves testing whether one node, which may represent&#10;a brain region, can control the dynamics of the other. The node that has such&#10;an impact on the other is called a threshold variable and can be classified as&#10;a causative because its functionality is the leading source operating as an&#10;instantaneous switching mechanism that regulates the time&#45;varying&#10;autoregressive structure of the other. This statistical concept is commonly&#10;referred to as threshold non&#45;linearity. Once threshold non&#45;linearity has been&#10;verified between a pair of nodes, the subsequent essential facet of TAR&#10;modeling is to assess the predictive ability of the causal node for the current&#10;activity on the other and represent causal interactions in autoregressive&#10;terms. This predictive ability is what underlies Granger causality. The TAR4C&#10;approach can discover non&#45;linear and time&#45;dependent causal interactions without&#10;negating the G&#45;causality perspective. The efficacy of the proposed approach is&#10;exemplified by analyzing the EEG signals recorded during the motor&#10;movement/imagery experiment. The similarities and differences between the&#10;causal interactions manifesting during the execution and the imagery of a given&#10;motor movement are demonstrated by analyzing EEG recordings from multiple&#10;subjects.&#10; | General | [Link](http://arxiv.org/abs/2409.10374v1) |&#10;| Instigating Cooperation among LLM Agents Using Adaptive Information&#10; &#160;Modulation | Qiliang Chen, &#160;Alireza, &#160;Ilami, Nunzio Lore, Babak Heydari | &#160;&#160;This paper introduces a novel framework combining LLM agents as proxies for&#10;human strategic behavior with reinforcement learning (RL) to engage these&#10;agents in evolving strategic interactions within team environments. Our&#10;approach extends traditional agent&#45;based simulations by using strategic LLM&#10;agents (SLA) and introducing dynamic and adaptive governance through a&#10;pro&#45;social promoting RL agent (PPA) that modulates information access across&#10;agents in a network, optimizing social welfare and promoting pro&#45;social&#10;behavior. Through validation in iterative games, including the prisoner&#10;dilemma, we demonstrate that SLA agents exhibit nuanced strategic adaptations.&#10;The PPA agent effectively learns to adjust information transparency, resulting&#10;in enhanced cooperation rates. This framework offers significant insights into&#10;AI&#45;mediated social dynamics, contributing to the deployment of AI in real&#45;world&#10;team settings.&#10; | General | [Link](http://arxiv.org/abs/2409.10372v1) |&#10;| Learning Gentle Grasping from Human&#45;Free Force Control Demonstration | Mingxuan Li, Lunwei Zhang, Tiemin Li, Yao Jiang | &#160;&#160;Humans can steadily and gently grasp unfamiliar objects based on tactile&#10;perception. Robots still face challenges in achieving similar performance due&#10;to the difficulty of learning accurate grasp&#45;force predictions and force&#10;control strategies that can be generalized from limited data. In this article,&#10;we propose an approach for learning grasping from ideal force control&#10;demonstrations, to achieve similar performance of human hands with limited data&#10;size. Our approach utilizes objects with known contact characteristics to&#10;automatically generate reference force curves without human demonstrations. In&#10;addition, we design the dual convolutional neural networks (Dual&#45;CNN)&#10;architecture which incorporating a physics&#45;based mechanics module for learning&#10;target grasping force predictions from demonstrations. The described method can&#10;be effectively applied in vision&#45;based tactile sensors and enables gentle and&#10;stable grasping of objects from the ground. The described prediction model and&#10;grasping strategy were validated in offline evaluations and online experiments,&#10;and the accuracy and generalizability were demonstrated.&#10; | General | [Link](http://arxiv.org/abs/2409.10371v1) |&#10;| Uncovering the Mechanism of Hepatotoxiciy of PFAS Targeting L&#45;FABP Using&#10; &#160;GCN and Computational Modeling | Lucas Jividen, Tibo Duran, Xi&#45;Zhi Niu, Jun Bai | &#160;&#160;Per&#45; and polyfluoroalkyl substances (PFAS) are persistent environmental&#10;pollutants with known toxicity and bioaccumulation issues. Their widespread&#10;industrial use and resistance to degradation have led to global environmental&#10;contamination and significant health concerns. While a minority of PFAS have&#10;been extensively studied, the toxicity of many PFAS remains poorly understood&#10;due to limited direct toxicological data. This study advances the predictive&#10;modeling of PFAS toxicity by combining semi&#45;supervised graph convolutional&#10;networks (GCNs) with molecular descriptors and fingerprints. We propose a novel&#10;approach to enhance the prediction of PFAS binding affinities by isolating&#10;molecular fingerprints to construct graphs where then descriptors are set as&#10;the node features. This approach specifically captures the structural,&#10;physicochemical, and topological features of PFAS without overfitting due to an&#10;abundance of features. Unsupervised clustering then identifies representative&#10;compounds for detailed binding studies. Our results provide a more accurate&#10;ability to estimate PFAS hepatotoxicity to provide guidance in chemical&#10;discovery of new PFAS and the development of new safety regulations.&#10; | General | [Link](http://arxiv.org/abs/2409.10370v1) |&#10;| Stochastic Control of UAVs: An Optimal Tradeoff between Performance,&#10; &#160;Flight Smoothness and Control Effort | George Rapakoulias, Panagiotis Tsiotras | &#160;&#160;Safe and accurate control of unmanned aerial vehicles in the presence of&#10;winds is a challenging control problem due to the hard&#45;to&#45;model and highly&#10;stochastic nature of the disturbance forces acting upon the vehicle. To meet&#10;performance constraints, state&#45;of&#45;the&#45;art control methods such as Incremental&#10;Nonlinear Dynamic Inversion (INDI) or other adaptive control techniques require&#10;high control gains to mitigate the effects of uncertainty entering the system.&#10;While achieving good tracking performance, IDNI requires excessive control&#10;effort, results in high actuator strain, and reduced flight smoothness due to&#10;constant and aggressive corrective actions commanded by the controller. In this&#10;paper, we propose a novel control architecture that allows the user to&#10;systematically address the trade&#45;off between high authority control and&#10;performance constraint satisfaction. Our approach consists of two parts. To&#10;cancel out biases introduced by unmodelled aerodynamic effects we propose a&#10;hybrid, model&#45;based disturbance force estimator augmented with a neural&#10;network, that can adapt to external wind conditions using a Kalman Filter. We&#10;then utilize state&#45;of&#45;the&#45;art results from Covariance Steering theory, which&#10;offers a principled way of controlling the uncertainty of the tracking error&#10;dynamics. We first analyze the properties of the combined system and then&#10;provide extensive experimental results to verify the advantages of the proposed&#10;approach over existing methods&#10; | General | [Link](http://arxiv.org/abs/2409.10369v1) |&#10;| Integrated nowcasting of convective precipitation with Transformer&#45;based&#10; &#160;models using multi&#45;source data | alar Kk, Aitor Atencia, Markus Dabernig | &#160;&#160;Precipitation nowcasting is crucial for mitigating the impacts of severe&#10;weather events and supporting daily activities. Conventional models&#10;predominantly relying on radar data have limited performance in predicting&#10;cases with complex temporal features such as convection initiation,&#10;highlighting the need to integrate data from other sources for more&#10;comprehensive nowcasting. Unlike physics&#45;based models, machine learning&#10;(ML)&#45;based models offer promising solutions for efficiently integrating large&#10;volumes of diverse data. We present EF4INCA, a spatiotemporal Transformer model&#10;for precipitation nowcasting that integrates satellite&#45; and ground&#45;based&#10;observations with numerical weather prediction outputs. EF4INCA provides&#10;high&#45;resolution forecasts over Austria, accurately predicting the location and&#10;shape of precipitation fields with a spatial resolution of 1 kilometre and a&#10;temporal resolution of 5 minutes, up to 90 minutes ahead. Our evaluation shows&#10;that EF4INCA outperforms conventional nowcasting models, including the&#10;operational model of Austria, particularly in scenarios with complex temporal&#10;features such as convective initiation and rapid weather changes. EF4INCA&#10;maintains higher accuracy in location forecasting but generates smoother fields&#10;at later prediction times compared to traditional models. Interpretation of our&#10;model showed that precipitation products and SEVIRI infrared channels CH7 and&#10;CH9 are the most important data streams. These results underscore the&#10;importance of combining data from different domains, including physics&#45;based&#10;model products, with ML approaches. Our study highlights the robustness of&#10;EF4INCA and its potential for improved precipitation nowcasting. We provide&#10;access to our code repository, model weights, and the dataset curated for&#10;benchmarking, facilitating further development and application.&#10; | General | [Link](http://arxiv.org/abs/2409.10367v1) |&#10;&#10;">
<text font-weight="bold" text-anchor="middle" x="2645" y="-567.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922637147216_5 -->
<g id="node71" class="node">
<title>139922637147216_5</title>
<ellipse fill="#edb7ad" stroke="#ba847a" stroke-width="3" cx="2794" cy="-528" rx="64.99" ry="18"/>
<text text-anchor="middle" x="2794" y="-524.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Scientist (5)</text>
</g>
<!-- 139922752308304_6&#45;&gt;139922637147216_5 -->
<g id="edge79" class="edge">
<title>139922752308304_6&#45;&gt;139922637147216_5</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M2377.11,-611.24C2481.96,-607.19 2649.32,-597.94 2709,-579 2728.64,-572.77 2748.61,-561.34 2764.25,-550.98"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2766.64,-553.59 2772.92,-545.05 2762.69,-547.81 2766.64,-553.59"/>
<g id="a_edge79&#45;label"><a xlink:title="exitcode: 0 (execution succeeded)&#10;Code output: &#10;| Title | Authors | Abstract | Domain | Source URL |&#10;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#10;| The VIRUS&#45;dE Survey I: Stars in dwarf elliptical galaxies &#45; 3D dynamics&#10; &#160;and radially resolved stellar initial mass functions | Mathias Lipka, Jens Thomas, Roberto Saglia, Ralf Bender, Maximilian Fabricius, Gary J. Hill, Matthias Kluge, Martin Landriau, Ximena Mazzalay, Eva Noyola, Taniya Parikh, Jan Snigula | &#160;&#160;We analyse the stellar structure of a sample of dwarf ellipticals (dE)&#10;inhabiting various environments within the Virgo cluster. Integral&#45;field&#10;observations with a high spectral resolution allow us to robustly determine&#10;their low velocity dispersions ($sim25$ km s$^{&#45;1}$) and higher&#45;order&#10;kinematic moments out to the half&#45;light radius. We find the dEs exhibit a&#10;diversity in ages with the younger dEs being less enhanced than the older,&#10;suggesting a complex star formation history for those dEs that recently entered&#10;Virgo while others have been quenched shortly after reionization.&#10;Orbit&#45;superposition modeling allowed us to recover viewing angles, stellar&#10;mass&#45;to&#45;light ratios (with gradients), as well as the intrinsic orbit&#10;structure. We find that the angular momentum of the dEs is strongly suppressed&#10;compared to ordinary early&#45;type galaxies and correlates with the environment.&#10;Flattened dEs are so because of a suppressed kinetic energy perpendicular to&#10;their equatorial plane. Combining population and dynamical modeling results, we&#10;find an age&#45;dependent stellar initial mass function (IMF) or, alternatively,&#10;evidence for a more extended star formation history for those galaxies that&#10;have had higher initial mass and/or inhabited lower density environments. dEs&#10;appear to have a spatially homogeneous stellar structure but the state they&#10;were `frozen&#39; in as they stopped forming stars varies dramatically according to&#10;their initial conditions.&#10; | General | [Link](http://arxiv.org/abs/2409.10518v1) |&#10;| RetrievalAttention: Accelerating Long&#45;Context LLM Inference via Vector&#10; &#160;Retrieval | Di Liu, Meng Chen, Baotong Lu, Huiqiang Jiang, Zhenhua Han, Qianxi Zhang, Qi Chen, Chengruidong Zhang, Bailu Ding, Kai Zhang, Chen Chen, Fan Yang, Yuqing Yang, Lili Qiu | &#160;&#160;Transformer&#45;based large Language Models (LLMs) become increasingly important&#10;in various domains. However, the quadratic time complexity of attention&#10;operation poses a significant challenge for scaling to longer contexts due to&#10;the extremely high inference latency and GPU memory consumption for caching&#10;key&#45;value (KV) vectors. This paper proposes RetrievalAttention, a training&#45;free&#10;approach to accelerate attention computation. To leverage the dynamic sparse&#10;property of attention, RetrievalAttention builds approximate nearest neighbor&#10;search (ANNS) indexes upon KV vectors in CPU memory and retrieves the most&#10;relevant ones via vector search during generation. Due to the&#10;out&#45;of&#45;distribution (OOD) between query vectors and key vectors, off&#45;the&#45;shelf&#10;ANNS indexes still need to scan O(N) (usually 30% of all keys) data for&#10;accurate retrieval, which fails to exploit the high sparsity.&#10;RetrievalAttention first identifies the OOD challenge of ANNS&#45;based attention,&#10;and addresses it via an attention&#45;aware vector search algorithm that can adapt&#10;to queries and only access 1&#45;&#45;3% of data, thus achieving a sub&#45;linear time&#10;complexity. RetrievalAttention greatly reduces the inference cost of&#10;long&#45;context LLM with much lower GPU memory requirements while maintaining the&#10;model accuracy. Especially, RetrievalAttention only needs 16GB GPU memory for&#10;serving 128K tokens in LLMs with 8B parameters, which is capable of generating&#10;one token in 0.188 seconds on a single NVIDIA RTX4090 (24GB).&#10; | General | [Link](http://arxiv.org/abs/2409.10516v1) |&#10;| An Efficient Self&#45;Learning Framework For Interactive Spoken Dialog&#10; &#160;Systems | Hitesh Tulsiani, David M. Chan, Shalini Ghosh, Garima Lalwani, Prabhat Pandey, Ankish Bansal, Sri Garimella, Ariya Rastrow, Bjrn Hoffmeister | &#160;&#160;Dialog systems, such as voice assistants, are expected to engage with users&#10;in complex, evolving conversations. Unfortunately, traditional automatic speech&#10;recognition (ASR) systems deployed in such applications are usually trained to&#10;recognize each turn independently and lack the ability to adapt to the&#10;conversational context or incorporate user feedback. In this work, we introduce&#10;a general framework for ASR in dialog systems that can go beyond learning from&#10;single&#45;turn utterances and learn over time how to adapt to both explicit&#10;supervision and implicit user feedback present in multi&#45;turn conversations. We&#10;accomplish that by leveraging advances in student&#45;teacher learning and&#10;context&#45;aware dialog processing, and designing contrastive self&#45;supervision&#10;approaches with Ohm, a new online hard&#45;negative mining approach. We show that&#10;leveraging our new framework compared to traditional training leads to relative&#10;WER reductions of close to 10% in real&#45;world dialog systems, and up to 26% on&#10;public synthetic data.&#10; | General | [Link](http://arxiv.org/abs/2409.10515v1) |&#10;| Constraints on axions from patchy screening of the cosmic microwave&#10; &#160;background | Samuel Goldstein, Fiona McCarthy, Cristina Mondino, J. Colin Hill, Junwu Huang, Matthew C. Johnson | &#160;&#160;The resonant conversion of cosmic microwave background (CMB) photons into&#10;axions within large&#45;scale structure induces an anisotropic spectral distortion&#10;in CMB temperature maps. Applying state&#45;of&#45;the&#45;art foreground cleaning&#10;techniques to $textit{Planck}$ CMB observations, we construct maps of&#10;axion&#45;induced &quot;patchy screening&quot; of the CMB. We cross&#45;correlate these maps with&#10;data from the $textit{unWISE}$ galaxy survey and find no evidence of axions.&#10;We constrain the axion&#45;photon coupling, $g_{agammagamma} &#10;esssim 2 times&#10;10^{&#45;12}~{&#13;m GeV}^{&#45;1}$, at the 95% confidence level for axion masses in the&#10;range $10^{&#45;13}~{&#13;m eV} &#10;esssim m_a &#10;esssim 10^{&#45;12}~{&#13;m eV}$. These&#10;constraints are competitive with the tightest astrophysical axion limits in&#10;this mass range and are inferred from robust population&#45;level statistics, which&#10;makes them complementary to existing searches that rely on modeling of&#10;individual systems.&#10; | General | [Link](http://arxiv.org/abs/2409.10514v1) |&#10;| Weak Superimposed Codes of Improved Asymptotic Rate and Their Randomized&#10; &#160;Construction | Yu Tsunoda, Yuichiro Fujiwara | &#160;&#160;Weak superimposed codes are combinatorial structures related closely to&#10;generalized cover&#45;free families, superimposed codes, and disjunct matrices in&#10;that they are only required to satisfy similar but less stringent conditions.&#10;This class of codes may also be seen as a stricter variant of what are known as&#10;locally thin families in combinatorics. Originally, weak superimposed codes&#10;were introduced in the context of multimedia content protection against illegal&#10;distribution of copies under the assumption that a coalition of malicious users&#10;may employ the averaging attack with adversarial noise. As in many other kinds&#10;of codes in information theory, it is of interest and importance in the study&#10;of weak superimposed codes to find the highest achievable rate in the&#10;asymptotic regime and give an efficient construction that produces an infinite&#10;sequence of codes that achieve it. Here, we prove a tighter lower bound than&#10;the sharpest known one on the rate of optimal weak superimposed codes and give&#10;a polynomial&#45;time randomized construction algorithm for codes that&#10;asymptotically attain our improved bound with high probability. Our&#10;probabilistic approach is versatile and applicable to many other related codes&#10;and arrays.&#10; | General | [Link](http://arxiv.org/abs/2409.10511v1) |&#10;| Pennsieve &#45; A Collaborative Platform for Translational Neuroscience and&#10; &#160;Beyond | Zack Goldblum, Zhongchuan Xu, Haoer Shi, Patryk Orzechowski, Jamaal Spence, Kathryn A Davis, Brian Litt, Nishant Sinha, Joost Wagenaar | &#160;&#160;The exponential growth of neuroscientific data necessitates platforms that&#10;facilitate data management and multidisciplinary collaboration. In this paper,&#10;we introduce Pennsieve &#45; an open&#45;source, cloud&#45;based scientific data management&#10;platform built to meet these needs. Pennsieve supports complex multimodal&#10;datasets and provides tools for data visualization and analyses. It takes a&#10;comprehensive approach to data integration, enabling researchers to define&#10;custom metadata schemas and utilize advanced tools to filter and query their&#10;data. Pennsieve&#39;s modular architecture allows external applications to extend&#10;its capabilities, and collaborative workspaces with peer&#45;reviewed data&#10;publishing mechanisms promote high&#45;quality datasets optimized for downstream&#10;analysis, both in the cloud and on&#45;premises.&#10; &#160;Pennsieve forms the core for major neuroscience research programs including&#10;the NIH SPARC Initiative, NIH HEAL Initiative&#39;s PRECISION Human Pain Network,&#10;and NIH HEAL RE&#45;JOIN Initiative. It serves more than 80 research groups&#10;worldwide, along with several large&#45;scale, inter&#45;institutional projects at&#10;clinical sites through the University of Pennsylvania. Underpinning the&#10;SPARC.Science, Epilepsy.Science, and Pennsieve Discover portals, Pennsieve&#10;stores over 125 TB of scientific data, with 35 TB of data publicly available&#10;across more than 350 high&#45;impact datasets. It adheres to the findable,&#10;accessible, interoperable, and reusable (FAIR) principles of data sharing and&#10;is recognized as one of the NIH&#45;approved Data Repositories. By facilitating&#10;scientific data management, discovery, and analysis, Pennsieve fosters a robust&#10;and collaborative research ecosystem for neuroscience and beyond.&#10; | General | [Link](http://arxiv.org/abs/2409.10509v1) |&#10;| General&#45;relativistic resistive&#45;magnetohydrodynamics simulations of&#10; &#160;self&#45;consistent magnetized rotating neutron stars | Patrick Chi&#45;Kit Cheong, Antonios Tsokaros, Milton Ruiz, Fabrizio Venturi, Juno Chun Lung Chan, Anson Ka Long Yip, Koji Uryu | &#160;&#160;We present the first general&#45;relativistic resistive magnetohydrodynamics&#10;simulations of self&#45;consistent, rotating neutron stars with mixed poloidal and&#10;toroidal magnetic fields. Specifically, we investigate the role of resistivity&#10;in the dynamical evolution of neutron stars over a period of up to 100 ms and&#10;its effects on their quasi&#45;equilibrium configurations. Our results demonstrate&#10;that resistivity can significantly influence the development of&#10;magnetohydrodynamic instabilities, resulting in markedly different magnetic&#10;field geometries. Additionally, resistivity suppresses the growth of these&#10;instabilities, leading to a reduction in the amplitude of emitted gravitational&#10;waves. Despite the variations in magnetic field geometries, the ratio of&#10;poloidal to toroidal field energies remains consistently 9:1 throughout the&#10;simulations, for the models we investigated.&#10; | General | [Link](http://arxiv.org/abs/2409.10508v1) |&#10;| Beth&#45;Uhlenbeck equation for the thermodynamics of fluctuations in a&#10; &#160;generalised 2+1D Gross&#45;Neveu model | Biplab Mahato, David Blaschke, Dietmar Ebert | &#160;&#160;We study a generalised version of Gross&#45;Neveu model in 2+1 dimensions. The&#10;model is inspired from graphene which shows a linear dispersion relation near&#10;the Dirac points. The phase structure and the thermodynamic properties in the&#10;mean field approximation have been studied before. Here we go beyond the mean&#10;field level by deriving a Beth&#45;Uhlenbeck equation for Gaussian fluctuations,&#10;solutions of which we explore numerically, for the first time including their&#10;momentum dependence. We discuss the excitonic mass, fluctuation pressure and&#10;phase shifts. We also perform a comparison with the NJL model in 3+1 dimension&#10;and discuss its implication for graphene.&#10; | General | [Link](http://arxiv.org/abs/2409.10507v1) |&#10;| Context&#45;aware Code Segmentation for C&#45;to&#45;Rust Translation using Large&#10; &#160;Language Models | Momoko Shiraishi, Takahiro Shinagawa | &#160;&#160;There is strong motivation to translate C code into Rust code due to the&#10;continuing threat of memory safety vulnerabilities in existing C programs and&#10;the significant attention paid to Rust as an alternative to the C language.&#10;While large language models (LLMs) show promise for automating this translation&#10;by generating more natural and safer code than rule&#45;based methods, previous&#10;studies have shown that LLM&#45;generated Rust code often fails to compile, even&#10;for relatively small C programs, due to significant differences between the two&#10;languages and context window limitations. We propose an LLM&#45;based translation&#10;scheme that improves the success rate of translating large&#45;scale C code into&#10;compilable Rust code. Our approach involves three key techniques: (1)&#10;pre&#45;processing the C code to better align its structure and expressions with&#10;Rust, (2) segmenting the code into optimally sized translation units to avoid&#10;exceeding the LLM&#39;s context window limits, and (3) iteratively compiling and&#10;repairing errors while maintaining consistency between translation units using&#10;context&#45;supplementing prompts. Compilation success is an essential first step&#10;in achieving functional equivalence, as only compilable code can be further&#10;tested. In experiments with 20 benchmark C programs, including those exceeding&#10;4 kilo lines of code, we successfully translated all programs into compilable&#10;Rust code without losing corresponding parts of the original code.&#10; | General | [Link](http://arxiv.org/abs/2409.10506v1) |&#10;| Machine Learning Optimization of non&#45;Kasha Behavior and of Transient&#10; &#160;Dynamics in Model Retinal Isomerization | Davinder Singh, Chern Chuang, Paul Brumer | &#160;&#160;Designing a model of retinal isomerization in Rhodopsin, the first step in&#10;vision, that accounts for both experimental transient and stationary state&#10;observables is challenging. Here, multi&#45;objective Bayesian optimization is&#10;employed to refine the parameters of a minimal two&#45;state&#45;two&#45;mode (TM) model&#10;describing the photoisomerization of retinal in Rhodopsin. With an appropriate&#10;selection of objectives, the optimized retinal model predicts excitation&#10;wavelength&#45;dependent fluorescence spectra that closely align with&#10;experimentally observed non&#45;Kasha behavior in the non&#45;equilibrium steady state.&#10;Further, adjustments to the potential energy surface within the TM model reduce&#10;the discrepancies across the time domain. Overall, agreement with experimental&#10;data is excellent.&#10; | General | [Link](http://arxiv.org/abs/2409.10505v1) |&#10;| DILA: Dictionary Label Attention for Mechanistic Interpretability in&#10; &#160;High&#45;dimensional Multi&#45;label Medical Coding Prediction | John Wu, David Wu, Jimeng Sun | &#160;&#160;Predicting high&#45;dimensional or extreme multilabels, such as in medical&#10;coding, requires both accuracy and interpretability. Existing works often rely&#10;on local interpretability methods, failing to provide comprehensive&#10;explanations of the overall mechanism behind each label prediction within a&#10;multilabel set. We propose a mechanistic interpretability module called&#10;DIctionary Label Attention (method) that disentangles uninterpretable dense&#10;embeddings into a sparse embedding space, where each nonzero element (a&#10;dictionary feature) represents a globally learned medical concept. Through&#10;human evaluations, we show that our sparse embeddings are more human&#10;understandable than its dense counterparts by at least 50 percent. Our&#10;automated dictionary feature identification pipeline, leveraging large language&#10;models (LLMs), uncovers thousands of learned medical concepts by examining and&#10;summarizing the highest activating tokens for each dictionary feature. We&#10;represent the relationships between dictionary features and medical codes&#10;through a sparse interpretable matrix, enhancing the mechanistic and global&#10;understanding of the model&#39;s predictions while maintaining competitive&#10;performance and scalability without extensive human annotation.&#10; | General | [Link](http://arxiv.org/abs/2409.10504v1) |&#10;| Causal Language Modeling Can Elicit Search and Reasoning Capabilities on&#10; &#160;Logic Puzzles | Kulin Shah, Nishanth Dikkala, Xin Wang, Rina Panigrahy | &#160;&#160;Causal language modeling using the Transformer architecture has yielded&#10;remarkable capabilities in Large Language Models (LLMs) over the last few&#10;years. However, the extent to which fundamental search and reasoning&#10;capabilities emerged within LLMs remains a topic of ongoing debate. In this&#10;work, we study if causal language modeling can learn a complex task such as&#10;solving Sudoku puzzles. To solve a Sudoku, the model is first required to&#10;search over all empty cells of the puzzle to decide on a cell to fill and then&#10;apply an appropriate strategy to fill the decided cell. Sometimes, the&#10;application of a strategy only results in thinning down the possible values in&#10;a cell rather than concluding the exact value of the cell. In such cases,&#10;multiple strategies are applied one after the other to fill a single cell. We&#10;observe that Transformer models trained on this synthetic task can indeed learn&#10;to solve Sudokus (our model solves $94.21%$ of the puzzles fully correctly)&#10;when trained on a logical sequence of steps taken by a solver. We find that&#10;training Transformers with the logical sequence of steps is necessary and&#10;without such training, they fail to learn Sudoku. We also extend our analysis&#10;to Zebra puzzles (known as Einstein puzzles) and show that the model solves&#10;$92.04 %$ of the puzzles fully correctly. In addition, we study the internal&#10;representations of the trained Transformer and find that through linear&#10;probing, we can decode information about the set of possible values in any&#10;given cell from them, pointing to the presence of a strong reasoning engine&#10;implicit in the Transformer weights.&#10; | General | [Link](http://arxiv.org/abs/2409.10502v1) |&#10;| Alignment with nonlinear velocity couplings: collision&#45;avoidance and&#10; &#160;micro&#45;to&#45;macro mean&#45;field limits | Young&#45;Pil Choi, Micha Fabisiak, Jan Peszek | &#160;&#160;We investigate the pressureless fractional Euler&#45;alignment system with&#10;nonlinear velocity couplings, referred to as the $p$&#45;Euler&#45;alignment system.&#10;This model features a nonlinear velocity alignment force, interpreted as a&#10;density&#45;weighted fractional $p$&#45;Laplacian when the singularity parameter&#10;$alpha$ exceeds the spatial dimension $d$. Our primary goal is to establish&#10;the existence of solutions for strongly singular interactions ($alpha ge d$)&#10;and compactly supported initial conditions. We construct solutions as&#10;mean&#45;field limits of empirical measures from a kinetic variant of the&#10;$p$&#45;Euler&#45;alignment system. Specifically, we show that a sequence of empirical&#10;measures converges to a finite Radon measure, whose local density and velocity&#10;satisfy the $p$&#45;Euler&#45;alignment system. Our results are the first to prove the&#10;existence of solutions to this system in multi&#45;dimensional settings without&#10;significant initial data restrictions, covering both nonlinear ($p&gt;2$) and&#10;linear ($p=2$) cases. Additionally, we establish global existence, uniqueness,&#10;and collision avoidance for the corresponding particle ODE system under&#10;non&#45;collisional initial conditions, extending previous results for $1 &#10;e p &#10;e&#10;alpha + 2$. This analysis supports our mean&#45;field limit argument and&#10;contributes to understanding alignment models with singular communication.&#10; | General | [Link](http://arxiv.org/abs/2409.10501v1) |&#10;| Focus diverse phase retrieval test results on broadband continuous&#10; &#160;wavefront sensing in space telescope applications | Hyukmo Kang, Kyle Van Gorkom, Meghdoot Biswas, Daewook Kim, Ewan S. Douglas | &#160;&#160;Continuous wavefront sensing benefits space observatories in on&#45;orbit optical&#10;performance maintenance. To measure the phase of a wavefront, phase retrieval&#10;is an attractive technique as it uses multiple point spread function (PSF)&#10;images that are acquired by the telescope itself without extra metrology&#10;systems nor complicated calibration. The focus diverse phase retrieval utilizes&#10;PSFs from predetermined defocused positions to enhance the dynamic range of the&#10;algorithm. We describe an updated visible light active optics testbed with the&#10;addition of a linear motorized focus stage. The performance of the phase&#10;retrieval algorithm in broadband is tested under various cases. While broadband&#10;pass filters have advantages in higher signal&#45;to&#45;noise ratio (SNR), the&#10;performance of phase retrieval can be restricted due to blurred image caused by&#10;diffraction and increased computing cost. We used multiple bandpass filters (10&#10;nm, 88 nm, and 150 nm) and investigated effects of bandwidth on the accuracy&#10;and required image acquisition conditions such as SNR, reaching accuracies&#10;below 20 nm RMS wavefront error at the widest bandwidth. We also investigated&#10;the dynamic range of the phase retrieval algorithm depending on the bandwidth&#10;and required amount of defocus to expand dynamic range. Finally, we simulated&#10;the continuous wavefront sensing and correction loop with a range of&#10;statistically generated representative telescope disturbance time series to&#10;test for edge cases.&#10; | General | [Link](http://arxiv.org/abs/2409.10500v1) |&#10;| The role of higher&#45;order terms in trapped&#45;ion quantum computing with&#10; &#160;magnetic gradient induced coupling | Sebastian Nagies, Kevin T. Geier, Javed Akram, Junichi Okamoto, Dimitris Badounas, Christof Wunderlich, Michael Johanning, Philipp Hauke | &#160;&#160;Trapped&#45;ion hardware based on the Magnetic Gradient Induced Coupling (MAGIC)&#10;scheme is emerging as a promising platform for quantum computing. Nevertheless,&#10;in this (as in any other) quantum&#45;computing platform, many technical questions&#10;still have to be resolved before large&#45;scale and error&#45;tolerant applications&#10;are possible. In this work, we present a thorough discussion of the&#10;contribution of higher&#45;order terms to the MAGIC setup, which can occur due to&#10;anharmonicities in the external potential of the ion crystal (e.g., through&#10;Coulomb repulsion) or through curvature of the applied magnetic field. These&#10;terms take the form of three&#45;spin couplings as well as diverse terms that&#10;couple spins to phonons. We find that most of these are negligible in realistic&#10;situations, with only two contributions that need careful attention. First,&#10;there are parasitic longitudinal fields whose strength increases with chain&#10;length, but which can easily be compensated by a microwave detuning. Second,&#10;anharmonicities of the Coulomb interaction can lead to well&#45;known two&#45;to&#45;one&#10;conversions of phonon excitations, which can be avoided if the phonons are&#10;ground&#45;state cooled. Our detailed analysis constitutes an important&#10;contribution on the way of making magnetic&#45;gradient trapped&#45;ion quantum&#10;technology fit for large&#45;scale applications, and it may inspire new ways to&#10;purposefully design interaction terms.&#10; | General | [Link](http://arxiv.org/abs/2409.10498v1) |&#10;| MusicLIME: Explainable Multimodal Music Understanding | Theodoros Sotirou, Vassilis Lyberatos, Orfeas Menis Mastromichalakis, Giorgos Stamou | &#160;&#160;Multimodal models are critical for music understanding tasks, as they capture&#10;the complex interplay between audio and lyrics. However, as these models become&#10;more prevalent, the need for explainability grows&#45;understanding how these&#10;systems make decisions is vital for ensuring fairness, reducing bias, and&#10;fostering trust. In this paper, we introduce MusicLIME, a model&#45;agnostic&#10;feature importance explanation method designed for multimodal music models.&#10;Unlike traditional unimodal methods, which analyze each modality separately&#10;without considering the interaction between them, often leading to incomplete&#10;or misleading explanations, MusicLIME reveals how audio and lyrical features&#10;interact and contribute to predictions, providing a holistic view of the&#10;model&#39;s decision&#45;making. Additionally, we enhance local explanations by&#10;aggregating them into global explanations, giving users a broader perspective&#10;of model behavior. Through this work, we contribute to improving the&#10;interpretability of multimodal music models, empowering users to make informed&#10;choices, and fostering more equitable, fair, and transparent music&#10;understanding systems.&#10; | General | [Link](http://arxiv.org/abs/2409.10496v1) |&#10;| Incorporating Classifier&#45;Free Guidance in Diffusion Model&#45;Based&#10; &#160;Recommendation | Noah Buchanan, Susan Gauch, Quan Mai | &#160;&#160;This paper presents a diffusion&#45;based recommender system that incorporates&#10;classifier&#45;free guidance. Most current recommender systems provide&#10;recommendations using conventional methods such as collaborative or&#10;content&#45;based filtering. Diffusion is a new approach to generative AI that&#10;improves on previous generative AI approaches such as Variational Autoencoders&#10;(VAEs) and Generative Adversarial Networks (GANs). We incorporate diffusion in&#10;a recommender system that mirrors the sequence users take when browsing and&#10;rating items. Although a few current recommender systems incorporate diffusion,&#10;they do not incorporate classifier&#45;free guidance, a new innovation in diffusion&#10;models as a whole. In this paper, we present a diffusion recommender system&#10;that augments the underlying recommender system model for improved performance&#10;and also incorporates classifier&#45;free guidance. Our findings show improvements&#10;over state&#45;of&#45;the&#45;art recommender systems for most metrics for several&#10;recommendation tasks on a variety of datasets. In particular, our approach&#10;demonstrates the potential to provide better recommendations when data is&#10;sparse.&#10; | General | [Link](http://arxiv.org/abs/2409.10494v1) |&#10;| Renormalization of the Einstein&#45;Cartan Theory in First&#45;Order Form | F. T. Brandt, J. Frenkel, S. Martins&#45;Filho, D. G. C. McKeon | &#160;&#160;We examine the Einstein&#45;Cartan (EC) theory in first&#45;order form, which has a&#10;diffeomorphism as well as a local Lorentz invariance. We study the&#10;renormalizability of this theory in the framework of the Batalin&#45;Vilkovisky&#10;formalism, which allows for a gauge invariant renormalization. Using the&#10;background field method, we discuss the gauge invariance of the background&#10;effective action and analyze the Ward identities which reflect the symmetries&#10;of the EC theory. As an application, we compute, in a general background gauge,&#10;the self&#45;energy of the tetrad field at one&#45;loop order.&#10; | General | [Link](http://arxiv.org/abs/2409.10493v1) |&#10;| What we can learn from the angular differential rates (only) in&#10; &#160;semileptonic $B to D^* ell _ell$ decays | G. Martinelli, S. Simula, L. Vittorio | &#160;&#160;We present a new, simple approach to the study of semileptonic $B to D^*&#10;ell &#10;u_ell$ decays based on the angular distributions of the final state&#10;particles only. Our approach is model independent and never requires the&#10;knowledge of $vert V_{cb}vert$. By studying such distributions in the case of&#10;light leptons, a comparison between results from different data sets from the&#10;Belle and BelleII Collaborations and between data and Standard Model&#10;calculations is also given for several interesting quantities. A good&#10;consistency is observed between some of the experimental results and the&#10;theoretical predictions.&#10; | General | [Link](http://arxiv.org/abs/2409.10492v1) |&#10;| Code Vulnerability Detection: A Comparative Analysis of Emerging Large&#10; &#160;Language Models | Shaznin Sultana, Sadia Afreen, Nasir U. Eisty | &#160;&#160;The growing trend of vulnerability issues in software development as a result&#10;of a large dependence on open&#45;source projects has received considerable&#10;attention recently. This paper investigates the effectiveness of Large Language&#10;Models (LLMs) in identifying vulnerabilities within codebases, with a focus on&#10;the latest advancements in LLM technology. Through a comparative analysis, we&#10;assess the performance of emerging LLMs, specifically Llama, CodeLlama, Gemma,&#10;and CodeGemma, alongside established state&#45;of&#45;the&#45;art models such as BERT,&#10;RoBERTa, and GPT&#45;3. Our study aims to shed light on the capabilities of LLMs in&#10;vulnerability detection, contributing to the enhancement of software security&#10;practices across diverse open&#45;source repositories. We observe that CodeGemma&#10;achieves the highest F1&#45;score of 58 and a Recall of 87, amongst the recent&#10;additions of large language models to detect software security vulnerabilities.&#10; | General | [Link](http://arxiv.org/abs/2409.10490v1) |&#10;| Flash STU: Fast Spectral Transform Units | Y. Isabel Liu, Windsor Nguyen, Yagiz Devre, Evan Dogariu, Anirudha Majumdar, Elad Hazan | &#160;&#160;This paper describes an efficient, open source PyTorch implementation of the&#10;Spectral Transform Unit. We investigate sequence prediction tasks over several&#10;modalities including language, robotics, and simulated dynamical systems. We&#10;find that for the same parameter count, the STU and its variants outperform the&#10;Transformer as well as other leading state space models across various&#10;modalities.&#10; | General | [Link](http://arxiv.org/abs/2409.10489v1) |&#10;| Do Pre&#45;trained Vision&#45;Language Models Encode Object States? | Kaleb Newman, Shijie Wang, Yuan Zang, David Heffren, Chen Sun | &#160;&#160;For a vision&#45;language model (VLM) to understand the physical world, such as&#10;cause and effect, a first step is to capture the temporal dynamics of the&#10;visual world, for example how the physical states of objects evolve over time&#10;(e.g. a whole apple into a sliced apple). Our paper aims to investigate if VLMs&#10;pre&#45;trained on web&#45;scale data learn to encode object states, which can be&#10;extracted with zero&#45;shot text prompts. We curate an object state recognition&#10;dataset ChangeIt&#45;Frames, and evaluate nine open&#45;source VLMs, including models&#10;trained with contrastive and generative objectives. We observe that while these&#10;state&#45;of&#45;the&#45;art vision&#45;language models can reliably perform object&#10;recognition, they consistently fail to accurately distinguish the objects&#39;&#10;physical states. Through extensive experiments, we identify three areas for&#10;improvements for VLMs to better encode object states, namely the quality of&#10;object localization, the architecture to bind concepts to objects, and the&#10;objective to learn discriminative visual and language encoders on object&#10;states. Data and code are released.&#10; | General | [Link](http://arxiv.org/abs/2409.10488v1) |&#10;| A Host Galaxy Morphology Link Between Quasi&#45;Periodic Eruptions and Tidal&#10; &#160;Disruption Events | Olivier Gilbert, John J. Ruan, Michael Eracleous, Daryl Haggard, Jessie C. Runnoe | &#160;&#160;The physical processes that produce X&#45;ray Quasi&#45;Periodic Eruptions (QPEs)&#10;recently discovered from the nuclei of several low&#45;redshift galaxies are&#10;mysterious. Several pieces of observational evidence strongly suggest a link&#10;between QPEs and Tidal Disruption Events (TDE). Previous studies also reveal&#10;that the morphologies of TDE host galaxies are highly concentrated, with high&#10;Sersic indicies, bulge&#45;to&#45;total light (B/T) ratios, and stellar surface mass&#10;densities relative to the broader galaxy population. We use these distinctive&#10;properties to test the link between QPEs and TDEs, by comparing these&#10;parameters of QPE host galaxies to TDE host galaxies. We employ archival Legacy&#10;Survey images of a sample of 9 QPE host galaxies and a sample of 13 TDE host&#10;galaxies, and model their surface brightness profiles. We show that QPE host&#10;galaxies have high Sersic indices of ~3, high B/T ratios of ~0.5, and high&#10;surface mass densities of ~10^10 Msun kpc^&#45;2. These properties are similar to&#10;TDE host galaxies, but are in strong contrast to a mass&#45; and redshift&#45;matched&#10;control sample of galaxies. We also find tentative evidence that the central&#10;black holes in both QPE and TDE host galaxies are undermassive relative to&#10;their stellar mass. The morphological similarities between QPE and TDE host&#10;galaxies at the population level add to the mounting evidence of a physical&#10;link between these phenomena, and favor QPE models that also invoke TDEs.&#10; | General | [Link](http://arxiv.org/abs/2409.10486v1) |&#10;| Tuning the Rate of Tightly Packed Systems To Produce Planet Occurrence&#10; &#160;Trends with Galactic Height | Sarah Ballard | &#160;&#160;The formation of planetary systems has historically been considered in&#10;isolation, decoupled from processes on galactic scales. Recent findings&#10;employing data from ESA&#39;s Gaia mission challenge this narrative, identifying&#10;trends in planet occurrence with galactic kinematics and stellar age. The&#10;findings indicate changes in planet occurrence over and above the predicted&#10;changes from metallicity variation within the Milky Way, so that changes to&#10;stellar metallicity alone (long understood to be deterministic in planet&#10;outcomes) cannot explain the trends entirely. The scope of potential factors&#10;influencing planet formation has grown progressively wider, with accompanying&#10;theoretical support for galactic&#45;scale influences upon planet formation. In&#10;this manuscript, we investigate specifically how changes to the rate of Systems&#10;of Tightly&#45;packed Inner Planets (STIPs) could manifest as a trend in planet&#10;occurrence with galactic height. We focus our study upon M dwarf planetary&#10;systems for two reasons: first, they host STIPs at high rates, and secondly,&#10;their longevity makes them useful probes for kinematic trends over Gyr. We&#10;consider two models for a varying STIP rate: one in which STIP likelihood is&#10;determined by stellar age alone, irrespective of galactic time, and another in&#10;which the STIP likelihood suddenly increased in recent galactic history. Both&#10;models, which impose a higher STIP likelihood among younger stars, produce a&#10;negative gradient in planet occurrence with increasing height from the galactic&#10;midplane. We find that a step function model in which STIP likelihood increased&#10;by a factor of several ~a few Gyr ago resembles an observed trend among FGK&#10;dwarfs. We consider plausible physical mechanisms that could mimic the&#10;hypothesized model, given known links between STIP occurrence and other stellar&#10;and planetary properties.&#10; | General | [Link](http://arxiv.org/abs/2409.10485v1) |&#10;| XLM for Autonomous Driving Systems: A Comprehensive Review | Sonda Fourati, Wael Jaafar, Noura Baccar, Safwan Alfattani | &#160;&#160;Large Language Models (LLMs) have showcased remarkable proficiency in various&#10;information&#45;processing tasks. These tasks span from extracting data and&#10;summarizing literature to generating content, predictive modeling,&#10;decision&#45;making, and system controls. Moreover, Vision Large Models (VLMs) and&#10;Multimodal LLMs (MLLMs), which represent the next generation of language&#10;models, a.k.a., XLMs, can combine and integrate many data modalities with the&#10;strength of language understanding, thus advancing several information&#45;based&#10;systems, such as Autonomous Driving Systems (ADS). Indeed, by combining&#10;language communication with multimodal sensory inputs, e.g., panoramic images&#10;and LiDAR or radar data, accurate driving actions can be taken. In this&#10;context, we provide in this survey paper a comprehensive overview of the&#10;potential of XLMs towards achieving autonomous driving. Specifically, we review&#10;the relevant literature on ADS and XLMs, including their architectures, tools,&#10;and frameworks. Then, we detail the proposed approaches to deploy XLMs for&#10;autonomous driving solutions. Finally, we provide the related challenges to XLM&#10;deployment for ADS and point to future research directions aiming to enable XLM&#10;adoption in future ADS frameworks.&#10; | General | [Link](http://arxiv.org/abs/2409.10484v1) |&#10;| Efficient polarizable QM/MM using the direct reaction field Hamiltonian&#10; &#160;with electrostatic potential fitted multipole operators | Thomas P. Fay, Nicolas Ferr, Miquel Huix&#45;Rotllant | &#160;&#160;Electronic polarization and dispersion are decisive actors in determining&#10;interaction energies between molecules. These interactions have a particularly&#10;profound effect on excitation energies of molecules in complex environments,&#10;especially when the excitation involves a significant degree of charge&#10;reorganisation. The direct reaction field (DRF) approach, which has seen a&#10;recent revival of interest, provides a powerful framework for describing these&#10;interactions in quantum mechanics/molecular mechanics (QM/MM) models of&#10;systems, where a small subsystem of interest is described using quantum&#10;chemical methods and the remainder is treated with a simple MM force field. In&#10;this paper we show how the DRF approach can be combined with the electrostatic&#10;potential fitted (ESPF) multipole operator description of the QM region charge&#10;density, which reduces the scaling $mathcal{O}(N_mathrm{MM}^3)$ of the method&#10;with MM system to $mathcal{O}(N_mathrm{MM}^2)$. We also show how the DRF&#10;approach can be combined with fluctuating charge descriptions of the&#10;polarizable environment, as well as previously used atom&#45;centred&#10;dipole&#45;polarizability based models. We further show that the ESPF&#45;DRF method&#10;provides an accurate description of molecular interactions in both ground and&#10;excited electronic states of the QM system and apply it to predict the gas to&#10;aqueous solution solvatochromic shifts in the UV/visible absorption spectrum of&#10;acrolein.&#10; | General | [Link](http://arxiv.org/abs/2409.10483v1) |&#10;| Schrodinger&#39;s Memory: Large Language Models | Wei Wang, Qing Li | &#160;&#160;Memory is the foundation of LLMs&#39; functionality, yet past research has lacked&#10;an in&#45;depth exploration of their memory capabilities and underlying theory. In&#10;this paper, we apply UAT theory to explain the memory mechanism of LLMs and&#10;propose a new approach for evaluating LLM performance by comparing the memory&#10;capacities of different models. Through extensive experiments, we validate our&#10;theory and the memory abilities of LLMs. Finally, we compare the capabilities&#10;of the human brain and LLMs, highlighting both their similarities and&#10;differences in terms of working mechanisms.&#10; | General | [Link](http://arxiv.org/abs/2409.10482v1) |&#10;| Exploring 3D Face Reconstruction and Fusion Methods for Face&#10; &#160;Verification: A Case&#45;Study in Video Surveillance | Simone Maurizio La Cava, Sara Concas, Ruben Tolosana, Roberto Casula, Giulia Orr, Martin Drahansky, Julian Fierrez, Gian Luca Marcialis | &#160;&#160;3D face reconstruction (3DFR) algorithms are based on specific assumptions&#10;tailored to distinct application scenarios. These assumptions limit their use&#10;when acquisition conditions, such as the subject&#39;s distance from the camera or&#10;the camera&#39;s characteristics, are different than expected, as typically happens&#10;in video surveillance. Additionally, 3DFR algorithms follow various strategies&#10;to address the reconstruction of a 3D shape from 2D data, such as statistical&#10;model fitting, photometric stereo, or deep learning. In the present study, we&#10;explore the application of three 3DFR algorithms representative of the SOTA,&#10;employing each one as the template set generator for a face verification&#10;system. The scores provided by each system are combined by score&#45;level fusion.&#10;We show that the complementarity induced by different 3DFR algorithms improves&#10;performance when tests are conducted at never&#45;seen&#45;before distances from the&#10;camera and camera characteristics (cross&#45;distance and cross&#45;camera settings),&#10;thus encouraging further investigations on multiple 3DFR&#45;based approaches.&#10; | General | [Link](http://arxiv.org/abs/2409.10481v1) |&#10;| Addressing misspecification in contextual optimization | Omar Bennouna, Jiawei Zhang, Saurabh Amin, Asuman Ozdaglar | &#160;&#160;We study a linear contextual optimization problem where a decision maker has&#10;access to historical data and contextual features to learn a cost prediction&#10;model aimed at minimizing decision error. We adopt the predict&#45;then&#45;optimize&#10;framework for this analysis. Given that perfect model alignment with reality is&#10;often unrealistic in practice, we focus on scenarios where the chosen&#10;hypothesis set is misspecified. In this context, it remains unclear whether&#10;current contextual optimization approaches can effectively address such model&#10;misspecification. In this paper, we present a novel integrated learning and&#10;optimization approach designed to tackle model misspecification in contextual&#10;optimization. This approach offers theoretical generalizability, tractability,&#10;and optimality guarantees, along with strong practical performance. Our method&#10;involves minimizing a tractable surrogate loss that aligns with the performance&#10;value from cost vector predictions, regardless of whether the model&#10;misspecified or not, and can be optimized in reasonable time. To our knowledge,&#10;no previous work has provided an approach with such guarantees in the context&#10;of model misspecification.&#10; | General | [Link](http://arxiv.org/abs/2409.10479v1) |&#10;| Local SGD for Near&#45;Quadratic Problems: Improving Convergence under&#10; &#160;Unconstrained Noise Conditions | Andrey Sadchikov, Savelii Chezhegov, Aleksandr Beznosikov, Alexander Gasnikov | &#160;&#160;Distributed optimization plays an important role in modern large&#45;scale&#10;machine learning and data processing systems by optimizing the utilization of&#10;computational resources. One of the classical and popular approaches is Local&#10;Stochastic Gradient Descent (Local SGD), characterized by multiple local&#10;updates before averaging, which is particularly useful in distributed&#10;environments to reduce communication bottlenecks and improve scalability. A&#10;typical feature of this method is the dependence on the frequency of&#10;communications. But in the case of a quadratic target function with homogeneous&#10;data distribution over all devices, the influence of frequency of&#10;communications vanishes. As a natural consequence, subsequent studies include&#10;the assumption of a Lipschitz Hessian, as this indicates the similarity of the&#10;optimized function to a quadratic one to some extent. However, in order to&#10;extend the completeness of the Local SGD theory and unlock its potential, in&#10;this paper we abandon the Lipschitz Hessian assumption by introducing a new&#10;concept of $textit{approximate quadraticity}$. This assumption gives a new&#10;perspective on problems that have near quadratic properties. In addition,&#10;existing theoretical analyses of Local SGD often assume bounded variance. We,&#10;in turn, consider the unbounded noise condition, which allows us to broaden the&#10;class of studied problems.&#10; | General | [Link](http://arxiv.org/abs/2409.10478v1) |&#10;| SimInversion: A Simple Framework for Inversion&#45;Based Text&#45;to&#45;Image&#10; &#160;Editing | Qi Qian, Haiyang Xu, Ming Yan, Juhua Hu | &#160;&#160;Diffusion models demonstrate impressive image generation performance with&#10;text guidance. Inspired by the learning process of diffusion, existing images&#10;can be edited according to text by DDIM inversion. However, the vanilla DDIM&#10;inversion is not optimized for classifier&#45;free guidance and the accumulated&#10;error will result in the undesired performance. While many algorithms are&#10;developed to improve the framework of DDIM inversion for editing, in this work,&#10;we investigate the approximation error in DDIM inversion and propose to&#10;disentangle the guidance scale for the source and target branches to reduce the&#10;error while keeping the original framework. Moreover, a better guidance scale&#10;(i.e., 0.5) than default settings can be derived theoretically. Experiments on&#10;PIE&#45;Bench show that our proposal can improve the performance of DDIM inversion&#10;dramatically without sacrificing efficiency.&#10; | General | [Link](http://arxiv.org/abs/2409.10476v1) |&#10;| Leadership and Engagement Dynamics in Legislative Twitter Networks:&#10; &#160;Statistical Analysis and Modeling | Carolina Luque, Juan Sosa | &#160;&#160;In this manuscript, we analyze the interaction network on Twitter among&#10;members of the 117th U.S. Congress to assess the visibility of political&#10;leaders and explore how systemic properties and node attributes influence the&#10;formation of legislative connections. We employ descriptive social network&#10;statistical methods, the exponential random graph model (ERGM), and the&#10;stochastic block model (SBM) to evaluate the relative impact of network&#10;systemic properties, as well as institutional and personal traits, on the&#10;generation of online relationships among legislators. Our findings reveal that&#10;legislative networks on social media platforms like Twitter tend to reinforce&#10;the leadership of dominant political actors rather than diminishing their&#10;influence. However, we identify that these leadership roles can manifest in&#10;various forms. Additionally, we highlight that online connections within&#10;legislative networks are influenced by both the systemic properties of the&#10;network and institutional characteristics.&#10; | General | [Link](http://arxiv.org/abs/2409.10475v1) |&#10;| MacDiff: Unified Skeleton Modeling with Masked Conditional Diffusion | Lehong Wu, Lilang Lin, Jiahang Zhang, Yiyang Ma, Jiaying Liu | &#160;&#160;Self&#45;supervised learning has proved effective for skeleton&#45;based human action&#10;understanding. However, previous works either rely on contrastive learning that&#10;suffers false negative problems or are based on reconstruction that learns too&#10;much unessential low&#45;level clues, leading to limited representations for&#10;downstream tasks. Recently, great advances have been made in generative&#10;learning, which is naturally a challenging yet meaningful pretext task to model&#10;the general underlying data distributions. However, the representation learning&#10;capacity of generative models is under&#45;explored, especially for the skeletons&#10;with spacial sparsity and temporal redundancy. To this end, we propose Masked&#10;Conditional Diffusion (MacDiff) as a unified framework for human skeleton&#10;modeling. For the first time, we leverage diffusion models as effective&#10;skeleton representation learners. Specifically, we train a diffusion decoder&#10;conditioned on the representations extracted by a semantic encoder. Random&#10;masking is applied to encoder inputs to introduce a information bottleneck and&#10;remove redundancy of skeletons. Furthermore, we theoretically demonstrate that&#10;our generative objective involves the contrastive learning objective which&#10;aligns the masked and noisy views. Meanwhile, it also enforces the&#10;representation to complement for the noisy view, leading to better&#10;generalization performance. MacDiff achieves state&#45;of&#45;the&#45;art performance on&#10;representation learning benchmarks while maintaining the competence for&#10;generative tasks. Moreover, we leverage the diffusion model for data&#10;augmentation, significantly enhancing the fine&#45;tuning performance in scenarios&#10;with scarce labeled data. Our project is available at&#10;https://lehongwu.github.io/ECCV24MacDiff/.&#10; | General | [Link](http://arxiv.org/abs/2409.10473v1) |&#10;| Towards Semantic Versioning of Open Pre&#45;trained Language Model Releases&#10; &#160;on Hugging Face | Adekunle Ajibode, Abdul Ali Bangash, Filipe Roseiro Cogo, Bram Adams, Ahmed E. Hassan | &#160;&#160;The proliferation of open Pre&#45;trained Language Models (PTLMs) on model&#10;registry platforms like Hugging Face (HF) presents both opportunities and&#10;challenges for companies building products around them. Similar to traditional&#10;software dependencies, PTLMs continue to evolve after a release. However, the&#10;current state of release practices of PTLMs on model registry platforms are&#10;plagued by a variety of inconsistencies, such as ambiguous naming conventions&#10;and inaccessible model training documentation. Given the knowledge gap on&#10;current PTLM release practices, our empirical study uses a mixed&#45;methods&#10;approach to analyze the releases of 52,227 PTLMs on the most well&#45;known model&#10;registry, HF. Our results reveal 148 different naming practices for PTLM&#10;releases, with 40.87% of changes to model weight files not represented in the&#10;adopted name&#45;based versioning practice or their documentation. In addition, we&#10;identified that the 52,227 PTLMs are derived from only 299 different base&#10;models (the modified original models used to create 52,227 PTLMs), with&#10;Fine&#45;tuning and Quantization being the most prevalent modification methods&#10;applied to these base models. Significant gaps in release transparency, in&#10;terms of training dataset specifications and model card availability, still&#10;exist, highlighting the need for standardized documentation. While we&#10;identified a model naming practice explicitly differentiating between major and&#10;minor PTLM releases, we did not find any significant difference in the types of&#10;changes that went into either type of releases, suggesting that major/minor&#10;version numbers for PTLMs often are chosen arbitrarily. Our findings provide&#10;valuable insights to improve PTLM release practices, nudging the field towards&#10;more formal semantic versioning practices.&#10; | General | [Link](http://arxiv.org/abs/2409.10472v1) |&#10;| Real&#45;Time Whole&#45;Body Control of Legged Robots with Model&#45;Predictive Path&#10; &#160;Integral Control | Juan Alvarez&#45;Padilla, John Z. Zhang, Sofia Kwok, John M. Dolan, Zachary Manchester | &#160;&#160;This paper presents a system for enabling real&#45;time synthesis of whole&#45;body&#10;locomotion and manipulation policies for real&#45;world legged robots. Motivated by&#10;recent advancements in robot simulation, we leverage the efficient&#10;parallelization capabilities of the MuJoCo simulator to achieve fast sampling&#10;over the robot state and action trajectories. Our results show surprisingly&#10;effective real&#45;world locomotion and manipulation capabilities with a very&#10;simple control strategy. We demonstrate our approach on several hardware and&#10;simulation experiments: robust locomotion over flat and uneven terrains,&#10;climbing over a box whose height is comparable to the robot, and pushing a box&#10;to a goal position. To our knowledge, this is the first successful deployment&#10;of whole&#45;body sampling&#45;based MPC on real&#45;world legged robot hardware.&#10;Experiment videos and code can be found at: https://whole&#45;body&#45;mppi.github.io/&#10; | General | [Link](http://arxiv.org/abs/2409.10469v1) |&#10;| Assortativity in sympatric speciation and species classification | Joao U. F. Lizarraga, Flavia M. D. Marquitti, Marcus A. M. de Aguiar | &#160;&#160;We investigate the role of assortative mating in speciation using the&#10;sympatric model of Derrida and Higgs. The model explores the idea that genetic&#10;differences create incompatibilities between individuals, preventing mating if&#10;the number of such differences is too large. Speciation, however, only happens&#10;in this mating system if the number of genes is large. Here we show that&#10;speciation with small genome sizes can occur if assortative mating is&#10;introduced. In our model individuals are represented by three chromosomes: one&#10;responsible for reproductive compatibility, one for coding the trait on which&#10;assortativity will operate, and a neutral chromosome. Reproduction is possible&#10;if individuals are genetically similar with respect to the first chromosome,&#10;but among these compatible mating partners, the one with the most similar trait&#10;coded by the second chromosome is selected. We show that this type of&#10;assortativity facilitates speciation, which can happen with a small number of&#10;genes in the first chromosome. Species, classified according to reproductive&#10;isolation, dictated by the first chromosome, can display different traits&#10;values, as measured by the second and the third chromosomes. Therefore, species&#10;can also be identified based on similarity of the neutral trait, which works as&#10;a proxy for reproductive isolation.&#10; | General | [Link](http://arxiv.org/abs/2409.10466v1) |&#10;| A stabilized total pressure&#45;formulation of the Biot&#39;s poroelasticity&#10; &#160;equations in frequency domain: numerical analysis and applications | Cristian Crcamo, Alfonso Caiazzo, Felipe Galarce, Joaqun Mura | &#160;&#160;This work focuses on the numerical solution of the dynamics of a poroelastic&#10;material in the frequency domain. We provide a detailed stability analysis&#10;based on the application of the Fredholm alternative in the continuous case,&#10;considering a total pressure formulation of the Biot&#39;s equations. In the&#10;discrete setting, we propose a stabilized equal order finite element method&#10;complemented by an additional pressure stabilization to enhance the robustness&#10;of the numerical scheme with respect to the fluid permeability. Utilizing the&#10;Fredholm alternative, we extend the well&#45;posedness results to the discrete&#10;setting, obtaining theoretical optimal convergence for the case of linear&#10;finite elements. We present different numerical experiments to validate the&#10;proposed method. First, we consider model problems with known analytic&#10;solutions in two and three dimensions. As next, we show that the method is&#10;robust for a wide range of permeabilities, including the case of discontinuous&#10;coefficients. Lastly, we show the application for the simulation of brain&#10;elastography on a realistic brain geometry obtained from medical imaging.&#10; | General | [Link](http://arxiv.org/abs/2409.10465v1) |&#10;| New Direct Sum Tests | Alek Westover, Edward Yu, Kai Zheng | &#160;&#160;A function $f:[n]^{d} to mathbb{F}_2$ is a defn{direct sum} if there are&#10;functions $L_i:[n]to mathbb{F}_2$ such that ${f(x) = sum_{i}L_i(x_i)}$. In&#10;this work we give multiple results related to the property testing of direct&#10;sums.&#10; &#160;Our first result concerns a test proposed by Dinur and Golubev in 2019. We&#10;call their test the Diamond test and show that it is indeed a direct sum&#10;tester. More specifically, we show that if a function $f$ is $epsilon$&#45;far&#10;from being a direct sum function, then the Diamond test rejects $f$ with&#10;probability at least $Omega_{n,epsilon}(1)$. Even in the case of $n = 2$, the&#10;Diamond test is, to the best of our knowledge, novel and yields a new tester&#10;for the classic property of affinity.&#10; &#160;Apart from the Diamond test, we also analyze a broad family of direct sum&#10;tests, which at a high level, run an arbitrary affinity test on the restriction&#10;of $f$ to a random hypercube inside of $[n]^d$. This family of tests includes&#10;the direct sum test analyzed in cite{di19}, but does not include the Diamond&#10;test. As an application of our result, we obtain a direct sum test which works&#10;in the online adversary model of cite{KRV}.&#10; &#160;Finally, we also discuss a Fourier analytic interpretation of the diamond&#10;tester in the $n=2$ case, as well as prove local correction results for direct&#10;sum as conjectured by Dinur and Golubev.&#10; | General | [Link](http://arxiv.org/abs/2409.10464v1) |&#10;| Kolmogorov&#45;Arnold Networks in Low&#45;Data Regimes: A Comparative Study with&#10; &#160;Multilayer Perceptrons | Farhad Pourkamali&#45;Anaraki | &#160;&#160;Multilayer Perceptrons (MLPs) have long been a cornerstone in deep learning,&#10;known for their capacity to model complex relationships. Recently,&#10;Kolmogorov&#45;Arnold Networks (KANs) have emerged as a compelling alternative,&#10;utilizing highly flexible learnable activation functions directly on network&#10;edges, a departure from the neuron&#45;centric approach of MLPs. However, KANs&#10;significantly increase the number of learnable parameters, raising concerns&#10;about their effectiveness in data&#45;scarce environments. This paper presents a&#10;comprehensive comparative study of MLPs and KANs from both algorithmic and&#10;experimental perspectives, with a focus on low&#45;data regimes. We introduce an&#10;effective technique for designing MLPs with unique, parameterized activation&#10;functions for each neuron, enabling a more balanced comparison with KANs. Using&#10;empirical evaluations on simulated data and two real&#45;world data sets from&#10;medicine and engineering, we explore the trade&#45;offs between model complexity&#10;and accuracy, with particular attention to the role of network depth. Our&#10;findings show that MLPs with individualized activation functions achieve&#10;significantly higher predictive accuracy with only a modest increase in&#10;parameters, especially when the sample size is limited to around one hundred.&#10;For example, in a three&#45;class classification problem within additive&#10;manufacturing, MLPs achieve a median accuracy of 0.91, significantly&#10;outperforming KANs, which only reach a median accuracy of 0.53 with default&#10;hyperparameters. These results offer valuable insights into the impact of&#10;activation function selection in neural networks.&#10; | General | [Link](http://arxiv.org/abs/2409.10463v1) |&#10;| Effects of synapse location, delay and background stochastic activity on&#10; &#160;synchronising hippocampal CA1 neurons | Alessandro Fiasconaro, Michele Migliore | &#160;&#160;We study the synchronisation of neurons in a realistic model under the&#10;Hodgkin&#45;Huxley dynamics. To focus on the role of the different locations of the&#10;excitatory synapses, we use two identical neurons where the set of input&#10;signals is grouped at two different distances from the soma. The system is&#10;intended to represent a CA1 hippocampal neuron in which the synapses arriving&#10;from the CA3 neurons of the trisynaptic pathway appear to be localised in the&#10;apical dendritic region and are, in principle, either proximal or distal to the&#10;soma. Synchronisation is studied using a specifically defined spiking&#10;correlation function as a function of various parameters such as the distance&#10;from the soma of one of the synaptic groups, the inhibition weight and the&#10;associated activation delay. We found that the neurons&#39; spiking activity&#10;depends nonmonotonically on the relative dendritic location of the synapses and&#10;their inhibitory weight, whereas the synchronisation measure always decreases&#10;with inhibition, and strongly depends on its activation time delay. The&#10;background activity on the somas results essentially independent on the&#10;fluctuation intensity and strongly support the importance of the balance&#10;between inhibition and excitation for neuronal synchronization.&#10; | General | [Link](http://arxiv.org/abs/2409.10460v1) |&#10;| Efficiently Crowdsourcing Visual Importance with Punch&#45;Hole Annotation | Minsuk Chang, Soohyun Lee, Aeri Cho, Hyeon Jeon, Seokhyeon Park, Cindy Xiong Bearfield, Jinwook Seo | &#160;&#160;We introduce a novel crowdsourcing method for identifying important areas in&#10;graphical images through punch&#45;hole labeling. Traditional methods, such as gaze&#10;trackers and mouse&#45;based annotations, which generate continuous data, can be&#10;impractical in crowdsourcing scenarios. They require many participants, and the&#10;outcome data can be noisy. In contrast, our method first segments the graphical&#10;image with a grid and drops a portion of the patches (punch holes). Then, we&#10;iteratively ask the labeler to validate each annotation with holes, narrowing&#10;down the annotation only having the most important area. This approach aims to&#10;reduce annotation noise in crowdsourcing by standardizing the annotations while&#10;enhancing labeling efficiency and reliability. Preliminary findings from&#10;fundamental charts demonstrate that punch&#45;hole labeling can effectively&#10;pinpoint critical regions. This also highlights its potential for broader&#10;application in visualization research, particularly in studying large&#45;scale&#10;users&#39; graphical perception. Our future work aims to enhance the algorithm to&#10;achieve faster labeling speed and prove its utility through large&#45;scale&#10;experiments.&#10; | General | [Link](http://arxiv.org/abs/2409.10459v1) |&#10;| Full distribution of local observables in an exactly solvable current&#10; &#160;carrying steady states of a driven XXZ chain | Sandipan Manna, G J Sreejith | &#160;&#160;Current carrying steady states of interacting spins chains exhibit rich&#10;structures generated through an interplay of current induced correlations and&#10;energetic constraints from the Hamiltonian. The XXZ spin chain when coupled to&#10;maximally polarizing Lindblad terms admits an exact solution in a matrix&#10;product state (MPS) form. We use this exact solution to study the correlations&#10;and distributions of simple local spin observables in the non equilibrium&#10;steady state (NESS). We present exact expressions for spin correlators, entropy&#10;per site, cumulant generating functions for distributions of local observables&#10;in the XX limit (Ising anisotropy $Delta=0$). Further, we use the exact MPS&#10;solution in systems with $Delta&gt;0$, to numerically exactly calculate the&#10;entropy, correlations, as well as distributions of spin observables in blocks&#10;as large as $nsim 200$ sites allowing an estimation of the rate functions. The&#10;$z$ magnetization distribution is consistant with short range spin correlations&#10;in the $z$ direction while the $x$&#45;magnetization shows a double peak structure&#10;at larger $Delta$ suggesting short range ferromagnetic ordering. We find that&#10;the distribution of $z$&#45;magnetization sharpens for parameters where the current&#10;is maximized.&#10; | General | [Link](http://arxiv.org/abs/2409.10458v1) |&#10;| Mean Residual Life Ageing Intensity Function | Ashutosh Singh, Ishapathik Das, Asok Kumar Nanda, Sumen Sen | &#160;&#160;The ageing intensity function is a powerful analytical tool that provides&#10;valuable insights into the ageing process across diverse domains such as&#10;reliability engineering, actuarial science, and healthcare. Its applications&#10;continue to expand as researchers delve deeper into understanding the complex&#10;dynamics of ageing and its implications for society. One common approach to&#10;defining the ageing intensity function is through the hazard rate or failure&#10;rate function, extensively explored in scholarly literature. Equally&#10;significant to the hazard rate function is the mean residual life function,&#10;which plays a crucial role in analyzing the ageing patterns exhibited by units&#10;or components. This article introduces the mean residual life ageing intensity&#10;(MRLAI) function to delve into component ageing behaviours across various&#10;distributions. Additionally, we scrutinize the closure properties of the MRLAI&#10;function across different reliability operations. Furthermore, a new order&#10;termed the mean residual life ageing intensity order is defined to analyze the&#10;ageing behaviour of a system, and the closure property of this order under&#10;various reliability operations is discussed.&#10; | General | [Link](http://arxiv.org/abs/2409.10456v1) |&#10;| Quantile Fourier regressions for decision making under uncertainty | Arash Khojaste, Geoffrey Pritchard, Golbon Zakeri | &#160;&#160;Weconsider Markov decision processes arising from a Markov model of an&#10;underlying natural phenomenon. Such phenomena are usually periodic (e.g.&#10;annual) in time, and so the Markov processes modelling them must be&#10;time&#45;inhomogeneous, with cyclostationary rather than stationary behaviour. We&#10;describe a technique for constructing such processes that allows for periodic&#10;variations both in the values taken by the process and in the serial dependence&#10;structure. We include two illustrative numerical examples: a hydropower&#10;scheduling problem and a model of offshore wind power integration.&#10; | General | [Link](http://arxiv.org/abs/2409.10455v1) |&#10;| The Debiased Near&#45;Earth Object Population from ATLAS Telescopes | Rogerio Deienno, Larry Denneau, David Nesvorn, David Vokrouhlick, William F. Bottke, Robert Jedicke, Shantanu Naidu, Steven R. Chesley, Davide Farnocchia, Paul W. Chodas | &#160;&#160;This work is dedicated to debias the Near&#45;Earth Objects (NEO) population&#10;based on observations from the Asteroid Terrestrial&#45;impact Last Alert System&#10;(ATLAS) telescopes. We have applied similar methods used to develop the&#10;recently released NEO model generator (NEOMOD), once debiasing the NEO&#10;population using data from Catalina Sky Survey (CSS) G96 telescope. ATLAS is&#10;composed of four different telescopes. We first analyzed observational data&#10;from each of all four telescopes separately and later combined them. Our&#10;results highlight main differences between CSS and ATLAS, e.g., sky coverage&#10;and survey power at debiasing the NEO population. ATLAS has a much larger sky&#10;coverage than CSS, allowing it to find bright NEOs that would be constantly&#10;&quot;hiding&quot; from CSS. Consequently, ATLAS is more powerful than CSS at debiasing&#10;the NEO population for H $&#10;esssim$ 19. With its intrinsically greater&#10;sensitivity and emphasis on observing near opposition, CSS excels in the&#10;debiasing of smaller objects. ATLAS, as an all sky survey designed to find&#10;imminent hazardous objects, necessarily spends a significant fraction of time&#10;looking at places on the sky where objects do not appear, reducing its power&#10;for debiasing the population of small objects. We estimate a NEO population&#10;completeness of $approx$ 88%$^{+3%}_{&#45;2%}$ for H $&lt;$ 17.75 and $approx$&#10;36%$^{+1%}_{&#45;1%}$ for H $&lt;$ 22.25. Those numbers are similar to previous&#10;estimates (within error bars for H $&lt;$ 17.75) from CSS, yet, around 3% and 8%&#10;smaller at their face values, respectively. We also confirm previous finding&#10;that the $&#10;u_6$ secular resonance is the main source of small and faint NEOs&#10;at H = 28, whereas the 3:1 mean motion resonance with Jupiter dominates for&#10;larger and brighter NEOs at H = 15.&#10; | General | [Link](http://arxiv.org/abs/2409.10453v1) |&#10;| Signed Graph Autoencoder for Explainable and Polarization&#45;Aware Network&#10; &#160;Embeddings | Nikolaos Nakis, Chrysoula Kosma, Giannis Nikolentzos, Michalis Chatzianastasis, Iakovos Evdaimon, Michalis Vazirgiannis | &#160;&#160;Autoencoders based on Graph Neural Networks (GNNs) have garnered significant&#10;attention in recent years for their ability to extract informative latent&#10;representations, characterizing the structure of complex topologies, such as&#10;graphs. Despite the prevalence of Graph Autoencoders, there has been limited&#10;focus on developing and evaluating explainable neural&#45;based graph generative&#10;models specifically designed for signed networks. To address this gap, we&#10;propose the Signed Graph Archetypal Autoencoder (SGAAE) framework. SGAAE&#10;extracts node&#45;level representations that express node memberships over distinct&#10;extreme profiles, referred to as archetypes, within the network. This is&#10;achieved by projecting the graph onto a learned polytope, which governs its&#10;polarization. The framework employs a recently proposed likelihood for&#10;analyzing signed networks based on the Skellam distribution, combined with&#10;relational archetypal analysis and GNNs. Our experimental evaluation&#10;demonstrates the SGAAEs&#39; capability to successfully infer node memberships over&#10;the different underlying latent structures while extracting competing&#10;communities formed through the participation of the opposing views in the&#10;network. Additionally, we introduce the 2&#45;level network polarization problem&#10;and show how SGAAE is able to characterize such a setting. The proposed model&#10;achieves high performance in different tasks of signed link prediction across&#10;four real&#45;world datasets, outperforming several baseline models.&#10; | General | [Link](http://arxiv.org/abs/2409.10452v1) |&#10;| Why you should also use OLS estimation of tail exponents | Thiago Trafane Oliveira Santos, Daniel Oliveira Cajueiro | &#160;&#160;Even though practitioners often estimate Pareto exponents running OLS&#10;rank&#45;size regressions, the usual recommendation is to use the Hill MLE with a&#10;small&#45;sample correction instead, due to its unbiasedness and efficiency. In&#10;this paper, we advocate that you should also apply OLS in empirical&#10;applications. On the one hand, we demonstrate that, with a small&#45;sample&#10;correction, the OLS estimator is also unbiased. On the other hand, we show that&#10;the MLE assigns significantly greater weight to smaller observations. This&#10;suggests that the OLS estimator may outperform the MLE in cases where the&#10;distribution is (i) strictly Pareto but only in the upper tail or (ii)&#10;regularly varying rather than strictly Pareto. We substantiate our theoretical&#10;findings with Monte Carlo simulations and real&#45;world applications,&#10;demonstrating the practical relevance of the OLS method in estimating tail&#10;exponents.&#10; | General | [Link](http://arxiv.org/abs/2409.10448v1) |&#10;| Hydrodynamic hovering of swimming bacteria above surfaces | Pyae Hein Htet, Debasish Das, Eric Lauga | &#160;&#160;Flagellated bacteria are hydrodynamically attracted to rigid walls, yet past&#10;work shows a &#39;hovering&#39; state where they swim stably at a finite height above&#10;surfaces. We use numerics and theory to reveal the physical origin of hovering.&#10;Simulations first show that hovering requires an elongated cell body and&#10;results from a tilt away from the wall. Theoretical models then identify two&#10;essential asymmetries: the response of width&#45;asymmetric cells to active flows&#10;created by length&#45;asymmetric cells. A minimal model reconciles near and&#10;far&#45;field hydrodynamics, capturing all key features of hovering.&#10; | General | [Link](http://arxiv.org/abs/2409.10447v1) |&#10;| KoroT&#45;3E: A Personalized Musical Mnemonics Tool for Enhancing Memory&#10; &#160;Retention of Complex Computer Science Concepts | Xiangzhe Yuan, Jiajun Wang, Siying Hu, Andrew Cheung, Zhicong Lu | &#160;&#160;As the demand for computer science (CS) skills grows, mastering foundational&#10;concepts is crucial yet challenging for novice learners. To address this&#10;challenge, we present KoroT&#45;3E, an AI&#45;based system that creates personalized&#10;musical mnemonics to enhance both memory retention and understanding of&#10;concepts in CS. KoroT&#45;3E enables users to transform complex concepts into&#10;memorable lyrics and compose melodies that suit their musical preferences. We&#10;conducted semi&#45;structured interviews (n=12) to investigate why novice learners&#10;find it challenging to memorize and understand CS concepts. The findings,&#10;combined with constructivist learning theory, established our initial design,&#10;which was then refined following consultations with CS education experts. An&#10;empirical experiment(n=36) showed that those using KoroT&#45;3E (n=18)&#10;significantly outperformed the control group (n=18), with improved memory&#10;efficiency, increased motivation, and a positive learning experience. These&#10;findings demonstrate the effectiveness of integrating multimodal generative AI&#10;into CS education to create personalized and interactive learning experiences.&#10; | General | [Link](http://arxiv.org/abs/2409.10446v1) |&#10;| Deep&#45;Wide Learning Assistance for Insect Pest Classification | Toan Nguyen, Huy Nguyen, Huy Ung, Hieu Ung, Binh Nguyen | &#160;&#160;Accurate insect pest recognition plays a critical role in agriculture. It is&#10;a challenging problem due to the intricate characteristics of insects. In this&#10;paper, we present DeWi, novel learning assistance for insect pest&#10;classification. With a one&#45;stage and alternating training strategy, DeWi&#10;simultaneously improves several Convolutional Neural Networks in two&#10;perspectives: discrimination (by optimizing a triplet margin loss in a&#10;supervised training manner) and generalization (via data augmentation). From&#10;that, DeWi can learn discriminative and in&#45;depth features of insect pests&#10;(deep) yet still generalize well to a large number of insect categories (wide).&#10;Experimental results show that DeWi achieves the highest performances on two&#10;insect pest classification benchmarks (76.44% accuracy on the IP102 dataset&#10;and 99.79% accuracy on the D0 dataset, respectively). In addition, extensive&#10;evaluations and ablation studies are conducted to thoroughly investigate our&#10;DeWi and demonstrate its superiority. Our source code is available at&#10;https://github.com/toannguyen1904/DeWi.&#10; | General | [Link](http://arxiv.org/abs/2409.10445v1) |&#10;| LLM as BT&#45;Planner: Leveraging LLMs for Behavior Tree Generation in Robot&#10; &#160;Task Planning | Jicong Ao, Fan Wu, Yansong Wu, Abdalla Swikir, Sami Haddadin | &#160;&#160;Robotic assembly tasks are open challenges due to the long task horizon and&#10;complex part relations. Behavior trees (BTs) are increasingly used in robot&#10;task planning for their modularity and flexibility, but manually designing them&#10;can be effort&#45;intensive. Large language models (LLMs) have recently been&#10;applied in robotic task planning for generating action sequences, but their&#10;ability to generate BTs has not been fully investigated. To this end, We&#10;propose LLM as BT&#45;planner, a novel framework to leverage LLMs for BT generation&#10;in robotic assembly task planning and execution. Four in&#45;context learning&#10;methods are introduced to utilize the natural language processing and inference&#10;capabilities of LLMs to produce task plans in BT format, reducing manual effort&#10;and ensuring robustness and comprehensibility. We also evaluate the performance&#10;of fine&#45;tuned, fewer&#45;parameter LLMs on the same tasks. Experiments in simulated&#10;and real&#45;world settings show that our framework enhances LLMs&#39; performance in&#10;BT generation, improving success rates in BT generation through in&#45;context&#10;learning and supervised fine&#45;tuning.&#10; | General | [Link](http://arxiv.org/abs/2409.10444v1) |&#10;| The James Webb Space Telescope Absolute Flux Calibration. II.&#10; &#160;Mid&#45;Infrared Instrument Imaging and Coronagraphy | Karl D. Gordon, G. C. Sloan, Macarena Garcia Marin, Mattia Libralato, George Rieke, Jonathan A. Aguilar, Ralph Bohlin, Misty Cracraft, Marjorie Decleir, Andras Gaspar, David R. Law, Alberto Noriega&#45;Crespo, Michael Regan | &#160;&#160;The absolute flux calibration of the Mid&#45;Infrared Instrument Imaging and&#10;Coronagraphy is based on observations of multiple stars taken during the first&#10;2.5 years of JWST operations. The observations were designed to ensure that the&#10;flux calibration is valid for a range of flux densities, different subarrays,&#10;and different types of stars. The flux calibration was measured by combining&#10;observed aperture photometry corrected to infinite aperture with predictions&#10;based on previous observations and models of stellar atmospheres. A subset of&#10;these observations were combined with model point&#45;spread&#45;functions to measure&#10;the corrections to infinite aperture. Variations in the calibration factor with&#10;time, flux density, background level, type of star, subarray, integration time,&#10;rate, and well depth were investigated, and the only significant variations&#10;were with time and subarray. Observations of the same star taken approximately&#10;every month revealed a modest time&#45;dependent response loss seen mainly at the&#10;longest wavelengths. This loss is well characterized by a decaying exponential&#10;with a time constant of ~200 days. After correcting for the response loss, the&#10;band&#45;dependent scatter around the corrected average (aka repeatability) was&#10;found to range from 0.1 to 1.2%. Signals in observations taken with different&#10;subarrays can be lower by up to 3.4% compared to FULL frame. After correcting&#10;for the time and subarray dependencies, the scatter in the calibration factors&#10;measured for individual stars ranges from 1 to 4% depending on the band. The&#10;formal uncertainties on the flux calibration averaged for all observations are&#10;0.3 to 1.0%, with longer&#45;wavelength bands generally having larger&#10;uncertainties.&#10; | General | [Link](http://arxiv.org/abs/2409.10443v1) |&#10;| CtRNet&#45;X: Camera&#45;to&#45;Robot Pose Estimation in Real&#45;world Conditions Using&#10; &#160;a Single Camera | Jingpei Lu, Zekai Liang, Tristin Xie, Florian Ritcher, Shan Lin, Sainan Liu, Michael C. Yip | &#160;&#160;Camera&#45;to&#45;robot calibration is crucial for vision&#45;based robot control and&#10;requires effort to make it accurate. Recent advancements in markerless pose&#10;estimation methods have eliminated the need for time&#45;consuming physical setups&#10;for camera&#45;to&#45;robot calibration. While the existing markerless pose estimation&#10;methods have demonstrated impressive accuracy without the need for cumbersome&#10;setups, they rely on the assumption that all the robot joints are visible&#10;within the camera&#39;s field of view. However, in practice, robots usually move in&#10;and out of view, and some portion of the robot may stay out&#45;of&#45;frame during the&#10;whole manipulation task due to real&#45;world constraints, leading to a lack of&#10;sufficient visual features and subsequent failure of these approaches. To&#10;address this challenge and enhance the applicability to vision&#45;based robot&#10;control, we propose a novel framework capable of estimating the robot pose with&#10;partially visible robot manipulators. Our approach leverages the&#10;Vision&#45;Language Models for fine&#45;grained robot components detection, and&#10;integrates it into a keypoint&#45;based pose estimation network, which enables more&#10;robust performance in varied operational conditions. The framework is evaluated&#10;on both public robot datasets and self&#45;collected partial&#45;view datasets to&#10;demonstrate our robustness and generalizability. As a result, this method is&#10;effective for robot pose estimation in a wider range of real&#45;world manipulation&#10;scenarios.&#10; | General | [Link](http://arxiv.org/abs/2409.10441v1) |&#10;| Successive topological phase transitions in two distinct spin&#45;flop&#10; &#160;phases on the honeycomb lattice | Xudong Li, Jize Zhao, Jinbin Li, Qiang Luo | &#160;&#160;The Kitaev magnets with bond&#45;dependent interactions have garnered&#10;considerable attention in recent years for their ability to harbor exotic&#10;phases and nontrivial excitations. The topological magnons, which are indicated&#10;by nonzero Chern number and thermal Hall conductivity, are proposed to&#10;partially explain thermal Hall measurements in real materials. Hitherto,&#10;topological magnons have been extensively explored when the magnetic field is&#10;normal to the honeycomb plane, but their topological characteristics are less&#10;studied in the presence of in&#45;plane magnetic field. Here, we study two distinct&#10;in&#45;plane field induced spin&#45;flop phases in the $Gamma$&#45;$Gamma&#39;$ model, both&#10;of which are off&#45;diagonal couplings that have intimate relation to the Kitaev&#10;interaction. The two spin&#45;flop phases are distinguished by their out&#45;of&#45;plane&#10;spin components which can be either antiparallel or parallel, thus dubbing&#10;antiferromagnetic (AFM) or ferromagnetic (FM) spin&#45;flop phases, respectively.&#10;We map out topological phase diagrams for both phases, revealing a rich pattern&#10;of the Chern number over exchange parameters and magnetic field. We&#10;analytically calculate the boundaries of topological phase transitions when the&#10;magnetic field is along the $a$ and $b$ directions. We find that the thermal&#10;Hall conductivity and its derivative display contrasting behaviors when&#10;crossing different topological phase transitions. The striking difference of&#10;the two phases lies in that when the magnetic field is along the $b$ direction,&#10;topological magnons are totally absent in the AFM spin&#45;flop phase, while they&#10;can survive in the FM analogue in certain parameter regions.&#10; | General | [Link](http://arxiv.org/abs/2409.10439v1) |&#10;| A functorial approach to $n$&#45;abelian categories | Vitor Gulisz | &#160;&#160;We develop a functorial approach to the study of $n$&#45;abelian categories by&#10;reformulating their axioms in terms of their categories of finitely presented&#10;functors. Such an approach allows the use of classical homological algebra and&#10;representation theory techniques to understand higher homological algebra. As&#10;an application, we present two possible generalizations of the axioms &quot;every&#10;monomorphism is a kernel&quot; and &quot;every epimorphism is a cokernel&quot; of an abelian&#10;category to $n$&#45;abelian categories. We also specialize our results to modules&#10;over rings, thereby describing when the category of finitely generated&#10;projective modules over a ring is $n$&#45;abelian. Moreover, we establish a&#10;correspondence for $n$&#45;abelian categories with additive generators, which&#10;extends the higher Auslander correspondence.&#10; | General | [Link](http://arxiv.org/abs/2409.10438v1) |&#10;| Color symmetry breaking in the Potts spin glass | Jean&#45;Christophe Mourrat | &#160;&#160;The Potts spin glass is an analogue of the Sherrington&#45;Kirkpatrick model in&#10;which each spin can take one of $kappa$ possible values, which we interpret as&#10;colors. It was suggested in arXiv:2310.06745 that the order parameter for this&#10;model is always invariant with respect to permutations of the colors. We show&#10;here that this is false whenever $kappa ge 58$.&#10; | General | [Link](http://arxiv.org/abs/2409.10437v1) |&#10;| Infector characteristics exposed by spatial analysis of SARS&#45;CoV&#45;2&#10; &#160;sequence and demographic data analysed at fine geographical scales | Anna Gama, Samantha Lycett, Will Harvey, Joseph Hughes, Sema Nickbakhsh, David L Robertson, Alison Smith Palmer, Anthony Wood, Rowland Kao | &#160;&#160;Characterising drivers of SARS&#45;CoV&#45;2 circulation is crucial for understanding&#10;COVID&#45;19 because of the severity of control measures adopted during the&#10;pandemic. Whole genome sequence data augmented with demographic metadata&#10;provides the best opportunity to do this. We use Random Forest Decision Tree&#10;models to analyse a combination of over 4000 SARS&#45;CoV2 sequences from a densely&#10;sampled, mixed urban and rural population (Tayside) in Scotland in the period&#10;from August 2020 to July 2021, with fine scale geographical and&#10;socio&#45;demographic metadata. Comparing periods in versus out of &quot;lockdown&quot;&#10;restrictions, we show using genetic distance relationships that individuals&#10;from more deprived areas are more likely to get infected during lockdown but&#10;less likely to spread the infection further. As disadvantaged communities were&#10;the most affected by both COVID&#45;19 and its restrictions, our finding has&#10;important implications for informing future approaches to control future&#10;pandemics driven by similar respiratory infections.&#10; | General | [Link](http://arxiv.org/abs/2409.10436v1) |&#10;| A study of pure multi&#45;strange hadrons production in Pb+Pb collisions at&#10; &#160;LHC energies using HYDJET++ model | Gauri Devi, B. K. Singh | &#160;&#160;For the present work, we have used the HYDJET++ model to explore the&#10;production of pure multi&#45;strange hadrons in Pb+Pb collisions at&#10;$sqrt{s_{NN}}$= 2.76 TeV and $sqrt{s_{NN}}$= 5.02 TeV collision energies,&#10;respectively. We have simulated the $p_{T}$&#45;spectra and elliptic flow ($v_{2}$)&#10;of $phi$&#45;meson and $Omega$&#45;baryons comparing our results with ALICE&#10;experimental data and several phenomenological models (HIJING/$Boverline{B}$,&#10;VISHNU, EPOS, AMPT, and Krakow) across various centrality intervals.&#10;Additionally, we have calculated the nuclear modification factors ($R_{AA}$ and&#10;$R_{CP}$), which provide a perception of jet quenching phenomena. Hence, our&#10;findings enable the study of the energy and system dependence of $phi$ and&#10;$Omega$ hadrons production over a wide range of ultra&#45;relativistic collision&#10;energies. We also present the particle ratios ($Omega/phi$,&#10;$overline{Omega}^{+}/Omega^{&#45;}$, $Omega/pi$, and $phi/pi$), offering&#10;insights on the strangeness enhancement and chemical properties of the medium&#10;at both LHC collision energies.&#10; | General | [Link](http://arxiv.org/abs/2409.10435v1) |&#10;| Magnetic metamaterials by ion&#45;implantation | Christina Vantaraki, Petter Strm, Tuan T. Tran, Matas P. Grassi, Giovanni Fevola, Michael Foerster, Jerzy T. Sadowski, Daniel Primetzhofer, Vassilios Kapaklis | &#160;&#160;We present a method for the additive fabrication of planar magnetic&#10;nanoarrays with minimal surface roughness. Synthesis is accomplished by&#10;combining electron&#45;beam lithography, used to generate nanometric patterned&#10;masks, with ion implantation in thin films. By implanting $^{56}$Fe$^{+}$ ions,&#10;we are able to introduce magnetic functionality in a controlled manner into&#10;continuous Pd thin films, achieving 3D spatial resolution down to a few tens of&#10;nanometers. Our results demonstrate the successful application of this&#10;technique in fabricating square artificial spin ice lattices, which exhibit&#10;well&#45;defined magnetization textures and interactions among the patterned&#10;magnetic elements.&#10; | General | [Link](http://arxiv.org/abs/2409.10433v1) |&#10;| Structure&#45;preserving learning for multi&#45;symplectic PDEs | Sleyman Yldz, Pawan Goyal, Peter Benner | &#160;&#160;This paper presents an energy&#45;preserving machine learning method for&#10;inferring reduced&#45;order models (ROMs) by exploiting the multi&#45;symplectic form&#10;of partial differential equations (PDEs). The vast majority of&#10;energy&#45;preserving reduced&#45;order methods use symplectic Galerkin projection to&#10;construct reduced&#45;order Hamiltonian models by projecting the full models onto a&#10;symplectic subspace. However, symplectic projection requires the existence of&#10;fully discrete operators, and in many cases, such as black&#45;box PDE solvers,&#10;these operators are inaccessible. In this work, we propose an energy&#45;preserving&#10;machine learning method that can infer the dynamics of the given PDE using data&#10;only, so that the proposed framework does not depend on the fully discrete&#10;operators. In this context, the proposed method is non&#45;intrusive. The proposed&#10;method is grey box in the sense that it requires only some basic knowledge of&#10;the multi&#45;symplectic model at the partial differential equation level. We prove&#10;that the proposed method satisfies spatially discrete local energy conservation&#10;and preserves the multi&#45;symplectic conservation laws. We test our method on the&#10;linear wave equation, the Korteweg&#45;de Vries equation, and the&#10;Zakharov&#45;Kuznetsov equation. We test the generalization of our learned models&#10;by testing them far outside the training time interval.&#10; | General | [Link](http://arxiv.org/abs/2409.10432v1) |&#10;| Hippocampal synchronization in a realistic CA1 neuron model | Alessandro Fiasconaro, Michele Migliore | &#160;&#160;This work delves into studying the synchronization in two realistic neuron&#10;models using Hodgkin&#45;Huxley dynamics. Unlike simplistic point&#45;like models,&#10;excitatory synapses are here randomly distributed along the dendrites,&#10;introducing strong stochastic contributions into their signal propagation. To&#10;focus on the role of different excitatory positions, we use two copies of the&#10;same neuron whose synapses are located at different distances from the soma and&#10;are exposed to identical Poissonian distributed current pulses. The&#10;synchronization is investigated through a specifically defined spiking&#10;correlation function, and its behavior is analyzed as a function of several&#10;parameters: inhibition weight, distance from the soma of one synaptic group,&#10;excitatory inactivation delay, and weight of the excitatory synapses.&#10; | General | [Link](http://arxiv.org/abs/2409.10431v1) |&#10;| Meta&#45;Whisper: Speech&#45;Based Meta&#45;ICL for ASR on Low&#45;Resource Languages | Ming&#45;Hao Hsu, Kuan Po Huang, Hung&#45;yi Lee | &#160;&#160;This paper presents Meta&#45;Whisper, a novel approach to improve automatic&#10;speech recognition (ASR) for low&#45;resource languages using the Whisper model. By&#10;leveraging Meta In&#45;Context Learning (Meta&#45;ICL) and a k&#45;Nearest Neighbors (KNN)&#10;algorithm for sample selection, Meta&#45;Whisper enhances Whisper&#39;s ability to&#10;recognize speech in unfamiliar languages without extensive fine&#45;tuning.&#10;Experiments on the ML&#45;SUPERB dataset show that Meta&#45;Whisper significantly&#10;reduces the Character Error Rate (CER) for low&#45;resource languages compared to&#10;the original Whisper model. This method offers a promising solution for&#10;developing more adaptable multilingual ASR systems, particularly for languages&#10;with limited resources.&#10; | General | [Link](http://arxiv.org/abs/2409.10429v1) |&#10;| User&#45;Authenticated Device&#45;Independent Quantum Secure Direct&#10; &#160;Communication Protocol | Nayana Das, Saikat Basu, Goutam Paul, Vijay S. Rao | &#160;&#160;Device&#45;Independent Quantum Secure Direct Communication (DI&#45;QSDC) enhances&#10;quantum cryptography by enabling secure message transmission without relying on&#10;the trustworthiness of the devices involved. This approach mitigates risks&#10;associated with compromised or untrusted devices, common in traditional quantum&#10;communication.&#10; &#160;In this paper, we propose the first of its kind DI&#45;QSDC protocol with user&#10;identity authentication. This ensures the authenticity of both the sender and&#10;receiver prior to message exchange. We then discuss the security of the&#10;proposed protocol against common attacks, demonstrating that no eavesdropper&#10;gains any information from either the quantum or the classical channel. Next,&#10;we implement the protocol on IBM&#39;s quantum hardware and evaluate its&#10;performance in a realistic noisy environment. Additionally, by simulating&#10;common attack models, we showcase that the protocol is secure against any&#10;eavesdropper in the channel. These findings highlight the protocol&#39;s robust&#10;security and practical feasibility for real&#45;world secure quantum communication.&#10; | General | [Link](http://arxiv.org/abs/2409.10427v1) |&#10;| Role of kinematic constraints in the time reversal symmetry breaking of&#10; &#160;a model active matter | Soumen Das, Shankar Ghosh, Tridib Sadhu, Juliane U Klamser | &#160;&#160;Active&#45;matter systems are inherently out&#45;of&#45;equilibrium and perform&#10;mechanical work by utilizing their internal energy sources. Breakdown of&#10;time&#45;reversal symmetry (BTRS) is a hallmark of such dissipative non&#45;equilibrium&#10;dynamics. We introduce a robust, experimentally accessible, noninvasive,&#10;quantitative measure of BTRS in terms of the Kullback&#45;Leibler divergence in&#10;collision events, demonstrated in our novel artificial active matter, comprised&#10;of battery&#45;powered spherical rolling robots whose energetics in different modes&#10;of motion can be measured with high precision. Our dimensionless measure&#10;characterizes how dissipation and internal energetics are influenced by&#10;kinematic constraints from interactions with the environment. We propose this&#10;measure of BTRS as an empirical estimate of the distance from equilibrium. An&#10;energetic insight into this departure of active matter from equilibrium comes&#10;from our demonstration of a non&#45;trivial fluctuation symmetry, which reveals a&#10;potentially universal thermodynamic characteristic of active energetics. As a&#10;many&#45;body consequence of BTRS in our experimental active system, we demonstrate&#10;the emergence of activity&#45;induced herding, which has no equilibrium analogue.&#10; | General | [Link](http://arxiv.org/abs/2409.10425v1) |&#10;| Unveiling V Modes: Enhancing CMB Sensitivity to BSM Physics with a&#10; &#160;Non&#45;Ideal Half&#45;Wave Plate | N. Raffuzzi, M. Lembo, S. Giardiello, M. Gerbino, M. Lattanzi, P. Natoli, L. Pagano | &#160;&#160;V&#45;mode polarization of the cosmic microwave background is expected to be&#10;vanishingly small in the $Lambda$CDM model and, hence, usually ignored.&#10;Nonetheless, several astrophysical effects, as well as beyond standard model&#10;physics could produce it at a detectable level. A realistic half&#45;wave plate &#45;&#10;an optical element commonly used in CMB experiments to modulate the polarized&#10;signal &#45; can provide sensitivity to V modes without significantly spoiling that&#10;to linear polarization. We assess this sensitivity for some new&#45;generation CMB&#10;experiments, such as the LiteBIRD satellite, the ground&#45;based Simons&#10;Observatory and a CMB&#45;S4&#45;like experiment. We forecast the efficiency of these&#10;experiments to constrain the phenomenology of certain classes of BSM models&#10;inducing mixing of linear polarization states and generation of V modes in the&#10;CMB. We find that new&#45;generation experiments can improve current limits by&#10;1&#45;to&#45;3 orders of magnitude, depending on the data combination. The inclusion of&#10;V&#45;mode information dramatically boosts the sensitivity to these BSM models.&#10; | General | [Link](http://arxiv.org/abs/2409.10424v1) |&#10;| Initial data for a deformed isolated horizon | Ale Flandera, David Kofro, Tom Ledvinka | &#160;&#160;Within the isolated horizon formalism, we investigate a static axisymmetric&#10;space&#45;time of a black hole influenced by matter in its neighborhood. To&#10;illustrate the role of ingredients and assumptions in this formalism, we first&#10;show how, in spherical symmetry, the field equations and gauge conditions imply&#10;the isolated horizon initial data leading to the Schwarzschild space&#45;time.&#10;Then, we construct the initial data for a static axisymmetric isolated horizon&#10;representing a deformed black hole. The space&#45;time description in the&#10;Bondi&#45;like coordinates is then found as a series expansion in the vicinity of&#10;the horizon. To graphically illustrate this construction, we also find a&#10;numerical solution for a black hole deformed by a particular analytic model of&#10;a thin accretion disk. We also discuss how an accretion disk affects the&#10;analytical properties of the horizon geometry.&#10; | General | [Link](http://arxiv.org/abs/2409.10423v1) |&#10;| Learning Semi&#45;Supervised Medical Image Segmentation from Spatial&#10; &#160;Registration | Qianying Liu, Paul Henderson, Xiao Gu, Hang Dai, Fani Deligianni | &#160;&#160;Semi&#45;supervised medical image segmentation has shown promise in training&#10;models with limited labeled data and abundant unlabeled data. However,&#10;state&#45;of&#45;the&#45;art methods ignore a potentially valuable source of unsupervised&#10;semantic information &#45;&#45; spatial registration transforms between image volumes.&#10;To address this, we propose CCT&#45;R, a contrastive cross&#45;teaching framework&#10;incorporating registration information. To leverage the semantic information&#10;available in registrations between volume pairs, CCT&#45;R incorporates two&#10;proposed modules: Registration Supervision Loss (RSL) and Registration&#45;Enhanced&#10;Positive Sampling (REPS). The RSL leverages segmentation knowledge derived from&#10;transforms between labeled and unlabeled volume pairs, providing an additional&#10;source of pseudo&#45;labels. REPS enhances contrastive learning by identifying&#10;anatomically&#45;corresponding positives across volumes using registration&#10;transforms. Experimental results on two challenging medical segmentation&#10;benchmarks demonstrate the effectiveness and superiority of CCT&#45;R across&#10;various semi&#45;supervised settings, with as few as one labeled case. Our code is&#10;available at&#10;https://github.com/kathyliu579/ContrastiveCross&#45;teachingWithRegistration.&#10; | General | [Link](http://arxiv.org/abs/2409.10422v1) |&#10;| Multidimensional Deconvolution with Profiling | Huanbiao Zhu, Krish Desai, Mikael Kuusela, Vinicius Mikuni, Benjamin Nachman, Larry Wasserman | &#160;&#160;In many experimental contexts, it is necessary to statistically remove the&#10;impact of instrumental effects in order to physically interpret measurements.&#10;This task has been extensively studied in particle physics, where the&#10;deconvolution task is called unfolding. A number of recent methods have shown&#10;how to perform high&#45;dimensional, unbinned unfolding using machine learning.&#10;However, one of the assumptions in all of these methods is that the detector&#10;response is accurately modeled in the Monte Carlo simulation. In practice, the&#10;detector response depends on a number of nuisance parameters that can be&#10;constrained with data. We propose a new algorithm called Profile OmniFold&#10;(POF), which works in a similar iterative manner as the OmniFold (OF) algorithm&#10;while being able to simultaneously profile the nuisance parameters. We&#10;illustrate the method with a Gaussian example as a proof of concept&#10;highlighting its promising capabilities.&#10; | General | [Link](http://arxiv.org/abs/2409.10421v1) |&#10;| HiFi&#45;CS: Towards Open Vocabulary Visual Grounding For Robotic Grasping&#10; &#160;Using Vision&#45;Language Models | Vineet Bhat, Prashanth Krishnamurthy, Ramesh Karri, Farshad Khorrami | &#160;&#160;Robots interacting with humans through natural language can unlock numerous&#10;applications such as Referring Grasp Synthesis (RGS). Given a text query, RGS&#10;determines a stable grasp pose to manipulate the referred object in the robot&#39;s&#10;workspace. RGS comprises two steps: visual grounding and grasp pose estimation.&#10;Recent studies leverage powerful Vision&#45;Language Models (VLMs) for visually&#10;grounding free&#45;flowing natural language in real&#45;world robotic execution.&#10;However, comparisons in complex, cluttered environments with multiple instances&#10;of the same object are lacking. This paper introduces HiFi&#45;CS, featuring&#10;hierarchical application of Featurewise Linear Modulation (FiLM) to fuse image&#10;and text embeddings, enhancing visual grounding for complex attribute rich text&#10;queries encountered in robotic grasping. Visual grounding associates an object&#10;in 2D/3D space with natural language input and is studied in two scenarios:&#10;Closed and Open Vocabulary. HiFi&#45;CS features a lightweight decoder combined&#10;with a frozen VLM and outperforms competitive baselines in closed vocabulary&#10;settings while being 100x smaller in size. Our model can effectively guide&#10;open&#45;set object detectors like GroundedSAM to enhance open&#45;vocabulary&#10;performance. We validate our approach through real&#45;world RGS experiments using&#10;a 7&#45;DOF robotic arm, achieving 90.33% visual grounding accuracy in 15 tabletop&#10;scenes. We include our codebase in the supplementary material.&#10; | General | [Link](http://arxiv.org/abs/2409.10419v1) |&#10;| X&#45;ray reverberation as an explanation for UV/optical variability in&#10; &#160;nearby Seyferts | M. Papoutsis, I. E. Papadakis, C. Panagiotou, M. Doviak, E. Kammoun | &#160;&#160;Active galactic nuclei (AGNs) are known to be variable across all&#10;wavelengths. Significant observational efforts have been invested in the last&#10;decade in studying their ultraviolet (UV) and optical variability. Long and&#10;densely sampled, multi&#45;wavelength monitoring campaigns of numerous Seyfert&#10;galaxies have been conducted with the aim of determining the X&#45;ray/UV/optical&#10;continuum time lags. Time&#45;lag studies can be used to constrain theoretical&#10;models. The observed time lags can be explained by thermal reprocessing of the&#10;X&#45;rays illuminating the accretion disc (known as the X&#45;ray reverberation&#10;model). However, the observed light curves contain more information that can be&#10;used to further constrain physical models. Our primary objective is to&#10;investigate whether, in addition to time lags, the X&#45;ray reverberation model&#10;can also explain the UV/optical variability amplitude of nearby Seyferts. To do&#10;this, we measured the excess variance of four sources (namely Mrk 509, NGC&#10;4151, NGC 2617, and Mrk 142) as a function of wavelength using data from&#10;archival long, multi&#45;wavelength campaigns with Swift, and ground&#45;based&#10;telescopes. We also computed the model excess variance in the case of the X&#45;ray&#10;reverberation model by determining the disc&#39;s transfer function and assuming a&#10;bending power law for the X&#45;ray power spectrum. We tested the validity of the&#10;model by comparing the measured and model variances for a range of accretion&#10;rates and X&#45;ray source heights. We conclude that the X&#45;ray thermal&#10;reverberation model can fit both the continuum, UV/optical time lags, as well&#10;as the variance in these AGNs, for the same physical parameters. Our results&#10;suggest that the accretion disc is constant and that all the observed&#10;UV/optical variations, on timescales of days and up to a few weeks, can be&#10;fully explained by the variable X&#45;rays as they illuminate the accretion disc.&#10; | General | [Link](http://arxiv.org/abs/2409.10417v1) |&#10;| Local central limit theorem for Mallows measure | Alexey Bufetov, Kailun Chen | &#160;&#160;We study the statistics of the Mallows measure on permutations in the limit&#10;pioneered by Starr (2009). Our main result is the local central limit theorem&#10;for its height function. We also re&#45;derive versions of the law of large numbers&#10;and the large deviation principle, obtain the standard central limit theorem&#10;from the local one, and establish a multi&#45;point version of the local central&#10;limit theorem.&#10; | General | [Link](http://arxiv.org/abs/2409.10415v1) |&#10;| On interactive anisotropic walks in two dimensions generated from a&#10; &#160;three state opinion dynamics model | Surajit Saha, Parongama Sen | &#160;&#160;A system of interacting walkers on a two&#45;dimensional space where the dynamics&#10;of each walker are governed by the opinions of agents of a three&#45;state opinion&#10;dynamics model are considered. Such walks, inspired by Ising&#45;like models and&#10;opinions dynamics models, are usually considered in one&#45;dimensional virtual&#10;spaces. Here, the mapping is done in such a way that the walk is directed along&#10;the $y$ axis while it can move either way along the $x$ axis. We explore the&#10;properties of such walks as the parameter representing the noise in the opinion&#10;dynamics model, responsible for a continuous phase transition, is varied. The&#10;walk features show marked differences as the system crosses the critical point.&#10;The bivariate distribution of the displacements below the critical point is a&#10;modified biased Gaussian function of x and y which is symmetric about the X&#10;axis.&#10; &#160;The marginal probability distributions can be extracted and the scaling forms&#10;of different quantities, showing power law behaviour, are obtained. The&#10;directed nature of the walk is reflected in the marginal distributions as well&#10;as in the exponents.&#10; | General | [Link](http://arxiv.org/abs/2409.10413v1) |&#10;| A Large&#45;Scale Privacy Assessment of Android Third&#45;Party SDKs | Mark Huasong Meng, Chuan Yan, Yun Hao, Qing Zhang, Zeyu Wang, Kailong Wang, Sin Gee Teo, Guangdong Bai, Jin Song Dong | &#160;&#160;Third&#45;party Software Development Kits (SDKs) are widely adopted in Android&#10;app development, to effortlessly accelerate development pipelines and enhance&#10;app functionality. However, this convenience raises substantial concerns about&#10;unauthorized access to users&#39; privacy&#45;sensitive information, which could be&#10;further abused for illegitimate purposes like user tracking or monetization.&#10;Our study offers a targeted analysis of user privacy protection among Android&#10;third&#45;party SDKs, filling a critical gap in the Android software supply chain.&#10;It focuses on two aspects of their privacy practices, including data&#10;exfiltration and behavior&#45;policy compliance (or privacy compliance), utilizing&#10;techniques of taint analysis and large language models. It covers 158&#10;widely&#45;used SDKs from two key SDK release platforms, the official one and a&#10;large alternative one. From them, we identified 338 instances of privacy data&#10;exfiltration. On the privacy compliance, our study reveals that more than 30%&#10;of the examined SDKs fail to provide a privacy policy to disclose their data&#10;handling practices. Among those that provide privacy policies, 37% of them&#10;over&#45;collect user data, and 88% falsely claim access to sensitive data. We&#10;revisit the latest versions of the SDKs after 12 months. Our analysis&#10;demonstrates a persistent lack of improvement in these concerning trends. Based&#10;on our findings, we propose three actionable recommendations to mitigate the&#10;privacy leakage risks and enhance privacy protection for Android users. Our&#10;research not only serves as an urgent call for industry attention but also&#10;provides crucial insights for future regulatory interventions.&#10; | General | [Link](http://arxiv.org/abs/2409.10411v1) |&#10;| A point process approach for the classification of noisy calcium imaging&#10; &#160;data | Arianna Burzacchi, Nicoletta D&#39;Angelo, David Payares&#45;Garcia, Jorge Mateu | &#160;&#160;We study noisy calcium imaging data, with a focus on the classification of&#10;spike traces. As raw traces obscure the true temporal structure of neuron&#39;s&#10;activity, we performed a tuned filtering of the calcium concentration using two&#10;methods: a biophysical model and a kernel mapping. The former characterizes&#10;spike trains related to a particular triggering event, while the latter filters&#10;out the signal and refines the selection of the underlying neuronal response.&#10;Transitioning from traditional time series analysis to point process theory,&#10;the study explores spike&#45;time distance metrics and point pattern prototypes to&#10;describe repeated observations. We assume that the analyzed neuron&#39;s firing&#10;events, i.e. spike occurrences, are temporal point process events. In&#10;particular, the study aims to categorize 47 point patterns by depth, assuming&#10;the similarity of spike occurrences within specific depth categories. The&#10;results highlight the pivotal roles of depth and stimuli in discerning diverse&#10;temporal structures of neuron firing events, confirming the point process&#10;approach based on prototype analysis is largely useful in the classification of&#10;spike traces.&#10; | General | [Link](http://arxiv.org/abs/2409.10409v1) |&#10;| Variational closures for composite homogenised fluid flows | Theo Diamantakis, Ruiao Hu | &#160;&#160;The Stochastic Advection by Lie Transport is a variational formulation of&#10;stochastic fluid dynamics introduced to model the effects of unresolved scales,&#10;whilst preserving the geometric structure of ideal fluid flows. In this work,&#10;we show that the SALT equations can arise from the decomposition of the fluid&#10;flow map into its mean and fluctuating components. The fluctuating component is&#10;realised as a prescribed stochastic diffeomorphism that introduces stochastic&#10;transport into the system and we construct it using homogenisation theory. The&#10;dynamics of the mean component are derived from a variational principle&#10;utilising particular forms of variations that preserve the composite structure&#10;of the flow. Using a new variational principle, we show that SALT equations can&#10;arise from random Lagrangians and are equivalent to random coefficient PDEs. We&#10;also demonstrate how to modify the composite flow and the associated&#10;variational principle to derive models inspired by the Lagrangian Averaged&#10;Euler&#45;Poincare (LAEP) theory.&#10; | General | [Link](http://arxiv.org/abs/2409.10408v1) |&#10;| Bitcoin Transaction Behavior Modeling Based on Balance Data | Yu Zhang, Claudio Tessone | &#160;&#160;When analyzing Bitcoin users&#39; balance distribution, we observed that it&#10;follows a log&#45;normal pattern. Drawing parallels from the successful application&#10;of Gibrat&#39;s law of proportional growth in explaining city size and word&#10;frequency distributions, we tested whether the same principle could account for&#10;the log&#45;normal distribution in Bitcoin balances. However, our calculations&#10;revealed that the exponent parameters in both the drift and variance terms&#10;deviate slightly from one. This suggests that Gibrat&#39;s proportional growth rule&#10;alone does not fully explain the log&#45;normal distribution observed in Bitcoin&#10;users&#39; balances. During our exploration, we discovered an intriguing&#10;phenomenon: Bitcoin users tend to fall into two distinct categories based on&#10;their behavior, which we refer to as ``poor&quot; and ``wealthy&quot; users. Poor users,&#10;who initially purchase only a small amount of Bitcoin, tend to buy more&#10;bitcoins first and then sell out all their holdings gradually over time. The&#10;certainty of selling all their coins is higher and higher with time. In&#10;contrast, wealthy users, who acquire a large amount of Bitcoin from the start,&#10;tend to sell off their holdings over time. The speed at which they sell their&#10;bitcoins is lower and lower over time and they will hold at least a small part&#10;of their initial holdings at last. Interestingly, the wealthier the user, the&#10;larger the proportion of their balance and the higher the certainty they tend&#10;to sell. This research provided an interesting perspective to explore bitcoin&#10;users&#39; behaviors which may apply to other finance markets.&#10; | General | [Link](http://arxiv.org/abs/2409.10407v1) |&#10;| Stochastic Data&#45;Driven Predictive Control: Chance&#45;Constraint&#10; &#160;Satisfaction with Identified Multi&#45;step Predictors | Haldun Balim, Andrea Carron, Melanie N. Zeilinger, Johannes Khler | &#160;&#160;We propose a novel data&#45;driven stochastic model predictive control framework&#10;for uncertain linear systems with noisy output measurements. Our approach&#10;leverages multi&#45;step predictors to efficiently propagate uncertainty, ensuring&#10;chance constraint satisfaction with minimal conservatism. In particular, we&#10;present a strategy to identify multi&#45;step predictors and quantify the&#10;associated uncertainty using a surrogate (data&#45;driven) state space model. Then,&#10;we utilize the derived distribution to formulate a constraint tightening that&#10;ensures chance constraint satisfaction. A numerical example highlights the&#10;reduced conservatism of handling parametric uncertainty in the proposed method&#10;compared to state&#45;of&#45;the&#45;art solutions.&#10; | General | [Link](http://arxiv.org/abs/2409.10405v1) |&#10;| A Knowledge&#45;Enhanced Disease Diagnosis Method Based on Prompt Learning&#10; &#160;and BERT Integration | Zhang Zheng | &#160;&#160;This paper proposes a knowledge&#45;enhanced disease diagnosis method based on a&#10;prompt learning framework. The method retrieves structured knowledge from&#10;external knowledge graphs related to clinical cases, encodes it, and injects it&#10;into the prompt templates to enhance the language model&#39;s understanding and&#10;reasoning capabilities for the task.We conducted experiments on three public&#10;datasets: CHIP&#45;CTC, IMCS&#45;V2&#45;NER, and KUAKE&#45;QTR. The results show that the&#10;proposed method significantly outperforms existing models across multiple&#10;evaluation metrics, with an F1 score improvement of 2.4% on the CHIP&#45;CTC&#10;dataset, 3.1% on the IMCS&#45;V2&#45;NER dataset,and 4.2% on the KUAKE&#45;QTR dataset.&#10;Additionally,ablation studies confirmed the critical role of the knowledge&#10;injection module,as the removal of this module resulted in a significant drop&#10;in F1 score. The experimental results demonstrate that the proposed method not&#10;only effectively improves the accuracy of disease diagnosis but also enhances&#10;the interpretability of the predictions, providing more reliable support and&#10;evidence for clinical diagnosis.&#10; | General | [Link](http://arxiv.org/abs/2409.10403v1) |&#10;| A Statistical Equilibrium Approach to Adam Smith&#39;s Labor Theory of Value | Ellis Scharfenaker, Bruno Theodosio, Duncan K. Foley | &#160;&#160;Adam Smith&#39;s inquiry into the emergence and stability of the&#10;self&#45;organization of the division of labor in commodity production and exchange&#10;is considered using statistical equilibrium methods from statistical physics.&#10;We develop a statistical equilibrium model of the distribution of independent&#10;direct producers in a hub&#45;and&#45;spoke framework that predicts both the center of&#10;gravity of producers across lines of production as well as the endogenous&#10;fluctuations between lines of production that arise from Smith&#39;s concept of&#10;&quot;perfect liberty&quot;. The ergodic distribution of producers implies a long&#45;run&#10;balancing of &quot;advantages to disadvantages&quot; across lines of employment and&#10;gravitation of market prices around Smith&#39;s natural prices.&#10; | General | [Link](http://arxiv.org/abs/2409.10402v1) |&#10;| Hydrodynamic mechanism for stable spindle positioning in meiosis II&#10; &#160;oocytes | Weida Liao, Eric Lauga | &#160;&#160;Cytoplasmic streaming, the persistent flow of fluid inside a cell, induces&#10;intracellular transport, which plays a key role in fundamental biological&#10;processes. In meiosis II mouse oocytes (developing egg cells) awaiting&#10;fertilisation, the spindle, which is the protein structure responsible for&#10;dividing genetic material in a cell, must maintain its position near the cell&#10;cortex (the thin actin network bound to the cell membrane) for many hours.&#10;However, the cytoplasmic streaming that accompanies this stable positioning&#10;would intuitively appear to destabilise the spindle position. Here, through a&#10;combination of numerical and analytical modelling, we reveal a new,&#10;hydrodynamic mechanism for stable spindle positioning beneath the cortical cap.&#10;We show that this stability depends critically on the spindle size and the&#10;active driving from the cortex, and demonstrate that stable spindle positioning&#10;can result purely from a hydrodynamic suction force exerted on the spindle by&#10;the cytoplasmic flow. Our findings show that local fluid dynamic forces can be&#10;sufficient to stabilise the spindle, explaining robustness against&#10;perturbations not only perpendicular but also parallel to the cortex. Our&#10;results shed light on the importance of cytoplasmic streaming in mammalian&#10;meiosis.&#10; | General | [Link](http://arxiv.org/abs/2409.10401v1) |&#10;| Sherpa: An Open Source Python Fitting Package | Aneta Siemiginowska, Douglas Burke, Hans Moritz Gnther, Nicholas P. Lee, Warren McLaughlin, David A. Principe, Harlan Cheer, Antonella Fruscione, Omar Laurino, Jonathan McDowell, Marie Terrell | &#160;&#160;We present an overview of Sherpa, an open source Python project, and discuss&#10;its development history, broad design concepts and capabilities. Sherpa&#10;contains powerful tools for combining parametric models into complex&#10;expressions that can be fit to data using a variety of statistics and&#10;optimization methods. It is easily extensible to include user&#45;defined models,&#10;statistics, and optimization methods. It provides a high&#45;level User Interface&#10;for interactive data&#45;analysis, such as within a Jupyter notebook, and it can&#10;also be used as a library component, providing fitting and modeling&#10;capabilities to an application. We include a few examples of Sherpa&#10;applications to multiwavelength astronomical data. The code is available&#10;GitHub: https://github.com/sherpa/sherpa&#10; | General | [Link](http://arxiv.org/abs/2409.10400v1) |&#10;| Minimally coupled $$&#45;exponential inflation with an $R^2$ term in&#10; &#160;the Palatini formulation | Nilay Bostan, Rafid H. Dejrah | &#160;&#160;We focus on the inflationary predictions of $beta$&#45;exponential potential&#10;models, in which the inflaton is a representation of the field delineating the&#10;size of extra&#45;dimension. Since it offers a well&#45;motivated starting point for&#10;the study of physics at very high energies, we incorporate an $R^2$ term in the&#10;Palatini gravity. In addition, afterward the inflation, the inflaton oscillates&#10;about the minimum of the inflation potential, and reheats the universe. This&#10;occurs during the reheating phase, at which the inflaton decays into the&#10;standard model particles, which fill the universe. We extend our examination by&#10;considering the reheating effects on inflationary observables by employing the&#10;different scenarios of the reheat temperature. Supposing the standard thermal&#10;history after inflation, we display the inflationary predictions, $n_s, r,&#10;mathrm{d}n_s/mathrm{d}&#10;n k$ of $beta$&#45;exponential potential with minimal&#10;coupling in Palatini $R^2$ gravity. Also, different kinds of constraints from a&#10;variety of observations, such as BICEP/Keck, Planck 2018, as well as future&#10;possible detectable sensitivities that might be reached by CMB experiments:&#10;CMB&#45;S4 and LiteBIRD are taken into account in this work. We indicate that our&#10;results are consistent with both the latest data and the future sensitivity&#10;forecasts of LiteBIRD/Planck and CMB&#45;S4. Finally, the results in this study&#10;highlight the viability of our model even in the case of the existence of more&#10;stringent constraints expected from future achievable confidence level limits.&#10; | General | [Link](http://arxiv.org/abs/2409.10398v1) |&#10;| Quantifying Observational Projection Effects with a Simulation&#45;based hot&#10; &#160;CGM model | Soumya Shreeram, Johan Comparat, Andrea Merloni, Yi Zhang, Gabriele Ponti, Kirpal Nandra, John ZuHone, Ilaria Marini, Stephan Vladutescu&#45;Zopp, Paola Popesso, Ruediger Pakmor, Riccardo Seppi, Celine Peroux, Daniele Sorini | &#160;&#160;The hot phase of the circumgalactic medium (CGM) allows us to probe the&#10;inflow and outflow of gas within a galaxy, which is responsible for dictating&#10;the evolution of the galaxy. Studying the hot CGM sheds light on a better&#10;understanding of gas physics, which is crucial to inform and constrain&#10;simulation models. With the recent advances in observational measurements&#10;probing the hot CGM in X&#45;rays and tSZ, we have a new avenue for widening our&#10;knowledge of gas physics and feedback by exploiting the information from&#10;current/future observations. In this paper, we use the TNG300 hydrodynamical&#10;simulations to build a fully self&#45;consistent forward model for the hot CGM. We&#10;construct a lightcone and generate mock X&#45;ray observations. We quantify the&#10;projection effects, namely the locally correlated large&#45;scale structure in&#10;X&#45;rays and the effect due to satellite galaxies misclassified as centrals which&#10;affects the measured hot CGM galactocentric profiles in stacking experiments.&#10;We present an analytical model that describes the intrinsic X&#45;ray surface&#10;brightness profile across the stellar and halo mass bins. The increasing&#10;stellar mass bins result in decreasing values of $beta$, the exponent&#10;quantifying the slope of the intrinsic galactocentric profiles. We carry&#10;forward the current state&#45;of&#45;the&#45;art by also showing the impact of the locally&#10;correlated environment on the measured X&#45;ray surface brightness profiles. We&#10;also present, for the first time, the effect of misclassified centrals in&#10;stacking experiments for three stellar mass bins: $10^{10.5&#45;11} M_odot$,&#10;$10^{11&#45;11.2} M_odot$, and $10^{11.2&#45;11.5} M_odot$. We find that the&#10;contaminating effect of the misclassified centrals on the stacked profiles&#10;increases when the stellar mass decreases.&#10; | General | [Link](http://arxiv.org/abs/2409.10397v1) |&#10;| MOST: MR reconstruction Optimization for multiple downStream Tasks via&#10; &#160;continual learning | Hwihun Jeong, Se Young Chun, Jongho Lee | &#160;&#160;Deep learning&#45;based Magnetic Resonance (MR) reconstruction methods have&#10;focused on generating high&#45;quality images but they often overlook the impact on&#10;downstream tasks (e.g., segmentation) that utilize the reconstructed images.&#10;Cascading separately trained reconstruction network and downstream task network&#10;has been shown to introduce performance degradation due to error propagation&#10;and domain gaps between training datasets. To mitigate this issue, downstream&#10;task&#45;oriented reconstruction optimization has been proposed for a single&#10;downstream task. Expanding this optimization to multi&#45;task scenarios is not&#10;straightforward. In this work, we extended this optimization to sequentially&#10;introduced multiple downstream tasks and demonstrated that a single MR&#10;reconstruction network can be optimized for multiple downstream tasks by&#10;deploying continual learning (MOST). MOST integrated techniques from&#10;replay&#45;based continual learning and image&#45;guided loss to overcome catastrophic&#10;forgetting. Comparative experiments demonstrated that MOST outperformed a&#10;reconstruction network without finetuning, a reconstruction network with&#10;na&quot;ive finetuning, and conventional continual learning methods. This&#10;advancement empowers the application of a single MR reconstruction network for&#10;multiple downstream tasks. The source code is available at:&#10;https://github.com/SNU&#45;LIST/MOST&#10; | General | [Link](http://arxiv.org/abs/2409.10394v1) |&#10;| Multicopy quantum state teleportation with application to storage and&#10; &#160;retrieval of quantum programs | Frdric Grosshans, Micha Horodecki, Mio Murao, Tomasz Mynik, Marco Tlio Quintino, Micha Studziski, Satoshi Yoshida | &#160;&#160;This work considers a teleportation task for Alice and Bob in a scenario&#10;where Bob cannot perform corrections. In particular, we analyse the task of&#10;textit{multicopy state teleportation}, where Alice has $k$ identical copies of&#10;an arbitrary unknown $d$&#45;dimensional qudit state $vertpsi&#13;angle$ to teleport&#10;a single copy of $vertpsi&#13;angle$ to Bob using a maximally entangled&#10;two&#45;qudit state shared between Alice and Bob without Bob&#39;s correction. Alice&#10;may perform a joint measurement on her half of the entangled state and the $k$&#10;copies of $vertpsi&#13;angle$. We prove that the maximal probability of success&#10;for teleporting the exact state $vertpsi&#13;angle$ to Bob is&#10;$p(d,k)=frac{k}{d(k&#45;1+d)}$ and present an explicit protocol to attain this&#10;performance. Then, by utilising $k$ copies of an arbitrary target state&#10;$vertpsi&#13;angle$, we show how the multicopy state teleportation protocol can&#10;be employed to enhance the success probability of storage and retrieval of&#10;quantum programs, which aims to universally retrieve the action of an arbitrary&#10;quantum channel that is stored in a state. Our proofs make use of group&#10;representation theory methods, which may find applications beyond the problems&#10;addressed in this work.&#10; | General | [Link](http://arxiv.org/abs/2409.10393v1) |&#10;| TPFL: Tsetlin&#45;Personalized Federated Learning with Confidence&#45;Based&#10; &#160;Clustering | Rasoul Jafari Gohari, Laya Aliahmadipour, Ezat Valipour | &#160;&#160;The world of Machine Learning (ML) has witnessed rapid changes in terms of&#10;new models and ways to process users data. The majority of work that has been&#10;done is focused on Deep Learning (DL) based approaches. However, with the&#10;emergence of new algorithms such as the Tsetlin Machine (TM) algorithm, there&#10;is growing interest in exploring alternative approaches that may offer unique&#10;advantages in certain domains or applications. One of these domains is&#10;Federated Learning (FL), in which users privacy is of utmost importance. Due to&#10;its novelty, FL has seen a surge in the incorporation of personalization&#10;techniques to enhance model accuracy while maintaining user privacy under&#10;personalized conditions. In this work, we propose a novel approach dubbed TPFL:&#10;Tsetlin&#45;Personalized Federated Learning, in which models are grouped into&#10;clusters based on their confidence towards a specific class. In this way,&#10;clustering can benefit from two key advantages. Firstly, clients share only&#10;what they are confident about, resulting in the elimination of wrongful weight&#10;aggregation among clients whose data for a specific class may have not been&#10;enough during the training. This phenomenon is prevalent when the data are&#10;non&#45;Independent and Identically Distributed (non&#45;IID). Secondly, by sharing&#10;only weights towards a specific class, communication cost is substantially&#10;reduced, making TPLF efficient in terms of both accuracy and communication&#10;cost. The results of TPFL demonstrated the highest accuracy on three different&#10;datasets; namely MNIST, FashionMNIST and FEMNIST.&#10; | General | [Link](http://arxiv.org/abs/2409.10392v1) |&#10;| Prompt&#45;and&#45;Transfer: Dynamic Class&#45;aware Enhancement for Few&#45;shot&#10; &#160;Segmentation | Hanbo Bi, Yingchao Feng, Wenhui Diao, Peijin Wang, Yongqiang Mao, Kun Fu, Hongqi Wang, Xian Sun | &#160;&#160;For more efficient generalization to unseen domains (classes), most Few&#45;shot&#10;Segmentation (FSS) would directly exploit pre&#45;trained encoders and only&#10;fine&#45;tune the decoder, especially in the current era of large models. However,&#10;such fixed feature encoders tend to be class&#45;agnostic, inevitably activating&#10;objects that are irrelevant to the target class. In contrast, humans can&#10;effortlessly focus on specific objects in the line of sight. This paper mimics&#10;the visual perception pattern of human beings and proposes a novel and powerful&#10;prompt&#45;driven scheme, called ``Prompt and Transfer&quot; (PAT), which constructs a&#10;dynamic class&#45;aware prompting paradigm to tune the encoder for focusing on the&#10;interested object (target class) in the current task. Three key points are&#10;elaborated to enhance the prompting: 1) Cross&#45;modal linguistic information is&#10;introduced to initialize prompts for each task. 2) Semantic Prompt Transfer&#10;(SPT) that precisely transfers the class&#45;specific semantics within the images&#10;to prompts. 3) Part Mask Generator (PMG) that works in conjunction with SPT to&#10;adaptively generate different but complementary part prompts for different&#10;individuals. Surprisingly, PAT achieves competitive performance on 4 different&#10;tasks including standard FSS, Cross&#45;domain FSS (e.g., CV, medical, and remote&#10;sensing domains), Weak&#45;label FSS, and Zero&#45;shot Segmentation, setting new&#10;state&#45;of&#45;the&#45;arts on 11 benchmarks.&#10; | General | [Link](http://arxiv.org/abs/2409.10389v1) |&#10;| Revising the Structure of Recurrent Neural Networks to Eliminate&#10; &#160;Numerical Derivatives in Forming Physics Informed Loss Terms with Respect to&#10; &#160;Time | Mahyar Jahani&#45;nasab, Mohamad Ali Bijarchi | &#160;&#160;Solving unsteady partial differential equations (PDEs) using recurrent neural&#10;networks (RNNs) typically requires numerical derivatives between each block of&#10;the RNN to form the physics informed loss function. However, this introduces&#10;the complexities of numerical derivatives into the training process of these&#10;models. In this study, we propose modifying the structure of the traditional&#10;RNN to enable the prediction of each block over a time interval, making it&#10;possible to calculate the derivative of the output with respect to time using&#10;the backpropagation algorithm. To achieve this, the time intervals of these&#10;blocks are overlapped, defining a mutual loss function between them.&#10;Additionally, the employment of conditional hidden states enables us to achieve&#10;a unique solution for each block. The forget factor is utilized to control the&#10;influence of the conditional hidden state on the prediction of the subsequent&#10;block. This new model, termed the Mutual Interval RNN (MI&#45;RNN), is applied to&#10;solve three different benchmarks: the Burgers equation, unsteady heat&#10;conduction in an irregular domain, and the Green vortex problem. Our results&#10;demonstrate that MI&#45;RNN can find the exact solution more accurately compared to&#10;existing RNN models. For instance, in the second problem, MI&#45;RNN achieved one&#10;order of magnitude less relative error compared to the RNN model with numerical&#10;derivatives.&#10; | General | [Link](http://arxiv.org/abs/2409.10388v1) |&#10;| Sharp decay rate for eigenfunctions of perturbed periodic Schrdinger&#10; &#160;operators | Wencai Liu, Rodrigo Matos, John N. Treuer | &#160;&#160;This paper investigates uniqueness results for perturbed periodic&#10;Schr&quot;odinger operators on $mathbb{Z}^d$. Specifically, we consider operators&#10;of the form $H = &#45;Delta + V + v$, where $Delta$ is the discrete Laplacian,&#10;$V: mathbb{Z}^d &#13;ightarrow mathbb{R}$ is a periodic potential, and $v:&#10;mathbb{Z}^d &#13;ightarrow mathbb{C}$ represents a decaying impurity. We&#10;establish quantitative conditions under which the equation $&#45;Delta u + V u + v&#10;u = &#10;ambda u$, for $&#10;ambda in mathbb{C}$, admits only the trivial solution&#10;$u equiv 0$. Key applications include the absence of embedded eigenvalues for&#10;operators with impurities decaying faster than any exponential function and the&#10;determination of sharp decay rates for eigenfunctions. Our findings extend&#10;previous works by providing precise decay conditions for impurities and&#10;analyzing different spectral regimes of $&#10;ambda$.&#10; | General | [Link](http://arxiv.org/abs/2409.10387v1) |&#10;| Mamba&#45;ST: State Space Model for Efficient Style Transfer | Filippo Botti, Alex Ergasti, Leonardo Rossi, Tomaso Fontanini, Claudio Ferrari, Massimo Bertozzi, Andrea Prati | &#160;&#160;The goal of style transfer is, given a content image and a style source,&#10;generating a new image preserving the content but with the artistic&#10;representation of the style source. Most of the state&#45;of&#45;the&#45;art architectures&#10;use transformers or diffusion&#45;based models to perform this task, despite the&#10;heavy computational burden that they require. In particular, transformers use&#10;self&#45; and cross&#45;attention layers which have large memory footprint, while&#10;diffusion models require high inference time. To overcome the above, this paper&#10;explores a novel design of Mamba, an emergent State&#45;Space Model (SSM), called&#10;Mamba&#45;ST, to perform style transfer. To do so, we adapt Mamba linear equation&#10;to simulate the behavior of cross&#45;attention layers, which are able to combine&#10;two separate embeddings into a single output, but drastically reducing memory&#10;usage and time complexity. We modified the Mamba&#39;s inner equations so to accept&#10;inputs from, and combine, two separate data streams. To the best of our&#10;knowledge, this is the first attempt to adapt the equations of SSMs to a vision&#10;task like style transfer without requiring any other module like&#10;cross&#45;attention or custom normalization layers. An extensive set of experiments&#10;demonstrates the superiority and efficiency of our method in performing style&#10;transfer compared to transformers and diffusion models. Results show improved&#10;quality in terms of both ArtFID and FID metrics. Code is available at&#10;https://github.com/FilippoBotti/MambaST.&#10; | General | [Link](http://arxiv.org/abs/2409.10385v1) |&#10;| Performance&#45;Portable Numerical Relativity with AthenaK | Hengrui Zhu, Jacob Fields, Francesco Zappa, David Radice, James Stone, Alireza Rashti, William Cook, Sebastiano Bernuzzi, Boris Daszuta | &#160;&#160;We present the numerical relativity module within AthenaK, an open source&#10;performance&#45;portable astrophysics code designed for exascale computing&#10;applications. This module employs the Z4c formulation to solve the Einstein&#10;equations. We demonstrate its accuracy through a series of standard numerical&#10;relativity tests, including convergence of the gravitational waveform from&#10;binary black hole coalescence. Furthermore, we conduct scaling tests on OLCF&#10;Frontier and NERSC Perlmutter, where AthenaK exhibits excellent weak scaling&#10;efficiency of 80% on up to 65,536 AMD MI250X GPUs on Frontier (relative to 4&#10;GPUs) and strong scaling efficiencies of 84% and 77% on AMD MI250X and NVIDIA&#10;A100 GPUs on Frontier and Perlmutter respectively. Additionally, we observe a&#10;significant performance boost, with two orders of magnitude speedup ($gtrsim&#10;200times$) on a GPU compared to a single CPU core, affirming that AthenaK is&#10;well&#45;suited for exascale computing, thereby expanding the potential for&#10;breakthroughs in numerical relativity research.&#10; | General | [Link](http://arxiv.org/abs/2409.10383v1) |&#10;| J&#45;UBIK: The JAX&#45;accelerated Universal Bayesian Imaging Kit | Vincent Eberle, Matteo Guardiani, Margret Westerkamp, Philipp Frank, Julian Rstig, Julia Stadler, Torsten A. Enlin | &#160;&#160;Many advances in astronomy and astrophysics originate from accurate images of&#10;the sky emission across multiple wavelengths. This often requires&#10;reconstructing spatially and spectrally correlated signals detected from&#10;multiple instruments. To facilitate the high&#45;fidelity imaging of these signals,&#10;we introduce the universal Bayesian imaging kit (UBIK). Specifically, we&#10;present J&#45;UBIK, a flexible and modular implementation leveraging the&#10;JAX&#45;accelerated NIFTy.re software as its backend. J&#45;UBIK streamlines the&#10;implementation of the key Bayesian inference components, providing for all the&#10;necessary steps of Bayesian imaging pipelines. First, it provides adaptable&#10;prior models for different sky realizations. Second, it includes likelihood&#10;models tailored to specific instruments. So far, the package includes three&#10;instruments: Chandra and eROSITA for X&#45;ray observations, and the James Webb&#10;Space Telescope (JWST) for the near&#45; and mid&#45;infrared. The aim is to expand&#10;this set in the future. Third, these models can be integrated with various&#10;inference and optimization schemes, such as maximum a posteriori estimation and&#10;variational inference. Explicit demos show how to integrate the individual&#10;modules into a full analysis pipeline. Overall, J&#45;UBIK enables efficient&#10;generation of high&#45;fidelity images via Bayesian pipelines that can be tailored&#10;to specific research objectives.&#10; | General | [Link](http://arxiv.org/abs/2409.10381v1) |&#10;| Thermolectricity in irradiated bilayer graphene flakes | Cynthia Ihuoma Osuala, Tanu Choudhary, Raju K. Biswas, Sudin Ganguly, Chunlei Qu, Santanu K. Maiti | &#160;&#160;We present a comprehensive study on enhancing the thermoelectric (TE)&#10;performance of bilayer graphene (BLG) through irradiation with arbitrarily&#10;polarized light, focusing on $AA$&#45; and $AB$&#45;stacked configurations with zigzag&#10;edges. Utilizing a combination of tight&#45;binding theory and density functional&#10;theory (DFT), we systematically analyze the impact of light irradiation on&#10;electronic and phononic transport properties. Light irradiation alters the&#10;electronic hopping parameters, creating an asymmetric transmission function,&#10;which significantly increases the Seebeck coefficient, thereby boosting the&#10;overall {it figure of merit} (FOM). For the phononic contribution, DFT&#10;calculations reveal that $AB$&#45;stacked BLG exhibits lower lattice thermal&#10;conductivity compared to $AA$&#45;stacked, attributed to enhanced anharmonic&#10;scattering and phonon group velocity. The combined analysis shows that FOM&#10;exceeds unity in both stacking types, with notable improvements near the&#10;irradiation&#45;induced gap. Additionally, we explore the dependence of FOM on the&#10;system dimensions and temperature, demonstrating that light&#45;irradiated BLG&#10;holds great promise for efficient thermoelectric energy conversion and waste&#10;heat recovery. Our results show favorable responses over a wide range of&#10;irradiation parameters. These findings provide crucial insights into optimizing&#10;BLG for advanced TE applications through light&#45;induced modifications.&#10; | General | [Link](http://arxiv.org/abs/2409.10380v1) |&#10;| Leveraging Joint Spectral and Spatial Learning with MAMBA for&#10; &#160;Multichannel Speech Enhancement | Wenze Ren, Haibin Wu, Yi&#45;Cheng Lin, Xuanjun Chen, Rong Chao, Kuo&#45;Hsuan Hung, You&#45;Jin Li, Wen&#45;Yuan Ting, Hsin&#45;Min Wang, Yu Tsao | &#160;&#160;In multichannel speech enhancement, effectively capturing spatial and&#10;spectral information across different microphones is crucial for noise&#10;reduction. Traditional methods, such as CNN or LSTM, attempt to model the&#10;temporal dynamics of full&#45;band and sub&#45;band spectral and spatial features.&#10;However, these approaches face limitations in fully modeling complex temporal&#10;dependencies, especially in dynamic acoustic environments. To overcome these&#10;challenges, we modify the current advanced model McNet by introducing an&#10;improved version of Mamba, a state&#45;space model, and further propose MCMamba.&#10;MCMamba has been completely reengineered to integrate full&#45;band and narrow&#45;band&#10;spatial information with sub&#45;band and full&#45;band spectral features, providing a&#10;more comprehensive approach to modeling spatial and spectral information. Our&#10;experimental results demonstrate that MCMamba significantly improves the&#10;modeling of spatial and spectral features in multichannel speech enhancement,&#10;outperforming McNet and achieving state&#45;of&#45;the&#45;art performance on the CHiME&#45;3&#10;dataset. Additionally, we find that Mamba performs exceptionally well in&#10;modeling spectral information.&#10; | General | [Link](http://arxiv.org/abs/2409.10376v1) |&#10;| Nonlinear Causality in Brain Networks: With Application to Motor Imagery&#10; &#160;vs Execution | Sipan Aslan, Hernando Ombao | &#160;&#160;One fundamental challenge of data&#45;driven analysis in neuroscience is modeling&#10;causal interactions and exploring the connectivity of nodes in a brain network.&#10;Various statistical methods, relying on various perspectives and employing&#10;different data modalities, are being developed to examine and comprehend the&#10;underlying causal structures inherent to brain dynamics. This study introduces&#10;a novel statistical approach, TAR4C, to dissect causal interactions in&#10;multichannel EEG recordings. TAR4C uses the threshold autoregressive model to&#10;describe the causal interaction between nodes or clusters of nodes in a brain&#10;network. The perspective involves testing whether one node, which may represent&#10;a brain region, can control the dynamics of the other. The node that has such&#10;an impact on the other is called a threshold variable and can be classified as&#10;a causative because its functionality is the leading source operating as an&#10;instantaneous switching mechanism that regulates the time&#45;varying&#10;autoregressive structure of the other. This statistical concept is commonly&#10;referred to as threshold non&#45;linearity. Once threshold non&#45;linearity has been&#10;verified between a pair of nodes, the subsequent essential facet of TAR&#10;modeling is to assess the predictive ability of the causal node for the current&#10;activity on the other and represent causal interactions in autoregressive&#10;terms. This predictive ability is what underlies Granger causality. The TAR4C&#10;approach can discover non&#45;linear and time&#45;dependent causal interactions without&#10;negating the G&#45;causality perspective. The efficacy of the proposed approach is&#10;exemplified by analyzing the EEG signals recorded during the motor&#10;movement/imagery experiment. The similarities and differences between the&#10;causal interactions manifesting during the execution and the imagery of a given&#10;motor movement are demonstrated by analyzing EEG recordings from multiple&#10;subjects.&#10; | General | [Link](http://arxiv.org/abs/2409.10374v1) |&#10;| Instigating Cooperation among LLM Agents Using Adaptive Information&#10; &#160;Modulation | Qiliang Chen, &#160;Alireza, &#160;Ilami, Nunzio Lore, Babak Heydari | &#160;&#160;This paper introduces a novel framework combining LLM agents as proxies for&#10;human strategic behavior with reinforcement learning (RL) to engage these&#10;agents in evolving strategic interactions within team environments. Our&#10;approach extends traditional agent&#45;based simulations by using strategic LLM&#10;agents (SLA) and introducing dynamic and adaptive governance through a&#10;pro&#45;social promoting RL agent (PPA) that modulates information access across&#10;agents in a network, optimizing social welfare and promoting pro&#45;social&#10;behavior. Through validation in iterative games, including the prisoner&#10;dilemma, we demonstrate that SLA agents exhibit nuanced strategic adaptations.&#10;The PPA agent effectively learns to adjust information transparency, resulting&#10;in enhanced cooperation rates. This framework offers significant insights into&#10;AI&#45;mediated social dynamics, contributing to the deployment of AI in real&#45;world&#10;team settings.&#10; | General | [Link](http://arxiv.org/abs/2409.10372v1) |&#10;| Learning Gentle Grasping from Human&#45;Free Force Control Demonstration | Mingxuan Li, Lunwei Zhang, Tiemin Li, Yao Jiang | &#160;&#160;Humans can steadily and gently grasp unfamiliar objects based on tactile&#10;perception. Robots still face challenges in achieving similar performance due&#10;to the difficulty of learning accurate grasp&#45;force predictions and force&#10;control strategies that can be generalized from limited data. In this article,&#10;we propose an approach for learning grasping from ideal force control&#10;demonstrations, to achieve similar performance of human hands with limited data&#10;size. Our approach utilizes objects with known contact characteristics to&#10;automatically generate reference force curves without human demonstrations. In&#10;addition, we design the dual convolutional neural networks (Dual&#45;CNN)&#10;architecture which incorporating a physics&#45;based mechanics module for learning&#10;target grasping force predictions from demonstrations. The described method can&#10;be effectively applied in vision&#45;based tactile sensors and enables gentle and&#10;stable grasping of objects from the ground. The described prediction model and&#10;grasping strategy were validated in offline evaluations and online experiments,&#10;and the accuracy and generalizability were demonstrated.&#10; | General | [Link](http://arxiv.org/abs/2409.10371v1) |&#10;| Uncovering the Mechanism of Hepatotoxiciy of PFAS Targeting L&#45;FABP Using&#10; &#160;GCN and Computational Modeling | Lucas Jividen, Tibo Duran, Xi&#45;Zhi Niu, Jun Bai | &#160;&#160;Per&#45; and polyfluoroalkyl substances (PFAS) are persistent environmental&#10;pollutants with known toxicity and bioaccumulation issues. Their widespread&#10;industrial use and resistance to degradation have led to global environmental&#10;contamination and significant health concerns. While a minority of PFAS have&#10;been extensively studied, the toxicity of many PFAS remains poorly understood&#10;due to limited direct toxicological data. This study advances the predictive&#10;modeling of PFAS toxicity by combining semi&#45;supervised graph convolutional&#10;networks (GCNs) with molecular descriptors and fingerprints. We propose a novel&#10;approach to enhance the prediction of PFAS binding affinities by isolating&#10;molecular fingerprints to construct graphs where then descriptors are set as&#10;the node features. This approach specifically captures the structural,&#10;physicochemical, and topological features of PFAS without overfitting due to an&#10;abundance of features. Unsupervised clustering then identifies representative&#10;compounds for detailed binding studies. Our results provide a more accurate&#10;ability to estimate PFAS hepatotoxicity to provide guidance in chemical&#10;discovery of new PFAS and the development of new safety regulations.&#10; | General | [Link](http://arxiv.org/abs/2409.10370v1) |&#10;| Stochastic Control of UAVs: An Optimal Tradeoff between Performance,&#10; &#160;Flight Smoothness and Control Effort | George Rapakoulias, Panagiotis Tsiotras | &#160;&#160;Safe and accurate control of unmanned aerial vehicles in the presence of&#10;winds is a challenging control problem due to the hard&#45;to&#45;model and highly&#10;stochastic nature of the disturbance forces acting upon the vehicle. To meet&#10;performance constraints, state&#45;of&#45;the&#45;art control methods such as Incremental&#10;Nonlinear Dynamic Inversion (INDI) or other adaptive control techniques require&#10;high control gains to mitigate the effects of uncertainty entering the system.&#10;While achieving good tracking performance, IDNI requires excessive control&#10;effort, results in high actuator strain, and reduced flight smoothness due to&#10;constant and aggressive corrective actions commanded by the controller. In this&#10;paper, we propose a novel control architecture that allows the user to&#10;systematically address the trade&#45;off between high authority control and&#10;performance constraint satisfaction. Our approach consists of two parts. To&#10;cancel out biases introduced by unmodelled aerodynamic effects we propose a&#10;hybrid, model&#45;based disturbance force estimator augmented with a neural&#10;network, that can adapt to external wind conditions using a Kalman Filter. We&#10;then utilize state&#45;of&#45;the&#45;art results from Covariance Steering theory, which&#10;offers a principled way of controlling the uncertainty of the tracking error&#10;dynamics. We first analyze the properties of the combined system and then&#10;provide extensive experimental results to verify the advantages of the proposed&#10;approach over existing methods&#10; | General | [Link](http://arxiv.org/abs/2409.10369v1) |&#10;| Integrated nowcasting of convective precipitation with Transformer&#45;based&#10; &#160;models using multi&#45;source data | alar Kk, Aitor Atencia, Markus Dabernig | &#160;&#160;Precipitation nowcasting is crucial for mitigating the impacts of severe&#10;weather events and supporting daily activities. Conventional models&#10;predominantly relying on radar data have limited performance in predicting&#10;cases with complex temporal features such as convection initiation,&#10;highlighting the need to integrate data from other sources for more&#10;comprehensive nowcasting. Unlike physics&#45;based models, machine learning&#10;(ML)&#45;based models offer promising solutions for efficiently integrating large&#10;volumes of diverse data. We present EF4INCA, a spatiotemporal Transformer model&#10;for precipitation nowcasting that integrates satellite&#45; and ground&#45;based&#10;observations with numerical weather prediction outputs. EF4INCA provides&#10;high&#45;resolution forecasts over Austria, accurately predicting the location and&#10;shape of precipitation fields with a spatial resolution of 1 kilometre and a&#10;temporal resolution of 5 minutes, up to 90 minutes ahead. Our evaluation shows&#10;that EF4INCA outperforms conventional nowcasting models, including the&#10;operational model of Austria, particularly in scenarios with complex temporal&#10;features such as convective initiation and rapid weather changes. EF4INCA&#10;maintains higher accuracy in location forecasting but generates smoother fields&#10;at later prediction times compared to traditional models. Interpretation of our&#10;model showed that precipitation products and SEVIRI infrared channels CH7 and&#10;CH9 are the most important data streams. These results underscore the&#10;importance of combining data from different domains, including physics&#45;based&#10;model products, with ML approaches. Our study highlights the robustness of&#10;EF4INCA and its potential for improved precipitation nowcasting. We provide&#10;access to our code repository, model weights, and the dataset curated for&#10;benchmarking, facilitating further development and application.&#10; | General | [Link](http://arxiv.org/abs/2409.10367v1) |&#10;&#10;">
<text font-weight="bold" text-anchor="middle" x="2805" y="-567.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922637023056_5 -->
<g id="node72" class="node">
<title>139922637023056_5</title>
<ellipse fill="#fbdbd5" stroke="#c8a8a2" stroke-width="3" cx="1798" cy="-528" rx="60.39" ry="18"/>
<text text-anchor="middle" x="1798" y="-524.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Planner (5)</text>
</g>
<!-- 139922752308304_6&#45;&gt;139922637023056_5 -->
<g id="edge80" class="edge">
<title>139922752308304_6&#45;&gt;139922637023056_5</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M2198.61,-611.42C2126.43,-607.85 2022.64,-599.33 1934,-579 1901.35,-571.51 1865.88,-558.29 1839.34,-547.32"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1840.57,-544.04 1830,-543.4 1837.86,-550.49 1840.57,-544.04"/>
<g id="a_edge80&#45;label"><a xlink:title="exitcode: 0 (execution succeeded)&#10;Code output: &#10;| Title | Authors | Abstract | Domain | Source URL |&#10;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#10;| The VIRUS&#45;dE Survey I: Stars in dwarf elliptical galaxies &#45; 3D dynamics&#10; &#160;and radially resolved stellar initial mass functions | Mathias Lipka, Jens Thomas, Roberto Saglia, Ralf Bender, Maximilian Fabricius, Gary J. Hill, Matthias Kluge, Martin Landriau, Ximena Mazzalay, Eva Noyola, Taniya Parikh, Jan Snigula | &#160;&#160;We analyse the stellar structure of a sample of dwarf ellipticals (dE)&#10;inhabiting various environments within the Virgo cluster. Integral&#45;field&#10;observations with a high spectral resolution allow us to robustly determine&#10;their low velocity dispersions ($sim25$ km s$^{&#45;1}$) and higher&#45;order&#10;kinematic moments out to the half&#45;light radius. We find the dEs exhibit a&#10;diversity in ages with the younger dEs being less enhanced than the older,&#10;suggesting a complex star formation history for those dEs that recently entered&#10;Virgo while others have been quenched shortly after reionization.&#10;Orbit&#45;superposition modeling allowed us to recover viewing angles, stellar&#10;mass&#45;to&#45;light ratios (with gradients), as well as the intrinsic orbit&#10;structure. We find that the angular momentum of the dEs is strongly suppressed&#10;compared to ordinary early&#45;type galaxies and correlates with the environment.&#10;Flattened dEs are so because of a suppressed kinetic energy perpendicular to&#10;their equatorial plane. Combining population and dynamical modeling results, we&#10;find an age&#45;dependent stellar initial mass function (IMF) or, alternatively,&#10;evidence for a more extended star formation history for those galaxies that&#10;have had higher initial mass and/or inhabited lower density environments. dEs&#10;appear to have a spatially homogeneous stellar structure but the state they&#10;were `frozen&#39; in as they stopped forming stars varies dramatically according to&#10;their initial conditions.&#10; | General | [Link](http://arxiv.org/abs/2409.10518v1) |&#10;| RetrievalAttention: Accelerating Long&#45;Context LLM Inference via Vector&#10; &#160;Retrieval | Di Liu, Meng Chen, Baotong Lu, Huiqiang Jiang, Zhenhua Han, Qianxi Zhang, Qi Chen, Chengruidong Zhang, Bailu Ding, Kai Zhang, Chen Chen, Fan Yang, Yuqing Yang, Lili Qiu | &#160;&#160;Transformer&#45;based large Language Models (LLMs) become increasingly important&#10;in various domains. However, the quadratic time complexity of attention&#10;operation poses a significant challenge for scaling to longer contexts due to&#10;the extremely high inference latency and GPU memory consumption for caching&#10;key&#45;value (KV) vectors. This paper proposes RetrievalAttention, a training&#45;free&#10;approach to accelerate attention computation. To leverage the dynamic sparse&#10;property of attention, RetrievalAttention builds approximate nearest neighbor&#10;search (ANNS) indexes upon KV vectors in CPU memory and retrieves the most&#10;relevant ones via vector search during generation. Due to the&#10;out&#45;of&#45;distribution (OOD) between query vectors and key vectors, off&#45;the&#45;shelf&#10;ANNS indexes still need to scan O(N) (usually 30% of all keys) data for&#10;accurate retrieval, which fails to exploit the high sparsity.&#10;RetrievalAttention first identifies the OOD challenge of ANNS&#45;based attention,&#10;and addresses it via an attention&#45;aware vector search algorithm that can adapt&#10;to queries and only access 1&#45;&#45;3% of data, thus achieving a sub&#45;linear time&#10;complexity. RetrievalAttention greatly reduces the inference cost of&#10;long&#45;context LLM with much lower GPU memory requirements while maintaining the&#10;model accuracy. Especially, RetrievalAttention only needs 16GB GPU memory for&#10;serving 128K tokens in LLMs with 8B parameters, which is capable of generating&#10;one token in 0.188 seconds on a single NVIDIA RTX4090 (24GB).&#10; | General | [Link](http://arxiv.org/abs/2409.10516v1) |&#10;| An Efficient Self&#45;Learning Framework For Interactive Spoken Dialog&#10; &#160;Systems | Hitesh Tulsiani, David M. Chan, Shalini Ghosh, Garima Lalwani, Prabhat Pandey, Ankish Bansal, Sri Garimella, Ariya Rastrow, Bjrn Hoffmeister | &#160;&#160;Dialog systems, such as voice assistants, are expected to engage with users&#10;in complex, evolving conversations. Unfortunately, traditional automatic speech&#10;recognition (ASR) systems deployed in such applications are usually trained to&#10;recognize each turn independently and lack the ability to adapt to the&#10;conversational context or incorporate user feedback. In this work, we introduce&#10;a general framework for ASR in dialog systems that can go beyond learning from&#10;single&#45;turn utterances and learn over time how to adapt to both explicit&#10;supervision and implicit user feedback present in multi&#45;turn conversations. We&#10;accomplish that by leveraging advances in student&#45;teacher learning and&#10;context&#45;aware dialog processing, and designing contrastive self&#45;supervision&#10;approaches with Ohm, a new online hard&#45;negative mining approach. We show that&#10;leveraging our new framework compared to traditional training leads to relative&#10;WER reductions of close to 10% in real&#45;world dialog systems, and up to 26% on&#10;public synthetic data.&#10; | General | [Link](http://arxiv.org/abs/2409.10515v1) |&#10;| Constraints on axions from patchy screening of the cosmic microwave&#10; &#160;background | Samuel Goldstein, Fiona McCarthy, Cristina Mondino, J. Colin Hill, Junwu Huang, Matthew C. Johnson | &#160;&#160;The resonant conversion of cosmic microwave background (CMB) photons into&#10;axions within large&#45;scale structure induces an anisotropic spectral distortion&#10;in CMB temperature maps. Applying state&#45;of&#45;the&#45;art foreground cleaning&#10;techniques to $textit{Planck}$ CMB observations, we construct maps of&#10;axion&#45;induced &quot;patchy screening&quot; of the CMB. We cross&#45;correlate these maps with&#10;data from the $textit{unWISE}$ galaxy survey and find no evidence of axions.&#10;We constrain the axion&#45;photon coupling, $g_{agammagamma} &#10;esssim 2 times&#10;10^{&#45;12}~{&#13;m GeV}^{&#45;1}$, at the 95% confidence level for axion masses in the&#10;range $10^{&#45;13}~{&#13;m eV} &#10;esssim m_a &#10;esssim 10^{&#45;12}~{&#13;m eV}$. These&#10;constraints are competitive with the tightest astrophysical axion limits in&#10;this mass range and are inferred from robust population&#45;level statistics, which&#10;makes them complementary to existing searches that rely on modeling of&#10;individual systems.&#10; | General | [Link](http://arxiv.org/abs/2409.10514v1) |&#10;| Weak Superimposed Codes of Improved Asymptotic Rate and Their Randomized&#10; &#160;Construction | Yu Tsunoda, Yuichiro Fujiwara | &#160;&#160;Weak superimposed codes are combinatorial structures related closely to&#10;generalized cover&#45;free families, superimposed codes, and disjunct matrices in&#10;that they are only required to satisfy similar but less stringent conditions.&#10;This class of codes may also be seen as a stricter variant of what are known as&#10;locally thin families in combinatorics. Originally, weak superimposed codes&#10;were introduced in the context of multimedia content protection against illegal&#10;distribution of copies under the assumption that a coalition of malicious users&#10;may employ the averaging attack with adversarial noise. As in many other kinds&#10;of codes in information theory, it is of interest and importance in the study&#10;of weak superimposed codes to find the highest achievable rate in the&#10;asymptotic regime and give an efficient construction that produces an infinite&#10;sequence of codes that achieve it. Here, we prove a tighter lower bound than&#10;the sharpest known one on the rate of optimal weak superimposed codes and give&#10;a polynomial&#45;time randomized construction algorithm for codes that&#10;asymptotically attain our improved bound with high probability. Our&#10;probabilistic approach is versatile and applicable to many other related codes&#10;and arrays.&#10; | General | [Link](http://arxiv.org/abs/2409.10511v1) |&#10;| Pennsieve &#45; A Collaborative Platform for Translational Neuroscience and&#10; &#160;Beyond | Zack Goldblum, Zhongchuan Xu, Haoer Shi, Patryk Orzechowski, Jamaal Spence, Kathryn A Davis, Brian Litt, Nishant Sinha, Joost Wagenaar | &#160;&#160;The exponential growth of neuroscientific data necessitates platforms that&#10;facilitate data management and multidisciplinary collaboration. In this paper,&#10;we introduce Pennsieve &#45; an open&#45;source, cloud&#45;based scientific data management&#10;platform built to meet these needs. Pennsieve supports complex multimodal&#10;datasets and provides tools for data visualization and analyses. It takes a&#10;comprehensive approach to data integration, enabling researchers to define&#10;custom metadata schemas and utilize advanced tools to filter and query their&#10;data. Pennsieve&#39;s modular architecture allows external applications to extend&#10;its capabilities, and collaborative workspaces with peer&#45;reviewed data&#10;publishing mechanisms promote high&#45;quality datasets optimized for downstream&#10;analysis, both in the cloud and on&#45;premises.&#10; &#160;Pennsieve forms the core for major neuroscience research programs including&#10;the NIH SPARC Initiative, NIH HEAL Initiative&#39;s PRECISION Human Pain Network,&#10;and NIH HEAL RE&#45;JOIN Initiative. It serves more than 80 research groups&#10;worldwide, along with several large&#45;scale, inter&#45;institutional projects at&#10;clinical sites through the University of Pennsylvania. Underpinning the&#10;SPARC.Science, Epilepsy.Science, and Pennsieve Discover portals, Pennsieve&#10;stores over 125 TB of scientific data, with 35 TB of data publicly available&#10;across more than 350 high&#45;impact datasets. It adheres to the findable,&#10;accessible, interoperable, and reusable (FAIR) principles of data sharing and&#10;is recognized as one of the NIH&#45;approved Data Repositories. By facilitating&#10;scientific data management, discovery, and analysis, Pennsieve fosters a robust&#10;and collaborative research ecosystem for neuroscience and beyond.&#10; | General | [Link](http://arxiv.org/abs/2409.10509v1) |&#10;| General&#45;relativistic resistive&#45;magnetohydrodynamics simulations of&#10; &#160;self&#45;consistent magnetized rotating neutron stars | Patrick Chi&#45;Kit Cheong, Antonios Tsokaros, Milton Ruiz, Fabrizio Venturi, Juno Chun Lung Chan, Anson Ka Long Yip, Koji Uryu | &#160;&#160;We present the first general&#45;relativistic resistive magnetohydrodynamics&#10;simulations of self&#45;consistent, rotating neutron stars with mixed poloidal and&#10;toroidal magnetic fields. Specifically, we investigate the role of resistivity&#10;in the dynamical evolution of neutron stars over a period of up to 100 ms and&#10;its effects on their quasi&#45;equilibrium configurations. Our results demonstrate&#10;that resistivity can significantly influence the development of&#10;magnetohydrodynamic instabilities, resulting in markedly different magnetic&#10;field geometries. Additionally, resistivity suppresses the growth of these&#10;instabilities, leading to a reduction in the amplitude of emitted gravitational&#10;waves. Despite the variations in magnetic field geometries, the ratio of&#10;poloidal to toroidal field energies remains consistently 9:1 throughout the&#10;simulations, for the models we investigated.&#10; | General | [Link](http://arxiv.org/abs/2409.10508v1) |&#10;| Beth&#45;Uhlenbeck equation for the thermodynamics of fluctuations in a&#10; &#160;generalised 2+1D Gross&#45;Neveu model | Biplab Mahato, David Blaschke, Dietmar Ebert | &#160;&#160;We study a generalised version of Gross&#45;Neveu model in 2+1 dimensions. The&#10;model is inspired from graphene which shows a linear dispersion relation near&#10;the Dirac points. The phase structure and the thermodynamic properties in the&#10;mean field approximation have been studied before. Here we go beyond the mean&#10;field level by deriving a Beth&#45;Uhlenbeck equation for Gaussian fluctuations,&#10;solutions of which we explore numerically, for the first time including their&#10;momentum dependence. We discuss the excitonic mass, fluctuation pressure and&#10;phase shifts. We also perform a comparison with the NJL model in 3+1 dimension&#10;and discuss its implication for graphene.&#10; | General | [Link](http://arxiv.org/abs/2409.10507v1) |&#10;| Context&#45;aware Code Segmentation for C&#45;to&#45;Rust Translation using Large&#10; &#160;Language Models | Momoko Shiraishi, Takahiro Shinagawa | &#160;&#160;There is strong motivation to translate C code into Rust code due to the&#10;continuing threat of memory safety vulnerabilities in existing C programs and&#10;the significant attention paid to Rust as an alternative to the C language.&#10;While large language models (LLMs) show promise for automating this translation&#10;by generating more natural and safer code than rule&#45;based methods, previous&#10;studies have shown that LLM&#45;generated Rust code often fails to compile, even&#10;for relatively small C programs, due to significant differences between the two&#10;languages and context window limitations. We propose an LLM&#45;based translation&#10;scheme that improves the success rate of translating large&#45;scale C code into&#10;compilable Rust code. Our approach involves three key techniques: (1)&#10;pre&#45;processing the C code to better align its structure and expressions with&#10;Rust, (2) segmenting the code into optimally sized translation units to avoid&#10;exceeding the LLM&#39;s context window limits, and (3) iteratively compiling and&#10;repairing errors while maintaining consistency between translation units using&#10;context&#45;supplementing prompts. Compilation success is an essential first step&#10;in achieving functional equivalence, as only compilable code can be further&#10;tested. In experiments with 20 benchmark C programs, including those exceeding&#10;4 kilo lines of code, we successfully translated all programs into compilable&#10;Rust code without losing corresponding parts of the original code.&#10; | General | [Link](http://arxiv.org/abs/2409.10506v1) |&#10;| Machine Learning Optimization of non&#45;Kasha Behavior and of Transient&#10; &#160;Dynamics in Model Retinal Isomerization | Davinder Singh, Chern Chuang, Paul Brumer | &#160;&#160;Designing a model of retinal isomerization in Rhodopsin, the first step in&#10;vision, that accounts for both experimental transient and stationary state&#10;observables is challenging. Here, multi&#45;objective Bayesian optimization is&#10;employed to refine the parameters of a minimal two&#45;state&#45;two&#45;mode (TM) model&#10;describing the photoisomerization of retinal in Rhodopsin. With an appropriate&#10;selection of objectives, the optimized retinal model predicts excitation&#10;wavelength&#45;dependent fluorescence spectra that closely align with&#10;experimentally observed non&#45;Kasha behavior in the non&#45;equilibrium steady state.&#10;Further, adjustments to the potential energy surface within the TM model reduce&#10;the discrepancies across the time domain. Overall, agreement with experimental&#10;data is excellent.&#10; | General | [Link](http://arxiv.org/abs/2409.10505v1) |&#10;| DILA: Dictionary Label Attention for Mechanistic Interpretability in&#10; &#160;High&#45;dimensional Multi&#45;label Medical Coding Prediction | John Wu, David Wu, Jimeng Sun | &#160;&#160;Predicting high&#45;dimensional or extreme multilabels, such as in medical&#10;coding, requires both accuracy and interpretability. Existing works often rely&#10;on local interpretability methods, failing to provide comprehensive&#10;explanations of the overall mechanism behind each label prediction within a&#10;multilabel set. We propose a mechanistic interpretability module called&#10;DIctionary Label Attention (method) that disentangles uninterpretable dense&#10;embeddings into a sparse embedding space, where each nonzero element (a&#10;dictionary feature) represents a globally learned medical concept. Through&#10;human evaluations, we show that our sparse embeddings are more human&#10;understandable than its dense counterparts by at least 50 percent. Our&#10;automated dictionary feature identification pipeline, leveraging large language&#10;models (LLMs), uncovers thousands of learned medical concepts by examining and&#10;summarizing the highest activating tokens for each dictionary feature. We&#10;represent the relationships between dictionary features and medical codes&#10;through a sparse interpretable matrix, enhancing the mechanistic and global&#10;understanding of the model&#39;s predictions while maintaining competitive&#10;performance and scalability without extensive human annotation.&#10; | General | [Link](http://arxiv.org/abs/2409.10504v1) |&#10;| Causal Language Modeling Can Elicit Search and Reasoning Capabilities on&#10; &#160;Logic Puzzles | Kulin Shah, Nishanth Dikkala, Xin Wang, Rina Panigrahy | &#160;&#160;Causal language modeling using the Transformer architecture has yielded&#10;remarkable capabilities in Large Language Models (LLMs) over the last few&#10;years. However, the extent to which fundamental search and reasoning&#10;capabilities emerged within LLMs remains a topic of ongoing debate. In this&#10;work, we study if causal language modeling can learn a complex task such as&#10;solving Sudoku puzzles. To solve a Sudoku, the model is first required to&#10;search over all empty cells of the puzzle to decide on a cell to fill and then&#10;apply an appropriate strategy to fill the decided cell. Sometimes, the&#10;application of a strategy only results in thinning down the possible values in&#10;a cell rather than concluding the exact value of the cell. In such cases,&#10;multiple strategies are applied one after the other to fill a single cell. We&#10;observe that Transformer models trained on this synthetic task can indeed learn&#10;to solve Sudokus (our model solves $94.21%$ of the puzzles fully correctly)&#10;when trained on a logical sequence of steps taken by a solver. We find that&#10;training Transformers with the logical sequence of steps is necessary and&#10;without such training, they fail to learn Sudoku. We also extend our analysis&#10;to Zebra puzzles (known as Einstein puzzles) and show that the model solves&#10;$92.04 %$ of the puzzles fully correctly. In addition, we study the internal&#10;representations of the trained Transformer and find that through linear&#10;probing, we can decode information about the set of possible values in any&#10;given cell from them, pointing to the presence of a strong reasoning engine&#10;implicit in the Transformer weights.&#10; | General | [Link](http://arxiv.org/abs/2409.10502v1) |&#10;| Alignment with nonlinear velocity couplings: collision&#45;avoidance and&#10; &#160;micro&#45;to&#45;macro mean&#45;field limits | Young&#45;Pil Choi, Micha Fabisiak, Jan Peszek | &#160;&#160;We investigate the pressureless fractional Euler&#45;alignment system with&#10;nonlinear velocity couplings, referred to as the $p$&#45;Euler&#45;alignment system.&#10;This model features a nonlinear velocity alignment force, interpreted as a&#10;density&#45;weighted fractional $p$&#45;Laplacian when the singularity parameter&#10;$alpha$ exceeds the spatial dimension $d$. Our primary goal is to establish&#10;the existence of solutions for strongly singular interactions ($alpha ge d$)&#10;and compactly supported initial conditions. We construct solutions as&#10;mean&#45;field limits of empirical measures from a kinetic variant of the&#10;$p$&#45;Euler&#45;alignment system. Specifically, we show that a sequence of empirical&#10;measures converges to a finite Radon measure, whose local density and velocity&#10;satisfy the $p$&#45;Euler&#45;alignment system. Our results are the first to prove the&#10;existence of solutions to this system in multi&#45;dimensional settings without&#10;significant initial data restrictions, covering both nonlinear ($p&gt;2$) and&#10;linear ($p=2$) cases. Additionally, we establish global existence, uniqueness,&#10;and collision avoidance for the corresponding particle ODE system under&#10;non&#45;collisional initial conditions, extending previous results for $1 &#10;e p &#10;e&#10;alpha + 2$. This analysis supports our mean&#45;field limit argument and&#10;contributes to understanding alignment models with singular communication.&#10; | General | [Link](http://arxiv.org/abs/2409.10501v1) |&#10;| Focus diverse phase retrieval test results on broadband continuous&#10; &#160;wavefront sensing in space telescope applications | Hyukmo Kang, Kyle Van Gorkom, Meghdoot Biswas, Daewook Kim, Ewan S. Douglas | &#160;&#160;Continuous wavefront sensing benefits space observatories in on&#45;orbit optical&#10;performance maintenance. To measure the phase of a wavefront, phase retrieval&#10;is an attractive technique as it uses multiple point spread function (PSF)&#10;images that are acquired by the telescope itself without extra metrology&#10;systems nor complicated calibration. The focus diverse phase retrieval utilizes&#10;PSFs from predetermined defocused positions to enhance the dynamic range of the&#10;algorithm. We describe an updated visible light active optics testbed with the&#10;addition of a linear motorized focus stage. The performance of the phase&#10;retrieval algorithm in broadband is tested under various cases. While broadband&#10;pass filters have advantages in higher signal&#45;to&#45;noise ratio (SNR), the&#10;performance of phase retrieval can be restricted due to blurred image caused by&#10;diffraction and increased computing cost. We used multiple bandpass filters (10&#10;nm, 88 nm, and 150 nm) and investigated effects of bandwidth on the accuracy&#10;and required image acquisition conditions such as SNR, reaching accuracies&#10;below 20 nm RMS wavefront error at the widest bandwidth. We also investigated&#10;the dynamic range of the phase retrieval algorithm depending on the bandwidth&#10;and required amount of defocus to expand dynamic range. Finally, we simulated&#10;the continuous wavefront sensing and correction loop with a range of&#10;statistically generated representative telescope disturbance time series to&#10;test for edge cases.&#10; | General | [Link](http://arxiv.org/abs/2409.10500v1) |&#10;| The role of higher&#45;order terms in trapped&#45;ion quantum computing with&#10; &#160;magnetic gradient induced coupling | Sebastian Nagies, Kevin T. Geier, Javed Akram, Junichi Okamoto, Dimitris Badounas, Christof Wunderlich, Michael Johanning, Philipp Hauke | &#160;&#160;Trapped&#45;ion hardware based on the Magnetic Gradient Induced Coupling (MAGIC)&#10;scheme is emerging as a promising platform for quantum computing. Nevertheless,&#10;in this (as in any other) quantum&#45;computing platform, many technical questions&#10;still have to be resolved before large&#45;scale and error&#45;tolerant applications&#10;are possible. In this work, we present a thorough discussion of the&#10;contribution of higher&#45;order terms to the MAGIC setup, which can occur due to&#10;anharmonicities in the external potential of the ion crystal (e.g., through&#10;Coulomb repulsion) or through curvature of the applied magnetic field. These&#10;terms take the form of three&#45;spin couplings as well as diverse terms that&#10;couple spins to phonons. We find that most of these are negligible in realistic&#10;situations, with only two contributions that need careful attention. First,&#10;there are parasitic longitudinal fields whose strength increases with chain&#10;length, but which can easily be compensated by a microwave detuning. Second,&#10;anharmonicities of the Coulomb interaction can lead to well&#45;known two&#45;to&#45;one&#10;conversions of phonon excitations, which can be avoided if the phonons are&#10;ground&#45;state cooled. Our detailed analysis constitutes an important&#10;contribution on the way of making magnetic&#45;gradient trapped&#45;ion quantum&#10;technology fit for large&#45;scale applications, and it may inspire new ways to&#10;purposefully design interaction terms.&#10; | General | [Link](http://arxiv.org/abs/2409.10498v1) |&#10;| MusicLIME: Explainable Multimodal Music Understanding | Theodoros Sotirou, Vassilis Lyberatos, Orfeas Menis Mastromichalakis, Giorgos Stamou | &#160;&#160;Multimodal models are critical for music understanding tasks, as they capture&#10;the complex interplay between audio and lyrics. However, as these models become&#10;more prevalent, the need for explainability grows&#45;understanding how these&#10;systems make decisions is vital for ensuring fairness, reducing bias, and&#10;fostering trust. In this paper, we introduce MusicLIME, a model&#45;agnostic&#10;feature importance explanation method designed for multimodal music models.&#10;Unlike traditional unimodal methods, which analyze each modality separately&#10;without considering the interaction between them, often leading to incomplete&#10;or misleading explanations, MusicLIME reveals how audio and lyrical features&#10;interact and contribute to predictions, providing a holistic view of the&#10;model&#39;s decision&#45;making. Additionally, we enhance local explanations by&#10;aggregating them into global explanations, giving users a broader perspective&#10;of model behavior. Through this work, we contribute to improving the&#10;interpretability of multimodal music models, empowering users to make informed&#10;choices, and fostering more equitable, fair, and transparent music&#10;understanding systems.&#10; | General | [Link](http://arxiv.org/abs/2409.10496v1) |&#10;| Incorporating Classifier&#45;Free Guidance in Diffusion Model&#45;Based&#10; &#160;Recommendation | Noah Buchanan, Susan Gauch, Quan Mai | &#160;&#160;This paper presents a diffusion&#45;based recommender system that incorporates&#10;classifier&#45;free guidance. Most current recommender systems provide&#10;recommendations using conventional methods such as collaborative or&#10;content&#45;based filtering. Diffusion is a new approach to generative AI that&#10;improves on previous generative AI approaches such as Variational Autoencoders&#10;(VAEs) and Generative Adversarial Networks (GANs). We incorporate diffusion in&#10;a recommender system that mirrors the sequence users take when browsing and&#10;rating items. Although a few current recommender systems incorporate diffusion,&#10;they do not incorporate classifier&#45;free guidance, a new innovation in diffusion&#10;models as a whole. In this paper, we present a diffusion recommender system&#10;that augments the underlying recommender system model for improved performance&#10;and also incorporates classifier&#45;free guidance. Our findings show improvements&#10;over state&#45;of&#45;the&#45;art recommender systems for most metrics for several&#10;recommendation tasks on a variety of datasets. In particular, our approach&#10;demonstrates the potential to provide better recommendations when data is&#10;sparse.&#10; | General | [Link](http://arxiv.org/abs/2409.10494v1) |&#10;| Renormalization of the Einstein&#45;Cartan Theory in First&#45;Order Form | F. T. Brandt, J. Frenkel, S. Martins&#45;Filho, D. G. C. McKeon | &#160;&#160;We examine the Einstein&#45;Cartan (EC) theory in first&#45;order form, which has a&#10;diffeomorphism as well as a local Lorentz invariance. We study the&#10;renormalizability of this theory in the framework of the Batalin&#45;Vilkovisky&#10;formalism, which allows for a gauge invariant renormalization. Using the&#10;background field method, we discuss the gauge invariance of the background&#10;effective action and analyze the Ward identities which reflect the symmetries&#10;of the EC theory. As an application, we compute, in a general background gauge,&#10;the self&#45;energy of the tetrad field at one&#45;loop order.&#10; | General | [Link](http://arxiv.org/abs/2409.10493v1) |&#10;| What we can learn from the angular differential rates (only) in&#10; &#160;semileptonic $B to D^* ell _ell$ decays | G. Martinelli, S. Simula, L. Vittorio | &#160;&#160;We present a new, simple approach to the study of semileptonic $B to D^*&#10;ell &#10;u_ell$ decays based on the angular distributions of the final state&#10;particles only. Our approach is model independent and never requires the&#10;knowledge of $vert V_{cb}vert$. By studying such distributions in the case of&#10;light leptons, a comparison between results from different data sets from the&#10;Belle and BelleII Collaborations and between data and Standard Model&#10;calculations is also given for several interesting quantities. A good&#10;consistency is observed between some of the experimental results and the&#10;theoretical predictions.&#10; | General | [Link](http://arxiv.org/abs/2409.10492v1) |&#10;| Code Vulnerability Detection: A Comparative Analysis of Emerging Large&#10; &#160;Language Models | Shaznin Sultana, Sadia Afreen, Nasir U. Eisty | &#160;&#160;The growing trend of vulnerability issues in software development as a result&#10;of a large dependence on open&#45;source projects has received considerable&#10;attention recently. This paper investigates the effectiveness of Large Language&#10;Models (LLMs) in identifying vulnerabilities within codebases, with a focus on&#10;the latest advancements in LLM technology. Through a comparative analysis, we&#10;assess the performance of emerging LLMs, specifically Llama, CodeLlama, Gemma,&#10;and CodeGemma, alongside established state&#45;of&#45;the&#45;art models such as BERT,&#10;RoBERTa, and GPT&#45;3. Our study aims to shed light on the capabilities of LLMs in&#10;vulnerability detection, contributing to the enhancement of software security&#10;practices across diverse open&#45;source repositories. We observe that CodeGemma&#10;achieves the highest F1&#45;score of 58 and a Recall of 87, amongst the recent&#10;additions of large language models to detect software security vulnerabilities.&#10; | General | [Link](http://arxiv.org/abs/2409.10490v1) |&#10;| Flash STU: Fast Spectral Transform Units | Y. Isabel Liu, Windsor Nguyen, Yagiz Devre, Evan Dogariu, Anirudha Majumdar, Elad Hazan | &#160;&#160;This paper describes an efficient, open source PyTorch implementation of the&#10;Spectral Transform Unit. We investigate sequence prediction tasks over several&#10;modalities including language, robotics, and simulated dynamical systems. We&#10;find that for the same parameter count, the STU and its variants outperform the&#10;Transformer as well as other leading state space models across various&#10;modalities.&#10; | General | [Link](http://arxiv.org/abs/2409.10489v1) |&#10;| Do Pre&#45;trained Vision&#45;Language Models Encode Object States? | Kaleb Newman, Shijie Wang, Yuan Zang, David Heffren, Chen Sun | &#160;&#160;For a vision&#45;language model (VLM) to understand the physical world, such as&#10;cause and effect, a first step is to capture the temporal dynamics of the&#10;visual world, for example how the physical states of objects evolve over time&#10;(e.g. a whole apple into a sliced apple). Our paper aims to investigate if VLMs&#10;pre&#45;trained on web&#45;scale data learn to encode object states, which can be&#10;extracted with zero&#45;shot text prompts. We curate an object state recognition&#10;dataset ChangeIt&#45;Frames, and evaluate nine open&#45;source VLMs, including models&#10;trained with contrastive and generative objectives. We observe that while these&#10;state&#45;of&#45;the&#45;art vision&#45;language models can reliably perform object&#10;recognition, they consistently fail to accurately distinguish the objects&#39;&#10;physical states. Through extensive experiments, we identify three areas for&#10;improvements for VLMs to better encode object states, namely the quality of&#10;object localization, the architecture to bind concepts to objects, and the&#10;objective to learn discriminative visual and language encoders on object&#10;states. Data and code are released.&#10; | General | [Link](http://arxiv.org/abs/2409.10488v1) |&#10;| A Host Galaxy Morphology Link Between Quasi&#45;Periodic Eruptions and Tidal&#10; &#160;Disruption Events | Olivier Gilbert, John J. Ruan, Michael Eracleous, Daryl Haggard, Jessie C. Runnoe | &#160;&#160;The physical processes that produce X&#45;ray Quasi&#45;Periodic Eruptions (QPEs)&#10;recently discovered from the nuclei of several low&#45;redshift galaxies are&#10;mysterious. Several pieces of observational evidence strongly suggest a link&#10;between QPEs and Tidal Disruption Events (TDE). Previous studies also reveal&#10;that the morphologies of TDE host galaxies are highly concentrated, with high&#10;Sersic indicies, bulge&#45;to&#45;total light (B/T) ratios, and stellar surface mass&#10;densities relative to the broader galaxy population. We use these distinctive&#10;properties to test the link between QPEs and TDEs, by comparing these&#10;parameters of QPE host galaxies to TDE host galaxies. We employ archival Legacy&#10;Survey images of a sample of 9 QPE host galaxies and a sample of 13 TDE host&#10;galaxies, and model their surface brightness profiles. We show that QPE host&#10;galaxies have high Sersic indices of ~3, high B/T ratios of ~0.5, and high&#10;surface mass densities of ~10^10 Msun kpc^&#45;2. These properties are similar to&#10;TDE host galaxies, but are in strong contrast to a mass&#45; and redshift&#45;matched&#10;control sample of galaxies. We also find tentative evidence that the central&#10;black holes in both QPE and TDE host galaxies are undermassive relative to&#10;their stellar mass. The morphological similarities between QPE and TDE host&#10;galaxies at the population level add to the mounting evidence of a physical&#10;link between these phenomena, and favor QPE models that also invoke TDEs.&#10; | General | [Link](http://arxiv.org/abs/2409.10486v1) |&#10;| Tuning the Rate of Tightly Packed Systems To Produce Planet Occurrence&#10; &#160;Trends with Galactic Height | Sarah Ballard | &#160;&#160;The formation of planetary systems has historically been considered in&#10;isolation, decoupled from processes on galactic scales. Recent findings&#10;employing data from ESA&#39;s Gaia mission challenge this narrative, identifying&#10;trends in planet occurrence with galactic kinematics and stellar age. The&#10;findings indicate changes in planet occurrence over and above the predicted&#10;changes from metallicity variation within the Milky Way, so that changes to&#10;stellar metallicity alone (long understood to be deterministic in planet&#10;outcomes) cannot explain the trends entirely. The scope of potential factors&#10;influencing planet formation has grown progressively wider, with accompanying&#10;theoretical support for galactic&#45;scale influences upon planet formation. In&#10;this manuscript, we investigate specifically how changes to the rate of Systems&#10;of Tightly&#45;packed Inner Planets (STIPs) could manifest as a trend in planet&#10;occurrence with galactic height. We focus our study upon M dwarf planetary&#10;systems for two reasons: first, they host STIPs at high rates, and secondly,&#10;their longevity makes them useful probes for kinematic trends over Gyr. We&#10;consider two models for a varying STIP rate: one in which STIP likelihood is&#10;determined by stellar age alone, irrespective of galactic time, and another in&#10;which the STIP likelihood suddenly increased in recent galactic history. Both&#10;models, which impose a higher STIP likelihood among younger stars, produce a&#10;negative gradient in planet occurrence with increasing height from the galactic&#10;midplane. We find that a step function model in which STIP likelihood increased&#10;by a factor of several ~a few Gyr ago resembles an observed trend among FGK&#10;dwarfs. We consider plausible physical mechanisms that could mimic the&#10;hypothesized model, given known links between STIP occurrence and other stellar&#10;and planetary properties.&#10; | General | [Link](http://arxiv.org/abs/2409.10485v1) |&#10;| XLM for Autonomous Driving Systems: A Comprehensive Review | Sonda Fourati, Wael Jaafar, Noura Baccar, Safwan Alfattani | &#160;&#160;Large Language Models (LLMs) have showcased remarkable proficiency in various&#10;information&#45;processing tasks. These tasks span from extracting data and&#10;summarizing literature to generating content, predictive modeling,&#10;decision&#45;making, and system controls. Moreover, Vision Large Models (VLMs) and&#10;Multimodal LLMs (MLLMs), which represent the next generation of language&#10;models, a.k.a., XLMs, can combine and integrate many data modalities with the&#10;strength of language understanding, thus advancing several information&#45;based&#10;systems, such as Autonomous Driving Systems (ADS). Indeed, by combining&#10;language communication with multimodal sensory inputs, e.g., panoramic images&#10;and LiDAR or radar data, accurate driving actions can be taken. In this&#10;context, we provide in this survey paper a comprehensive overview of the&#10;potential of XLMs towards achieving autonomous driving. Specifically, we review&#10;the relevant literature on ADS and XLMs, including their architectures, tools,&#10;and frameworks. Then, we detail the proposed approaches to deploy XLMs for&#10;autonomous driving solutions. Finally, we provide the related challenges to XLM&#10;deployment for ADS and point to future research directions aiming to enable XLM&#10;adoption in future ADS frameworks.&#10; | General | [Link](http://arxiv.org/abs/2409.10484v1) |&#10;| Efficient polarizable QM/MM using the direct reaction field Hamiltonian&#10; &#160;with electrostatic potential fitted multipole operators | Thomas P. Fay, Nicolas Ferr, Miquel Huix&#45;Rotllant | &#160;&#160;Electronic polarization and dispersion are decisive actors in determining&#10;interaction energies between molecules. These interactions have a particularly&#10;profound effect on excitation energies of molecules in complex environments,&#10;especially when the excitation involves a significant degree of charge&#10;reorganisation. The direct reaction field (DRF) approach, which has seen a&#10;recent revival of interest, provides a powerful framework for describing these&#10;interactions in quantum mechanics/molecular mechanics (QM/MM) models of&#10;systems, where a small subsystem of interest is described using quantum&#10;chemical methods and the remainder is treated with a simple MM force field. In&#10;this paper we show how the DRF approach can be combined with the electrostatic&#10;potential fitted (ESPF) multipole operator description of the QM region charge&#10;density, which reduces the scaling $mathcal{O}(N_mathrm{MM}^3)$ of the method&#10;with MM system to $mathcal{O}(N_mathrm{MM}^2)$. We also show how the DRF&#10;approach can be combined with fluctuating charge descriptions of the&#10;polarizable environment, as well as previously used atom&#45;centred&#10;dipole&#45;polarizability based models. We further show that the ESPF&#45;DRF method&#10;provides an accurate description of molecular interactions in both ground and&#10;excited electronic states of the QM system and apply it to predict the gas to&#10;aqueous solution solvatochromic shifts in the UV/visible absorption spectrum of&#10;acrolein.&#10; | General | [Link](http://arxiv.org/abs/2409.10483v1) |&#10;| Schrodinger&#39;s Memory: Large Language Models | Wei Wang, Qing Li | &#160;&#160;Memory is the foundation of LLMs&#39; functionality, yet past research has lacked&#10;an in&#45;depth exploration of their memory capabilities and underlying theory. In&#10;this paper, we apply UAT theory to explain the memory mechanism of LLMs and&#10;propose a new approach for evaluating LLM performance by comparing the memory&#10;capacities of different models. Through extensive experiments, we validate our&#10;theory and the memory abilities of LLMs. Finally, we compare the capabilities&#10;of the human brain and LLMs, highlighting both their similarities and&#10;differences in terms of working mechanisms.&#10; | General | [Link](http://arxiv.org/abs/2409.10482v1) |&#10;| Exploring 3D Face Reconstruction and Fusion Methods for Face&#10; &#160;Verification: A Case&#45;Study in Video Surveillance | Simone Maurizio La Cava, Sara Concas, Ruben Tolosana, Roberto Casula, Giulia Orr, Martin Drahansky, Julian Fierrez, Gian Luca Marcialis | &#160;&#160;3D face reconstruction (3DFR) algorithms are based on specific assumptions&#10;tailored to distinct application scenarios. These assumptions limit their use&#10;when acquisition conditions, such as the subject&#39;s distance from the camera or&#10;the camera&#39;s characteristics, are different than expected, as typically happens&#10;in video surveillance. Additionally, 3DFR algorithms follow various strategies&#10;to address the reconstruction of a 3D shape from 2D data, such as statistical&#10;model fitting, photometric stereo, or deep learning. In the present study, we&#10;explore the application of three 3DFR algorithms representative of the SOTA,&#10;employing each one as the template set generator for a face verification&#10;system. The scores provided by each system are combined by score&#45;level fusion.&#10;We show that the complementarity induced by different 3DFR algorithms improves&#10;performance when tests are conducted at never&#45;seen&#45;before distances from the&#10;camera and camera characteristics (cross&#45;distance and cross&#45;camera settings),&#10;thus encouraging further investigations on multiple 3DFR&#45;based approaches.&#10; | General | [Link](http://arxiv.org/abs/2409.10481v1) |&#10;| Addressing misspecification in contextual optimization | Omar Bennouna, Jiawei Zhang, Saurabh Amin, Asuman Ozdaglar | &#160;&#160;We study a linear contextual optimization problem where a decision maker has&#10;access to historical data and contextual features to learn a cost prediction&#10;model aimed at minimizing decision error. We adopt the predict&#45;then&#45;optimize&#10;framework for this analysis. Given that perfect model alignment with reality is&#10;often unrealistic in practice, we focus on scenarios where the chosen&#10;hypothesis set is misspecified. In this context, it remains unclear whether&#10;current contextual optimization approaches can effectively address such model&#10;misspecification. In this paper, we present a novel integrated learning and&#10;optimization approach designed to tackle model misspecification in contextual&#10;optimization. This approach offers theoretical generalizability, tractability,&#10;and optimality guarantees, along with strong practical performance. Our method&#10;involves minimizing a tractable surrogate loss that aligns with the performance&#10;value from cost vector predictions, regardless of whether the model&#10;misspecified or not, and can be optimized in reasonable time. To our knowledge,&#10;no previous work has provided an approach with such guarantees in the context&#10;of model misspecification.&#10; | General | [Link](http://arxiv.org/abs/2409.10479v1) |&#10;| Local SGD for Near&#45;Quadratic Problems: Improving Convergence under&#10; &#160;Unconstrained Noise Conditions | Andrey Sadchikov, Savelii Chezhegov, Aleksandr Beznosikov, Alexander Gasnikov | &#160;&#160;Distributed optimization plays an important role in modern large&#45;scale&#10;machine learning and data processing systems by optimizing the utilization of&#10;computational resources. One of the classical and popular approaches is Local&#10;Stochastic Gradient Descent (Local SGD), characterized by multiple local&#10;updates before averaging, which is particularly useful in distributed&#10;environments to reduce communication bottlenecks and improve scalability. A&#10;typical feature of this method is the dependence on the frequency of&#10;communications. But in the case of a quadratic target function with homogeneous&#10;data distribution over all devices, the influence of frequency of&#10;communications vanishes. As a natural consequence, subsequent studies include&#10;the assumption of a Lipschitz Hessian, as this indicates the similarity of the&#10;optimized function to a quadratic one to some extent. However, in order to&#10;extend the completeness of the Local SGD theory and unlock its potential, in&#10;this paper we abandon the Lipschitz Hessian assumption by introducing a new&#10;concept of $textit{approximate quadraticity}$. This assumption gives a new&#10;perspective on problems that have near quadratic properties. In addition,&#10;existing theoretical analyses of Local SGD often assume bounded variance. We,&#10;in turn, consider the unbounded noise condition, which allows us to broaden the&#10;class of studied problems.&#10; | General | [Link](http://arxiv.org/abs/2409.10478v1) |&#10;| SimInversion: A Simple Framework for Inversion&#45;Based Text&#45;to&#45;Image&#10; &#160;Editing | Qi Qian, Haiyang Xu, Ming Yan, Juhua Hu | &#160;&#160;Diffusion models demonstrate impressive image generation performance with&#10;text guidance. Inspired by the learning process of diffusion, existing images&#10;can be edited according to text by DDIM inversion. However, the vanilla DDIM&#10;inversion is not optimized for classifier&#45;free guidance and the accumulated&#10;error will result in the undesired performance. While many algorithms are&#10;developed to improve the framework of DDIM inversion for editing, in this work,&#10;we investigate the approximation error in DDIM inversion and propose to&#10;disentangle the guidance scale for the source and target branches to reduce the&#10;error while keeping the original framework. Moreover, a better guidance scale&#10;(i.e., 0.5) than default settings can be derived theoretically. Experiments on&#10;PIE&#45;Bench show that our proposal can improve the performance of DDIM inversion&#10;dramatically without sacrificing efficiency.&#10; | General | [Link](http://arxiv.org/abs/2409.10476v1) |&#10;| Leadership and Engagement Dynamics in Legislative Twitter Networks:&#10; &#160;Statistical Analysis and Modeling | Carolina Luque, Juan Sosa | &#160;&#160;In this manuscript, we analyze the interaction network on Twitter among&#10;members of the 117th U.S. Congress to assess the visibility of political&#10;leaders and explore how systemic properties and node attributes influence the&#10;formation of legislative connections. We employ descriptive social network&#10;statistical methods, the exponential random graph model (ERGM), and the&#10;stochastic block model (SBM) to evaluate the relative impact of network&#10;systemic properties, as well as institutional and personal traits, on the&#10;generation of online relationships among legislators. Our findings reveal that&#10;legislative networks on social media platforms like Twitter tend to reinforce&#10;the leadership of dominant political actors rather than diminishing their&#10;influence. However, we identify that these leadership roles can manifest in&#10;various forms. Additionally, we highlight that online connections within&#10;legislative networks are influenced by both the systemic properties of the&#10;network and institutional characteristics.&#10; | General | [Link](http://arxiv.org/abs/2409.10475v1) |&#10;| MacDiff: Unified Skeleton Modeling with Masked Conditional Diffusion | Lehong Wu, Lilang Lin, Jiahang Zhang, Yiyang Ma, Jiaying Liu | &#160;&#160;Self&#45;supervised learning has proved effective for skeleton&#45;based human action&#10;understanding. However, previous works either rely on contrastive learning that&#10;suffers false negative problems or are based on reconstruction that learns too&#10;much unessential low&#45;level clues, leading to limited representations for&#10;downstream tasks. Recently, great advances have been made in generative&#10;learning, which is naturally a challenging yet meaningful pretext task to model&#10;the general underlying data distributions. However, the representation learning&#10;capacity of generative models is under&#45;explored, especially for the skeletons&#10;with spacial sparsity and temporal redundancy. To this end, we propose Masked&#10;Conditional Diffusion (MacDiff) as a unified framework for human skeleton&#10;modeling. For the first time, we leverage diffusion models as effective&#10;skeleton representation learners. Specifically, we train a diffusion decoder&#10;conditioned on the representations extracted by a semantic encoder. Random&#10;masking is applied to encoder inputs to introduce a information bottleneck and&#10;remove redundancy of skeletons. Furthermore, we theoretically demonstrate that&#10;our generative objective involves the contrastive learning objective which&#10;aligns the masked and noisy views. Meanwhile, it also enforces the&#10;representation to complement for the noisy view, leading to better&#10;generalization performance. MacDiff achieves state&#45;of&#45;the&#45;art performance on&#10;representation learning benchmarks while maintaining the competence for&#10;generative tasks. Moreover, we leverage the diffusion model for data&#10;augmentation, significantly enhancing the fine&#45;tuning performance in scenarios&#10;with scarce labeled data. Our project is available at&#10;https://lehongwu.github.io/ECCV24MacDiff/.&#10; | General | [Link](http://arxiv.org/abs/2409.10473v1) |&#10;| Towards Semantic Versioning of Open Pre&#45;trained Language Model Releases&#10; &#160;on Hugging Face | Adekunle Ajibode, Abdul Ali Bangash, Filipe Roseiro Cogo, Bram Adams, Ahmed E. Hassan | &#160;&#160;The proliferation of open Pre&#45;trained Language Models (PTLMs) on model&#10;registry platforms like Hugging Face (HF) presents both opportunities and&#10;challenges for companies building products around them. Similar to traditional&#10;software dependencies, PTLMs continue to evolve after a release. However, the&#10;current state of release practices of PTLMs on model registry platforms are&#10;plagued by a variety of inconsistencies, such as ambiguous naming conventions&#10;and inaccessible model training documentation. Given the knowledge gap on&#10;current PTLM release practices, our empirical study uses a mixed&#45;methods&#10;approach to analyze the releases of 52,227 PTLMs on the most well&#45;known model&#10;registry, HF. Our results reveal 148 different naming practices for PTLM&#10;releases, with 40.87% of changes to model weight files not represented in the&#10;adopted name&#45;based versioning practice or their documentation. In addition, we&#10;identified that the 52,227 PTLMs are derived from only 299 different base&#10;models (the modified original models used to create 52,227 PTLMs), with&#10;Fine&#45;tuning and Quantization being the most prevalent modification methods&#10;applied to these base models. Significant gaps in release transparency, in&#10;terms of training dataset specifications and model card availability, still&#10;exist, highlighting the need for standardized documentation. While we&#10;identified a model naming practice explicitly differentiating between major and&#10;minor PTLM releases, we did not find any significant difference in the types of&#10;changes that went into either type of releases, suggesting that major/minor&#10;version numbers for PTLMs often are chosen arbitrarily. Our findings provide&#10;valuable insights to improve PTLM release practices, nudging the field towards&#10;more formal semantic versioning practices.&#10; | General | [Link](http://arxiv.org/abs/2409.10472v1) |&#10;| Real&#45;Time Whole&#45;Body Control of Legged Robots with Model&#45;Predictive Path&#10; &#160;Integral Control | Juan Alvarez&#45;Padilla, John Z. Zhang, Sofia Kwok, John M. Dolan, Zachary Manchester | &#160;&#160;This paper presents a system for enabling real&#45;time synthesis of whole&#45;body&#10;locomotion and manipulation policies for real&#45;world legged robots. Motivated by&#10;recent advancements in robot simulation, we leverage the efficient&#10;parallelization capabilities of the MuJoCo simulator to achieve fast sampling&#10;over the robot state and action trajectories. Our results show surprisingly&#10;effective real&#45;world locomotion and manipulation capabilities with a very&#10;simple control strategy. We demonstrate our approach on several hardware and&#10;simulation experiments: robust locomotion over flat and uneven terrains,&#10;climbing over a box whose height is comparable to the robot, and pushing a box&#10;to a goal position. To our knowledge, this is the first successful deployment&#10;of whole&#45;body sampling&#45;based MPC on real&#45;world legged robot hardware.&#10;Experiment videos and code can be found at: https://whole&#45;body&#45;mppi.github.io/&#10; | General | [Link](http://arxiv.org/abs/2409.10469v1) |&#10;| Assortativity in sympatric speciation and species classification | Joao U. F. Lizarraga, Flavia M. D. Marquitti, Marcus A. M. de Aguiar | &#160;&#160;We investigate the role of assortative mating in speciation using the&#10;sympatric model of Derrida and Higgs. The model explores the idea that genetic&#10;differences create incompatibilities between individuals, preventing mating if&#10;the number of such differences is too large. Speciation, however, only happens&#10;in this mating system if the number of genes is large. Here we show that&#10;speciation with small genome sizes can occur if assortative mating is&#10;introduced. In our model individuals are represented by three chromosomes: one&#10;responsible for reproductive compatibility, one for coding the trait on which&#10;assortativity will operate, and a neutral chromosome. Reproduction is possible&#10;if individuals are genetically similar with respect to the first chromosome,&#10;but among these compatible mating partners, the one with the most similar trait&#10;coded by the second chromosome is selected. We show that this type of&#10;assortativity facilitates speciation, which can happen with a small number of&#10;genes in the first chromosome. Species, classified according to reproductive&#10;isolation, dictated by the first chromosome, can display different traits&#10;values, as measured by the second and the third chromosomes. Therefore, species&#10;can also be identified based on similarity of the neutral trait, which works as&#10;a proxy for reproductive isolation.&#10; | General | [Link](http://arxiv.org/abs/2409.10466v1) |&#10;| A stabilized total pressure&#45;formulation of the Biot&#39;s poroelasticity&#10; &#160;equations in frequency domain: numerical analysis and applications | Cristian Crcamo, Alfonso Caiazzo, Felipe Galarce, Joaqun Mura | &#160;&#160;This work focuses on the numerical solution of the dynamics of a poroelastic&#10;material in the frequency domain. We provide a detailed stability analysis&#10;based on the application of the Fredholm alternative in the continuous case,&#10;considering a total pressure formulation of the Biot&#39;s equations. In the&#10;discrete setting, we propose a stabilized equal order finite element method&#10;complemented by an additional pressure stabilization to enhance the robustness&#10;of the numerical scheme with respect to the fluid permeability. Utilizing the&#10;Fredholm alternative, we extend the well&#45;posedness results to the discrete&#10;setting, obtaining theoretical optimal convergence for the case of linear&#10;finite elements. We present different numerical experiments to validate the&#10;proposed method. First, we consider model problems with known analytic&#10;solutions in two and three dimensions. As next, we show that the method is&#10;robust for a wide range of permeabilities, including the case of discontinuous&#10;coefficients. Lastly, we show the application for the simulation of brain&#10;elastography on a realistic brain geometry obtained from medical imaging.&#10; | General | [Link](http://arxiv.org/abs/2409.10465v1) |&#10;| New Direct Sum Tests | Alek Westover, Edward Yu, Kai Zheng | &#160;&#160;A function $f:[n]^{d} to mathbb{F}_2$ is a defn{direct sum} if there are&#10;functions $L_i:[n]to mathbb{F}_2$ such that ${f(x) = sum_{i}L_i(x_i)}$. In&#10;this work we give multiple results related to the property testing of direct&#10;sums.&#10; &#160;Our first result concerns a test proposed by Dinur and Golubev in 2019. We&#10;call their test the Diamond test and show that it is indeed a direct sum&#10;tester. More specifically, we show that if a function $f$ is $epsilon$&#45;far&#10;from being a direct sum function, then the Diamond test rejects $f$ with&#10;probability at least $Omega_{n,epsilon}(1)$. Even in the case of $n = 2$, the&#10;Diamond test is, to the best of our knowledge, novel and yields a new tester&#10;for the classic property of affinity.&#10; &#160;Apart from the Diamond test, we also analyze a broad family of direct sum&#10;tests, which at a high level, run an arbitrary affinity test on the restriction&#10;of $f$ to a random hypercube inside of $[n]^d$. This family of tests includes&#10;the direct sum test analyzed in cite{di19}, but does not include the Diamond&#10;test. As an application of our result, we obtain a direct sum test which works&#10;in the online adversary model of cite{KRV}.&#10; &#160;Finally, we also discuss a Fourier analytic interpretation of the diamond&#10;tester in the $n=2$ case, as well as prove local correction results for direct&#10;sum as conjectured by Dinur and Golubev.&#10; | General | [Link](http://arxiv.org/abs/2409.10464v1) |&#10;| Kolmogorov&#45;Arnold Networks in Low&#45;Data Regimes: A Comparative Study with&#10; &#160;Multilayer Perceptrons | Farhad Pourkamali&#45;Anaraki | &#160;&#160;Multilayer Perceptrons (MLPs) have long been a cornerstone in deep learning,&#10;known for their capacity to model complex relationships. Recently,&#10;Kolmogorov&#45;Arnold Networks (KANs) have emerged as a compelling alternative,&#10;utilizing highly flexible learnable activation functions directly on network&#10;edges, a departure from the neuron&#45;centric approach of MLPs. However, KANs&#10;significantly increase the number of learnable parameters, raising concerns&#10;about their effectiveness in data&#45;scarce environments. This paper presents a&#10;comprehensive comparative study of MLPs and KANs from both algorithmic and&#10;experimental perspectives, with a focus on low&#45;data regimes. We introduce an&#10;effective technique for designing MLPs with unique, parameterized activation&#10;functions for each neuron, enabling a more balanced comparison with KANs. Using&#10;empirical evaluations on simulated data and two real&#45;world data sets from&#10;medicine and engineering, we explore the trade&#45;offs between model complexity&#10;and accuracy, with particular attention to the role of network depth. Our&#10;findings show that MLPs with individualized activation functions achieve&#10;significantly higher predictive accuracy with only a modest increase in&#10;parameters, especially when the sample size is limited to around one hundred.&#10;For example, in a three&#45;class classification problem within additive&#10;manufacturing, MLPs achieve a median accuracy of 0.91, significantly&#10;outperforming KANs, which only reach a median accuracy of 0.53 with default&#10;hyperparameters. These results offer valuable insights into the impact of&#10;activation function selection in neural networks.&#10; | General | [Link](http://arxiv.org/abs/2409.10463v1) |&#10;| Effects of synapse location, delay and background stochastic activity on&#10; &#160;synchronising hippocampal CA1 neurons | Alessandro Fiasconaro, Michele Migliore | &#160;&#160;We study the synchronisation of neurons in a realistic model under the&#10;Hodgkin&#45;Huxley dynamics. To focus on the role of the different locations of the&#10;excitatory synapses, we use two identical neurons where the set of input&#10;signals is grouped at two different distances from the soma. The system is&#10;intended to represent a CA1 hippocampal neuron in which the synapses arriving&#10;from the CA3 neurons of the trisynaptic pathway appear to be localised in the&#10;apical dendritic region and are, in principle, either proximal or distal to the&#10;soma. Synchronisation is studied using a specifically defined spiking&#10;correlation function as a function of various parameters such as the distance&#10;from the soma of one of the synaptic groups, the inhibition weight and the&#10;associated activation delay. We found that the neurons&#39; spiking activity&#10;depends nonmonotonically on the relative dendritic location of the synapses and&#10;their inhibitory weight, whereas the synchronisation measure always decreases&#10;with inhibition, and strongly depends on its activation time delay. The&#10;background activity on the somas results essentially independent on the&#10;fluctuation intensity and strongly support the importance of the balance&#10;between inhibition and excitation for neuronal synchronization.&#10; | General | [Link](http://arxiv.org/abs/2409.10460v1) |&#10;| Efficiently Crowdsourcing Visual Importance with Punch&#45;Hole Annotation | Minsuk Chang, Soohyun Lee, Aeri Cho, Hyeon Jeon, Seokhyeon Park, Cindy Xiong Bearfield, Jinwook Seo | &#160;&#160;We introduce a novel crowdsourcing method for identifying important areas in&#10;graphical images through punch&#45;hole labeling. Traditional methods, such as gaze&#10;trackers and mouse&#45;based annotations, which generate continuous data, can be&#10;impractical in crowdsourcing scenarios. They require many participants, and the&#10;outcome data can be noisy. In contrast, our method first segments the graphical&#10;image with a grid and drops a portion of the patches (punch holes). Then, we&#10;iteratively ask the labeler to validate each annotation with holes, narrowing&#10;down the annotation only having the most important area. This approach aims to&#10;reduce annotation noise in crowdsourcing by standardizing the annotations while&#10;enhancing labeling efficiency and reliability. Preliminary findings from&#10;fundamental charts demonstrate that punch&#45;hole labeling can effectively&#10;pinpoint critical regions. This also highlights its potential for broader&#10;application in visualization research, particularly in studying large&#45;scale&#10;users&#39; graphical perception. Our future work aims to enhance the algorithm to&#10;achieve faster labeling speed and prove its utility through large&#45;scale&#10;experiments.&#10; | General | [Link](http://arxiv.org/abs/2409.10459v1) |&#10;| Full distribution of local observables in an exactly solvable current&#10; &#160;carrying steady states of a driven XXZ chain | Sandipan Manna, G J Sreejith | &#160;&#160;Current carrying steady states of interacting spins chains exhibit rich&#10;structures generated through an interplay of current induced correlations and&#10;energetic constraints from the Hamiltonian. The XXZ spin chain when coupled to&#10;maximally polarizing Lindblad terms admits an exact solution in a matrix&#10;product state (MPS) form. We use this exact solution to study the correlations&#10;and distributions of simple local spin observables in the non equilibrium&#10;steady state (NESS). We present exact expressions for spin correlators, entropy&#10;per site, cumulant generating functions for distributions of local observables&#10;in the XX limit (Ising anisotropy $Delta=0$). Further, we use the exact MPS&#10;solution in systems with $Delta&gt;0$, to numerically exactly calculate the&#10;entropy, correlations, as well as distributions of spin observables in blocks&#10;as large as $nsim 200$ sites allowing an estimation of the rate functions. The&#10;$z$ magnetization distribution is consistant with short range spin correlations&#10;in the $z$ direction while the $x$&#45;magnetization shows a double peak structure&#10;at larger $Delta$ suggesting short range ferromagnetic ordering. We find that&#10;the distribution of $z$&#45;magnetization sharpens for parameters where the current&#10;is maximized.&#10; | General | [Link](http://arxiv.org/abs/2409.10458v1) |&#10;| Mean Residual Life Ageing Intensity Function | Ashutosh Singh, Ishapathik Das, Asok Kumar Nanda, Sumen Sen | &#160;&#160;The ageing intensity function is a powerful analytical tool that provides&#10;valuable insights into the ageing process across diverse domains such as&#10;reliability engineering, actuarial science, and healthcare. Its applications&#10;continue to expand as researchers delve deeper into understanding the complex&#10;dynamics of ageing and its implications for society. One common approach to&#10;defining the ageing intensity function is through the hazard rate or failure&#10;rate function, extensively explored in scholarly literature. Equally&#10;significant to the hazard rate function is the mean residual life function,&#10;which plays a crucial role in analyzing the ageing patterns exhibited by units&#10;or components. This article introduces the mean residual life ageing intensity&#10;(MRLAI) function to delve into component ageing behaviours across various&#10;distributions. Additionally, we scrutinize the closure properties of the MRLAI&#10;function across different reliability operations. Furthermore, a new order&#10;termed the mean residual life ageing intensity order is defined to analyze the&#10;ageing behaviour of a system, and the closure property of this order under&#10;various reliability operations is discussed.&#10; | General | [Link](http://arxiv.org/abs/2409.10456v1) |&#10;| Quantile Fourier regressions for decision making under uncertainty | Arash Khojaste, Geoffrey Pritchard, Golbon Zakeri | &#160;&#160;Weconsider Markov decision processes arising from a Markov model of an&#10;underlying natural phenomenon. Such phenomena are usually periodic (e.g.&#10;annual) in time, and so the Markov processes modelling them must be&#10;time&#45;inhomogeneous, with cyclostationary rather than stationary behaviour. We&#10;describe a technique for constructing such processes that allows for periodic&#10;variations both in the values taken by the process and in the serial dependence&#10;structure. We include two illustrative numerical examples: a hydropower&#10;scheduling problem and a model of offshore wind power integration.&#10; | General | [Link](http://arxiv.org/abs/2409.10455v1) |&#10;| The Debiased Near&#45;Earth Object Population from ATLAS Telescopes | Rogerio Deienno, Larry Denneau, David Nesvorn, David Vokrouhlick, William F. Bottke, Robert Jedicke, Shantanu Naidu, Steven R. Chesley, Davide Farnocchia, Paul W. Chodas | &#160;&#160;This work is dedicated to debias the Near&#45;Earth Objects (NEO) population&#10;based on observations from the Asteroid Terrestrial&#45;impact Last Alert System&#10;(ATLAS) telescopes. We have applied similar methods used to develop the&#10;recently released NEO model generator (NEOMOD), once debiasing the NEO&#10;population using data from Catalina Sky Survey (CSS) G96 telescope. ATLAS is&#10;composed of four different telescopes. We first analyzed observational data&#10;from each of all four telescopes separately and later combined them. Our&#10;results highlight main differences between CSS and ATLAS, e.g., sky coverage&#10;and survey power at debiasing the NEO population. ATLAS has a much larger sky&#10;coverage than CSS, allowing it to find bright NEOs that would be constantly&#10;&quot;hiding&quot; from CSS. Consequently, ATLAS is more powerful than CSS at debiasing&#10;the NEO population for H $&#10;esssim$ 19. With its intrinsically greater&#10;sensitivity and emphasis on observing near opposition, CSS excels in the&#10;debiasing of smaller objects. ATLAS, as an all sky survey designed to find&#10;imminent hazardous objects, necessarily spends a significant fraction of time&#10;looking at places on the sky where objects do not appear, reducing its power&#10;for debiasing the population of small objects. We estimate a NEO population&#10;completeness of $approx$ 88%$^{+3%}_{&#45;2%}$ for H $&lt;$ 17.75 and $approx$&#10;36%$^{+1%}_{&#45;1%}$ for H $&lt;$ 22.25. Those numbers are similar to previous&#10;estimates (within error bars for H $&lt;$ 17.75) from CSS, yet, around 3% and 8%&#10;smaller at their face values, respectively. We also confirm previous finding&#10;that the $&#10;u_6$ secular resonance is the main source of small and faint NEOs&#10;at H = 28, whereas the 3:1 mean motion resonance with Jupiter dominates for&#10;larger and brighter NEOs at H = 15.&#10; | General | [Link](http://arxiv.org/abs/2409.10453v1) |&#10;| Signed Graph Autoencoder for Explainable and Polarization&#45;Aware Network&#10; &#160;Embeddings | Nikolaos Nakis, Chrysoula Kosma, Giannis Nikolentzos, Michalis Chatzianastasis, Iakovos Evdaimon, Michalis Vazirgiannis | &#160;&#160;Autoencoders based on Graph Neural Networks (GNNs) have garnered significant&#10;attention in recent years for their ability to extract informative latent&#10;representations, characterizing the structure of complex topologies, such as&#10;graphs. Despite the prevalence of Graph Autoencoders, there has been limited&#10;focus on developing and evaluating explainable neural&#45;based graph generative&#10;models specifically designed for signed networks. To address this gap, we&#10;propose the Signed Graph Archetypal Autoencoder (SGAAE) framework. SGAAE&#10;extracts node&#45;level representations that express node memberships over distinct&#10;extreme profiles, referred to as archetypes, within the network. This is&#10;achieved by projecting the graph onto a learned polytope, which governs its&#10;polarization. The framework employs a recently proposed likelihood for&#10;analyzing signed networks based on the Skellam distribution, combined with&#10;relational archetypal analysis and GNNs. Our experimental evaluation&#10;demonstrates the SGAAEs&#39; capability to successfully infer node memberships over&#10;the different underlying latent structures while extracting competing&#10;communities formed through the participation of the opposing views in the&#10;network. Additionally, we introduce the 2&#45;level network polarization problem&#10;and show how SGAAE is able to characterize such a setting. The proposed model&#10;achieves high performance in different tasks of signed link prediction across&#10;four real&#45;world datasets, outperforming several baseline models.&#10; | General | [Link](http://arxiv.org/abs/2409.10452v1) |&#10;| Why you should also use OLS estimation of tail exponents | Thiago Trafane Oliveira Santos, Daniel Oliveira Cajueiro | &#160;&#160;Even though practitioners often estimate Pareto exponents running OLS&#10;rank&#45;size regressions, the usual recommendation is to use the Hill MLE with a&#10;small&#45;sample correction instead, due to its unbiasedness and efficiency. In&#10;this paper, we advocate that you should also apply OLS in empirical&#10;applications. On the one hand, we demonstrate that, with a small&#45;sample&#10;correction, the OLS estimator is also unbiased. On the other hand, we show that&#10;the MLE assigns significantly greater weight to smaller observations. This&#10;suggests that the OLS estimator may outperform the MLE in cases where the&#10;distribution is (i) strictly Pareto but only in the upper tail or (ii)&#10;regularly varying rather than strictly Pareto. We substantiate our theoretical&#10;findings with Monte Carlo simulations and real&#45;world applications,&#10;demonstrating the practical relevance of the OLS method in estimating tail&#10;exponents.&#10; | General | [Link](http://arxiv.org/abs/2409.10448v1) |&#10;| Hydrodynamic hovering of swimming bacteria above surfaces | Pyae Hein Htet, Debasish Das, Eric Lauga | &#160;&#160;Flagellated bacteria are hydrodynamically attracted to rigid walls, yet past&#10;work shows a &#39;hovering&#39; state where they swim stably at a finite height above&#10;surfaces. We use numerics and theory to reveal the physical origin of hovering.&#10;Simulations first show that hovering requires an elongated cell body and&#10;results from a tilt away from the wall. Theoretical models then identify two&#10;essential asymmetries: the response of width&#45;asymmetric cells to active flows&#10;created by length&#45;asymmetric cells. A minimal model reconciles near and&#10;far&#45;field hydrodynamics, capturing all key features of hovering.&#10; | General | [Link](http://arxiv.org/abs/2409.10447v1) |&#10;| KoroT&#45;3E: A Personalized Musical Mnemonics Tool for Enhancing Memory&#10; &#160;Retention of Complex Computer Science Concepts | Xiangzhe Yuan, Jiajun Wang, Siying Hu, Andrew Cheung, Zhicong Lu | &#160;&#160;As the demand for computer science (CS) skills grows, mastering foundational&#10;concepts is crucial yet challenging for novice learners. To address this&#10;challenge, we present KoroT&#45;3E, an AI&#45;based system that creates personalized&#10;musical mnemonics to enhance both memory retention and understanding of&#10;concepts in CS. KoroT&#45;3E enables users to transform complex concepts into&#10;memorable lyrics and compose melodies that suit their musical preferences. We&#10;conducted semi&#45;structured interviews (n=12) to investigate why novice learners&#10;find it challenging to memorize and understand CS concepts. The findings,&#10;combined with constructivist learning theory, established our initial design,&#10;which was then refined following consultations with CS education experts. An&#10;empirical experiment(n=36) showed that those using KoroT&#45;3E (n=18)&#10;significantly outperformed the control group (n=18), with improved memory&#10;efficiency, increased motivation, and a positive learning experience. These&#10;findings demonstrate the effectiveness of integrating multimodal generative AI&#10;into CS education to create personalized and interactive learning experiences.&#10; | General | [Link](http://arxiv.org/abs/2409.10446v1) |&#10;| Deep&#45;Wide Learning Assistance for Insect Pest Classification | Toan Nguyen, Huy Nguyen, Huy Ung, Hieu Ung, Binh Nguyen | &#160;&#160;Accurate insect pest recognition plays a critical role in agriculture. It is&#10;a challenging problem due to the intricate characteristics of insects. In this&#10;paper, we present DeWi, novel learning assistance for insect pest&#10;classification. With a one&#45;stage and alternating training strategy, DeWi&#10;simultaneously improves several Convolutional Neural Networks in two&#10;perspectives: discrimination (by optimizing a triplet margin loss in a&#10;supervised training manner) and generalization (via data augmentation). From&#10;that, DeWi can learn discriminative and in&#45;depth features of insect pests&#10;(deep) yet still generalize well to a large number of insect categories (wide).&#10;Experimental results show that DeWi achieves the highest performances on two&#10;insect pest classification benchmarks (76.44% accuracy on the IP102 dataset&#10;and 99.79% accuracy on the D0 dataset, respectively). In addition, extensive&#10;evaluations and ablation studies are conducted to thoroughly investigate our&#10;DeWi and demonstrate its superiority. Our source code is available at&#10;https://github.com/toannguyen1904/DeWi.&#10; | General | [Link](http://arxiv.org/abs/2409.10445v1) |&#10;| LLM as BT&#45;Planner: Leveraging LLMs for Behavior Tree Generation in Robot&#10; &#160;Task Planning | Jicong Ao, Fan Wu, Yansong Wu, Abdalla Swikir, Sami Haddadin | &#160;&#160;Robotic assembly tasks are open challenges due to the long task horizon and&#10;complex part relations. Behavior trees (BTs) are increasingly used in robot&#10;task planning for their modularity and flexibility, but manually designing them&#10;can be effort&#45;intensive. Large language models (LLMs) have recently been&#10;applied in robotic task planning for generating action sequences, but their&#10;ability to generate BTs has not been fully investigated. To this end, We&#10;propose LLM as BT&#45;planner, a novel framework to leverage LLMs for BT generation&#10;in robotic assembly task planning and execution. Four in&#45;context learning&#10;methods are introduced to utilize the natural language processing and inference&#10;capabilities of LLMs to produce task plans in BT format, reducing manual effort&#10;and ensuring robustness and comprehensibility. We also evaluate the performance&#10;of fine&#45;tuned, fewer&#45;parameter LLMs on the same tasks. Experiments in simulated&#10;and real&#45;world settings show that our framework enhances LLMs&#39; performance in&#10;BT generation, improving success rates in BT generation through in&#45;context&#10;learning and supervised fine&#45;tuning.&#10; | General | [Link](http://arxiv.org/abs/2409.10444v1) |&#10;| The James Webb Space Telescope Absolute Flux Calibration. II.&#10; &#160;Mid&#45;Infrared Instrument Imaging and Coronagraphy | Karl D. Gordon, G. C. Sloan, Macarena Garcia Marin, Mattia Libralato, George Rieke, Jonathan A. Aguilar, Ralph Bohlin, Misty Cracraft, Marjorie Decleir, Andras Gaspar, David R. Law, Alberto Noriega&#45;Crespo, Michael Regan | &#160;&#160;The absolute flux calibration of the Mid&#45;Infrared Instrument Imaging and&#10;Coronagraphy is based on observations of multiple stars taken during the first&#10;2.5 years of JWST operations. The observations were designed to ensure that the&#10;flux calibration is valid for a range of flux densities, different subarrays,&#10;and different types of stars. The flux calibration was measured by combining&#10;observed aperture photometry corrected to infinite aperture with predictions&#10;based on previous observations and models of stellar atmospheres. A subset of&#10;these observations were combined with model point&#45;spread&#45;functions to measure&#10;the corrections to infinite aperture. Variations in the calibration factor with&#10;time, flux density, background level, type of star, subarray, integration time,&#10;rate, and well depth were investigated, and the only significant variations&#10;were with time and subarray. Observations of the same star taken approximately&#10;every month revealed a modest time&#45;dependent response loss seen mainly at the&#10;longest wavelengths. This loss is well characterized by a decaying exponential&#10;with a time constant of ~200 days. After correcting for the response loss, the&#10;band&#45;dependent scatter around the corrected average (aka repeatability) was&#10;found to range from 0.1 to 1.2%. Signals in observations taken with different&#10;subarrays can be lower by up to 3.4% compared to FULL frame. After correcting&#10;for the time and subarray dependencies, the scatter in the calibration factors&#10;measured for individual stars ranges from 1 to 4% depending on the band. The&#10;formal uncertainties on the flux calibration averaged for all observations are&#10;0.3 to 1.0%, with longer&#45;wavelength bands generally having larger&#10;uncertainties.&#10; | General | [Link](http://arxiv.org/abs/2409.10443v1) |&#10;| CtRNet&#45;X: Camera&#45;to&#45;Robot Pose Estimation in Real&#45;world Conditions Using&#10; &#160;a Single Camera | Jingpei Lu, Zekai Liang, Tristin Xie, Florian Ritcher, Shan Lin, Sainan Liu, Michael C. Yip | &#160;&#160;Camera&#45;to&#45;robot calibration is crucial for vision&#45;based robot control and&#10;requires effort to make it accurate. Recent advancements in markerless pose&#10;estimation methods have eliminated the need for time&#45;consuming physical setups&#10;for camera&#45;to&#45;robot calibration. While the existing markerless pose estimation&#10;methods have demonstrated impressive accuracy without the need for cumbersome&#10;setups, they rely on the assumption that all the robot joints are visible&#10;within the camera&#39;s field of view. However, in practice, robots usually move in&#10;and out of view, and some portion of the robot may stay out&#45;of&#45;frame during the&#10;whole manipulation task due to real&#45;world constraints, leading to a lack of&#10;sufficient visual features and subsequent failure of these approaches. To&#10;address this challenge and enhance the applicability to vision&#45;based robot&#10;control, we propose a novel framework capable of estimating the robot pose with&#10;partially visible robot manipulators. Our approach leverages the&#10;Vision&#45;Language Models for fine&#45;grained robot components detection, and&#10;integrates it into a keypoint&#45;based pose estimation network, which enables more&#10;robust performance in varied operational conditions. The framework is evaluated&#10;on both public robot datasets and self&#45;collected partial&#45;view datasets to&#10;demonstrate our robustness and generalizability. As a result, this method is&#10;effective for robot pose estimation in a wider range of real&#45;world manipulation&#10;scenarios.&#10; | General | [Link](http://arxiv.org/abs/2409.10441v1) |&#10;| Successive topological phase transitions in two distinct spin&#45;flop&#10; &#160;phases on the honeycomb lattice | Xudong Li, Jize Zhao, Jinbin Li, Qiang Luo | &#160;&#160;The Kitaev magnets with bond&#45;dependent interactions have garnered&#10;considerable attention in recent years for their ability to harbor exotic&#10;phases and nontrivial excitations. The topological magnons, which are indicated&#10;by nonzero Chern number and thermal Hall conductivity, are proposed to&#10;partially explain thermal Hall measurements in real materials. Hitherto,&#10;topological magnons have been extensively explored when the magnetic field is&#10;normal to the honeycomb plane, but their topological characteristics are less&#10;studied in the presence of in&#45;plane magnetic field. Here, we study two distinct&#10;in&#45;plane field induced spin&#45;flop phases in the $Gamma$&#45;$Gamma&#39;$ model, both&#10;of which are off&#45;diagonal couplings that have intimate relation to the Kitaev&#10;interaction. The two spin&#45;flop phases are distinguished by their out&#45;of&#45;plane&#10;spin components which can be either antiparallel or parallel, thus dubbing&#10;antiferromagnetic (AFM) or ferromagnetic (FM) spin&#45;flop phases, respectively.&#10;We map out topological phase diagrams for both phases, revealing a rich pattern&#10;of the Chern number over exchange parameters and magnetic field. We&#10;analytically calculate the boundaries of topological phase transitions when the&#10;magnetic field is along the $a$ and $b$ directions. We find that the thermal&#10;Hall conductivity and its derivative display contrasting behaviors when&#10;crossing different topological phase transitions. The striking difference of&#10;the two phases lies in that when the magnetic field is along the $b$ direction,&#10;topological magnons are totally absent in the AFM spin&#45;flop phase, while they&#10;can survive in the FM analogue in certain parameter regions.&#10; | General | [Link](http://arxiv.org/abs/2409.10439v1) |&#10;| A functorial approach to $n$&#45;abelian categories | Vitor Gulisz | &#160;&#160;We develop a functorial approach to the study of $n$&#45;abelian categories by&#10;reformulating their axioms in terms of their categories of finitely presented&#10;functors. Such an approach allows the use of classical homological algebra and&#10;representation theory techniques to understand higher homological algebra. As&#10;an application, we present two possible generalizations of the axioms &quot;every&#10;monomorphism is a kernel&quot; and &quot;every epimorphism is a cokernel&quot; of an abelian&#10;category to $n$&#45;abelian categories. We also specialize our results to modules&#10;over rings, thereby describing when the category of finitely generated&#10;projective modules over a ring is $n$&#45;abelian. Moreover, we establish a&#10;correspondence for $n$&#45;abelian categories with additive generators, which&#10;extends the higher Auslander correspondence.&#10; | General | [Link](http://arxiv.org/abs/2409.10438v1) |&#10;| Color symmetry breaking in the Potts spin glass | Jean&#45;Christophe Mourrat | &#160;&#160;The Potts spin glass is an analogue of the Sherrington&#45;Kirkpatrick model in&#10;which each spin can take one of $kappa$ possible values, which we interpret as&#10;colors. It was suggested in arXiv:2310.06745 that the order parameter for this&#10;model is always invariant with respect to permutations of the colors. We show&#10;here that this is false whenever $kappa ge 58$.&#10; | General | [Link](http://arxiv.org/abs/2409.10437v1) |&#10;| Infector characteristics exposed by spatial analysis of SARS&#45;CoV&#45;2&#10; &#160;sequence and demographic data analysed at fine geographical scales | Anna Gama, Samantha Lycett, Will Harvey, Joseph Hughes, Sema Nickbakhsh, David L Robertson, Alison Smith Palmer, Anthony Wood, Rowland Kao | &#160;&#160;Characterising drivers of SARS&#45;CoV&#45;2 circulation is crucial for understanding&#10;COVID&#45;19 because of the severity of control measures adopted during the&#10;pandemic. Whole genome sequence data augmented with demographic metadata&#10;provides the best opportunity to do this. We use Random Forest Decision Tree&#10;models to analyse a combination of over 4000 SARS&#45;CoV2 sequences from a densely&#10;sampled, mixed urban and rural population (Tayside) in Scotland in the period&#10;from August 2020 to July 2021, with fine scale geographical and&#10;socio&#45;demographic metadata. Comparing periods in versus out of &quot;lockdown&quot;&#10;restrictions, we show using genetic distance relationships that individuals&#10;from more deprived areas are more likely to get infected during lockdown but&#10;less likely to spread the infection further. As disadvantaged communities were&#10;the most affected by both COVID&#45;19 and its restrictions, our finding has&#10;important implications for informing future approaches to control future&#10;pandemics driven by similar respiratory infections.&#10; | General | [Link](http://arxiv.org/abs/2409.10436v1) |&#10;| A study of pure multi&#45;strange hadrons production in Pb+Pb collisions at&#10; &#160;LHC energies using HYDJET++ model | Gauri Devi, B. K. Singh | &#160;&#160;For the present work, we have used the HYDJET++ model to explore the&#10;production of pure multi&#45;strange hadrons in Pb+Pb collisions at&#10;$sqrt{s_{NN}}$= 2.76 TeV and $sqrt{s_{NN}}$= 5.02 TeV collision energies,&#10;respectively. We have simulated the $p_{T}$&#45;spectra and elliptic flow ($v_{2}$)&#10;of $phi$&#45;meson and $Omega$&#45;baryons comparing our results with ALICE&#10;experimental data and several phenomenological models (HIJING/$Boverline{B}$,&#10;VISHNU, EPOS, AMPT, and Krakow) across various centrality intervals.&#10;Additionally, we have calculated the nuclear modification factors ($R_{AA}$ and&#10;$R_{CP}$), which provide a perception of jet quenching phenomena. Hence, our&#10;findings enable the study of the energy and system dependence of $phi$ and&#10;$Omega$ hadrons production over a wide range of ultra&#45;relativistic collision&#10;energies. We also present the particle ratios ($Omega/phi$,&#10;$overline{Omega}^{+}/Omega^{&#45;}$, $Omega/pi$, and $phi/pi$), offering&#10;insights on the strangeness enhancement and chemical properties of the medium&#10;at both LHC collision energies.&#10; | General | [Link](http://arxiv.org/abs/2409.10435v1) |&#10;| Magnetic metamaterials by ion&#45;implantation | Christina Vantaraki, Petter Strm, Tuan T. Tran, Matas P. Grassi, Giovanni Fevola, Michael Foerster, Jerzy T. Sadowski, Daniel Primetzhofer, Vassilios Kapaklis | &#160;&#160;We present a method for the additive fabrication of planar magnetic&#10;nanoarrays with minimal surface roughness. Synthesis is accomplished by&#10;combining electron&#45;beam lithography, used to generate nanometric patterned&#10;masks, with ion implantation in thin films. By implanting $^{56}$Fe$^{+}$ ions,&#10;we are able to introduce magnetic functionality in a controlled manner into&#10;continuous Pd thin films, achieving 3D spatial resolution down to a few tens of&#10;nanometers. Our results demonstrate the successful application of this&#10;technique in fabricating square artificial spin ice lattices, which exhibit&#10;well&#45;defined magnetization textures and interactions among the patterned&#10;magnetic elements.&#10; | General | [Link](http://arxiv.org/abs/2409.10433v1) |&#10;| Structure&#45;preserving learning for multi&#45;symplectic PDEs | Sleyman Yldz, Pawan Goyal, Peter Benner | &#160;&#160;This paper presents an energy&#45;preserving machine learning method for&#10;inferring reduced&#45;order models (ROMs) by exploiting the multi&#45;symplectic form&#10;of partial differential equations (PDEs). The vast majority of&#10;energy&#45;preserving reduced&#45;order methods use symplectic Galerkin projection to&#10;construct reduced&#45;order Hamiltonian models by projecting the full models onto a&#10;symplectic subspace. However, symplectic projection requires the existence of&#10;fully discrete operators, and in many cases, such as black&#45;box PDE solvers,&#10;these operators are inaccessible. In this work, we propose an energy&#45;preserving&#10;machine learning method that can infer the dynamics of the given PDE using data&#10;only, so that the proposed framework does not depend on the fully discrete&#10;operators. In this context, the proposed method is non&#45;intrusive. The proposed&#10;method is grey box in the sense that it requires only some basic knowledge of&#10;the multi&#45;symplectic model at the partial differential equation level. We prove&#10;that the proposed method satisfies spatially discrete local energy conservation&#10;and preserves the multi&#45;symplectic conservation laws. We test our method on the&#10;linear wave equation, the Korteweg&#45;de Vries equation, and the&#10;Zakharov&#45;Kuznetsov equation. We test the generalization of our learned models&#10;by testing them far outside the training time interval.&#10; | General | [Link](http://arxiv.org/abs/2409.10432v1) |&#10;| Hippocampal synchronization in a realistic CA1 neuron model | Alessandro Fiasconaro, Michele Migliore | &#160;&#160;This work delves into studying the synchronization in two realistic neuron&#10;models using Hodgkin&#45;Huxley dynamics. Unlike simplistic point&#45;like models,&#10;excitatory synapses are here randomly distributed along the dendrites,&#10;introducing strong stochastic contributions into their signal propagation. To&#10;focus on the role of different excitatory positions, we use two copies of the&#10;same neuron whose synapses are located at different distances from the soma and&#10;are exposed to identical Poissonian distributed current pulses. The&#10;synchronization is investigated through a specifically defined spiking&#10;correlation function, and its behavior is analyzed as a function of several&#10;parameters: inhibition weight, distance from the soma of one synaptic group,&#10;excitatory inactivation delay, and weight of the excitatory synapses.&#10; | General | [Link](http://arxiv.org/abs/2409.10431v1) |&#10;| Meta&#45;Whisper: Speech&#45;Based Meta&#45;ICL for ASR on Low&#45;Resource Languages | Ming&#45;Hao Hsu, Kuan Po Huang, Hung&#45;yi Lee | &#160;&#160;This paper presents Meta&#45;Whisper, a novel approach to improve automatic&#10;speech recognition (ASR) for low&#45;resource languages using the Whisper model. By&#10;leveraging Meta In&#45;Context Learning (Meta&#45;ICL) and a k&#45;Nearest Neighbors (KNN)&#10;algorithm for sample selection, Meta&#45;Whisper enhances Whisper&#39;s ability to&#10;recognize speech in unfamiliar languages without extensive fine&#45;tuning.&#10;Experiments on the ML&#45;SUPERB dataset show that Meta&#45;Whisper significantly&#10;reduces the Character Error Rate (CER) for low&#45;resource languages compared to&#10;the original Whisper model. This method offers a promising solution for&#10;developing more adaptable multilingual ASR systems, particularly for languages&#10;with limited resources.&#10; | General | [Link](http://arxiv.org/abs/2409.10429v1) |&#10;| User&#45;Authenticated Device&#45;Independent Quantum Secure Direct&#10; &#160;Communication Protocol | Nayana Das, Saikat Basu, Goutam Paul, Vijay S. Rao | &#160;&#160;Device&#45;Independent Quantum Secure Direct Communication (DI&#45;QSDC) enhances&#10;quantum cryptography by enabling secure message transmission without relying on&#10;the trustworthiness of the devices involved. This approach mitigates risks&#10;associated with compromised or untrusted devices, common in traditional quantum&#10;communication.&#10; &#160;In this paper, we propose the first of its kind DI&#45;QSDC protocol with user&#10;identity authentication. This ensures the authenticity of both the sender and&#10;receiver prior to message exchange. We then discuss the security of the&#10;proposed protocol against common attacks, demonstrating that no eavesdropper&#10;gains any information from either the quantum or the classical channel. Next,&#10;we implement the protocol on IBM&#39;s quantum hardware and evaluate its&#10;performance in a realistic noisy environment. Additionally, by simulating&#10;common attack models, we showcase that the protocol is secure against any&#10;eavesdropper in the channel. These findings highlight the protocol&#39;s robust&#10;security and practical feasibility for real&#45;world secure quantum communication.&#10; | General | [Link](http://arxiv.org/abs/2409.10427v1) |&#10;| Role of kinematic constraints in the time reversal symmetry breaking of&#10; &#160;a model active matter | Soumen Das, Shankar Ghosh, Tridib Sadhu, Juliane U Klamser | &#160;&#160;Active&#45;matter systems are inherently out&#45;of&#45;equilibrium and perform&#10;mechanical work by utilizing their internal energy sources. Breakdown of&#10;time&#45;reversal symmetry (BTRS) is a hallmark of such dissipative non&#45;equilibrium&#10;dynamics. We introduce a robust, experimentally accessible, noninvasive,&#10;quantitative measure of BTRS in terms of the Kullback&#45;Leibler divergence in&#10;collision events, demonstrated in our novel artificial active matter, comprised&#10;of battery&#45;powered spherical rolling robots whose energetics in different modes&#10;of motion can be measured with high precision. Our dimensionless measure&#10;characterizes how dissipation and internal energetics are influenced by&#10;kinematic constraints from interactions with the environment. We propose this&#10;measure of BTRS as an empirical estimate of the distance from equilibrium. An&#10;energetic insight into this departure of active matter from equilibrium comes&#10;from our demonstration of a non&#45;trivial fluctuation symmetry, which reveals a&#10;potentially universal thermodynamic characteristic of active energetics. As a&#10;many&#45;body consequence of BTRS in our experimental active system, we demonstrate&#10;the emergence of activity&#45;induced herding, which has no equilibrium analogue.&#10; | General | [Link](http://arxiv.org/abs/2409.10425v1) |&#10;| Unveiling V Modes: Enhancing CMB Sensitivity to BSM Physics with a&#10; &#160;Non&#45;Ideal Half&#45;Wave Plate | N. Raffuzzi, M. Lembo, S. Giardiello, M. Gerbino, M. Lattanzi, P. Natoli, L. Pagano | &#160;&#160;V&#45;mode polarization of the cosmic microwave background is expected to be&#10;vanishingly small in the $Lambda$CDM model and, hence, usually ignored.&#10;Nonetheless, several astrophysical effects, as well as beyond standard model&#10;physics could produce it at a detectable level. A realistic half&#45;wave plate &#45;&#10;an optical element commonly used in CMB experiments to modulate the polarized&#10;signal &#45; can provide sensitivity to V modes without significantly spoiling that&#10;to linear polarization. We assess this sensitivity for some new&#45;generation CMB&#10;experiments, such as the LiteBIRD satellite, the ground&#45;based Simons&#10;Observatory and a CMB&#45;S4&#45;like experiment. We forecast the efficiency of these&#10;experiments to constrain the phenomenology of certain classes of BSM models&#10;inducing mixing of linear polarization states and generation of V modes in the&#10;CMB. We find that new&#45;generation experiments can improve current limits by&#10;1&#45;to&#45;3 orders of magnitude, depending on the data combination. The inclusion of&#10;V&#45;mode information dramatically boosts the sensitivity to these BSM models.&#10; | General | [Link](http://arxiv.org/abs/2409.10424v1) |&#10;| Initial data for a deformed isolated horizon | Ale Flandera, David Kofro, Tom Ledvinka | &#160;&#160;Within the isolated horizon formalism, we investigate a static axisymmetric&#10;space&#45;time of a black hole influenced by matter in its neighborhood. To&#10;illustrate the role of ingredients and assumptions in this formalism, we first&#10;show how, in spherical symmetry, the field equations and gauge conditions imply&#10;the isolated horizon initial data leading to the Schwarzschild space&#45;time.&#10;Then, we construct the initial data for a static axisymmetric isolated horizon&#10;representing a deformed black hole. The space&#45;time description in the&#10;Bondi&#45;like coordinates is then found as a series expansion in the vicinity of&#10;the horizon. To graphically illustrate this construction, we also find a&#10;numerical solution for a black hole deformed by a particular analytic model of&#10;a thin accretion disk. We also discuss how an accretion disk affects the&#10;analytical properties of the horizon geometry.&#10; | General | [Link](http://arxiv.org/abs/2409.10423v1) |&#10;| Learning Semi&#45;Supervised Medical Image Segmentation from Spatial&#10; &#160;Registration | Qianying Liu, Paul Henderson, Xiao Gu, Hang Dai, Fani Deligianni | &#160;&#160;Semi&#45;supervised medical image segmentation has shown promise in training&#10;models with limited labeled data and abundant unlabeled data. However,&#10;state&#45;of&#45;the&#45;art methods ignore a potentially valuable source of unsupervised&#10;semantic information &#45;&#45; spatial registration transforms between image volumes.&#10;To address this, we propose CCT&#45;R, a contrastive cross&#45;teaching framework&#10;incorporating registration information. To leverage the semantic information&#10;available in registrations between volume pairs, CCT&#45;R incorporates two&#10;proposed modules: Registration Supervision Loss (RSL) and Registration&#45;Enhanced&#10;Positive Sampling (REPS). The RSL leverages segmentation knowledge derived from&#10;transforms between labeled and unlabeled volume pairs, providing an additional&#10;source of pseudo&#45;labels. REPS enhances contrastive learning by identifying&#10;anatomically&#45;corresponding positives across volumes using registration&#10;transforms. Experimental results on two challenging medical segmentation&#10;benchmarks demonstrate the effectiveness and superiority of CCT&#45;R across&#10;various semi&#45;supervised settings, with as few as one labeled case. Our code is&#10;available at&#10;https://github.com/kathyliu579/ContrastiveCross&#45;teachingWithRegistration.&#10; | General | [Link](http://arxiv.org/abs/2409.10422v1) |&#10;| Multidimensional Deconvolution with Profiling | Huanbiao Zhu, Krish Desai, Mikael Kuusela, Vinicius Mikuni, Benjamin Nachman, Larry Wasserman | &#160;&#160;In many experimental contexts, it is necessary to statistically remove the&#10;impact of instrumental effects in order to physically interpret measurements.&#10;This task has been extensively studied in particle physics, where the&#10;deconvolution task is called unfolding. A number of recent methods have shown&#10;how to perform high&#45;dimensional, unbinned unfolding using machine learning.&#10;However, one of the assumptions in all of these methods is that the detector&#10;response is accurately modeled in the Monte Carlo simulation. In practice, the&#10;detector response depends on a number of nuisance parameters that can be&#10;constrained with data. We propose a new algorithm called Profile OmniFold&#10;(POF), which works in a similar iterative manner as the OmniFold (OF) algorithm&#10;while being able to simultaneously profile the nuisance parameters. We&#10;illustrate the method with a Gaussian example as a proof of concept&#10;highlighting its promising capabilities.&#10; | General | [Link](http://arxiv.org/abs/2409.10421v1) |&#10;| HiFi&#45;CS: Towards Open Vocabulary Visual Grounding For Robotic Grasping&#10; &#160;Using Vision&#45;Language Models | Vineet Bhat, Prashanth Krishnamurthy, Ramesh Karri, Farshad Khorrami | &#160;&#160;Robots interacting with humans through natural language can unlock numerous&#10;applications such as Referring Grasp Synthesis (RGS). Given a text query, RGS&#10;determines a stable grasp pose to manipulate the referred object in the robot&#39;s&#10;workspace. RGS comprises two steps: visual grounding and grasp pose estimation.&#10;Recent studies leverage powerful Vision&#45;Language Models (VLMs) for visually&#10;grounding free&#45;flowing natural language in real&#45;world robotic execution.&#10;However, comparisons in complex, cluttered environments with multiple instances&#10;of the same object are lacking. This paper introduces HiFi&#45;CS, featuring&#10;hierarchical application of Featurewise Linear Modulation (FiLM) to fuse image&#10;and text embeddings, enhancing visual grounding for complex attribute rich text&#10;queries encountered in robotic grasping. Visual grounding associates an object&#10;in 2D/3D space with natural language input and is studied in two scenarios:&#10;Closed and Open Vocabulary. HiFi&#45;CS features a lightweight decoder combined&#10;with a frozen VLM and outperforms competitive baselines in closed vocabulary&#10;settings while being 100x smaller in size. Our model can effectively guide&#10;open&#45;set object detectors like GroundedSAM to enhance open&#45;vocabulary&#10;performance. We validate our approach through real&#45;world RGS experiments using&#10;a 7&#45;DOF robotic arm, achieving 90.33% visual grounding accuracy in 15 tabletop&#10;scenes. We include our codebase in the supplementary material.&#10; | General | [Link](http://arxiv.org/abs/2409.10419v1) |&#10;| X&#45;ray reverberation as an explanation for UV/optical variability in&#10; &#160;nearby Seyferts | M. Papoutsis, I. E. Papadakis, C. Panagiotou, M. Doviak, E. Kammoun | &#160;&#160;Active galactic nuclei (AGNs) are known to be variable across all&#10;wavelengths. Significant observational efforts have been invested in the last&#10;decade in studying their ultraviolet (UV) and optical variability. Long and&#10;densely sampled, multi&#45;wavelength monitoring campaigns of numerous Seyfert&#10;galaxies have been conducted with the aim of determining the X&#45;ray/UV/optical&#10;continuum time lags. Time&#45;lag studies can be used to constrain theoretical&#10;models. The observed time lags can be explained by thermal reprocessing of the&#10;X&#45;rays illuminating the accretion disc (known as the X&#45;ray reverberation&#10;model). However, the observed light curves contain more information that can be&#10;used to further constrain physical models. Our primary objective is to&#10;investigate whether, in addition to time lags, the X&#45;ray reverberation model&#10;can also explain the UV/optical variability amplitude of nearby Seyferts. To do&#10;this, we measured the excess variance of four sources (namely Mrk 509, NGC&#10;4151, NGC 2617, and Mrk 142) as a function of wavelength using data from&#10;archival long, multi&#45;wavelength campaigns with Swift, and ground&#45;based&#10;telescopes. We also computed the model excess variance in the case of the X&#45;ray&#10;reverberation model by determining the disc&#39;s transfer function and assuming a&#10;bending power law for the X&#45;ray power spectrum. We tested the validity of the&#10;model by comparing the measured and model variances for a range of accretion&#10;rates and X&#45;ray source heights. We conclude that the X&#45;ray thermal&#10;reverberation model can fit both the continuum, UV/optical time lags, as well&#10;as the variance in these AGNs, for the same physical parameters. Our results&#10;suggest that the accretion disc is constant and that all the observed&#10;UV/optical variations, on timescales of days and up to a few weeks, can be&#10;fully explained by the variable X&#45;rays as they illuminate the accretion disc.&#10; | General | [Link](http://arxiv.org/abs/2409.10417v1) |&#10;| Local central limit theorem for Mallows measure | Alexey Bufetov, Kailun Chen | &#160;&#160;We study the statistics of the Mallows measure on permutations in the limit&#10;pioneered by Starr (2009). Our main result is the local central limit theorem&#10;for its height function. We also re&#45;derive versions of the law of large numbers&#10;and the large deviation principle, obtain the standard central limit theorem&#10;from the local one, and establish a multi&#45;point version of the local central&#10;limit theorem.&#10; | General | [Link](http://arxiv.org/abs/2409.10415v1) |&#10;| On interactive anisotropic walks in two dimensions generated from a&#10; &#160;three state opinion dynamics model | Surajit Saha, Parongama Sen | &#160;&#160;A system of interacting walkers on a two&#45;dimensional space where the dynamics&#10;of each walker are governed by the opinions of agents of a three&#45;state opinion&#10;dynamics model are considered. Such walks, inspired by Ising&#45;like models and&#10;opinions dynamics models, are usually considered in one&#45;dimensional virtual&#10;spaces. Here, the mapping is done in such a way that the walk is directed along&#10;the $y$ axis while it can move either way along the $x$ axis. We explore the&#10;properties of such walks as the parameter representing the noise in the opinion&#10;dynamics model, responsible for a continuous phase transition, is varied. The&#10;walk features show marked differences as the system crosses the critical point.&#10;The bivariate distribution of the displacements below the critical point is a&#10;modified biased Gaussian function of x and y which is symmetric about the X&#10;axis.&#10; &#160;The marginal probability distributions can be extracted and the scaling forms&#10;of different quantities, showing power law behaviour, are obtained. The&#10;directed nature of the walk is reflected in the marginal distributions as well&#10;as in the exponents.&#10; | General | [Link](http://arxiv.org/abs/2409.10413v1) |&#10;| A Large&#45;Scale Privacy Assessment of Android Third&#45;Party SDKs | Mark Huasong Meng, Chuan Yan, Yun Hao, Qing Zhang, Zeyu Wang, Kailong Wang, Sin Gee Teo, Guangdong Bai, Jin Song Dong | &#160;&#160;Third&#45;party Software Development Kits (SDKs) are widely adopted in Android&#10;app development, to effortlessly accelerate development pipelines and enhance&#10;app functionality. However, this convenience raises substantial concerns about&#10;unauthorized access to users&#39; privacy&#45;sensitive information, which could be&#10;further abused for illegitimate purposes like user tracking or monetization.&#10;Our study offers a targeted analysis of user privacy protection among Android&#10;third&#45;party SDKs, filling a critical gap in the Android software supply chain.&#10;It focuses on two aspects of their privacy practices, including data&#10;exfiltration and behavior&#45;policy compliance (or privacy compliance), utilizing&#10;techniques of taint analysis and large language models. It covers 158&#10;widely&#45;used SDKs from two key SDK release platforms, the official one and a&#10;large alternative one. From them, we identified 338 instances of privacy data&#10;exfiltration. On the privacy compliance, our study reveals that more than 30%&#10;of the examined SDKs fail to provide a privacy policy to disclose their data&#10;handling practices. Among those that provide privacy policies, 37% of them&#10;over&#45;collect user data, and 88% falsely claim access to sensitive data. We&#10;revisit the latest versions of the SDKs after 12 months. Our analysis&#10;demonstrates a persistent lack of improvement in these concerning trends. Based&#10;on our findings, we propose three actionable recommendations to mitigate the&#10;privacy leakage risks and enhance privacy protection for Android users. Our&#10;research not only serves as an urgent call for industry attention but also&#10;provides crucial insights for future regulatory interventions.&#10; | General | [Link](http://arxiv.org/abs/2409.10411v1) |&#10;| A point process approach for the classification of noisy calcium imaging&#10; &#160;data | Arianna Burzacchi, Nicoletta D&#39;Angelo, David Payares&#45;Garcia, Jorge Mateu | &#160;&#160;We study noisy calcium imaging data, with a focus on the classification of&#10;spike traces. As raw traces obscure the true temporal structure of neuron&#39;s&#10;activity, we performed a tuned filtering of the calcium concentration using two&#10;methods: a biophysical model and a kernel mapping. The former characterizes&#10;spike trains related to a particular triggering event, while the latter filters&#10;out the signal and refines the selection of the underlying neuronal response.&#10;Transitioning from traditional time series analysis to point process theory,&#10;the study explores spike&#45;time distance metrics and point pattern prototypes to&#10;describe repeated observations. We assume that the analyzed neuron&#39;s firing&#10;events, i.e. spike occurrences, are temporal point process events. In&#10;particular, the study aims to categorize 47 point patterns by depth, assuming&#10;the similarity of spike occurrences within specific depth categories. The&#10;results highlight the pivotal roles of depth and stimuli in discerning diverse&#10;temporal structures of neuron firing events, confirming the point process&#10;approach based on prototype analysis is largely useful in the classification of&#10;spike traces.&#10; | General | [Link](http://arxiv.org/abs/2409.10409v1) |&#10;| Variational closures for composite homogenised fluid flows | Theo Diamantakis, Ruiao Hu | &#160;&#160;The Stochastic Advection by Lie Transport is a variational formulation of&#10;stochastic fluid dynamics introduced to model the effects of unresolved scales,&#10;whilst preserving the geometric structure of ideal fluid flows. In this work,&#10;we show that the SALT equations can arise from the decomposition of the fluid&#10;flow map into its mean and fluctuating components. The fluctuating component is&#10;realised as a prescribed stochastic diffeomorphism that introduces stochastic&#10;transport into the system and we construct it using homogenisation theory. The&#10;dynamics of the mean component are derived from a variational principle&#10;utilising particular forms of variations that preserve the composite structure&#10;of the flow. Using a new variational principle, we show that SALT equations can&#10;arise from random Lagrangians and are equivalent to random coefficient PDEs. We&#10;also demonstrate how to modify the composite flow and the associated&#10;variational principle to derive models inspired by the Lagrangian Averaged&#10;Euler&#45;Poincare (LAEP) theory.&#10; | General | [Link](http://arxiv.org/abs/2409.10408v1) |&#10;| Bitcoin Transaction Behavior Modeling Based on Balance Data | Yu Zhang, Claudio Tessone | &#160;&#160;When analyzing Bitcoin users&#39; balance distribution, we observed that it&#10;follows a log&#45;normal pattern. Drawing parallels from the successful application&#10;of Gibrat&#39;s law of proportional growth in explaining city size and word&#10;frequency distributions, we tested whether the same principle could account for&#10;the log&#45;normal distribution in Bitcoin balances. However, our calculations&#10;revealed that the exponent parameters in both the drift and variance terms&#10;deviate slightly from one. This suggests that Gibrat&#39;s proportional growth rule&#10;alone does not fully explain the log&#45;normal distribution observed in Bitcoin&#10;users&#39; balances. During our exploration, we discovered an intriguing&#10;phenomenon: Bitcoin users tend to fall into two distinct categories based on&#10;their behavior, which we refer to as ``poor&quot; and ``wealthy&quot; users. Poor users,&#10;who initially purchase only a small amount of Bitcoin, tend to buy more&#10;bitcoins first and then sell out all their holdings gradually over time. The&#10;certainty of selling all their coins is higher and higher with time. In&#10;contrast, wealthy users, who acquire a large amount of Bitcoin from the start,&#10;tend to sell off their holdings over time. The speed at which they sell their&#10;bitcoins is lower and lower over time and they will hold at least a small part&#10;of their initial holdings at last. Interestingly, the wealthier the user, the&#10;larger the proportion of their balance and the higher the certainty they tend&#10;to sell. This research provided an interesting perspective to explore bitcoin&#10;users&#39; behaviors which may apply to other finance markets.&#10; | General | [Link](http://arxiv.org/abs/2409.10407v1) |&#10;| Stochastic Data&#45;Driven Predictive Control: Chance&#45;Constraint&#10; &#160;Satisfaction with Identified Multi&#45;step Predictors | Haldun Balim, Andrea Carron, Melanie N. Zeilinger, Johannes Khler | &#160;&#160;We propose a novel data&#45;driven stochastic model predictive control framework&#10;for uncertain linear systems with noisy output measurements. Our approach&#10;leverages multi&#45;step predictors to efficiently propagate uncertainty, ensuring&#10;chance constraint satisfaction with minimal conservatism. In particular, we&#10;present a strategy to identify multi&#45;step predictors and quantify the&#10;associated uncertainty using a surrogate (data&#45;driven) state space model. Then,&#10;we utilize the derived distribution to formulate a constraint tightening that&#10;ensures chance constraint satisfaction. A numerical example highlights the&#10;reduced conservatism of handling parametric uncertainty in the proposed method&#10;compared to state&#45;of&#45;the&#45;art solutions.&#10; | General | [Link](http://arxiv.org/abs/2409.10405v1) |&#10;| A Knowledge&#45;Enhanced Disease Diagnosis Method Based on Prompt Learning&#10; &#160;and BERT Integration | Zhang Zheng | &#160;&#160;This paper proposes a knowledge&#45;enhanced disease diagnosis method based on a&#10;prompt learning framework. The method retrieves structured knowledge from&#10;external knowledge graphs related to clinical cases, encodes it, and injects it&#10;into the prompt templates to enhance the language model&#39;s understanding and&#10;reasoning capabilities for the task.We conducted experiments on three public&#10;datasets: CHIP&#45;CTC, IMCS&#45;V2&#45;NER, and KUAKE&#45;QTR. The results show that the&#10;proposed method significantly outperforms existing models across multiple&#10;evaluation metrics, with an F1 score improvement of 2.4% on the CHIP&#45;CTC&#10;dataset, 3.1% on the IMCS&#45;V2&#45;NER dataset,and 4.2% on the KUAKE&#45;QTR dataset.&#10;Additionally,ablation studies confirmed the critical role of the knowledge&#10;injection module,as the removal of this module resulted in a significant drop&#10;in F1 score. The experimental results demonstrate that the proposed method not&#10;only effectively improves the accuracy of disease diagnosis but also enhances&#10;the interpretability of the predictions, providing more reliable support and&#10;evidence for clinical diagnosis.&#10; | General | [Link](http://arxiv.org/abs/2409.10403v1) |&#10;| A Statistical Equilibrium Approach to Adam Smith&#39;s Labor Theory of Value | Ellis Scharfenaker, Bruno Theodosio, Duncan K. Foley | &#160;&#160;Adam Smith&#39;s inquiry into the emergence and stability of the&#10;self&#45;organization of the division of labor in commodity production and exchange&#10;is considered using statistical equilibrium methods from statistical physics.&#10;We develop a statistical equilibrium model of the distribution of independent&#10;direct producers in a hub&#45;and&#45;spoke framework that predicts both the center of&#10;gravity of producers across lines of production as well as the endogenous&#10;fluctuations between lines of production that arise from Smith&#39;s concept of&#10;&quot;perfect liberty&quot;. The ergodic distribution of producers implies a long&#45;run&#10;balancing of &quot;advantages to disadvantages&quot; across lines of employment and&#10;gravitation of market prices around Smith&#39;s natural prices.&#10; | General | [Link](http://arxiv.org/abs/2409.10402v1) |&#10;| Hydrodynamic mechanism for stable spindle positioning in meiosis II&#10; &#160;oocytes | Weida Liao, Eric Lauga | &#160;&#160;Cytoplasmic streaming, the persistent flow of fluid inside a cell, induces&#10;intracellular transport, which plays a key role in fundamental biological&#10;processes. In meiosis II mouse oocytes (developing egg cells) awaiting&#10;fertilisation, the spindle, which is the protein structure responsible for&#10;dividing genetic material in a cell, must maintain its position near the cell&#10;cortex (the thin actin network bound to the cell membrane) for many hours.&#10;However, the cytoplasmic streaming that accompanies this stable positioning&#10;would intuitively appear to destabilise the spindle position. Here, through a&#10;combination of numerical and analytical modelling, we reveal a new,&#10;hydrodynamic mechanism for stable spindle positioning beneath the cortical cap.&#10;We show that this stability depends critically on the spindle size and the&#10;active driving from the cortex, and demonstrate that stable spindle positioning&#10;can result purely from a hydrodynamic suction force exerted on the spindle by&#10;the cytoplasmic flow. Our findings show that local fluid dynamic forces can be&#10;sufficient to stabilise the spindle, explaining robustness against&#10;perturbations not only perpendicular but also parallel to the cortex. Our&#10;results shed light on the importance of cytoplasmic streaming in mammalian&#10;meiosis.&#10; | General | [Link](http://arxiv.org/abs/2409.10401v1) |&#10;| Sherpa: An Open Source Python Fitting Package | Aneta Siemiginowska, Douglas Burke, Hans Moritz Gnther, Nicholas P. Lee, Warren McLaughlin, David A. Principe, Harlan Cheer, Antonella Fruscione, Omar Laurino, Jonathan McDowell, Marie Terrell | &#160;&#160;We present an overview of Sherpa, an open source Python project, and discuss&#10;its development history, broad design concepts and capabilities. Sherpa&#10;contains powerful tools for combining parametric models into complex&#10;expressions that can be fit to data using a variety of statistics and&#10;optimization methods. It is easily extensible to include user&#45;defined models,&#10;statistics, and optimization methods. It provides a high&#45;level User Interface&#10;for interactive data&#45;analysis, such as within a Jupyter notebook, and it can&#10;also be used as a library component, providing fitting and modeling&#10;capabilities to an application. We include a few examples of Sherpa&#10;applications to multiwavelength astronomical data. The code is available&#10;GitHub: https://github.com/sherpa/sherpa&#10; | General | [Link](http://arxiv.org/abs/2409.10400v1) |&#10;| Minimally coupled $$&#45;exponential inflation with an $R^2$ term in&#10; &#160;the Palatini formulation | Nilay Bostan, Rafid H. Dejrah | &#160;&#160;We focus on the inflationary predictions of $beta$&#45;exponential potential&#10;models, in which the inflaton is a representation of the field delineating the&#10;size of extra&#45;dimension. Since it offers a well&#45;motivated starting point for&#10;the study of physics at very high energies, we incorporate an $R^2$ term in the&#10;Palatini gravity. In addition, afterward the inflation, the inflaton oscillates&#10;about the minimum of the inflation potential, and reheats the universe. This&#10;occurs during the reheating phase, at which the inflaton decays into the&#10;standard model particles, which fill the universe. We extend our examination by&#10;considering the reheating effects on inflationary observables by employing the&#10;different scenarios of the reheat temperature. Supposing the standard thermal&#10;history after inflation, we display the inflationary predictions, $n_s, r,&#10;mathrm{d}n_s/mathrm{d}&#10;n k$ of $beta$&#45;exponential potential with minimal&#10;coupling in Palatini $R^2$ gravity. Also, different kinds of constraints from a&#10;variety of observations, such as BICEP/Keck, Planck 2018, as well as future&#10;possible detectable sensitivities that might be reached by CMB experiments:&#10;CMB&#45;S4 and LiteBIRD are taken into account in this work. We indicate that our&#10;results are consistent with both the latest data and the future sensitivity&#10;forecasts of LiteBIRD/Planck and CMB&#45;S4. Finally, the results in this study&#10;highlight the viability of our model even in the case of the existence of more&#10;stringent constraints expected from future achievable confidence level limits.&#10; | General | [Link](http://arxiv.org/abs/2409.10398v1) |&#10;| Quantifying Observational Projection Effects with a Simulation&#45;based hot&#10; &#160;CGM model | Soumya Shreeram, Johan Comparat, Andrea Merloni, Yi Zhang, Gabriele Ponti, Kirpal Nandra, John ZuHone, Ilaria Marini, Stephan Vladutescu&#45;Zopp, Paola Popesso, Ruediger Pakmor, Riccardo Seppi, Celine Peroux, Daniele Sorini | &#160;&#160;The hot phase of the circumgalactic medium (CGM) allows us to probe the&#10;inflow and outflow of gas within a galaxy, which is responsible for dictating&#10;the evolution of the galaxy. Studying the hot CGM sheds light on a better&#10;understanding of gas physics, which is crucial to inform and constrain&#10;simulation models. With the recent advances in observational measurements&#10;probing the hot CGM in X&#45;rays and tSZ, we have a new avenue for widening our&#10;knowledge of gas physics and feedback by exploiting the information from&#10;current/future observations. In this paper, we use the TNG300 hydrodynamical&#10;simulations to build a fully self&#45;consistent forward model for the hot CGM. We&#10;construct a lightcone and generate mock X&#45;ray observations. We quantify the&#10;projection effects, namely the locally correlated large&#45;scale structure in&#10;X&#45;rays and the effect due to satellite galaxies misclassified as centrals which&#10;affects the measured hot CGM galactocentric profiles in stacking experiments.&#10;We present an analytical model that describes the intrinsic X&#45;ray surface&#10;brightness profile across the stellar and halo mass bins. The increasing&#10;stellar mass bins result in decreasing values of $beta$, the exponent&#10;quantifying the slope of the intrinsic galactocentric profiles. We carry&#10;forward the current state&#45;of&#45;the&#45;art by also showing the impact of the locally&#10;correlated environment on the measured X&#45;ray surface brightness profiles. We&#10;also present, for the first time, the effect of misclassified centrals in&#10;stacking experiments for three stellar mass bins: $10^{10.5&#45;11} M_odot$,&#10;$10^{11&#45;11.2} M_odot$, and $10^{11.2&#45;11.5} M_odot$. We find that the&#10;contaminating effect of the misclassified centrals on the stacked profiles&#10;increases when the stellar mass decreases.&#10; | General | [Link](http://arxiv.org/abs/2409.10397v1) |&#10;| MOST: MR reconstruction Optimization for multiple downStream Tasks via&#10; &#160;continual learning | Hwihun Jeong, Se Young Chun, Jongho Lee | &#160;&#160;Deep learning&#45;based Magnetic Resonance (MR) reconstruction methods have&#10;focused on generating high&#45;quality images but they often overlook the impact on&#10;downstream tasks (e.g., segmentation) that utilize the reconstructed images.&#10;Cascading separately trained reconstruction network and downstream task network&#10;has been shown to introduce performance degradation due to error propagation&#10;and domain gaps between training datasets. To mitigate this issue, downstream&#10;task&#45;oriented reconstruction optimization has been proposed for a single&#10;downstream task. Expanding this optimization to multi&#45;task scenarios is not&#10;straightforward. In this work, we extended this optimization to sequentially&#10;introduced multiple downstream tasks and demonstrated that a single MR&#10;reconstruction network can be optimized for multiple downstream tasks by&#10;deploying continual learning (MOST). MOST integrated techniques from&#10;replay&#45;based continual learning and image&#45;guided loss to overcome catastrophic&#10;forgetting. Comparative experiments demonstrated that MOST outperformed a&#10;reconstruction network without finetuning, a reconstruction network with&#10;na&quot;ive finetuning, and conventional continual learning methods. This&#10;advancement empowers the application of a single MR reconstruction network for&#10;multiple downstream tasks. The source code is available at:&#10;https://github.com/SNU&#45;LIST/MOST&#10; | General | [Link](http://arxiv.org/abs/2409.10394v1) |&#10;| Multicopy quantum state teleportation with application to storage and&#10; &#160;retrieval of quantum programs | Frdric Grosshans, Micha Horodecki, Mio Murao, Tomasz Mynik, Marco Tlio Quintino, Micha Studziski, Satoshi Yoshida | &#160;&#160;This work considers a teleportation task for Alice and Bob in a scenario&#10;where Bob cannot perform corrections. In particular, we analyse the task of&#10;textit{multicopy state teleportation}, where Alice has $k$ identical copies of&#10;an arbitrary unknown $d$&#45;dimensional qudit state $vertpsi&#13;angle$ to teleport&#10;a single copy of $vertpsi&#13;angle$ to Bob using a maximally entangled&#10;two&#45;qudit state shared between Alice and Bob without Bob&#39;s correction. Alice&#10;may perform a joint measurement on her half of the entangled state and the $k$&#10;copies of $vertpsi&#13;angle$. We prove that the maximal probability of success&#10;for teleporting the exact state $vertpsi&#13;angle$ to Bob is&#10;$p(d,k)=frac{k}{d(k&#45;1+d)}$ and present an explicit protocol to attain this&#10;performance. Then, by utilising $k$ copies of an arbitrary target state&#10;$vertpsi&#13;angle$, we show how the multicopy state teleportation protocol can&#10;be employed to enhance the success probability of storage and retrieval of&#10;quantum programs, which aims to universally retrieve the action of an arbitrary&#10;quantum channel that is stored in a state. Our proofs make use of group&#10;representation theory methods, which may find applications beyond the problems&#10;addressed in this work.&#10; | General | [Link](http://arxiv.org/abs/2409.10393v1) |&#10;| TPFL: Tsetlin&#45;Personalized Federated Learning with Confidence&#45;Based&#10; &#160;Clustering | Rasoul Jafari Gohari, Laya Aliahmadipour, Ezat Valipour | &#160;&#160;The world of Machine Learning (ML) has witnessed rapid changes in terms of&#10;new models and ways to process users data. The majority of work that has been&#10;done is focused on Deep Learning (DL) based approaches. However, with the&#10;emergence of new algorithms such as the Tsetlin Machine (TM) algorithm, there&#10;is growing interest in exploring alternative approaches that may offer unique&#10;advantages in certain domains or applications. One of these domains is&#10;Federated Learning (FL), in which users privacy is of utmost importance. Due to&#10;its novelty, FL has seen a surge in the incorporation of personalization&#10;techniques to enhance model accuracy while maintaining user privacy under&#10;personalized conditions. In this work, we propose a novel approach dubbed TPFL:&#10;Tsetlin&#45;Personalized Federated Learning, in which models are grouped into&#10;clusters based on their confidence towards a specific class. In this way,&#10;clustering can benefit from two key advantages. Firstly, clients share only&#10;what they are confident about, resulting in the elimination of wrongful weight&#10;aggregation among clients whose data for a specific class may have not been&#10;enough during the training. This phenomenon is prevalent when the data are&#10;non&#45;Independent and Identically Distributed (non&#45;IID). Secondly, by sharing&#10;only weights towards a specific class, communication cost is substantially&#10;reduced, making TPLF efficient in terms of both accuracy and communication&#10;cost. The results of TPFL demonstrated the highest accuracy on three different&#10;datasets; namely MNIST, FashionMNIST and FEMNIST.&#10; | General | [Link](http://arxiv.org/abs/2409.10392v1) |&#10;| Prompt&#45;and&#45;Transfer: Dynamic Class&#45;aware Enhancement for Few&#45;shot&#10; &#160;Segmentation | Hanbo Bi, Yingchao Feng, Wenhui Diao, Peijin Wang, Yongqiang Mao, Kun Fu, Hongqi Wang, Xian Sun | &#160;&#160;For more efficient generalization to unseen domains (classes), most Few&#45;shot&#10;Segmentation (FSS) would directly exploit pre&#45;trained encoders and only&#10;fine&#45;tune the decoder, especially in the current era of large models. However,&#10;such fixed feature encoders tend to be class&#45;agnostic, inevitably activating&#10;objects that are irrelevant to the target class. In contrast, humans can&#10;effortlessly focus on specific objects in the line of sight. This paper mimics&#10;the visual perception pattern of human beings and proposes a novel and powerful&#10;prompt&#45;driven scheme, called ``Prompt and Transfer&quot; (PAT), which constructs a&#10;dynamic class&#45;aware prompting paradigm to tune the encoder for focusing on the&#10;interested object (target class) in the current task. Three key points are&#10;elaborated to enhance the prompting: 1) Cross&#45;modal linguistic information is&#10;introduced to initialize prompts for each task. 2) Semantic Prompt Transfer&#10;(SPT) that precisely transfers the class&#45;specific semantics within the images&#10;to prompts. 3) Part Mask Generator (PMG) that works in conjunction with SPT to&#10;adaptively generate different but complementary part prompts for different&#10;individuals. Surprisingly, PAT achieves competitive performance on 4 different&#10;tasks including standard FSS, Cross&#45;domain FSS (e.g., CV, medical, and remote&#10;sensing domains), Weak&#45;label FSS, and Zero&#45;shot Segmentation, setting new&#10;state&#45;of&#45;the&#45;arts on 11 benchmarks.&#10; | General | [Link](http://arxiv.org/abs/2409.10389v1) |&#10;| Revising the Structure of Recurrent Neural Networks to Eliminate&#10; &#160;Numerical Derivatives in Forming Physics Informed Loss Terms with Respect to&#10; &#160;Time | Mahyar Jahani&#45;nasab, Mohamad Ali Bijarchi | &#160;&#160;Solving unsteady partial differential equations (PDEs) using recurrent neural&#10;networks (RNNs) typically requires numerical derivatives between each block of&#10;the RNN to form the physics informed loss function. However, this introduces&#10;the complexities of numerical derivatives into the training process of these&#10;models. In this study, we propose modifying the structure of the traditional&#10;RNN to enable the prediction of each block over a time interval, making it&#10;possible to calculate the derivative of the output with respect to time using&#10;the backpropagation algorithm. To achieve this, the time intervals of these&#10;blocks are overlapped, defining a mutual loss function between them.&#10;Additionally, the employment of conditional hidden states enables us to achieve&#10;a unique solution for each block. The forget factor is utilized to control the&#10;influence of the conditional hidden state on the prediction of the subsequent&#10;block. This new model, termed the Mutual Interval RNN (MI&#45;RNN), is applied to&#10;solve three different benchmarks: the Burgers equation, unsteady heat&#10;conduction in an irregular domain, and the Green vortex problem. Our results&#10;demonstrate that MI&#45;RNN can find the exact solution more accurately compared to&#10;existing RNN models. For instance, in the second problem, MI&#45;RNN achieved one&#10;order of magnitude less relative error compared to the RNN model with numerical&#10;derivatives.&#10; | General | [Link](http://arxiv.org/abs/2409.10388v1) |&#10;| Sharp decay rate for eigenfunctions of perturbed periodic Schrdinger&#10; &#160;operators | Wencai Liu, Rodrigo Matos, John N. Treuer | &#160;&#160;This paper investigates uniqueness results for perturbed periodic&#10;Schr&quot;odinger operators on $mathbb{Z}^d$. Specifically, we consider operators&#10;of the form $H = &#45;Delta + V + v$, where $Delta$ is the discrete Laplacian,&#10;$V: mathbb{Z}^d &#13;ightarrow mathbb{R}$ is a periodic potential, and $v:&#10;mathbb{Z}^d &#13;ightarrow mathbb{C}$ represents a decaying impurity. We&#10;establish quantitative conditions under which the equation $&#45;Delta u + V u + v&#10;u = &#10;ambda u$, for $&#10;ambda in mathbb{C}$, admits only the trivial solution&#10;$u equiv 0$. Key applications include the absence of embedded eigenvalues for&#10;operators with impurities decaying faster than any exponential function and the&#10;determination of sharp decay rates for eigenfunctions. Our findings extend&#10;previous works by providing precise decay conditions for impurities and&#10;analyzing different spectral regimes of $&#10;ambda$.&#10; | General | [Link](http://arxiv.org/abs/2409.10387v1) |&#10;| Mamba&#45;ST: State Space Model for Efficient Style Transfer | Filippo Botti, Alex Ergasti, Leonardo Rossi, Tomaso Fontanini, Claudio Ferrari, Massimo Bertozzi, Andrea Prati | &#160;&#160;The goal of style transfer is, given a content image and a style source,&#10;generating a new image preserving the content but with the artistic&#10;representation of the style source. Most of the state&#45;of&#45;the&#45;art architectures&#10;use transformers or diffusion&#45;based models to perform this task, despite the&#10;heavy computational burden that they require. In particular, transformers use&#10;self&#45; and cross&#45;attention layers which have large memory footprint, while&#10;diffusion models require high inference time. To overcome the above, this paper&#10;explores a novel design of Mamba, an emergent State&#45;Space Model (SSM), called&#10;Mamba&#45;ST, to perform style transfer. To do so, we adapt Mamba linear equation&#10;to simulate the behavior of cross&#45;attention layers, which are able to combine&#10;two separate embeddings into a single output, but drastically reducing memory&#10;usage and time complexity. We modified the Mamba&#39;s inner equations so to accept&#10;inputs from, and combine, two separate data streams. To the best of our&#10;knowledge, this is the first attempt to adapt the equations of SSMs to a vision&#10;task like style transfer without requiring any other module like&#10;cross&#45;attention or custom normalization layers. An extensive set of experiments&#10;demonstrates the superiority and efficiency of our method in performing style&#10;transfer compared to transformers and diffusion models. Results show improved&#10;quality in terms of both ArtFID and FID metrics. Code is available at&#10;https://github.com/FilippoBotti/MambaST.&#10; | General | [Link](http://arxiv.org/abs/2409.10385v1) |&#10;| Performance&#45;Portable Numerical Relativity with AthenaK | Hengrui Zhu, Jacob Fields, Francesco Zappa, David Radice, James Stone, Alireza Rashti, William Cook, Sebastiano Bernuzzi, Boris Daszuta | &#160;&#160;We present the numerical relativity module within AthenaK, an open source&#10;performance&#45;portable astrophysics code designed for exascale computing&#10;applications. This module employs the Z4c formulation to solve the Einstein&#10;equations. We demonstrate its accuracy through a series of standard numerical&#10;relativity tests, including convergence of the gravitational waveform from&#10;binary black hole coalescence. Furthermore, we conduct scaling tests on OLCF&#10;Frontier and NERSC Perlmutter, where AthenaK exhibits excellent weak scaling&#10;efficiency of 80% on up to 65,536 AMD MI250X GPUs on Frontier (relative to 4&#10;GPUs) and strong scaling efficiencies of 84% and 77% on AMD MI250X and NVIDIA&#10;A100 GPUs on Frontier and Perlmutter respectively. Additionally, we observe a&#10;significant performance boost, with two orders of magnitude speedup ($gtrsim&#10;200times$) on a GPU compared to a single CPU core, affirming that AthenaK is&#10;well&#45;suited for exascale computing, thereby expanding the potential for&#10;breakthroughs in numerical relativity research.&#10; | General | [Link](http://arxiv.org/abs/2409.10383v1) |&#10;| J&#45;UBIK: The JAX&#45;accelerated Universal Bayesian Imaging Kit | Vincent Eberle, Matteo Guardiani, Margret Westerkamp, Philipp Frank, Julian Rstig, Julia Stadler, Torsten A. Enlin | &#160;&#160;Many advances in astronomy and astrophysics originate from accurate images of&#10;the sky emission across multiple wavelengths. This often requires&#10;reconstructing spatially and spectrally correlated signals detected from&#10;multiple instruments. To facilitate the high&#45;fidelity imaging of these signals,&#10;we introduce the universal Bayesian imaging kit (UBIK). Specifically, we&#10;present J&#45;UBIK, a flexible and modular implementation leveraging the&#10;JAX&#45;accelerated NIFTy.re software as its backend. J&#45;UBIK streamlines the&#10;implementation of the key Bayesian inference components, providing for all the&#10;necessary steps of Bayesian imaging pipelines. First, it provides adaptable&#10;prior models for different sky realizations. Second, it includes likelihood&#10;models tailored to specific instruments. So far, the package includes three&#10;instruments: Chandra and eROSITA for X&#45;ray observations, and the James Webb&#10;Space Telescope (JWST) for the near&#45; and mid&#45;infrared. The aim is to expand&#10;this set in the future. Third, these models can be integrated with various&#10;inference and optimization schemes, such as maximum a posteriori estimation and&#10;variational inference. Explicit demos show how to integrate the individual&#10;modules into a full analysis pipeline. Overall, J&#45;UBIK enables efficient&#10;generation of high&#45;fidelity images via Bayesian pipelines that can be tailored&#10;to specific research objectives.&#10; | General | [Link](http://arxiv.org/abs/2409.10381v1) |&#10;| Thermolectricity in irradiated bilayer graphene flakes | Cynthia Ihuoma Osuala, Tanu Choudhary, Raju K. Biswas, Sudin Ganguly, Chunlei Qu, Santanu K. Maiti | &#160;&#160;We present a comprehensive study on enhancing the thermoelectric (TE)&#10;performance of bilayer graphene (BLG) through irradiation with arbitrarily&#10;polarized light, focusing on $AA$&#45; and $AB$&#45;stacked configurations with zigzag&#10;edges. Utilizing a combination of tight&#45;binding theory and density functional&#10;theory (DFT), we systematically analyze the impact of light irradiation on&#10;electronic and phononic transport properties. Light irradiation alters the&#10;electronic hopping parameters, creating an asymmetric transmission function,&#10;which significantly increases the Seebeck coefficient, thereby boosting the&#10;overall {it figure of merit} (FOM). For the phononic contribution, DFT&#10;calculations reveal that $AB$&#45;stacked BLG exhibits lower lattice thermal&#10;conductivity compared to $AA$&#45;stacked, attributed to enhanced anharmonic&#10;scattering and phonon group velocity. The combined analysis shows that FOM&#10;exceeds unity in both stacking types, with notable improvements near the&#10;irradiation&#45;induced gap. Additionally, we explore the dependence of FOM on the&#10;system dimensions and temperature, demonstrating that light&#45;irradiated BLG&#10;holds great promise for efficient thermoelectric energy conversion and waste&#10;heat recovery. Our results show favorable responses over a wide range of&#10;irradiation parameters. These findings provide crucial insights into optimizing&#10;BLG for advanced TE applications through light&#45;induced modifications.&#10; | General | [Link](http://arxiv.org/abs/2409.10380v1) |&#10;| Leveraging Joint Spectral and Spatial Learning with MAMBA for&#10; &#160;Multichannel Speech Enhancement | Wenze Ren, Haibin Wu, Yi&#45;Cheng Lin, Xuanjun Chen, Rong Chao, Kuo&#45;Hsuan Hung, You&#45;Jin Li, Wen&#45;Yuan Ting, Hsin&#45;Min Wang, Yu Tsao | &#160;&#160;In multichannel speech enhancement, effectively capturing spatial and&#10;spectral information across different microphones is crucial for noise&#10;reduction. Traditional methods, such as CNN or LSTM, attempt to model the&#10;temporal dynamics of full&#45;band and sub&#45;band spectral and spatial features.&#10;However, these approaches face limitations in fully modeling complex temporal&#10;dependencies, especially in dynamic acoustic environments. To overcome these&#10;challenges, we modify the current advanced model McNet by introducing an&#10;improved version of Mamba, a state&#45;space model, and further propose MCMamba.&#10;MCMamba has been completely reengineered to integrate full&#45;band and narrow&#45;band&#10;spatial information with sub&#45;band and full&#45;band spectral features, providing a&#10;more comprehensive approach to modeling spatial and spectral information. Our&#10;experimental results demonstrate that MCMamba significantly improves the&#10;modeling of spatial and spectral features in multichannel speech enhancement,&#10;outperforming McNet and achieving state&#45;of&#45;the&#45;art performance on the CHiME&#45;3&#10;dataset. Additionally, we find that Mamba performs exceptionally well in&#10;modeling spectral information.&#10; | General | [Link](http://arxiv.org/abs/2409.10376v1) |&#10;| Nonlinear Causality in Brain Networks: With Application to Motor Imagery&#10; &#160;vs Execution | Sipan Aslan, Hernando Ombao | &#160;&#160;One fundamental challenge of data&#45;driven analysis in neuroscience is modeling&#10;causal interactions and exploring the connectivity of nodes in a brain network.&#10;Various statistical methods, relying on various perspectives and employing&#10;different data modalities, are being developed to examine and comprehend the&#10;underlying causal structures inherent to brain dynamics. This study introduces&#10;a novel statistical approach, TAR4C, to dissect causal interactions in&#10;multichannel EEG recordings. TAR4C uses the threshold autoregressive model to&#10;describe the causal interaction between nodes or clusters of nodes in a brain&#10;network. The perspective involves testing whether one node, which may represent&#10;a brain region, can control the dynamics of the other. The node that has such&#10;an impact on the other is called a threshold variable and can be classified as&#10;a causative because its functionality is the leading source operating as an&#10;instantaneous switching mechanism that regulates the time&#45;varying&#10;autoregressive structure of the other. This statistical concept is commonly&#10;referred to as threshold non&#45;linearity. Once threshold non&#45;linearity has been&#10;verified between a pair of nodes, the subsequent essential facet of TAR&#10;modeling is to assess the predictive ability of the causal node for the current&#10;activity on the other and represent causal interactions in autoregressive&#10;terms. This predictive ability is what underlies Granger causality. The TAR4C&#10;approach can discover non&#45;linear and time&#45;dependent causal interactions without&#10;negating the G&#45;causality perspective. The efficacy of the proposed approach is&#10;exemplified by analyzing the EEG signals recorded during the motor&#10;movement/imagery experiment. The similarities and differences between the&#10;causal interactions manifesting during the execution and the imagery of a given&#10;motor movement are demonstrated by analyzing EEG recordings from multiple&#10;subjects.&#10; | General | [Link](http://arxiv.org/abs/2409.10374v1) |&#10;| Instigating Cooperation among LLM Agents Using Adaptive Information&#10; &#160;Modulation | Qiliang Chen, &#160;Alireza, &#160;Ilami, Nunzio Lore, Babak Heydari | &#160;&#160;This paper introduces a novel framework combining LLM agents as proxies for&#10;human strategic behavior with reinforcement learning (RL) to engage these&#10;agents in evolving strategic interactions within team environments. Our&#10;approach extends traditional agent&#45;based simulations by using strategic LLM&#10;agents (SLA) and introducing dynamic and adaptive governance through a&#10;pro&#45;social promoting RL agent (PPA) that modulates information access across&#10;agents in a network, optimizing social welfare and promoting pro&#45;social&#10;behavior. Through validation in iterative games, including the prisoner&#10;dilemma, we demonstrate that SLA agents exhibit nuanced strategic adaptations.&#10;The PPA agent effectively learns to adjust information transparency, resulting&#10;in enhanced cooperation rates. This framework offers significant insights into&#10;AI&#45;mediated social dynamics, contributing to the deployment of AI in real&#45;world&#10;team settings.&#10; | General | [Link](http://arxiv.org/abs/2409.10372v1) |&#10;| Learning Gentle Grasping from Human&#45;Free Force Control Demonstration | Mingxuan Li, Lunwei Zhang, Tiemin Li, Yao Jiang | &#160;&#160;Humans can steadily and gently grasp unfamiliar objects based on tactile&#10;perception. Robots still face challenges in achieving similar performance due&#10;to the difficulty of learning accurate grasp&#45;force predictions and force&#10;control strategies that can be generalized from limited data. In this article,&#10;we propose an approach for learning grasping from ideal force control&#10;demonstrations, to achieve similar performance of human hands with limited data&#10;size. Our approach utilizes objects with known contact characteristics to&#10;automatically generate reference force curves without human demonstrations. In&#10;addition, we design the dual convolutional neural networks (Dual&#45;CNN)&#10;architecture which incorporating a physics&#45;based mechanics module for learning&#10;target grasping force predictions from demonstrations. The described method can&#10;be effectively applied in vision&#45;based tactile sensors and enables gentle and&#10;stable grasping of objects from the ground. The described prediction model and&#10;grasping strategy were validated in offline evaluations and online experiments,&#10;and the accuracy and generalizability were demonstrated.&#10; | General | [Link](http://arxiv.org/abs/2409.10371v1) |&#10;| Uncovering the Mechanism of Hepatotoxiciy of PFAS Targeting L&#45;FABP Using&#10; &#160;GCN and Computational Modeling | Lucas Jividen, Tibo Duran, Xi&#45;Zhi Niu, Jun Bai | &#160;&#160;Per&#45; and polyfluoroalkyl substances (PFAS) are persistent environmental&#10;pollutants with known toxicity and bioaccumulation issues. Their widespread&#10;industrial use and resistance to degradation have led to global environmental&#10;contamination and significant health concerns. While a minority of PFAS have&#10;been extensively studied, the toxicity of many PFAS remains poorly understood&#10;due to limited direct toxicological data. This study advances the predictive&#10;modeling of PFAS toxicity by combining semi&#45;supervised graph convolutional&#10;networks (GCNs) with molecular descriptors and fingerprints. We propose a novel&#10;approach to enhance the prediction of PFAS binding affinities by isolating&#10;molecular fingerprints to construct graphs where then descriptors are set as&#10;the node features. This approach specifically captures the structural,&#10;physicochemical, and topological features of PFAS without overfitting due to an&#10;abundance of features. Unsupervised clustering then identifies representative&#10;compounds for detailed binding studies. Our results provide a more accurate&#10;ability to estimate PFAS hepatotoxicity to provide guidance in chemical&#10;discovery of new PFAS and the development of new safety regulations.&#10; | General | [Link](http://arxiv.org/abs/2409.10370v1) |&#10;| Stochastic Control of UAVs: An Optimal Tradeoff between Performance,&#10; &#160;Flight Smoothness and Control Effort | George Rapakoulias, Panagiotis Tsiotras | &#160;&#160;Safe and accurate control of unmanned aerial vehicles in the presence of&#10;winds is a challenging control problem due to the hard&#45;to&#45;model and highly&#10;stochastic nature of the disturbance forces acting upon the vehicle. To meet&#10;performance constraints, state&#45;of&#45;the&#45;art control methods such as Incremental&#10;Nonlinear Dynamic Inversion (INDI) or other adaptive control techniques require&#10;high control gains to mitigate the effects of uncertainty entering the system.&#10;While achieving good tracking performance, IDNI requires excessive control&#10;effort, results in high actuator strain, and reduced flight smoothness due to&#10;constant and aggressive corrective actions commanded by the controller. In this&#10;paper, we propose a novel control architecture that allows the user to&#10;systematically address the trade&#45;off between high authority control and&#10;performance constraint satisfaction. Our approach consists of two parts. To&#10;cancel out biases introduced by unmodelled aerodynamic effects we propose a&#10;hybrid, model&#45;based disturbance force estimator augmented with a neural&#10;network, that can adapt to external wind conditions using a Kalman Filter. We&#10;then utilize state&#45;of&#45;the&#45;art results from Covariance Steering theory, which&#10;offers a principled way of controlling the uncertainty of the tracking error&#10;dynamics. We first analyze the properties of the combined system and then&#10;provide extensive experimental results to verify the advantages of the proposed&#10;approach over existing methods&#10; | General | [Link](http://arxiv.org/abs/2409.10369v1) |&#10;| Integrated nowcasting of convective precipitation with Transformer&#45;based&#10; &#160;models using multi&#45;source data | alar Kk, Aitor Atencia, Markus Dabernig | &#160;&#160;Precipitation nowcasting is crucial for mitigating the impacts of severe&#10;weather events and supporting daily activities. Conventional models&#10;predominantly relying on radar data have limited performance in predicting&#10;cases with complex temporal features such as convection initiation,&#10;highlighting the need to integrate data from other sources for more&#10;comprehensive nowcasting. Unlike physics&#45;based models, machine learning&#10;(ML)&#45;based models offer promising solutions for efficiently integrating large&#10;volumes of diverse data. We present EF4INCA, a spatiotemporal Transformer model&#10;for precipitation nowcasting that integrates satellite&#45; and ground&#45;based&#10;observations with numerical weather prediction outputs. EF4INCA provides&#10;high&#45;resolution forecasts over Austria, accurately predicting the location and&#10;shape of precipitation fields with a spatial resolution of 1 kilometre and a&#10;temporal resolution of 5 minutes, up to 90 minutes ahead. Our evaluation shows&#10;that EF4INCA outperforms conventional nowcasting models, including the&#10;operational model of Austria, particularly in scenarios with complex temporal&#10;features such as convective initiation and rapid weather changes. EF4INCA&#10;maintains higher accuracy in location forecasting but generates smoother fields&#10;at later prediction times compared to traditional models. Interpretation of our&#10;model showed that precipitation products and SEVIRI infrared channels CH7 and&#10;CH9 are the most important data streams. These results underscore the&#10;importance of combining data from different domains, including physics&#45;based&#10;model products, with ML approaches. Our study highlights the robustness of&#10;EF4INCA and its potential for improved precipitation nowcasting. We provide&#10;access to our code repository, model weights, and the dataset curated for&#10;benchmarking, facilitating further development and application.&#10; | General | [Link](http://arxiv.org/abs/2409.10367v1) |&#10;&#10;">
<text font-weight="bold" text-anchor="middle" x="1998" y="-567.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922677986320_5 -->
<g id="node73" class="node">
<title>139922677986320_5</title>
<ellipse fill="#cdd5c6" stroke="#9aa293" stroke-width="3" cx="1926" cy="-528" rx="50.09" ry="18"/>
<text text-anchor="middle" x="1926" y="-524.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Critic (5)</text>
</g>
<!-- 139922752308304_6&#45;&gt;139922677986320_5 -->
<g id="edge81" class="edge">
<title>139922752308304_6&#45;&gt;139922677986320_5</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M2227.89,-601.38C2197.58,-594.9 2160.29,-586.76 2127,-579 2075.18,-566.93 2016.12,-552.11 1975.49,-541.75"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1976.13,-538.3 1965.58,-539.21 1974.4,-545.08 1976.13,-538.3"/>
<g id="a_edge81&#45;label"><a xlink:title="exitcode: 0 (execution succeeded)&#10;Code output: &#10;| Title | Authors | Abstract | Domain | Source URL |&#10;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#10;| The VIRUS&#45;dE Survey I: Stars in dwarf elliptical galaxies &#45; 3D dynamics&#10; &#160;and radially resolved stellar initial mass functions | Mathias Lipka, Jens Thomas, Roberto Saglia, Ralf Bender, Maximilian Fabricius, Gary J. Hill, Matthias Kluge, Martin Landriau, Ximena Mazzalay, Eva Noyola, Taniya Parikh, Jan Snigula | &#160;&#160;We analyse the stellar structure of a sample of dwarf ellipticals (dE)&#10;inhabiting various environments within the Virgo cluster. Integral&#45;field&#10;observations with a high spectral resolution allow us to robustly determine&#10;their low velocity dispersions ($sim25$ km s$^{&#45;1}$) and higher&#45;order&#10;kinematic moments out to the half&#45;light radius. We find the dEs exhibit a&#10;diversity in ages with the younger dEs being less enhanced than the older,&#10;suggesting a complex star formation history for those dEs that recently entered&#10;Virgo while others have been quenched shortly after reionization.&#10;Orbit&#45;superposition modeling allowed us to recover viewing angles, stellar&#10;mass&#45;to&#45;light ratios (with gradients), as well as the intrinsic orbit&#10;structure. We find that the angular momentum of the dEs is strongly suppressed&#10;compared to ordinary early&#45;type galaxies and correlates with the environment.&#10;Flattened dEs are so because of a suppressed kinetic energy perpendicular to&#10;their equatorial plane. Combining population and dynamical modeling results, we&#10;find an age&#45;dependent stellar initial mass function (IMF) or, alternatively,&#10;evidence for a more extended star formation history for those galaxies that&#10;have had higher initial mass and/or inhabited lower density environments. dEs&#10;appear to have a spatially homogeneous stellar structure but the state they&#10;were `frozen&#39; in as they stopped forming stars varies dramatically according to&#10;their initial conditions.&#10; | General | [Link](http://arxiv.org/abs/2409.10518v1) |&#10;| RetrievalAttention: Accelerating Long&#45;Context LLM Inference via Vector&#10; &#160;Retrieval | Di Liu, Meng Chen, Baotong Lu, Huiqiang Jiang, Zhenhua Han, Qianxi Zhang, Qi Chen, Chengruidong Zhang, Bailu Ding, Kai Zhang, Chen Chen, Fan Yang, Yuqing Yang, Lili Qiu | &#160;&#160;Transformer&#45;based large Language Models (LLMs) become increasingly important&#10;in various domains. However, the quadratic time complexity of attention&#10;operation poses a significant challenge for scaling to longer contexts due to&#10;the extremely high inference latency and GPU memory consumption for caching&#10;key&#45;value (KV) vectors. This paper proposes RetrievalAttention, a training&#45;free&#10;approach to accelerate attention computation. To leverage the dynamic sparse&#10;property of attention, RetrievalAttention builds approximate nearest neighbor&#10;search (ANNS) indexes upon KV vectors in CPU memory and retrieves the most&#10;relevant ones via vector search during generation. Due to the&#10;out&#45;of&#45;distribution (OOD) between query vectors and key vectors, off&#45;the&#45;shelf&#10;ANNS indexes still need to scan O(N) (usually 30% of all keys) data for&#10;accurate retrieval, which fails to exploit the high sparsity.&#10;RetrievalAttention first identifies the OOD challenge of ANNS&#45;based attention,&#10;and addresses it via an attention&#45;aware vector search algorithm that can adapt&#10;to queries and only access 1&#45;&#45;3% of data, thus achieving a sub&#45;linear time&#10;complexity. RetrievalAttention greatly reduces the inference cost of&#10;long&#45;context LLM with much lower GPU memory requirements while maintaining the&#10;model accuracy. Especially, RetrievalAttention only needs 16GB GPU memory for&#10;serving 128K tokens in LLMs with 8B parameters, which is capable of generating&#10;one token in 0.188 seconds on a single NVIDIA RTX4090 (24GB).&#10; | General | [Link](http://arxiv.org/abs/2409.10516v1) |&#10;| An Efficient Self&#45;Learning Framework For Interactive Spoken Dialog&#10; &#160;Systems | Hitesh Tulsiani, David M. Chan, Shalini Ghosh, Garima Lalwani, Prabhat Pandey, Ankish Bansal, Sri Garimella, Ariya Rastrow, Bjrn Hoffmeister | &#160;&#160;Dialog systems, such as voice assistants, are expected to engage with users&#10;in complex, evolving conversations. Unfortunately, traditional automatic speech&#10;recognition (ASR) systems deployed in such applications are usually trained to&#10;recognize each turn independently and lack the ability to adapt to the&#10;conversational context or incorporate user feedback. In this work, we introduce&#10;a general framework for ASR in dialog systems that can go beyond learning from&#10;single&#45;turn utterances and learn over time how to adapt to both explicit&#10;supervision and implicit user feedback present in multi&#45;turn conversations. We&#10;accomplish that by leveraging advances in student&#45;teacher learning and&#10;context&#45;aware dialog processing, and designing contrastive self&#45;supervision&#10;approaches with Ohm, a new online hard&#45;negative mining approach. We show that&#10;leveraging our new framework compared to traditional training leads to relative&#10;WER reductions of close to 10% in real&#45;world dialog systems, and up to 26% on&#10;public synthetic data.&#10; | General | [Link](http://arxiv.org/abs/2409.10515v1) |&#10;| Constraints on axions from patchy screening of the cosmic microwave&#10; &#160;background | Samuel Goldstein, Fiona McCarthy, Cristina Mondino, J. Colin Hill, Junwu Huang, Matthew C. Johnson | &#160;&#160;The resonant conversion of cosmic microwave background (CMB) photons into&#10;axions within large&#45;scale structure induces an anisotropic spectral distortion&#10;in CMB temperature maps. Applying state&#45;of&#45;the&#45;art foreground cleaning&#10;techniques to $textit{Planck}$ CMB observations, we construct maps of&#10;axion&#45;induced &quot;patchy screening&quot; of the CMB. We cross&#45;correlate these maps with&#10;data from the $textit{unWISE}$ galaxy survey and find no evidence of axions.&#10;We constrain the axion&#45;photon coupling, $g_{agammagamma} &#10;esssim 2 times&#10;10^{&#45;12}~{&#13;m GeV}^{&#45;1}$, at the 95% confidence level for axion masses in the&#10;range $10^{&#45;13}~{&#13;m eV} &#10;esssim m_a &#10;esssim 10^{&#45;12}~{&#13;m eV}$. These&#10;constraints are competitive with the tightest astrophysical axion limits in&#10;this mass range and are inferred from robust population&#45;level statistics, which&#10;makes them complementary to existing searches that rely on modeling of&#10;individual systems.&#10; | General | [Link](http://arxiv.org/abs/2409.10514v1) |&#10;| Weak Superimposed Codes of Improved Asymptotic Rate and Their Randomized&#10; &#160;Construction | Yu Tsunoda, Yuichiro Fujiwara | &#160;&#160;Weak superimposed codes are combinatorial structures related closely to&#10;generalized cover&#45;free families, superimposed codes, and disjunct matrices in&#10;that they are only required to satisfy similar but less stringent conditions.&#10;This class of codes may also be seen as a stricter variant of what are known as&#10;locally thin families in combinatorics. Originally, weak superimposed codes&#10;were introduced in the context of multimedia content protection against illegal&#10;distribution of copies under the assumption that a coalition of malicious users&#10;may employ the averaging attack with adversarial noise. As in many other kinds&#10;of codes in information theory, it is of interest and importance in the study&#10;of weak superimposed codes to find the highest achievable rate in the&#10;asymptotic regime and give an efficient construction that produces an infinite&#10;sequence of codes that achieve it. Here, we prove a tighter lower bound than&#10;the sharpest known one on the rate of optimal weak superimposed codes and give&#10;a polynomial&#45;time randomized construction algorithm for codes that&#10;asymptotically attain our improved bound with high probability. Our&#10;probabilistic approach is versatile and applicable to many other related codes&#10;and arrays.&#10; | General | [Link](http://arxiv.org/abs/2409.10511v1) |&#10;| Pennsieve &#45; A Collaborative Platform for Translational Neuroscience and&#10; &#160;Beyond | Zack Goldblum, Zhongchuan Xu, Haoer Shi, Patryk Orzechowski, Jamaal Spence, Kathryn A Davis, Brian Litt, Nishant Sinha, Joost Wagenaar | &#160;&#160;The exponential growth of neuroscientific data necessitates platforms that&#10;facilitate data management and multidisciplinary collaboration. In this paper,&#10;we introduce Pennsieve &#45; an open&#45;source, cloud&#45;based scientific data management&#10;platform built to meet these needs. Pennsieve supports complex multimodal&#10;datasets and provides tools for data visualization and analyses. It takes a&#10;comprehensive approach to data integration, enabling researchers to define&#10;custom metadata schemas and utilize advanced tools to filter and query their&#10;data. Pennsieve&#39;s modular architecture allows external applications to extend&#10;its capabilities, and collaborative workspaces with peer&#45;reviewed data&#10;publishing mechanisms promote high&#45;quality datasets optimized for downstream&#10;analysis, both in the cloud and on&#45;premises.&#10; &#160;Pennsieve forms the core for major neuroscience research programs including&#10;the NIH SPARC Initiative, NIH HEAL Initiative&#39;s PRECISION Human Pain Network,&#10;and NIH HEAL RE&#45;JOIN Initiative. It serves more than 80 research groups&#10;worldwide, along with several large&#45;scale, inter&#45;institutional projects at&#10;clinical sites through the University of Pennsylvania. Underpinning the&#10;SPARC.Science, Epilepsy.Science, and Pennsieve Discover portals, Pennsieve&#10;stores over 125 TB of scientific data, with 35 TB of data publicly available&#10;across more than 350 high&#45;impact datasets. It adheres to the findable,&#10;accessible, interoperable, and reusable (FAIR) principles of data sharing and&#10;is recognized as one of the NIH&#45;approved Data Repositories. By facilitating&#10;scientific data management, discovery, and analysis, Pennsieve fosters a robust&#10;and collaborative research ecosystem for neuroscience and beyond.&#10; | General | [Link](http://arxiv.org/abs/2409.10509v1) |&#10;| General&#45;relativistic resistive&#45;magnetohydrodynamics simulations of&#10; &#160;self&#45;consistent magnetized rotating neutron stars | Patrick Chi&#45;Kit Cheong, Antonios Tsokaros, Milton Ruiz, Fabrizio Venturi, Juno Chun Lung Chan, Anson Ka Long Yip, Koji Uryu | &#160;&#160;We present the first general&#45;relativistic resistive magnetohydrodynamics&#10;simulations of self&#45;consistent, rotating neutron stars with mixed poloidal and&#10;toroidal magnetic fields. Specifically, we investigate the role of resistivity&#10;in the dynamical evolution of neutron stars over a period of up to 100 ms and&#10;its effects on their quasi&#45;equilibrium configurations. Our results demonstrate&#10;that resistivity can significantly influence the development of&#10;magnetohydrodynamic instabilities, resulting in markedly different magnetic&#10;field geometries. Additionally, resistivity suppresses the growth of these&#10;instabilities, leading to a reduction in the amplitude of emitted gravitational&#10;waves. Despite the variations in magnetic field geometries, the ratio of&#10;poloidal to toroidal field energies remains consistently 9:1 throughout the&#10;simulations, for the models we investigated.&#10; | General | [Link](http://arxiv.org/abs/2409.10508v1) |&#10;| Beth&#45;Uhlenbeck equation for the thermodynamics of fluctuations in a&#10; &#160;generalised 2+1D Gross&#45;Neveu model | Biplab Mahato, David Blaschke, Dietmar Ebert | &#160;&#160;We study a generalised version of Gross&#45;Neveu model in 2+1 dimensions. The&#10;model is inspired from graphene which shows a linear dispersion relation near&#10;the Dirac points. The phase structure and the thermodynamic properties in the&#10;mean field approximation have been studied before. Here we go beyond the mean&#10;field level by deriving a Beth&#45;Uhlenbeck equation for Gaussian fluctuations,&#10;solutions of which we explore numerically, for the first time including their&#10;momentum dependence. We discuss the excitonic mass, fluctuation pressure and&#10;phase shifts. We also perform a comparison with the NJL model in 3+1 dimension&#10;and discuss its implication for graphene.&#10; | General | [Link](http://arxiv.org/abs/2409.10507v1) |&#10;| Context&#45;aware Code Segmentation for C&#45;to&#45;Rust Translation using Large&#10; &#160;Language Models | Momoko Shiraishi, Takahiro Shinagawa | &#160;&#160;There is strong motivation to translate C code into Rust code due to the&#10;continuing threat of memory safety vulnerabilities in existing C programs and&#10;the significant attention paid to Rust as an alternative to the C language.&#10;While large language models (LLMs) show promise for automating this translation&#10;by generating more natural and safer code than rule&#45;based methods, previous&#10;studies have shown that LLM&#45;generated Rust code often fails to compile, even&#10;for relatively small C programs, due to significant differences between the two&#10;languages and context window limitations. We propose an LLM&#45;based translation&#10;scheme that improves the success rate of translating large&#45;scale C code into&#10;compilable Rust code. Our approach involves three key techniques: (1)&#10;pre&#45;processing the C code to better align its structure and expressions with&#10;Rust, (2) segmenting the code into optimally sized translation units to avoid&#10;exceeding the LLM&#39;s context window limits, and (3) iteratively compiling and&#10;repairing errors while maintaining consistency between translation units using&#10;context&#45;supplementing prompts. Compilation success is an essential first step&#10;in achieving functional equivalence, as only compilable code can be further&#10;tested. In experiments with 20 benchmark C programs, including those exceeding&#10;4 kilo lines of code, we successfully translated all programs into compilable&#10;Rust code without losing corresponding parts of the original code.&#10; | General | [Link](http://arxiv.org/abs/2409.10506v1) |&#10;| Machine Learning Optimization of non&#45;Kasha Behavior and of Transient&#10; &#160;Dynamics in Model Retinal Isomerization | Davinder Singh, Chern Chuang, Paul Brumer | &#160;&#160;Designing a model of retinal isomerization in Rhodopsin, the first step in&#10;vision, that accounts for both experimental transient and stationary state&#10;observables is challenging. Here, multi&#45;objective Bayesian optimization is&#10;employed to refine the parameters of a minimal two&#45;state&#45;two&#45;mode (TM) model&#10;describing the photoisomerization of retinal in Rhodopsin. With an appropriate&#10;selection of objectives, the optimized retinal model predicts excitation&#10;wavelength&#45;dependent fluorescence spectra that closely align with&#10;experimentally observed non&#45;Kasha behavior in the non&#45;equilibrium steady state.&#10;Further, adjustments to the potential energy surface within the TM model reduce&#10;the discrepancies across the time domain. Overall, agreement with experimental&#10;data is excellent.&#10; | General | [Link](http://arxiv.org/abs/2409.10505v1) |&#10;| DILA: Dictionary Label Attention for Mechanistic Interpretability in&#10; &#160;High&#45;dimensional Multi&#45;label Medical Coding Prediction | John Wu, David Wu, Jimeng Sun | &#160;&#160;Predicting high&#45;dimensional or extreme multilabels, such as in medical&#10;coding, requires both accuracy and interpretability. Existing works often rely&#10;on local interpretability methods, failing to provide comprehensive&#10;explanations of the overall mechanism behind each label prediction within a&#10;multilabel set. We propose a mechanistic interpretability module called&#10;DIctionary Label Attention (method) that disentangles uninterpretable dense&#10;embeddings into a sparse embedding space, where each nonzero element (a&#10;dictionary feature) represents a globally learned medical concept. Through&#10;human evaluations, we show that our sparse embeddings are more human&#10;understandable than its dense counterparts by at least 50 percent. Our&#10;automated dictionary feature identification pipeline, leveraging large language&#10;models (LLMs), uncovers thousands of learned medical concepts by examining and&#10;summarizing the highest activating tokens for each dictionary feature. We&#10;represent the relationships between dictionary features and medical codes&#10;through a sparse interpretable matrix, enhancing the mechanistic and global&#10;understanding of the model&#39;s predictions while maintaining competitive&#10;performance and scalability without extensive human annotation.&#10; | General | [Link](http://arxiv.org/abs/2409.10504v1) |&#10;| Causal Language Modeling Can Elicit Search and Reasoning Capabilities on&#10; &#160;Logic Puzzles | Kulin Shah, Nishanth Dikkala, Xin Wang, Rina Panigrahy | &#160;&#160;Causal language modeling using the Transformer architecture has yielded&#10;remarkable capabilities in Large Language Models (LLMs) over the last few&#10;years. However, the extent to which fundamental search and reasoning&#10;capabilities emerged within LLMs remains a topic of ongoing debate. In this&#10;work, we study if causal language modeling can learn a complex task such as&#10;solving Sudoku puzzles. To solve a Sudoku, the model is first required to&#10;search over all empty cells of the puzzle to decide on a cell to fill and then&#10;apply an appropriate strategy to fill the decided cell. Sometimes, the&#10;application of a strategy only results in thinning down the possible values in&#10;a cell rather than concluding the exact value of the cell. In such cases,&#10;multiple strategies are applied one after the other to fill a single cell. We&#10;observe that Transformer models trained on this synthetic task can indeed learn&#10;to solve Sudokus (our model solves $94.21%$ of the puzzles fully correctly)&#10;when trained on a logical sequence of steps taken by a solver. We find that&#10;training Transformers with the logical sequence of steps is necessary and&#10;without such training, they fail to learn Sudoku. We also extend our analysis&#10;to Zebra puzzles (known as Einstein puzzles) and show that the model solves&#10;$92.04 %$ of the puzzles fully correctly. In addition, we study the internal&#10;representations of the trained Transformer and find that through linear&#10;probing, we can decode information about the set of possible values in any&#10;given cell from them, pointing to the presence of a strong reasoning engine&#10;implicit in the Transformer weights.&#10; | General | [Link](http://arxiv.org/abs/2409.10502v1) |&#10;| Alignment with nonlinear velocity couplings: collision&#45;avoidance and&#10; &#160;micro&#45;to&#45;macro mean&#45;field limits | Young&#45;Pil Choi, Micha Fabisiak, Jan Peszek | &#160;&#160;We investigate the pressureless fractional Euler&#45;alignment system with&#10;nonlinear velocity couplings, referred to as the $p$&#45;Euler&#45;alignment system.&#10;This model features a nonlinear velocity alignment force, interpreted as a&#10;density&#45;weighted fractional $p$&#45;Laplacian when the singularity parameter&#10;$alpha$ exceeds the spatial dimension $d$. Our primary goal is to establish&#10;the existence of solutions for strongly singular interactions ($alpha ge d$)&#10;and compactly supported initial conditions. We construct solutions as&#10;mean&#45;field limits of empirical measures from a kinetic variant of the&#10;$p$&#45;Euler&#45;alignment system. Specifically, we show that a sequence of empirical&#10;measures converges to a finite Radon measure, whose local density and velocity&#10;satisfy the $p$&#45;Euler&#45;alignment system. Our results are the first to prove the&#10;existence of solutions to this system in multi&#45;dimensional settings without&#10;significant initial data restrictions, covering both nonlinear ($p&gt;2$) and&#10;linear ($p=2$) cases. Additionally, we establish global existence, uniqueness,&#10;and collision avoidance for the corresponding particle ODE system under&#10;non&#45;collisional initial conditions, extending previous results for $1 &#10;e p &#10;e&#10;alpha + 2$. This analysis supports our mean&#45;field limit argument and&#10;contributes to understanding alignment models with singular communication.&#10; | General | [Link](http://arxiv.org/abs/2409.10501v1) |&#10;| Focus diverse phase retrieval test results on broadband continuous&#10; &#160;wavefront sensing in space telescope applications | Hyukmo Kang, Kyle Van Gorkom, Meghdoot Biswas, Daewook Kim, Ewan S. Douglas | &#160;&#160;Continuous wavefront sensing benefits space observatories in on&#45;orbit optical&#10;performance maintenance. To measure the phase of a wavefront, phase retrieval&#10;is an attractive technique as it uses multiple point spread function (PSF)&#10;images that are acquired by the telescope itself without extra metrology&#10;systems nor complicated calibration. The focus diverse phase retrieval utilizes&#10;PSFs from predetermined defocused positions to enhance the dynamic range of the&#10;algorithm. We describe an updated visible light active optics testbed with the&#10;addition of a linear motorized focus stage. The performance of the phase&#10;retrieval algorithm in broadband is tested under various cases. While broadband&#10;pass filters have advantages in higher signal&#45;to&#45;noise ratio (SNR), the&#10;performance of phase retrieval can be restricted due to blurred image caused by&#10;diffraction and increased computing cost. We used multiple bandpass filters (10&#10;nm, 88 nm, and 150 nm) and investigated effects of bandwidth on the accuracy&#10;and required image acquisition conditions such as SNR, reaching accuracies&#10;below 20 nm RMS wavefront error at the widest bandwidth. We also investigated&#10;the dynamic range of the phase retrieval algorithm depending on the bandwidth&#10;and required amount of defocus to expand dynamic range. Finally, we simulated&#10;the continuous wavefront sensing and correction loop with a range of&#10;statistically generated representative telescope disturbance time series to&#10;test for edge cases.&#10; | General | [Link](http://arxiv.org/abs/2409.10500v1) |&#10;| The role of higher&#45;order terms in trapped&#45;ion quantum computing with&#10; &#160;magnetic gradient induced coupling | Sebastian Nagies, Kevin T. Geier, Javed Akram, Junichi Okamoto, Dimitris Badounas, Christof Wunderlich, Michael Johanning, Philipp Hauke | &#160;&#160;Trapped&#45;ion hardware based on the Magnetic Gradient Induced Coupling (MAGIC)&#10;scheme is emerging as a promising platform for quantum computing. Nevertheless,&#10;in this (as in any other) quantum&#45;computing platform, many technical questions&#10;still have to be resolved before large&#45;scale and error&#45;tolerant applications&#10;are possible. In this work, we present a thorough discussion of the&#10;contribution of higher&#45;order terms to the MAGIC setup, which can occur due to&#10;anharmonicities in the external potential of the ion crystal (e.g., through&#10;Coulomb repulsion) or through curvature of the applied magnetic field. These&#10;terms take the form of three&#45;spin couplings as well as diverse terms that&#10;couple spins to phonons. We find that most of these are negligible in realistic&#10;situations, with only two contributions that need careful attention. First,&#10;there are parasitic longitudinal fields whose strength increases with chain&#10;length, but which can easily be compensated by a microwave detuning. Second,&#10;anharmonicities of the Coulomb interaction can lead to well&#45;known two&#45;to&#45;one&#10;conversions of phonon excitations, which can be avoided if the phonons are&#10;ground&#45;state cooled. Our detailed analysis constitutes an important&#10;contribution on the way of making magnetic&#45;gradient trapped&#45;ion quantum&#10;technology fit for large&#45;scale applications, and it may inspire new ways to&#10;purposefully design interaction terms.&#10; | General | [Link](http://arxiv.org/abs/2409.10498v1) |&#10;| MusicLIME: Explainable Multimodal Music Understanding | Theodoros Sotirou, Vassilis Lyberatos, Orfeas Menis Mastromichalakis, Giorgos Stamou | &#160;&#160;Multimodal models are critical for music understanding tasks, as they capture&#10;the complex interplay between audio and lyrics. However, as these models become&#10;more prevalent, the need for explainability grows&#45;understanding how these&#10;systems make decisions is vital for ensuring fairness, reducing bias, and&#10;fostering trust. In this paper, we introduce MusicLIME, a model&#45;agnostic&#10;feature importance explanation method designed for multimodal music models.&#10;Unlike traditional unimodal methods, which analyze each modality separately&#10;without considering the interaction between them, often leading to incomplete&#10;or misleading explanations, MusicLIME reveals how audio and lyrical features&#10;interact and contribute to predictions, providing a holistic view of the&#10;model&#39;s decision&#45;making. Additionally, we enhance local explanations by&#10;aggregating them into global explanations, giving users a broader perspective&#10;of model behavior. Through this work, we contribute to improving the&#10;interpretability of multimodal music models, empowering users to make informed&#10;choices, and fostering more equitable, fair, and transparent music&#10;understanding systems.&#10; | General | [Link](http://arxiv.org/abs/2409.10496v1) |&#10;| Incorporating Classifier&#45;Free Guidance in Diffusion Model&#45;Based&#10; &#160;Recommendation | Noah Buchanan, Susan Gauch, Quan Mai | &#160;&#160;This paper presents a diffusion&#45;based recommender system that incorporates&#10;classifier&#45;free guidance. Most current recommender systems provide&#10;recommendations using conventional methods such as collaborative or&#10;content&#45;based filtering. Diffusion is a new approach to generative AI that&#10;improves on previous generative AI approaches such as Variational Autoencoders&#10;(VAEs) and Generative Adversarial Networks (GANs). We incorporate diffusion in&#10;a recommender system that mirrors the sequence users take when browsing and&#10;rating items. Although a few current recommender systems incorporate diffusion,&#10;they do not incorporate classifier&#45;free guidance, a new innovation in diffusion&#10;models as a whole. In this paper, we present a diffusion recommender system&#10;that augments the underlying recommender system model for improved performance&#10;and also incorporates classifier&#45;free guidance. Our findings show improvements&#10;over state&#45;of&#45;the&#45;art recommender systems for most metrics for several&#10;recommendation tasks on a variety of datasets. In particular, our approach&#10;demonstrates the potential to provide better recommendations when data is&#10;sparse.&#10; | General | [Link](http://arxiv.org/abs/2409.10494v1) |&#10;| Renormalization of the Einstein&#45;Cartan Theory in First&#45;Order Form | F. T. Brandt, J. Frenkel, S. Martins&#45;Filho, D. G. C. McKeon | &#160;&#160;We examine the Einstein&#45;Cartan (EC) theory in first&#45;order form, which has a&#10;diffeomorphism as well as a local Lorentz invariance. We study the&#10;renormalizability of this theory in the framework of the Batalin&#45;Vilkovisky&#10;formalism, which allows for a gauge invariant renormalization. Using the&#10;background field method, we discuss the gauge invariance of the background&#10;effective action and analyze the Ward identities which reflect the symmetries&#10;of the EC theory. As an application, we compute, in a general background gauge,&#10;the self&#45;energy of the tetrad field at one&#45;loop order.&#10; | General | [Link](http://arxiv.org/abs/2409.10493v1) |&#10;| What we can learn from the angular differential rates (only) in&#10; &#160;semileptonic $B to D^* ell _ell$ decays | G. Martinelli, S. Simula, L. Vittorio | &#160;&#160;We present a new, simple approach to the study of semileptonic $B to D^*&#10;ell &#10;u_ell$ decays based on the angular distributions of the final state&#10;particles only. Our approach is model independent and never requires the&#10;knowledge of $vert V_{cb}vert$. By studying such distributions in the case of&#10;light leptons, a comparison between results from different data sets from the&#10;Belle and BelleII Collaborations and between data and Standard Model&#10;calculations is also given for several interesting quantities. A good&#10;consistency is observed between some of the experimental results and the&#10;theoretical predictions.&#10; | General | [Link](http://arxiv.org/abs/2409.10492v1) |&#10;| Code Vulnerability Detection: A Comparative Analysis of Emerging Large&#10; &#160;Language Models | Shaznin Sultana, Sadia Afreen, Nasir U. Eisty | &#160;&#160;The growing trend of vulnerability issues in software development as a result&#10;of a large dependence on open&#45;source projects has received considerable&#10;attention recently. This paper investigates the effectiveness of Large Language&#10;Models (LLMs) in identifying vulnerabilities within codebases, with a focus on&#10;the latest advancements in LLM technology. Through a comparative analysis, we&#10;assess the performance of emerging LLMs, specifically Llama, CodeLlama, Gemma,&#10;and CodeGemma, alongside established state&#45;of&#45;the&#45;art models such as BERT,&#10;RoBERTa, and GPT&#45;3. Our study aims to shed light on the capabilities of LLMs in&#10;vulnerability detection, contributing to the enhancement of software security&#10;practices across diverse open&#45;source repositories. We observe that CodeGemma&#10;achieves the highest F1&#45;score of 58 and a Recall of 87, amongst the recent&#10;additions of large language models to detect software security vulnerabilities.&#10; | General | [Link](http://arxiv.org/abs/2409.10490v1) |&#10;| Flash STU: Fast Spectral Transform Units | Y. Isabel Liu, Windsor Nguyen, Yagiz Devre, Evan Dogariu, Anirudha Majumdar, Elad Hazan | &#160;&#160;This paper describes an efficient, open source PyTorch implementation of the&#10;Spectral Transform Unit. We investigate sequence prediction tasks over several&#10;modalities including language, robotics, and simulated dynamical systems. We&#10;find that for the same parameter count, the STU and its variants outperform the&#10;Transformer as well as other leading state space models across various&#10;modalities.&#10; | General | [Link](http://arxiv.org/abs/2409.10489v1) |&#10;| Do Pre&#45;trained Vision&#45;Language Models Encode Object States? | Kaleb Newman, Shijie Wang, Yuan Zang, David Heffren, Chen Sun | &#160;&#160;For a vision&#45;language model (VLM) to understand the physical world, such as&#10;cause and effect, a first step is to capture the temporal dynamics of the&#10;visual world, for example how the physical states of objects evolve over time&#10;(e.g. a whole apple into a sliced apple). Our paper aims to investigate if VLMs&#10;pre&#45;trained on web&#45;scale data learn to encode object states, which can be&#10;extracted with zero&#45;shot text prompts. We curate an object state recognition&#10;dataset ChangeIt&#45;Frames, and evaluate nine open&#45;source VLMs, including models&#10;trained with contrastive and generative objectives. We observe that while these&#10;state&#45;of&#45;the&#45;art vision&#45;language models can reliably perform object&#10;recognition, they consistently fail to accurately distinguish the objects&#39;&#10;physical states. Through extensive experiments, we identify three areas for&#10;improvements for VLMs to better encode object states, namely the quality of&#10;object localization, the architecture to bind concepts to objects, and the&#10;objective to learn discriminative visual and language encoders on object&#10;states. Data and code are released.&#10; | General | [Link](http://arxiv.org/abs/2409.10488v1) |&#10;| A Host Galaxy Morphology Link Between Quasi&#45;Periodic Eruptions and Tidal&#10; &#160;Disruption Events | Olivier Gilbert, John J. Ruan, Michael Eracleous, Daryl Haggard, Jessie C. Runnoe | &#160;&#160;The physical processes that produce X&#45;ray Quasi&#45;Periodic Eruptions (QPEs)&#10;recently discovered from the nuclei of several low&#45;redshift galaxies are&#10;mysterious. Several pieces of observational evidence strongly suggest a link&#10;between QPEs and Tidal Disruption Events (TDE). Previous studies also reveal&#10;that the morphologies of TDE host galaxies are highly concentrated, with high&#10;Sersic indicies, bulge&#45;to&#45;total light (B/T) ratios, and stellar surface mass&#10;densities relative to the broader galaxy population. We use these distinctive&#10;properties to test the link between QPEs and TDEs, by comparing these&#10;parameters of QPE host galaxies to TDE host galaxies. We employ archival Legacy&#10;Survey images of a sample of 9 QPE host galaxies and a sample of 13 TDE host&#10;galaxies, and model their surface brightness profiles. We show that QPE host&#10;galaxies have high Sersic indices of ~3, high B/T ratios of ~0.5, and high&#10;surface mass densities of ~10^10 Msun kpc^&#45;2. These properties are similar to&#10;TDE host galaxies, but are in strong contrast to a mass&#45; and redshift&#45;matched&#10;control sample of galaxies. We also find tentative evidence that the central&#10;black holes in both QPE and TDE host galaxies are undermassive relative to&#10;their stellar mass. The morphological similarities between QPE and TDE host&#10;galaxies at the population level add to the mounting evidence of a physical&#10;link between these phenomena, and favor QPE models that also invoke TDEs.&#10; | General | [Link](http://arxiv.org/abs/2409.10486v1) |&#10;| Tuning the Rate of Tightly Packed Systems To Produce Planet Occurrence&#10; &#160;Trends with Galactic Height | Sarah Ballard | &#160;&#160;The formation of planetary systems has historically been considered in&#10;isolation, decoupled from processes on galactic scales. Recent findings&#10;employing data from ESA&#39;s Gaia mission challenge this narrative, identifying&#10;trends in planet occurrence with galactic kinematics and stellar age. The&#10;findings indicate changes in planet occurrence over and above the predicted&#10;changes from metallicity variation within the Milky Way, so that changes to&#10;stellar metallicity alone (long understood to be deterministic in planet&#10;outcomes) cannot explain the trends entirely. The scope of potential factors&#10;influencing planet formation has grown progressively wider, with accompanying&#10;theoretical support for galactic&#45;scale influences upon planet formation. In&#10;this manuscript, we investigate specifically how changes to the rate of Systems&#10;of Tightly&#45;packed Inner Planets (STIPs) could manifest as a trend in planet&#10;occurrence with galactic height. We focus our study upon M dwarf planetary&#10;systems for two reasons: first, they host STIPs at high rates, and secondly,&#10;their longevity makes them useful probes for kinematic trends over Gyr. We&#10;consider two models for a varying STIP rate: one in which STIP likelihood is&#10;determined by stellar age alone, irrespective of galactic time, and another in&#10;which the STIP likelihood suddenly increased in recent galactic history. Both&#10;models, which impose a higher STIP likelihood among younger stars, produce a&#10;negative gradient in planet occurrence with increasing height from the galactic&#10;midplane. We find that a step function model in which STIP likelihood increased&#10;by a factor of several ~a few Gyr ago resembles an observed trend among FGK&#10;dwarfs. We consider plausible physical mechanisms that could mimic the&#10;hypothesized model, given known links between STIP occurrence and other stellar&#10;and planetary properties.&#10; | General | [Link](http://arxiv.org/abs/2409.10485v1) |&#10;| XLM for Autonomous Driving Systems: A Comprehensive Review | Sonda Fourati, Wael Jaafar, Noura Baccar, Safwan Alfattani | &#160;&#160;Large Language Models (LLMs) have showcased remarkable proficiency in various&#10;information&#45;processing tasks. These tasks span from extracting data and&#10;summarizing literature to generating content, predictive modeling,&#10;decision&#45;making, and system controls. Moreover, Vision Large Models (VLMs) and&#10;Multimodal LLMs (MLLMs), which represent the next generation of language&#10;models, a.k.a., XLMs, can combine and integrate many data modalities with the&#10;strength of language understanding, thus advancing several information&#45;based&#10;systems, such as Autonomous Driving Systems (ADS). Indeed, by combining&#10;language communication with multimodal sensory inputs, e.g., panoramic images&#10;and LiDAR or radar data, accurate driving actions can be taken. In this&#10;context, we provide in this survey paper a comprehensive overview of the&#10;potential of XLMs towards achieving autonomous driving. Specifically, we review&#10;the relevant literature on ADS and XLMs, including their architectures, tools,&#10;and frameworks. Then, we detail the proposed approaches to deploy XLMs for&#10;autonomous driving solutions. Finally, we provide the related challenges to XLM&#10;deployment for ADS and point to future research directions aiming to enable XLM&#10;adoption in future ADS frameworks.&#10; | General | [Link](http://arxiv.org/abs/2409.10484v1) |&#10;| Efficient polarizable QM/MM using the direct reaction field Hamiltonian&#10; &#160;with electrostatic potential fitted multipole operators | Thomas P. Fay, Nicolas Ferr, Miquel Huix&#45;Rotllant | &#160;&#160;Electronic polarization and dispersion are decisive actors in determining&#10;interaction energies between molecules. These interactions have a particularly&#10;profound effect on excitation energies of molecules in complex environments,&#10;especially when the excitation involves a significant degree of charge&#10;reorganisation. The direct reaction field (DRF) approach, which has seen a&#10;recent revival of interest, provides a powerful framework for describing these&#10;interactions in quantum mechanics/molecular mechanics (QM/MM) models of&#10;systems, where a small subsystem of interest is described using quantum&#10;chemical methods and the remainder is treated with a simple MM force field. In&#10;this paper we show how the DRF approach can be combined with the electrostatic&#10;potential fitted (ESPF) multipole operator description of the QM region charge&#10;density, which reduces the scaling $mathcal{O}(N_mathrm{MM}^3)$ of the method&#10;with MM system to $mathcal{O}(N_mathrm{MM}^2)$. We also show how the DRF&#10;approach can be combined with fluctuating charge descriptions of the&#10;polarizable environment, as well as previously used atom&#45;centred&#10;dipole&#45;polarizability based models. We further show that the ESPF&#45;DRF method&#10;provides an accurate description of molecular interactions in both ground and&#10;excited electronic states of the QM system and apply it to predict the gas to&#10;aqueous solution solvatochromic shifts in the UV/visible absorption spectrum of&#10;acrolein.&#10; | General | [Link](http://arxiv.org/abs/2409.10483v1) |&#10;| Schrodinger&#39;s Memory: Large Language Models | Wei Wang, Qing Li | &#160;&#160;Memory is the foundation of LLMs&#39; functionality, yet past research has lacked&#10;an in&#45;depth exploration of their memory capabilities and underlying theory. In&#10;this paper, we apply UAT theory to explain the memory mechanism of LLMs and&#10;propose a new approach for evaluating LLM performance by comparing the memory&#10;capacities of different models. Through extensive experiments, we validate our&#10;theory and the memory abilities of LLMs. Finally, we compare the capabilities&#10;of the human brain and LLMs, highlighting both their similarities and&#10;differences in terms of working mechanisms.&#10; | General | [Link](http://arxiv.org/abs/2409.10482v1) |&#10;| Exploring 3D Face Reconstruction and Fusion Methods for Face&#10; &#160;Verification: A Case&#45;Study in Video Surveillance | Simone Maurizio La Cava, Sara Concas, Ruben Tolosana, Roberto Casula, Giulia Orr, Martin Drahansky, Julian Fierrez, Gian Luca Marcialis | &#160;&#160;3D face reconstruction (3DFR) algorithms are based on specific assumptions&#10;tailored to distinct application scenarios. These assumptions limit their use&#10;when acquisition conditions, such as the subject&#39;s distance from the camera or&#10;the camera&#39;s characteristics, are different than expected, as typically happens&#10;in video surveillance. Additionally, 3DFR algorithms follow various strategies&#10;to address the reconstruction of a 3D shape from 2D data, such as statistical&#10;model fitting, photometric stereo, or deep learning. In the present study, we&#10;explore the application of three 3DFR algorithms representative of the SOTA,&#10;employing each one as the template set generator for a face verification&#10;system. The scores provided by each system are combined by score&#45;level fusion.&#10;We show that the complementarity induced by different 3DFR algorithms improves&#10;performance when tests are conducted at never&#45;seen&#45;before distances from the&#10;camera and camera characteristics (cross&#45;distance and cross&#45;camera settings),&#10;thus encouraging further investigations on multiple 3DFR&#45;based approaches.&#10; | General | [Link](http://arxiv.org/abs/2409.10481v1) |&#10;| Addressing misspecification in contextual optimization | Omar Bennouna, Jiawei Zhang, Saurabh Amin, Asuman Ozdaglar | &#160;&#160;We study a linear contextual optimization problem where a decision maker has&#10;access to historical data and contextual features to learn a cost prediction&#10;model aimed at minimizing decision error. We adopt the predict&#45;then&#45;optimize&#10;framework for this analysis. Given that perfect model alignment with reality is&#10;often unrealistic in practice, we focus on scenarios where the chosen&#10;hypothesis set is misspecified. In this context, it remains unclear whether&#10;current contextual optimization approaches can effectively address such model&#10;misspecification. In this paper, we present a novel integrated learning and&#10;optimization approach designed to tackle model misspecification in contextual&#10;optimization. This approach offers theoretical generalizability, tractability,&#10;and optimality guarantees, along with strong practical performance. Our method&#10;involves minimizing a tractable surrogate loss that aligns with the performance&#10;value from cost vector predictions, regardless of whether the model&#10;misspecified or not, and can be optimized in reasonable time. To our knowledge,&#10;no previous work has provided an approach with such guarantees in the context&#10;of model misspecification.&#10; | General | [Link](http://arxiv.org/abs/2409.10479v1) |&#10;| Local SGD for Near&#45;Quadratic Problems: Improving Convergence under&#10; &#160;Unconstrained Noise Conditions | Andrey Sadchikov, Savelii Chezhegov, Aleksandr Beznosikov, Alexander Gasnikov | &#160;&#160;Distributed optimization plays an important role in modern large&#45;scale&#10;machine learning and data processing systems by optimizing the utilization of&#10;computational resources. One of the classical and popular approaches is Local&#10;Stochastic Gradient Descent (Local SGD), characterized by multiple local&#10;updates before averaging, which is particularly useful in distributed&#10;environments to reduce communication bottlenecks and improve scalability. A&#10;typical feature of this method is the dependence on the frequency of&#10;communications. But in the case of a quadratic target function with homogeneous&#10;data distribution over all devices, the influence of frequency of&#10;communications vanishes. As a natural consequence, subsequent studies include&#10;the assumption of a Lipschitz Hessian, as this indicates the similarity of the&#10;optimized function to a quadratic one to some extent. However, in order to&#10;extend the completeness of the Local SGD theory and unlock its potential, in&#10;this paper we abandon the Lipschitz Hessian assumption by introducing a new&#10;concept of $textit{approximate quadraticity}$. This assumption gives a new&#10;perspective on problems that have near quadratic properties. In addition,&#10;existing theoretical analyses of Local SGD often assume bounded variance. We,&#10;in turn, consider the unbounded noise condition, which allows us to broaden the&#10;class of studied problems.&#10; | General | [Link](http://arxiv.org/abs/2409.10478v1) |&#10;| SimInversion: A Simple Framework for Inversion&#45;Based Text&#45;to&#45;Image&#10; &#160;Editing | Qi Qian, Haiyang Xu, Ming Yan, Juhua Hu | &#160;&#160;Diffusion models demonstrate impressive image generation performance with&#10;text guidance. Inspired by the learning process of diffusion, existing images&#10;can be edited according to text by DDIM inversion. However, the vanilla DDIM&#10;inversion is not optimized for classifier&#45;free guidance and the accumulated&#10;error will result in the undesired performance. While many algorithms are&#10;developed to improve the framework of DDIM inversion for editing, in this work,&#10;we investigate the approximation error in DDIM inversion and propose to&#10;disentangle the guidance scale for the source and target branches to reduce the&#10;error while keeping the original framework. Moreover, a better guidance scale&#10;(i.e., 0.5) than default settings can be derived theoretically. Experiments on&#10;PIE&#45;Bench show that our proposal can improve the performance of DDIM inversion&#10;dramatically without sacrificing efficiency.&#10; | General | [Link](http://arxiv.org/abs/2409.10476v1) |&#10;| Leadership and Engagement Dynamics in Legislative Twitter Networks:&#10; &#160;Statistical Analysis and Modeling | Carolina Luque, Juan Sosa | &#160;&#160;In this manuscript, we analyze the interaction network on Twitter among&#10;members of the 117th U.S. Congress to assess the visibility of political&#10;leaders and explore how systemic properties and node attributes influence the&#10;formation of legislative connections. We employ descriptive social network&#10;statistical methods, the exponential random graph model (ERGM), and the&#10;stochastic block model (SBM) to evaluate the relative impact of network&#10;systemic properties, as well as institutional and personal traits, on the&#10;generation of online relationships among legislators. Our findings reveal that&#10;legislative networks on social media platforms like Twitter tend to reinforce&#10;the leadership of dominant political actors rather than diminishing their&#10;influence. However, we identify that these leadership roles can manifest in&#10;various forms. Additionally, we highlight that online connections within&#10;legislative networks are influenced by both the systemic properties of the&#10;network and institutional characteristics.&#10; | General | [Link](http://arxiv.org/abs/2409.10475v1) |&#10;| MacDiff: Unified Skeleton Modeling with Masked Conditional Diffusion | Lehong Wu, Lilang Lin, Jiahang Zhang, Yiyang Ma, Jiaying Liu | &#160;&#160;Self&#45;supervised learning has proved effective for skeleton&#45;based human action&#10;understanding. However, previous works either rely on contrastive learning that&#10;suffers false negative problems or are based on reconstruction that learns too&#10;much unessential low&#45;level clues, leading to limited representations for&#10;downstream tasks. Recently, great advances have been made in generative&#10;learning, which is naturally a challenging yet meaningful pretext task to model&#10;the general underlying data distributions. However, the representation learning&#10;capacity of generative models is under&#45;explored, especially for the skeletons&#10;with spacial sparsity and temporal redundancy. To this end, we propose Masked&#10;Conditional Diffusion (MacDiff) as a unified framework for human skeleton&#10;modeling. For the first time, we leverage diffusion models as effective&#10;skeleton representation learners. Specifically, we train a diffusion decoder&#10;conditioned on the representations extracted by a semantic encoder. Random&#10;masking is applied to encoder inputs to introduce a information bottleneck and&#10;remove redundancy of skeletons. Furthermore, we theoretically demonstrate that&#10;our generative objective involves the contrastive learning objective which&#10;aligns the masked and noisy views. Meanwhile, it also enforces the&#10;representation to complement for the noisy view, leading to better&#10;generalization performance. MacDiff achieves state&#45;of&#45;the&#45;art performance on&#10;representation learning benchmarks while maintaining the competence for&#10;generative tasks. Moreover, we leverage the diffusion model for data&#10;augmentation, significantly enhancing the fine&#45;tuning performance in scenarios&#10;with scarce labeled data. Our project is available at&#10;https://lehongwu.github.io/ECCV24MacDiff/.&#10; | General | [Link](http://arxiv.org/abs/2409.10473v1) |&#10;| Towards Semantic Versioning of Open Pre&#45;trained Language Model Releases&#10; &#160;on Hugging Face | Adekunle Ajibode, Abdul Ali Bangash, Filipe Roseiro Cogo, Bram Adams, Ahmed E. Hassan | &#160;&#160;The proliferation of open Pre&#45;trained Language Models (PTLMs) on model&#10;registry platforms like Hugging Face (HF) presents both opportunities and&#10;challenges for companies building products around them. Similar to traditional&#10;software dependencies, PTLMs continue to evolve after a release. However, the&#10;current state of release practices of PTLMs on model registry platforms are&#10;plagued by a variety of inconsistencies, such as ambiguous naming conventions&#10;and inaccessible model training documentation. Given the knowledge gap on&#10;current PTLM release practices, our empirical study uses a mixed&#45;methods&#10;approach to analyze the releases of 52,227 PTLMs on the most well&#45;known model&#10;registry, HF. Our results reveal 148 different naming practices for PTLM&#10;releases, with 40.87% of changes to model weight files not represented in the&#10;adopted name&#45;based versioning practice or their documentation. In addition, we&#10;identified that the 52,227 PTLMs are derived from only 299 different base&#10;models (the modified original models used to create 52,227 PTLMs), with&#10;Fine&#45;tuning and Quantization being the most prevalent modification methods&#10;applied to these base models. Significant gaps in release transparency, in&#10;terms of training dataset specifications and model card availability, still&#10;exist, highlighting the need for standardized documentation. While we&#10;identified a model naming practice explicitly differentiating between major and&#10;minor PTLM releases, we did not find any significant difference in the types of&#10;changes that went into either type of releases, suggesting that major/minor&#10;version numbers for PTLMs often are chosen arbitrarily. Our findings provide&#10;valuable insights to improve PTLM release practices, nudging the field towards&#10;more formal semantic versioning practices.&#10; | General | [Link](http://arxiv.org/abs/2409.10472v1) |&#10;| Real&#45;Time Whole&#45;Body Control of Legged Robots with Model&#45;Predictive Path&#10; &#160;Integral Control | Juan Alvarez&#45;Padilla, John Z. Zhang, Sofia Kwok, John M. Dolan, Zachary Manchester | &#160;&#160;This paper presents a system for enabling real&#45;time synthesis of whole&#45;body&#10;locomotion and manipulation policies for real&#45;world legged robots. Motivated by&#10;recent advancements in robot simulation, we leverage the efficient&#10;parallelization capabilities of the MuJoCo simulator to achieve fast sampling&#10;over the robot state and action trajectories. Our results show surprisingly&#10;effective real&#45;world locomotion and manipulation capabilities with a very&#10;simple control strategy. We demonstrate our approach on several hardware and&#10;simulation experiments: robust locomotion over flat and uneven terrains,&#10;climbing over a box whose height is comparable to the robot, and pushing a box&#10;to a goal position. To our knowledge, this is the first successful deployment&#10;of whole&#45;body sampling&#45;based MPC on real&#45;world legged robot hardware.&#10;Experiment videos and code can be found at: https://whole&#45;body&#45;mppi.github.io/&#10; | General | [Link](http://arxiv.org/abs/2409.10469v1) |&#10;| Assortativity in sympatric speciation and species classification | Joao U. F. Lizarraga, Flavia M. D. Marquitti, Marcus A. M. de Aguiar | &#160;&#160;We investigate the role of assortative mating in speciation using the&#10;sympatric model of Derrida and Higgs. The model explores the idea that genetic&#10;differences create incompatibilities between individuals, preventing mating if&#10;the number of such differences is too large. Speciation, however, only happens&#10;in this mating system if the number of genes is large. Here we show that&#10;speciation with small genome sizes can occur if assortative mating is&#10;introduced. In our model individuals are represented by three chromosomes: one&#10;responsible for reproductive compatibility, one for coding the trait on which&#10;assortativity will operate, and a neutral chromosome. Reproduction is possible&#10;if individuals are genetically similar with respect to the first chromosome,&#10;but among these compatible mating partners, the one with the most similar trait&#10;coded by the second chromosome is selected. We show that this type of&#10;assortativity facilitates speciation, which can happen with a small number of&#10;genes in the first chromosome. Species, classified according to reproductive&#10;isolation, dictated by the first chromosome, can display different traits&#10;values, as measured by the second and the third chromosomes. Therefore, species&#10;can also be identified based on similarity of the neutral trait, which works as&#10;a proxy for reproductive isolation.&#10; | General | [Link](http://arxiv.org/abs/2409.10466v1) |&#10;| A stabilized total pressure&#45;formulation of the Biot&#39;s poroelasticity&#10; &#160;equations in frequency domain: numerical analysis and applications | Cristian Crcamo, Alfonso Caiazzo, Felipe Galarce, Joaqun Mura | &#160;&#160;This work focuses on the numerical solution of the dynamics of a poroelastic&#10;material in the frequency domain. We provide a detailed stability analysis&#10;based on the application of the Fredholm alternative in the continuous case,&#10;considering a total pressure formulation of the Biot&#39;s equations. In the&#10;discrete setting, we propose a stabilized equal order finite element method&#10;complemented by an additional pressure stabilization to enhance the robustness&#10;of the numerical scheme with respect to the fluid permeability. Utilizing the&#10;Fredholm alternative, we extend the well&#45;posedness results to the discrete&#10;setting, obtaining theoretical optimal convergence for the case of linear&#10;finite elements. We present different numerical experiments to validate the&#10;proposed method. First, we consider model problems with known analytic&#10;solutions in two and three dimensions. As next, we show that the method is&#10;robust for a wide range of permeabilities, including the case of discontinuous&#10;coefficients. Lastly, we show the application for the simulation of brain&#10;elastography on a realistic brain geometry obtained from medical imaging.&#10; | General | [Link](http://arxiv.org/abs/2409.10465v1) |&#10;| New Direct Sum Tests | Alek Westover, Edward Yu, Kai Zheng | &#160;&#160;A function $f:[n]^{d} to mathbb{F}_2$ is a defn{direct sum} if there are&#10;functions $L_i:[n]to mathbb{F}_2$ such that ${f(x) = sum_{i}L_i(x_i)}$. In&#10;this work we give multiple results related to the property testing of direct&#10;sums.&#10; &#160;Our first result concerns a test proposed by Dinur and Golubev in 2019. We&#10;call their test the Diamond test and show that it is indeed a direct sum&#10;tester. More specifically, we show that if a function $f$ is $epsilon$&#45;far&#10;from being a direct sum function, then the Diamond test rejects $f$ with&#10;probability at least $Omega_{n,epsilon}(1)$. Even in the case of $n = 2$, the&#10;Diamond test is, to the best of our knowledge, novel and yields a new tester&#10;for the classic property of affinity.&#10; &#160;Apart from the Diamond test, we also analyze a broad family of direct sum&#10;tests, which at a high level, run an arbitrary affinity test on the restriction&#10;of $f$ to a random hypercube inside of $[n]^d$. This family of tests includes&#10;the direct sum test analyzed in cite{di19}, but does not include the Diamond&#10;test. As an application of our result, we obtain a direct sum test which works&#10;in the online adversary model of cite{KRV}.&#10; &#160;Finally, we also discuss a Fourier analytic interpretation of the diamond&#10;tester in the $n=2$ case, as well as prove local correction results for direct&#10;sum as conjectured by Dinur and Golubev.&#10; | General | [Link](http://arxiv.org/abs/2409.10464v1) |&#10;| Kolmogorov&#45;Arnold Networks in Low&#45;Data Regimes: A Comparative Study with&#10; &#160;Multilayer Perceptrons | Farhad Pourkamali&#45;Anaraki | &#160;&#160;Multilayer Perceptrons (MLPs) have long been a cornerstone in deep learning,&#10;known for their capacity to model complex relationships. Recently,&#10;Kolmogorov&#45;Arnold Networks (KANs) have emerged as a compelling alternative,&#10;utilizing highly flexible learnable activation functions directly on network&#10;edges, a departure from the neuron&#45;centric approach of MLPs. However, KANs&#10;significantly increase the number of learnable parameters, raising concerns&#10;about their effectiveness in data&#45;scarce environments. This paper presents a&#10;comprehensive comparative study of MLPs and KANs from both algorithmic and&#10;experimental perspectives, with a focus on low&#45;data regimes. We introduce an&#10;effective technique for designing MLPs with unique, parameterized activation&#10;functions for each neuron, enabling a more balanced comparison with KANs. Using&#10;empirical evaluations on simulated data and two real&#45;world data sets from&#10;medicine and engineering, we explore the trade&#45;offs between model complexity&#10;and accuracy, with particular attention to the role of network depth. Our&#10;findings show that MLPs with individualized activation functions achieve&#10;significantly higher predictive accuracy with only a modest increase in&#10;parameters, especially when the sample size is limited to around one hundred.&#10;For example, in a three&#45;class classification problem within additive&#10;manufacturing, MLPs achieve a median accuracy of 0.91, significantly&#10;outperforming KANs, which only reach a median accuracy of 0.53 with default&#10;hyperparameters. These results offer valuable insights into the impact of&#10;activation function selection in neural networks.&#10; | General | [Link](http://arxiv.org/abs/2409.10463v1) |&#10;| Effects of synapse location, delay and background stochastic activity on&#10; &#160;synchronising hippocampal CA1 neurons | Alessandro Fiasconaro, Michele Migliore | &#160;&#160;We study the synchronisation of neurons in a realistic model under the&#10;Hodgkin&#45;Huxley dynamics. To focus on the role of the different locations of the&#10;excitatory synapses, we use two identical neurons where the set of input&#10;signals is grouped at two different distances from the soma. The system is&#10;intended to represent a CA1 hippocampal neuron in which the synapses arriving&#10;from the CA3 neurons of the trisynaptic pathway appear to be localised in the&#10;apical dendritic region and are, in principle, either proximal or distal to the&#10;soma. Synchronisation is studied using a specifically defined spiking&#10;correlation function as a function of various parameters such as the distance&#10;from the soma of one of the synaptic groups, the inhibition weight and the&#10;associated activation delay. We found that the neurons&#39; spiking activity&#10;depends nonmonotonically on the relative dendritic location of the synapses and&#10;their inhibitory weight, whereas the synchronisation measure always decreases&#10;with inhibition, and strongly depends on its activation time delay. The&#10;background activity on the somas results essentially independent on the&#10;fluctuation intensity and strongly support the importance of the balance&#10;between inhibition and excitation for neuronal synchronization.&#10; | General | [Link](http://arxiv.org/abs/2409.10460v1) |&#10;| Efficiently Crowdsourcing Visual Importance with Punch&#45;Hole Annotation | Minsuk Chang, Soohyun Lee, Aeri Cho, Hyeon Jeon, Seokhyeon Park, Cindy Xiong Bearfield, Jinwook Seo | &#160;&#160;We introduce a novel crowdsourcing method for identifying important areas in&#10;graphical images through punch&#45;hole labeling. Traditional methods, such as gaze&#10;trackers and mouse&#45;based annotations, which generate continuous data, can be&#10;impractical in crowdsourcing scenarios. They require many participants, and the&#10;outcome data can be noisy. In contrast, our method first segments the graphical&#10;image with a grid and drops a portion of the patches (punch holes). Then, we&#10;iteratively ask the labeler to validate each annotation with holes, narrowing&#10;down the annotation only having the most important area. This approach aims to&#10;reduce annotation noise in crowdsourcing by standardizing the annotations while&#10;enhancing labeling efficiency and reliability. Preliminary findings from&#10;fundamental charts demonstrate that punch&#45;hole labeling can effectively&#10;pinpoint critical regions. This also highlights its potential for broader&#10;application in visualization research, particularly in studying large&#45;scale&#10;users&#39; graphical perception. Our future work aims to enhance the algorithm to&#10;achieve faster labeling speed and prove its utility through large&#45;scale&#10;experiments.&#10; | General | [Link](http://arxiv.org/abs/2409.10459v1) |&#10;| Full distribution of local observables in an exactly solvable current&#10; &#160;carrying steady states of a driven XXZ chain | Sandipan Manna, G J Sreejith | &#160;&#160;Current carrying steady states of interacting spins chains exhibit rich&#10;structures generated through an interplay of current induced correlations and&#10;energetic constraints from the Hamiltonian. The XXZ spin chain when coupled to&#10;maximally polarizing Lindblad terms admits an exact solution in a matrix&#10;product state (MPS) form. We use this exact solution to study the correlations&#10;and distributions of simple local spin observables in the non equilibrium&#10;steady state (NESS). We present exact expressions for spin correlators, entropy&#10;per site, cumulant generating functions for distributions of local observables&#10;in the XX limit (Ising anisotropy $Delta=0$). Further, we use the exact MPS&#10;solution in systems with $Delta&gt;0$, to numerically exactly calculate the&#10;entropy, correlations, as well as distributions of spin observables in blocks&#10;as large as $nsim 200$ sites allowing an estimation of the rate functions. The&#10;$z$ magnetization distribution is consistant with short range spin correlations&#10;in the $z$ direction while the $x$&#45;magnetization shows a double peak structure&#10;at larger $Delta$ suggesting short range ferromagnetic ordering. We find that&#10;the distribution of $z$&#45;magnetization sharpens for parameters where the current&#10;is maximized.&#10; | General | [Link](http://arxiv.org/abs/2409.10458v1) |&#10;| Mean Residual Life Ageing Intensity Function | Ashutosh Singh, Ishapathik Das, Asok Kumar Nanda, Sumen Sen | &#160;&#160;The ageing intensity function is a powerful analytical tool that provides&#10;valuable insights into the ageing process across diverse domains such as&#10;reliability engineering, actuarial science, and healthcare. Its applications&#10;continue to expand as researchers delve deeper into understanding the complex&#10;dynamics of ageing and its implications for society. One common approach to&#10;defining the ageing intensity function is through the hazard rate or failure&#10;rate function, extensively explored in scholarly literature. Equally&#10;significant to the hazard rate function is the mean residual life function,&#10;which plays a crucial role in analyzing the ageing patterns exhibited by units&#10;or components. This article introduces the mean residual life ageing intensity&#10;(MRLAI) function to delve into component ageing behaviours across various&#10;distributions. Additionally, we scrutinize the closure properties of the MRLAI&#10;function across different reliability operations. Furthermore, a new order&#10;termed the mean residual life ageing intensity order is defined to analyze the&#10;ageing behaviour of a system, and the closure property of this order under&#10;various reliability operations is discussed.&#10; | General | [Link](http://arxiv.org/abs/2409.10456v1) |&#10;| Quantile Fourier regressions for decision making under uncertainty | Arash Khojaste, Geoffrey Pritchard, Golbon Zakeri | &#160;&#160;Weconsider Markov decision processes arising from a Markov model of an&#10;underlying natural phenomenon. Such phenomena are usually periodic (e.g.&#10;annual) in time, and so the Markov processes modelling them must be&#10;time&#45;inhomogeneous, with cyclostationary rather than stationary behaviour. We&#10;describe a technique for constructing such processes that allows for periodic&#10;variations both in the values taken by the process and in the serial dependence&#10;structure. We include two illustrative numerical examples: a hydropower&#10;scheduling problem and a model of offshore wind power integration.&#10; | General | [Link](http://arxiv.org/abs/2409.10455v1) |&#10;| The Debiased Near&#45;Earth Object Population from ATLAS Telescopes | Rogerio Deienno, Larry Denneau, David Nesvorn, David Vokrouhlick, William F. Bottke, Robert Jedicke, Shantanu Naidu, Steven R. Chesley, Davide Farnocchia, Paul W. Chodas | &#160;&#160;This work is dedicated to debias the Near&#45;Earth Objects (NEO) population&#10;based on observations from the Asteroid Terrestrial&#45;impact Last Alert System&#10;(ATLAS) telescopes. We have applied similar methods used to develop the&#10;recently released NEO model generator (NEOMOD), once debiasing the NEO&#10;population using data from Catalina Sky Survey (CSS) G96 telescope. ATLAS is&#10;composed of four different telescopes. We first analyzed observational data&#10;from each of all four telescopes separately and later combined them. Our&#10;results highlight main differences between CSS and ATLAS, e.g., sky coverage&#10;and survey power at debiasing the NEO population. ATLAS has a much larger sky&#10;coverage than CSS, allowing it to find bright NEOs that would be constantly&#10;&quot;hiding&quot; from CSS. Consequently, ATLAS is more powerful than CSS at debiasing&#10;the NEO population for H $&#10;esssim$ 19. With its intrinsically greater&#10;sensitivity and emphasis on observing near opposition, CSS excels in the&#10;debiasing of smaller objects. ATLAS, as an all sky survey designed to find&#10;imminent hazardous objects, necessarily spends a significant fraction of time&#10;looking at places on the sky where objects do not appear, reducing its power&#10;for debiasing the population of small objects. We estimate a NEO population&#10;completeness of $approx$ 88%$^{+3%}_{&#45;2%}$ for H $&lt;$ 17.75 and $approx$&#10;36%$^{+1%}_{&#45;1%}$ for H $&lt;$ 22.25. Those numbers are similar to previous&#10;estimates (within error bars for H $&lt;$ 17.75) from CSS, yet, around 3% and 8%&#10;smaller at their face values, respectively. We also confirm previous finding&#10;that the $&#10;u_6$ secular resonance is the main source of small and faint NEOs&#10;at H = 28, whereas the 3:1 mean motion resonance with Jupiter dominates for&#10;larger and brighter NEOs at H = 15.&#10; | General | [Link](http://arxiv.org/abs/2409.10453v1) |&#10;| Signed Graph Autoencoder for Explainable and Polarization&#45;Aware Network&#10; &#160;Embeddings | Nikolaos Nakis, Chrysoula Kosma, Giannis Nikolentzos, Michalis Chatzianastasis, Iakovos Evdaimon, Michalis Vazirgiannis | &#160;&#160;Autoencoders based on Graph Neural Networks (GNNs) have garnered significant&#10;attention in recent years for their ability to extract informative latent&#10;representations, characterizing the structure of complex topologies, such as&#10;graphs. Despite the prevalence of Graph Autoencoders, there has been limited&#10;focus on developing and evaluating explainable neural&#45;based graph generative&#10;models specifically designed for signed networks. To address this gap, we&#10;propose the Signed Graph Archetypal Autoencoder (SGAAE) framework. SGAAE&#10;extracts node&#45;level representations that express node memberships over distinct&#10;extreme profiles, referred to as archetypes, within the network. This is&#10;achieved by projecting the graph onto a learned polytope, which governs its&#10;polarization. The framework employs a recently proposed likelihood for&#10;analyzing signed networks based on the Skellam distribution, combined with&#10;relational archetypal analysis and GNNs. Our experimental evaluation&#10;demonstrates the SGAAEs&#39; capability to successfully infer node memberships over&#10;the different underlying latent structures while extracting competing&#10;communities formed through the participation of the opposing views in the&#10;network. Additionally, we introduce the 2&#45;level network polarization problem&#10;and show how SGAAE is able to characterize such a setting. The proposed model&#10;achieves high performance in different tasks of signed link prediction across&#10;four real&#45;world datasets, outperforming several baseline models.&#10; | General | [Link](http://arxiv.org/abs/2409.10452v1) |&#10;| Why you should also use OLS estimation of tail exponents | Thiago Trafane Oliveira Santos, Daniel Oliveira Cajueiro | &#160;&#160;Even though practitioners often estimate Pareto exponents running OLS&#10;rank&#45;size regressions, the usual recommendation is to use the Hill MLE with a&#10;small&#45;sample correction instead, due to its unbiasedness and efficiency. In&#10;this paper, we advocate that you should also apply OLS in empirical&#10;applications. On the one hand, we demonstrate that, with a small&#45;sample&#10;correction, the OLS estimator is also unbiased. On the other hand, we show that&#10;the MLE assigns significantly greater weight to smaller observations. This&#10;suggests that the OLS estimator may outperform the MLE in cases where the&#10;distribution is (i) strictly Pareto but only in the upper tail or (ii)&#10;regularly varying rather than strictly Pareto. We substantiate our theoretical&#10;findings with Monte Carlo simulations and real&#45;world applications,&#10;demonstrating the practical relevance of the OLS method in estimating tail&#10;exponents.&#10; | General | [Link](http://arxiv.org/abs/2409.10448v1) |&#10;| Hydrodynamic hovering of swimming bacteria above surfaces | Pyae Hein Htet, Debasish Das, Eric Lauga | &#160;&#160;Flagellated bacteria are hydrodynamically attracted to rigid walls, yet past&#10;work shows a &#39;hovering&#39; state where they swim stably at a finite height above&#10;surfaces. We use numerics and theory to reveal the physical origin of hovering.&#10;Simulations first show that hovering requires an elongated cell body and&#10;results from a tilt away from the wall. Theoretical models then identify two&#10;essential asymmetries: the response of width&#45;asymmetric cells to active flows&#10;created by length&#45;asymmetric cells. A minimal model reconciles near and&#10;far&#45;field hydrodynamics, capturing all key features of hovering.&#10; | General | [Link](http://arxiv.org/abs/2409.10447v1) |&#10;| KoroT&#45;3E: A Personalized Musical Mnemonics Tool for Enhancing Memory&#10; &#160;Retention of Complex Computer Science Concepts | Xiangzhe Yuan, Jiajun Wang, Siying Hu, Andrew Cheung, Zhicong Lu | &#160;&#160;As the demand for computer science (CS) skills grows, mastering foundational&#10;concepts is crucial yet challenging for novice learners. To address this&#10;challenge, we present KoroT&#45;3E, an AI&#45;based system that creates personalized&#10;musical mnemonics to enhance both memory retention and understanding of&#10;concepts in CS. KoroT&#45;3E enables users to transform complex concepts into&#10;memorable lyrics and compose melodies that suit their musical preferences. We&#10;conducted semi&#45;structured interviews (n=12) to investigate why novice learners&#10;find it challenging to memorize and understand CS concepts. The findings,&#10;combined with constructivist learning theory, established our initial design,&#10;which was then refined following consultations with CS education experts. An&#10;empirical experiment(n=36) showed that those using KoroT&#45;3E (n=18)&#10;significantly outperformed the control group (n=18), with improved memory&#10;efficiency, increased motivation, and a positive learning experience. These&#10;findings demonstrate the effectiveness of integrating multimodal generative AI&#10;into CS education to create personalized and interactive learning experiences.&#10; | General | [Link](http://arxiv.org/abs/2409.10446v1) |&#10;| Deep&#45;Wide Learning Assistance for Insect Pest Classification | Toan Nguyen, Huy Nguyen, Huy Ung, Hieu Ung, Binh Nguyen | &#160;&#160;Accurate insect pest recognition plays a critical role in agriculture. It is&#10;a challenging problem due to the intricate characteristics of insects. In this&#10;paper, we present DeWi, novel learning assistance for insect pest&#10;classification. With a one&#45;stage and alternating training strategy, DeWi&#10;simultaneously improves several Convolutional Neural Networks in two&#10;perspectives: discrimination (by optimizing a triplet margin loss in a&#10;supervised training manner) and generalization (via data augmentation). From&#10;that, DeWi can learn discriminative and in&#45;depth features of insect pests&#10;(deep) yet still generalize well to a large number of insect categories (wide).&#10;Experimental results show that DeWi achieves the highest performances on two&#10;insect pest classification benchmarks (76.44% accuracy on the IP102 dataset&#10;and 99.79% accuracy on the D0 dataset, respectively). In addition, extensive&#10;evaluations and ablation studies are conducted to thoroughly investigate our&#10;DeWi and demonstrate its superiority. Our source code is available at&#10;https://github.com/toannguyen1904/DeWi.&#10; | General | [Link](http://arxiv.org/abs/2409.10445v1) |&#10;| LLM as BT&#45;Planner: Leveraging LLMs for Behavior Tree Generation in Robot&#10; &#160;Task Planning | Jicong Ao, Fan Wu, Yansong Wu, Abdalla Swikir, Sami Haddadin | &#160;&#160;Robotic assembly tasks are open challenges due to the long task horizon and&#10;complex part relations. Behavior trees (BTs) are increasingly used in robot&#10;task planning for their modularity and flexibility, but manually designing them&#10;can be effort&#45;intensive. Large language models (LLMs) have recently been&#10;applied in robotic task planning for generating action sequences, but their&#10;ability to generate BTs has not been fully investigated. To this end, We&#10;propose LLM as BT&#45;planner, a novel framework to leverage LLMs for BT generation&#10;in robotic assembly task planning and execution. Four in&#45;context learning&#10;methods are introduced to utilize the natural language processing and inference&#10;capabilities of LLMs to produce task plans in BT format, reducing manual effort&#10;and ensuring robustness and comprehensibility. We also evaluate the performance&#10;of fine&#45;tuned, fewer&#45;parameter LLMs on the same tasks. Experiments in simulated&#10;and real&#45;world settings show that our framework enhances LLMs&#39; performance in&#10;BT generation, improving success rates in BT generation through in&#45;context&#10;learning and supervised fine&#45;tuning.&#10; | General | [Link](http://arxiv.org/abs/2409.10444v1) |&#10;| The James Webb Space Telescope Absolute Flux Calibration. II.&#10; &#160;Mid&#45;Infrared Instrument Imaging and Coronagraphy | Karl D. Gordon, G. C. Sloan, Macarena Garcia Marin, Mattia Libralato, George Rieke, Jonathan A. Aguilar, Ralph Bohlin, Misty Cracraft, Marjorie Decleir, Andras Gaspar, David R. Law, Alberto Noriega&#45;Crespo, Michael Regan | &#160;&#160;The absolute flux calibration of the Mid&#45;Infrared Instrument Imaging and&#10;Coronagraphy is based on observations of multiple stars taken during the first&#10;2.5 years of JWST operations. The observations were designed to ensure that the&#10;flux calibration is valid for a range of flux densities, different subarrays,&#10;and different types of stars. The flux calibration was measured by combining&#10;observed aperture photometry corrected to infinite aperture with predictions&#10;based on previous observations and models of stellar atmospheres. A subset of&#10;these observations were combined with model point&#45;spread&#45;functions to measure&#10;the corrections to infinite aperture. Variations in the calibration factor with&#10;time, flux density, background level, type of star, subarray, integration time,&#10;rate, and well depth were investigated, and the only significant variations&#10;were with time and subarray. Observations of the same star taken approximately&#10;every month revealed a modest time&#45;dependent response loss seen mainly at the&#10;longest wavelengths. This loss is well characterized by a decaying exponential&#10;with a time constant of ~200 days. After correcting for the response loss, the&#10;band&#45;dependent scatter around the corrected average (aka repeatability) was&#10;found to range from 0.1 to 1.2%. Signals in observations taken with different&#10;subarrays can be lower by up to 3.4% compared to FULL frame. After correcting&#10;for the time and subarray dependencies, the scatter in the calibration factors&#10;measured for individual stars ranges from 1 to 4% depending on the band. The&#10;formal uncertainties on the flux calibration averaged for all observations are&#10;0.3 to 1.0%, with longer&#45;wavelength bands generally having larger&#10;uncertainties.&#10; | General | [Link](http://arxiv.org/abs/2409.10443v1) |&#10;| CtRNet&#45;X: Camera&#45;to&#45;Robot Pose Estimation in Real&#45;world Conditions Using&#10; &#160;a Single Camera | Jingpei Lu, Zekai Liang, Tristin Xie, Florian Ritcher, Shan Lin, Sainan Liu, Michael C. Yip | &#160;&#160;Camera&#45;to&#45;robot calibration is crucial for vision&#45;based robot control and&#10;requires effort to make it accurate. Recent advancements in markerless pose&#10;estimation methods have eliminated the need for time&#45;consuming physical setups&#10;for camera&#45;to&#45;robot calibration. While the existing markerless pose estimation&#10;methods have demonstrated impressive accuracy without the need for cumbersome&#10;setups, they rely on the assumption that all the robot joints are visible&#10;within the camera&#39;s field of view. However, in practice, robots usually move in&#10;and out of view, and some portion of the robot may stay out&#45;of&#45;frame during the&#10;whole manipulation task due to real&#45;world constraints, leading to a lack of&#10;sufficient visual features and subsequent failure of these approaches. To&#10;address this challenge and enhance the applicability to vision&#45;based robot&#10;control, we propose a novel framework capable of estimating the robot pose with&#10;partially visible robot manipulators. Our approach leverages the&#10;Vision&#45;Language Models for fine&#45;grained robot components detection, and&#10;integrates it into a keypoint&#45;based pose estimation network, which enables more&#10;robust performance in varied operational conditions. The framework is evaluated&#10;on both public robot datasets and self&#45;collected partial&#45;view datasets to&#10;demonstrate our robustness and generalizability. As a result, this method is&#10;effective for robot pose estimation in a wider range of real&#45;world manipulation&#10;scenarios.&#10; | General | [Link](http://arxiv.org/abs/2409.10441v1) |&#10;| Successive topological phase transitions in two distinct spin&#45;flop&#10; &#160;phases on the honeycomb lattice | Xudong Li, Jize Zhao, Jinbin Li, Qiang Luo | &#160;&#160;The Kitaev magnets with bond&#45;dependent interactions have garnered&#10;considerable attention in recent years for their ability to harbor exotic&#10;phases and nontrivial excitations. The topological magnons, which are indicated&#10;by nonzero Chern number and thermal Hall conductivity, are proposed to&#10;partially explain thermal Hall measurements in real materials. Hitherto,&#10;topological magnons have been extensively explored when the magnetic field is&#10;normal to the honeycomb plane, but their topological characteristics are less&#10;studied in the presence of in&#45;plane magnetic field. Here, we study two distinct&#10;in&#45;plane field induced spin&#45;flop phases in the $Gamma$&#45;$Gamma&#39;$ model, both&#10;of which are off&#45;diagonal couplings that have intimate relation to the Kitaev&#10;interaction. The two spin&#45;flop phases are distinguished by their out&#45;of&#45;plane&#10;spin components which can be either antiparallel or parallel, thus dubbing&#10;antiferromagnetic (AFM) or ferromagnetic (FM) spin&#45;flop phases, respectively.&#10;We map out topological phase diagrams for both phases, revealing a rich pattern&#10;of the Chern number over exchange parameters and magnetic field. We&#10;analytically calculate the boundaries of topological phase transitions when the&#10;magnetic field is along the $a$ and $b$ directions. We find that the thermal&#10;Hall conductivity and its derivative display contrasting behaviors when&#10;crossing different topological phase transitions. The striking difference of&#10;the two phases lies in that when the magnetic field is along the $b$ direction,&#10;topological magnons are totally absent in the AFM spin&#45;flop phase, while they&#10;can survive in the FM analogue in certain parameter regions.&#10; | General | [Link](http://arxiv.org/abs/2409.10439v1) |&#10;| A functorial approach to $n$&#45;abelian categories | Vitor Gulisz | &#160;&#160;We develop a functorial approach to the study of $n$&#45;abelian categories by&#10;reformulating their axioms in terms of their categories of finitely presented&#10;functors. Such an approach allows the use of classical homological algebra and&#10;representation theory techniques to understand higher homological algebra. As&#10;an application, we present two possible generalizations of the axioms &quot;every&#10;monomorphism is a kernel&quot; and &quot;every epimorphism is a cokernel&quot; of an abelian&#10;category to $n$&#45;abelian categories. We also specialize our results to modules&#10;over rings, thereby describing when the category of finitely generated&#10;projective modules over a ring is $n$&#45;abelian. Moreover, we establish a&#10;correspondence for $n$&#45;abelian categories with additive generators, which&#10;extends the higher Auslander correspondence.&#10; | General | [Link](http://arxiv.org/abs/2409.10438v1) |&#10;| Color symmetry breaking in the Potts spin glass | Jean&#45;Christophe Mourrat | &#160;&#160;The Potts spin glass is an analogue of the Sherrington&#45;Kirkpatrick model in&#10;which each spin can take one of $kappa$ possible values, which we interpret as&#10;colors. It was suggested in arXiv:2310.06745 that the order parameter for this&#10;model is always invariant with respect to permutations of the colors. We show&#10;here that this is false whenever $kappa ge 58$.&#10; | General | [Link](http://arxiv.org/abs/2409.10437v1) |&#10;| Infector characteristics exposed by spatial analysis of SARS&#45;CoV&#45;2&#10; &#160;sequence and demographic data analysed at fine geographical scales | Anna Gama, Samantha Lycett, Will Harvey, Joseph Hughes, Sema Nickbakhsh, David L Robertson, Alison Smith Palmer, Anthony Wood, Rowland Kao | &#160;&#160;Characterising drivers of SARS&#45;CoV&#45;2 circulation is crucial for understanding&#10;COVID&#45;19 because of the severity of control measures adopted during the&#10;pandemic. Whole genome sequence data augmented with demographic metadata&#10;provides the best opportunity to do this. We use Random Forest Decision Tree&#10;models to analyse a combination of over 4000 SARS&#45;CoV2 sequences from a densely&#10;sampled, mixed urban and rural population (Tayside) in Scotland in the period&#10;from August 2020 to July 2021, with fine scale geographical and&#10;socio&#45;demographic metadata. Comparing periods in versus out of &quot;lockdown&quot;&#10;restrictions, we show using genetic distance relationships that individuals&#10;from more deprived areas are more likely to get infected during lockdown but&#10;less likely to spread the infection further. As disadvantaged communities were&#10;the most affected by both COVID&#45;19 and its restrictions, our finding has&#10;important implications for informing future approaches to control future&#10;pandemics driven by similar respiratory infections.&#10; | General | [Link](http://arxiv.org/abs/2409.10436v1) |&#10;| A study of pure multi&#45;strange hadrons production in Pb+Pb collisions at&#10; &#160;LHC energies using HYDJET++ model | Gauri Devi, B. K. Singh | &#160;&#160;For the present work, we have used the HYDJET++ model to explore the&#10;production of pure multi&#45;strange hadrons in Pb+Pb collisions at&#10;$sqrt{s_{NN}}$= 2.76 TeV and $sqrt{s_{NN}}$= 5.02 TeV collision energies,&#10;respectively. We have simulated the $p_{T}$&#45;spectra and elliptic flow ($v_{2}$)&#10;of $phi$&#45;meson and $Omega$&#45;baryons comparing our results with ALICE&#10;experimental data and several phenomenological models (HIJING/$Boverline{B}$,&#10;VISHNU, EPOS, AMPT, and Krakow) across various centrality intervals.&#10;Additionally, we have calculated the nuclear modification factors ($R_{AA}$ and&#10;$R_{CP}$), which provide a perception of jet quenching phenomena. Hence, our&#10;findings enable the study of the energy and system dependence of $phi$ and&#10;$Omega$ hadrons production over a wide range of ultra&#45;relativistic collision&#10;energies. We also present the particle ratios ($Omega/phi$,&#10;$overline{Omega}^{+}/Omega^{&#45;}$, $Omega/pi$, and $phi/pi$), offering&#10;insights on the strangeness enhancement and chemical properties of the medium&#10;at both LHC collision energies.&#10; | General | [Link](http://arxiv.org/abs/2409.10435v1) |&#10;| Magnetic metamaterials by ion&#45;implantation | Christina Vantaraki, Petter Strm, Tuan T. Tran, Matas P. Grassi, Giovanni Fevola, Michael Foerster, Jerzy T. Sadowski, Daniel Primetzhofer, Vassilios Kapaklis | &#160;&#160;We present a method for the additive fabrication of planar magnetic&#10;nanoarrays with minimal surface roughness. Synthesis is accomplished by&#10;combining electron&#45;beam lithography, used to generate nanometric patterned&#10;masks, with ion implantation in thin films. By implanting $^{56}$Fe$^{+}$ ions,&#10;we are able to introduce magnetic functionality in a controlled manner into&#10;continuous Pd thin films, achieving 3D spatial resolution down to a few tens of&#10;nanometers. Our results demonstrate the successful application of this&#10;technique in fabricating square artificial spin ice lattices, which exhibit&#10;well&#45;defined magnetization textures and interactions among the patterned&#10;magnetic elements.&#10; | General | [Link](http://arxiv.org/abs/2409.10433v1) |&#10;| Structure&#45;preserving learning for multi&#45;symplectic PDEs | Sleyman Yldz, Pawan Goyal, Peter Benner | &#160;&#160;This paper presents an energy&#45;preserving machine learning method for&#10;inferring reduced&#45;order models (ROMs) by exploiting the multi&#45;symplectic form&#10;of partial differential equations (PDEs). The vast majority of&#10;energy&#45;preserving reduced&#45;order methods use symplectic Galerkin projection to&#10;construct reduced&#45;order Hamiltonian models by projecting the full models onto a&#10;symplectic subspace. However, symplectic projection requires the existence of&#10;fully discrete operators, and in many cases, such as black&#45;box PDE solvers,&#10;these operators are inaccessible. In this work, we propose an energy&#45;preserving&#10;machine learning method that can infer the dynamics of the given PDE using data&#10;only, so that the proposed framework does not depend on the fully discrete&#10;operators. In this context, the proposed method is non&#45;intrusive. The proposed&#10;method is grey box in the sense that it requires only some basic knowledge of&#10;the multi&#45;symplectic model at the partial differential equation level. We prove&#10;that the proposed method satisfies spatially discrete local energy conservation&#10;and preserves the multi&#45;symplectic conservation laws. We test our method on the&#10;linear wave equation, the Korteweg&#45;de Vries equation, and the&#10;Zakharov&#45;Kuznetsov equation. We test the generalization of our learned models&#10;by testing them far outside the training time interval.&#10; | General | [Link](http://arxiv.org/abs/2409.10432v1) |&#10;| Hippocampal synchronization in a realistic CA1 neuron model | Alessandro Fiasconaro, Michele Migliore | &#160;&#160;This work delves into studying the synchronization in two realistic neuron&#10;models using Hodgkin&#45;Huxley dynamics. Unlike simplistic point&#45;like models,&#10;excitatory synapses are here randomly distributed along the dendrites,&#10;introducing strong stochastic contributions into their signal propagation. To&#10;focus on the role of different excitatory positions, we use two copies of the&#10;same neuron whose synapses are located at different distances from the soma and&#10;are exposed to identical Poissonian distributed current pulses. The&#10;synchronization is investigated through a specifically defined spiking&#10;correlation function, and its behavior is analyzed as a function of several&#10;parameters: inhibition weight, distance from the soma of one synaptic group,&#10;excitatory inactivation delay, and weight of the excitatory synapses.&#10; | General | [Link](http://arxiv.org/abs/2409.10431v1) |&#10;| Meta&#45;Whisper: Speech&#45;Based Meta&#45;ICL for ASR on Low&#45;Resource Languages | Ming&#45;Hao Hsu, Kuan Po Huang, Hung&#45;yi Lee | &#160;&#160;This paper presents Meta&#45;Whisper, a novel approach to improve automatic&#10;speech recognition (ASR) for low&#45;resource languages using the Whisper model. By&#10;leveraging Meta In&#45;Context Learning (Meta&#45;ICL) and a k&#45;Nearest Neighbors (KNN)&#10;algorithm for sample selection, Meta&#45;Whisper enhances Whisper&#39;s ability to&#10;recognize speech in unfamiliar languages without extensive fine&#45;tuning.&#10;Experiments on the ML&#45;SUPERB dataset show that Meta&#45;Whisper significantly&#10;reduces the Character Error Rate (CER) for low&#45;resource languages compared to&#10;the original Whisper model. This method offers a promising solution for&#10;developing more adaptable multilingual ASR systems, particularly for languages&#10;with limited resources.&#10; | General | [Link](http://arxiv.org/abs/2409.10429v1) |&#10;| User&#45;Authenticated Device&#45;Independent Quantum Secure Direct&#10; &#160;Communication Protocol | Nayana Das, Saikat Basu, Goutam Paul, Vijay S. Rao | &#160;&#160;Device&#45;Independent Quantum Secure Direct Communication (DI&#45;QSDC) enhances&#10;quantum cryptography by enabling secure message transmission without relying on&#10;the trustworthiness of the devices involved. This approach mitigates risks&#10;associated with compromised or untrusted devices, common in traditional quantum&#10;communication.&#10; &#160;In this paper, we propose the first of its kind DI&#45;QSDC protocol with user&#10;identity authentication. This ensures the authenticity of both the sender and&#10;receiver prior to message exchange. We then discuss the security of the&#10;proposed protocol against common attacks, demonstrating that no eavesdropper&#10;gains any information from either the quantum or the classical channel. Next,&#10;we implement the protocol on IBM&#39;s quantum hardware and evaluate its&#10;performance in a realistic noisy environment. Additionally, by simulating&#10;common attack models, we showcase that the protocol is secure against any&#10;eavesdropper in the channel. These findings highlight the protocol&#39;s robust&#10;security and practical feasibility for real&#45;world secure quantum communication.&#10; | General | [Link](http://arxiv.org/abs/2409.10427v1) |&#10;| Role of kinematic constraints in the time reversal symmetry breaking of&#10; &#160;a model active matter | Soumen Das, Shankar Ghosh, Tridib Sadhu, Juliane U Klamser | &#160;&#160;Active&#45;matter systems are inherently out&#45;of&#45;equilibrium and perform&#10;mechanical work by utilizing their internal energy sources. Breakdown of&#10;time&#45;reversal symmetry (BTRS) is a hallmark of such dissipative non&#45;equilibrium&#10;dynamics. We introduce a robust, experimentally accessible, noninvasive,&#10;quantitative measure of BTRS in terms of the Kullback&#45;Leibler divergence in&#10;collision events, demonstrated in our novel artificial active matter, comprised&#10;of battery&#45;powered spherical rolling robots whose energetics in different modes&#10;of motion can be measured with high precision. Our dimensionless measure&#10;characterizes how dissipation and internal energetics are influenced by&#10;kinematic constraints from interactions with the environment. We propose this&#10;measure of BTRS as an empirical estimate of the distance from equilibrium. An&#10;energetic insight into this departure of active matter from equilibrium comes&#10;from our demonstration of a non&#45;trivial fluctuation symmetry, which reveals a&#10;potentially universal thermodynamic characteristic of active energetics. As a&#10;many&#45;body consequence of BTRS in our experimental active system, we demonstrate&#10;the emergence of activity&#45;induced herding, which has no equilibrium analogue.&#10; | General | [Link](http://arxiv.org/abs/2409.10425v1) |&#10;| Unveiling V Modes: Enhancing CMB Sensitivity to BSM Physics with a&#10; &#160;Non&#45;Ideal Half&#45;Wave Plate | N. Raffuzzi, M. Lembo, S. Giardiello, M. Gerbino, M. Lattanzi, P. Natoli, L. Pagano | &#160;&#160;V&#45;mode polarization of the cosmic microwave background is expected to be&#10;vanishingly small in the $Lambda$CDM model and, hence, usually ignored.&#10;Nonetheless, several astrophysical effects, as well as beyond standard model&#10;physics could produce it at a detectable level. A realistic half&#45;wave plate &#45;&#10;an optical element commonly used in CMB experiments to modulate the polarized&#10;signal &#45; can provide sensitivity to V modes without significantly spoiling that&#10;to linear polarization. We assess this sensitivity for some new&#45;generation CMB&#10;experiments, such as the LiteBIRD satellite, the ground&#45;based Simons&#10;Observatory and a CMB&#45;S4&#45;like experiment. We forecast the efficiency of these&#10;experiments to constrain the phenomenology of certain classes of BSM models&#10;inducing mixing of linear polarization states and generation of V modes in the&#10;CMB. We find that new&#45;generation experiments can improve current limits by&#10;1&#45;to&#45;3 orders of magnitude, depending on the data combination. The inclusion of&#10;V&#45;mode information dramatically boosts the sensitivity to these BSM models.&#10; | General | [Link](http://arxiv.org/abs/2409.10424v1) |&#10;| Initial data for a deformed isolated horizon | Ale Flandera, David Kofro, Tom Ledvinka | &#160;&#160;Within the isolated horizon formalism, we investigate a static axisymmetric&#10;space&#45;time of a black hole influenced by matter in its neighborhood. To&#10;illustrate the role of ingredients and assumptions in this formalism, we first&#10;show how, in spherical symmetry, the field equations and gauge conditions imply&#10;the isolated horizon initial data leading to the Schwarzschild space&#45;time.&#10;Then, we construct the initial data for a static axisymmetric isolated horizon&#10;representing a deformed black hole. The space&#45;time description in the&#10;Bondi&#45;like coordinates is then found as a series expansion in the vicinity of&#10;the horizon. To graphically illustrate this construction, we also find a&#10;numerical solution for a black hole deformed by a particular analytic model of&#10;a thin accretion disk. We also discuss how an accretion disk affects the&#10;analytical properties of the horizon geometry.&#10; | General | [Link](http://arxiv.org/abs/2409.10423v1) |&#10;| Learning Semi&#45;Supervised Medical Image Segmentation from Spatial&#10; &#160;Registration | Qianying Liu, Paul Henderson, Xiao Gu, Hang Dai, Fani Deligianni | &#160;&#160;Semi&#45;supervised medical image segmentation has shown promise in training&#10;models with limited labeled data and abundant unlabeled data. However,&#10;state&#45;of&#45;the&#45;art methods ignore a potentially valuable source of unsupervised&#10;semantic information &#45;&#45; spatial registration transforms between image volumes.&#10;To address this, we propose CCT&#45;R, a contrastive cross&#45;teaching framework&#10;incorporating registration information. To leverage the semantic information&#10;available in registrations between volume pairs, CCT&#45;R incorporates two&#10;proposed modules: Registration Supervision Loss (RSL) and Registration&#45;Enhanced&#10;Positive Sampling (REPS). The RSL leverages segmentation knowledge derived from&#10;transforms between labeled and unlabeled volume pairs, providing an additional&#10;source of pseudo&#45;labels. REPS enhances contrastive learning by identifying&#10;anatomically&#45;corresponding positives across volumes using registration&#10;transforms. Experimental results on two challenging medical segmentation&#10;benchmarks demonstrate the effectiveness and superiority of CCT&#45;R across&#10;various semi&#45;supervised settings, with as few as one labeled case. Our code is&#10;available at&#10;https://github.com/kathyliu579/ContrastiveCross&#45;teachingWithRegistration.&#10; | General | [Link](http://arxiv.org/abs/2409.10422v1) |&#10;| Multidimensional Deconvolution with Profiling | Huanbiao Zhu, Krish Desai, Mikael Kuusela, Vinicius Mikuni, Benjamin Nachman, Larry Wasserman | &#160;&#160;In many experimental contexts, it is necessary to statistically remove the&#10;impact of instrumental effects in order to physically interpret measurements.&#10;This task has been extensively studied in particle physics, where the&#10;deconvolution task is called unfolding. A number of recent methods have shown&#10;how to perform high&#45;dimensional, unbinned unfolding using machine learning.&#10;However, one of the assumptions in all of these methods is that the detector&#10;response is accurately modeled in the Monte Carlo simulation. In practice, the&#10;detector response depends on a number of nuisance parameters that can be&#10;constrained with data. We propose a new algorithm called Profile OmniFold&#10;(POF), which works in a similar iterative manner as the OmniFold (OF) algorithm&#10;while being able to simultaneously profile the nuisance parameters. We&#10;illustrate the method with a Gaussian example as a proof of concept&#10;highlighting its promising capabilities.&#10; | General | [Link](http://arxiv.org/abs/2409.10421v1) |&#10;| HiFi&#45;CS: Towards Open Vocabulary Visual Grounding For Robotic Grasping&#10; &#160;Using Vision&#45;Language Models | Vineet Bhat, Prashanth Krishnamurthy, Ramesh Karri, Farshad Khorrami | &#160;&#160;Robots interacting with humans through natural language can unlock numerous&#10;applications such as Referring Grasp Synthesis (RGS). Given a text query, RGS&#10;determines a stable grasp pose to manipulate the referred object in the robot&#39;s&#10;workspace. RGS comprises two steps: visual grounding and grasp pose estimation.&#10;Recent studies leverage powerful Vision&#45;Language Models (VLMs) for visually&#10;grounding free&#45;flowing natural language in real&#45;world robotic execution.&#10;However, comparisons in complex, cluttered environments with multiple instances&#10;of the same object are lacking. This paper introduces HiFi&#45;CS, featuring&#10;hierarchical application of Featurewise Linear Modulation (FiLM) to fuse image&#10;and text embeddings, enhancing visual grounding for complex attribute rich text&#10;queries encountered in robotic grasping. Visual grounding associates an object&#10;in 2D/3D space with natural language input and is studied in two scenarios:&#10;Closed and Open Vocabulary. HiFi&#45;CS features a lightweight decoder combined&#10;with a frozen VLM and outperforms competitive baselines in closed vocabulary&#10;settings while being 100x smaller in size. Our model can effectively guide&#10;open&#45;set object detectors like GroundedSAM to enhance open&#45;vocabulary&#10;performance. We validate our approach through real&#45;world RGS experiments using&#10;a 7&#45;DOF robotic arm, achieving 90.33% visual grounding accuracy in 15 tabletop&#10;scenes. We include our codebase in the supplementary material.&#10; | General | [Link](http://arxiv.org/abs/2409.10419v1) |&#10;| X&#45;ray reverberation as an explanation for UV/optical variability in&#10; &#160;nearby Seyferts | M. Papoutsis, I. E. Papadakis, C. Panagiotou, M. Doviak, E. Kammoun | &#160;&#160;Active galactic nuclei (AGNs) are known to be variable across all&#10;wavelengths. Significant observational efforts have been invested in the last&#10;decade in studying their ultraviolet (UV) and optical variability. Long and&#10;densely sampled, multi&#45;wavelength monitoring campaigns of numerous Seyfert&#10;galaxies have been conducted with the aim of determining the X&#45;ray/UV/optical&#10;continuum time lags. Time&#45;lag studies can be used to constrain theoretical&#10;models. The observed time lags can be explained by thermal reprocessing of the&#10;X&#45;rays illuminating the accretion disc (known as the X&#45;ray reverberation&#10;model). However, the observed light curves contain more information that can be&#10;used to further constrain physical models. Our primary objective is to&#10;investigate whether, in addition to time lags, the X&#45;ray reverberation model&#10;can also explain the UV/optical variability amplitude of nearby Seyferts. To do&#10;this, we measured the excess variance of four sources (namely Mrk 509, NGC&#10;4151, NGC 2617, and Mrk 142) as a function of wavelength using data from&#10;archival long, multi&#45;wavelength campaigns with Swift, and ground&#45;based&#10;telescopes. We also computed the model excess variance in the case of the X&#45;ray&#10;reverberation model by determining the disc&#39;s transfer function and assuming a&#10;bending power law for the X&#45;ray power spectrum. We tested the validity of the&#10;model by comparing the measured and model variances for a range of accretion&#10;rates and X&#45;ray source heights. We conclude that the X&#45;ray thermal&#10;reverberation model can fit both the continuum, UV/optical time lags, as well&#10;as the variance in these AGNs, for the same physical parameters. Our results&#10;suggest that the accretion disc is constant and that all the observed&#10;UV/optical variations, on timescales of days and up to a few weeks, can be&#10;fully explained by the variable X&#45;rays as they illuminate the accretion disc.&#10; | General | [Link](http://arxiv.org/abs/2409.10417v1) |&#10;| Local central limit theorem for Mallows measure | Alexey Bufetov, Kailun Chen | &#160;&#160;We study the statistics of the Mallows measure on permutations in the limit&#10;pioneered by Starr (2009). Our main result is the local central limit theorem&#10;for its height function. We also re&#45;derive versions of the law of large numbers&#10;and the large deviation principle, obtain the standard central limit theorem&#10;from the local one, and establish a multi&#45;point version of the local central&#10;limit theorem.&#10; | General | [Link](http://arxiv.org/abs/2409.10415v1) |&#10;| On interactive anisotropic walks in two dimensions generated from a&#10; &#160;three state opinion dynamics model | Surajit Saha, Parongama Sen | &#160;&#160;A system of interacting walkers on a two&#45;dimensional space where the dynamics&#10;of each walker are governed by the opinions of agents of a three&#45;state opinion&#10;dynamics model are considered. Such walks, inspired by Ising&#45;like models and&#10;opinions dynamics models, are usually considered in one&#45;dimensional virtual&#10;spaces. Here, the mapping is done in such a way that the walk is directed along&#10;the $y$ axis while it can move either way along the $x$ axis. We explore the&#10;properties of such walks as the parameter representing the noise in the opinion&#10;dynamics model, responsible for a continuous phase transition, is varied. The&#10;walk features show marked differences as the system crosses the critical point.&#10;The bivariate distribution of the displacements below the critical point is a&#10;modified biased Gaussian function of x and y which is symmetric about the X&#10;axis.&#10; &#160;The marginal probability distributions can be extracted and the scaling forms&#10;of different quantities, showing power law behaviour, are obtained. The&#10;directed nature of the walk is reflected in the marginal distributions as well&#10;as in the exponents.&#10; | General | [Link](http://arxiv.org/abs/2409.10413v1) |&#10;| A Large&#45;Scale Privacy Assessment of Android Third&#45;Party SDKs | Mark Huasong Meng, Chuan Yan, Yun Hao, Qing Zhang, Zeyu Wang, Kailong Wang, Sin Gee Teo, Guangdong Bai, Jin Song Dong | &#160;&#160;Third&#45;party Software Development Kits (SDKs) are widely adopted in Android&#10;app development, to effortlessly accelerate development pipelines and enhance&#10;app functionality. However, this convenience raises substantial concerns about&#10;unauthorized access to users&#39; privacy&#45;sensitive information, which could be&#10;further abused for illegitimate purposes like user tracking or monetization.&#10;Our study offers a targeted analysis of user privacy protection among Android&#10;third&#45;party SDKs, filling a critical gap in the Android software supply chain.&#10;It focuses on two aspects of their privacy practices, including data&#10;exfiltration and behavior&#45;policy compliance (or privacy compliance), utilizing&#10;techniques of taint analysis and large language models. It covers 158&#10;widely&#45;used SDKs from two key SDK release platforms, the official one and a&#10;large alternative one. From them, we identified 338 instances of privacy data&#10;exfiltration. On the privacy compliance, our study reveals that more than 30%&#10;of the examined SDKs fail to provide a privacy policy to disclose their data&#10;handling practices. Among those that provide privacy policies, 37% of them&#10;over&#45;collect user data, and 88% falsely claim access to sensitive data. We&#10;revisit the latest versions of the SDKs after 12 months. Our analysis&#10;demonstrates a persistent lack of improvement in these concerning trends. Based&#10;on our findings, we propose three actionable recommendations to mitigate the&#10;privacy leakage risks and enhance privacy protection for Android users. Our&#10;research not only serves as an urgent call for industry attention but also&#10;provides crucial insights for future regulatory interventions.&#10; | General | [Link](http://arxiv.org/abs/2409.10411v1) |&#10;| A point process approach for the classification of noisy calcium imaging&#10; &#160;data | Arianna Burzacchi, Nicoletta D&#39;Angelo, David Payares&#45;Garcia, Jorge Mateu | &#160;&#160;We study noisy calcium imaging data, with a focus on the classification of&#10;spike traces. As raw traces obscure the true temporal structure of neuron&#39;s&#10;activity, we performed a tuned filtering of the calcium concentration using two&#10;methods: a biophysical model and a kernel mapping. The former characterizes&#10;spike trains related to a particular triggering event, while the latter filters&#10;out the signal and refines the selection of the underlying neuronal response.&#10;Transitioning from traditional time series analysis to point process theory,&#10;the study explores spike&#45;time distance metrics and point pattern prototypes to&#10;describe repeated observations. We assume that the analyzed neuron&#39;s firing&#10;events, i.e. spike occurrences, are temporal point process events. In&#10;particular, the study aims to categorize 47 point patterns by depth, assuming&#10;the similarity of spike occurrences within specific depth categories. The&#10;results highlight the pivotal roles of depth and stimuli in discerning diverse&#10;temporal structures of neuron firing events, confirming the point process&#10;approach based on prototype analysis is largely useful in the classification of&#10;spike traces.&#10; | General | [Link](http://arxiv.org/abs/2409.10409v1) |&#10;| Variational closures for composite homogenised fluid flows | Theo Diamantakis, Ruiao Hu | &#160;&#160;The Stochastic Advection by Lie Transport is a variational formulation of&#10;stochastic fluid dynamics introduced to model the effects of unresolved scales,&#10;whilst preserving the geometric structure of ideal fluid flows. In this work,&#10;we show that the SALT equations can arise from the decomposition of the fluid&#10;flow map into its mean and fluctuating components. The fluctuating component is&#10;realised as a prescribed stochastic diffeomorphism that introduces stochastic&#10;transport into the system and we construct it using homogenisation theory. The&#10;dynamics of the mean component are derived from a variational principle&#10;utilising particular forms of variations that preserve the composite structure&#10;of the flow. Using a new variational principle, we show that SALT equations can&#10;arise from random Lagrangians and are equivalent to random coefficient PDEs. We&#10;also demonstrate how to modify the composite flow and the associated&#10;variational principle to derive models inspired by the Lagrangian Averaged&#10;Euler&#45;Poincare (LAEP) theory.&#10; | General | [Link](http://arxiv.org/abs/2409.10408v1) |&#10;| Bitcoin Transaction Behavior Modeling Based on Balance Data | Yu Zhang, Claudio Tessone | &#160;&#160;When analyzing Bitcoin users&#39; balance distribution, we observed that it&#10;follows a log&#45;normal pattern. Drawing parallels from the successful application&#10;of Gibrat&#39;s law of proportional growth in explaining city size and word&#10;frequency distributions, we tested whether the same principle could account for&#10;the log&#45;normal distribution in Bitcoin balances. However, our calculations&#10;revealed that the exponent parameters in both the drift and variance terms&#10;deviate slightly from one. This suggests that Gibrat&#39;s proportional growth rule&#10;alone does not fully explain the log&#45;normal distribution observed in Bitcoin&#10;users&#39; balances. During our exploration, we discovered an intriguing&#10;phenomenon: Bitcoin users tend to fall into two distinct categories based on&#10;their behavior, which we refer to as ``poor&quot; and ``wealthy&quot; users. Poor users,&#10;who initially purchase only a small amount of Bitcoin, tend to buy more&#10;bitcoins first and then sell out all their holdings gradually over time. The&#10;certainty of selling all their coins is higher and higher with time. In&#10;contrast, wealthy users, who acquire a large amount of Bitcoin from the start,&#10;tend to sell off their holdings over time. The speed at which they sell their&#10;bitcoins is lower and lower over time and they will hold at least a small part&#10;of their initial holdings at last. Interestingly, the wealthier the user, the&#10;larger the proportion of their balance and the higher the certainty they tend&#10;to sell. This research provided an interesting perspective to explore bitcoin&#10;users&#39; behaviors which may apply to other finance markets.&#10; | General | [Link](http://arxiv.org/abs/2409.10407v1) |&#10;| Stochastic Data&#45;Driven Predictive Control: Chance&#45;Constraint&#10; &#160;Satisfaction with Identified Multi&#45;step Predictors | Haldun Balim, Andrea Carron, Melanie N. Zeilinger, Johannes Khler | &#160;&#160;We propose a novel data&#45;driven stochastic model predictive control framework&#10;for uncertain linear systems with noisy output measurements. Our approach&#10;leverages multi&#45;step predictors to efficiently propagate uncertainty, ensuring&#10;chance constraint satisfaction with minimal conservatism. In particular, we&#10;present a strategy to identify multi&#45;step predictors and quantify the&#10;associated uncertainty using a surrogate (data&#45;driven) state space model. Then,&#10;we utilize the derived distribution to formulate a constraint tightening that&#10;ensures chance constraint satisfaction. A numerical example highlights the&#10;reduced conservatism of handling parametric uncertainty in the proposed method&#10;compared to state&#45;of&#45;the&#45;art solutions.&#10; | General | [Link](http://arxiv.org/abs/2409.10405v1) |&#10;| A Knowledge&#45;Enhanced Disease Diagnosis Method Based on Prompt Learning&#10; &#160;and BERT Integration | Zhang Zheng | &#160;&#160;This paper proposes a knowledge&#45;enhanced disease diagnosis method based on a&#10;prompt learning framework. The method retrieves structured knowledge from&#10;external knowledge graphs related to clinical cases, encodes it, and injects it&#10;into the prompt templates to enhance the language model&#39;s understanding and&#10;reasoning capabilities for the task.We conducted experiments on three public&#10;datasets: CHIP&#45;CTC, IMCS&#45;V2&#45;NER, and KUAKE&#45;QTR. The results show that the&#10;proposed method significantly outperforms existing models across multiple&#10;evaluation metrics, with an F1 score improvement of 2.4% on the CHIP&#45;CTC&#10;dataset, 3.1% on the IMCS&#45;V2&#45;NER dataset,and 4.2% on the KUAKE&#45;QTR dataset.&#10;Additionally,ablation studies confirmed the critical role of the knowledge&#10;injection module,as the removal of this module resulted in a significant drop&#10;in F1 score. The experimental results demonstrate that the proposed method not&#10;only effectively improves the accuracy of disease diagnosis but also enhances&#10;the interpretability of the predictions, providing more reliable support and&#10;evidence for clinical diagnosis.&#10; | General | [Link](http://arxiv.org/abs/2409.10403v1) |&#10;| A Statistical Equilibrium Approach to Adam Smith&#39;s Labor Theory of Value | Ellis Scharfenaker, Bruno Theodosio, Duncan K. Foley | &#160;&#160;Adam Smith&#39;s inquiry into the emergence and stability of the&#10;self&#45;organization of the division of labor in commodity production and exchange&#10;is considered using statistical equilibrium methods from statistical physics.&#10;We develop a statistical equilibrium model of the distribution of independent&#10;direct producers in a hub&#45;and&#45;spoke framework that predicts both the center of&#10;gravity of producers across lines of production as well as the endogenous&#10;fluctuations between lines of production that arise from Smith&#39;s concept of&#10;&quot;perfect liberty&quot;. The ergodic distribution of producers implies a long&#45;run&#10;balancing of &quot;advantages to disadvantages&quot; across lines of employment and&#10;gravitation of market prices around Smith&#39;s natural prices.&#10; | General | [Link](http://arxiv.org/abs/2409.10402v1) |&#10;| Hydrodynamic mechanism for stable spindle positioning in meiosis II&#10; &#160;oocytes | Weida Liao, Eric Lauga | &#160;&#160;Cytoplasmic streaming, the persistent flow of fluid inside a cell, induces&#10;intracellular transport, which plays a key role in fundamental biological&#10;processes. In meiosis II mouse oocytes (developing egg cells) awaiting&#10;fertilisation, the spindle, which is the protein structure responsible for&#10;dividing genetic material in a cell, must maintain its position near the cell&#10;cortex (the thin actin network bound to the cell membrane) for many hours.&#10;However, the cytoplasmic streaming that accompanies this stable positioning&#10;would intuitively appear to destabilise the spindle position. Here, through a&#10;combination of numerical and analytical modelling, we reveal a new,&#10;hydrodynamic mechanism for stable spindle positioning beneath the cortical cap.&#10;We show that this stability depends critically on the spindle size and the&#10;active driving from the cortex, and demonstrate that stable spindle positioning&#10;can result purely from a hydrodynamic suction force exerted on the spindle by&#10;the cytoplasmic flow. Our findings show that local fluid dynamic forces can be&#10;sufficient to stabilise the spindle, explaining robustness against&#10;perturbations not only perpendicular but also parallel to the cortex. Our&#10;results shed light on the importance of cytoplasmic streaming in mammalian&#10;meiosis.&#10; | General | [Link](http://arxiv.org/abs/2409.10401v1) |&#10;| Sherpa: An Open Source Python Fitting Package | Aneta Siemiginowska, Douglas Burke, Hans Moritz Gnther, Nicholas P. Lee, Warren McLaughlin, David A. Principe, Harlan Cheer, Antonella Fruscione, Omar Laurino, Jonathan McDowell, Marie Terrell | &#160;&#160;We present an overview of Sherpa, an open source Python project, and discuss&#10;its development history, broad design concepts and capabilities. Sherpa&#10;contains powerful tools for combining parametric models into complex&#10;expressions that can be fit to data using a variety of statistics and&#10;optimization methods. It is easily extensible to include user&#45;defined models,&#10;statistics, and optimization methods. It provides a high&#45;level User Interface&#10;for interactive data&#45;analysis, such as within a Jupyter notebook, and it can&#10;also be used as a library component, providing fitting and modeling&#10;capabilities to an application. We include a few examples of Sherpa&#10;applications to multiwavelength astronomical data. The code is available&#10;GitHub: https://github.com/sherpa/sherpa&#10; | General | [Link](http://arxiv.org/abs/2409.10400v1) |&#10;| Minimally coupled $$&#45;exponential inflation with an $R^2$ term in&#10; &#160;the Palatini formulation | Nilay Bostan, Rafid H. Dejrah | &#160;&#160;We focus on the inflationary predictions of $beta$&#45;exponential potential&#10;models, in which the inflaton is a representation of the field delineating the&#10;size of extra&#45;dimension. Since it offers a well&#45;motivated starting point for&#10;the study of physics at very high energies, we incorporate an $R^2$ term in the&#10;Palatini gravity. In addition, afterward the inflation, the inflaton oscillates&#10;about the minimum of the inflation potential, and reheats the universe. This&#10;occurs during the reheating phase, at which the inflaton decays into the&#10;standard model particles, which fill the universe. We extend our examination by&#10;considering the reheating effects on inflationary observables by employing the&#10;different scenarios of the reheat temperature. Supposing the standard thermal&#10;history after inflation, we display the inflationary predictions, $n_s, r,&#10;mathrm{d}n_s/mathrm{d}&#10;n k$ of $beta$&#45;exponential potential with minimal&#10;coupling in Palatini $R^2$ gravity. Also, different kinds of constraints from a&#10;variety of observations, such as BICEP/Keck, Planck 2018, as well as future&#10;possible detectable sensitivities that might be reached by CMB experiments:&#10;CMB&#45;S4 and LiteBIRD are taken into account in this work. We indicate that our&#10;results are consistent with both the latest data and the future sensitivity&#10;forecasts of LiteBIRD/Planck and CMB&#45;S4. Finally, the results in this study&#10;highlight the viability of our model even in the case of the existence of more&#10;stringent constraints expected from future achievable confidence level limits.&#10; | General | [Link](http://arxiv.org/abs/2409.10398v1) |&#10;| Quantifying Observational Projection Effects with a Simulation&#45;based hot&#10; &#160;CGM model | Soumya Shreeram, Johan Comparat, Andrea Merloni, Yi Zhang, Gabriele Ponti, Kirpal Nandra, John ZuHone, Ilaria Marini, Stephan Vladutescu&#45;Zopp, Paola Popesso, Ruediger Pakmor, Riccardo Seppi, Celine Peroux, Daniele Sorini | &#160;&#160;The hot phase of the circumgalactic medium (CGM) allows us to probe the&#10;inflow and outflow of gas within a galaxy, which is responsible for dictating&#10;the evolution of the galaxy. Studying the hot CGM sheds light on a better&#10;understanding of gas physics, which is crucial to inform and constrain&#10;simulation models. With the recent advances in observational measurements&#10;probing the hot CGM in X&#45;rays and tSZ, we have a new avenue for widening our&#10;knowledge of gas physics and feedback by exploiting the information from&#10;current/future observations. In this paper, we use the TNG300 hydrodynamical&#10;simulations to build a fully self&#45;consistent forward model for the hot CGM. We&#10;construct a lightcone and generate mock X&#45;ray observations. We quantify the&#10;projection effects, namely the locally correlated large&#45;scale structure in&#10;X&#45;rays and the effect due to satellite galaxies misclassified as centrals which&#10;affects the measured hot CGM galactocentric profiles in stacking experiments.&#10;We present an analytical model that describes the intrinsic X&#45;ray surface&#10;brightness profile across the stellar and halo mass bins. The increasing&#10;stellar mass bins result in decreasing values of $beta$, the exponent&#10;quantifying the slope of the intrinsic galactocentric profiles. We carry&#10;forward the current state&#45;of&#45;the&#45;art by also showing the impact of the locally&#10;correlated environment on the measured X&#45;ray surface brightness profiles. We&#10;also present, for the first time, the effect of misclassified centrals in&#10;stacking experiments for three stellar mass bins: $10^{10.5&#45;11} M_odot$,&#10;$10^{11&#45;11.2} M_odot$, and $10^{11.2&#45;11.5} M_odot$. We find that the&#10;contaminating effect of the misclassified centrals on the stacked profiles&#10;increases when the stellar mass decreases.&#10; | General | [Link](http://arxiv.org/abs/2409.10397v1) |&#10;| MOST: MR reconstruction Optimization for multiple downStream Tasks via&#10; &#160;continual learning | Hwihun Jeong, Se Young Chun, Jongho Lee | &#160;&#160;Deep learning&#45;based Magnetic Resonance (MR) reconstruction methods have&#10;focused on generating high&#45;quality images but they often overlook the impact on&#10;downstream tasks (e.g., segmentation) that utilize the reconstructed images.&#10;Cascading separately trained reconstruction network and downstream task network&#10;has been shown to introduce performance degradation due to error propagation&#10;and domain gaps between training datasets. To mitigate this issue, downstream&#10;task&#45;oriented reconstruction optimization has been proposed for a single&#10;downstream task. Expanding this optimization to multi&#45;task scenarios is not&#10;straightforward. In this work, we extended this optimization to sequentially&#10;introduced multiple downstream tasks and demonstrated that a single MR&#10;reconstruction network can be optimized for multiple downstream tasks by&#10;deploying continual learning (MOST). MOST integrated techniques from&#10;replay&#45;based continual learning and image&#45;guided loss to overcome catastrophic&#10;forgetting. Comparative experiments demonstrated that MOST outperformed a&#10;reconstruction network without finetuning, a reconstruction network with&#10;na&quot;ive finetuning, and conventional continual learning methods. This&#10;advancement empowers the application of a single MR reconstruction network for&#10;multiple downstream tasks. The source code is available at:&#10;https://github.com/SNU&#45;LIST/MOST&#10; | General | [Link](http://arxiv.org/abs/2409.10394v1) |&#10;| Multicopy quantum state teleportation with application to storage and&#10; &#160;retrieval of quantum programs | Frdric Grosshans, Micha Horodecki, Mio Murao, Tomasz Mynik, Marco Tlio Quintino, Micha Studziski, Satoshi Yoshida | &#160;&#160;This work considers a teleportation task for Alice and Bob in a scenario&#10;where Bob cannot perform corrections. In particular, we analyse the task of&#10;textit{multicopy state teleportation}, where Alice has $k$ identical copies of&#10;an arbitrary unknown $d$&#45;dimensional qudit state $vertpsi&#13;angle$ to teleport&#10;a single copy of $vertpsi&#13;angle$ to Bob using a maximally entangled&#10;two&#45;qudit state shared between Alice and Bob without Bob&#39;s correction. Alice&#10;may perform a joint measurement on her half of the entangled state and the $k$&#10;copies of $vertpsi&#13;angle$. We prove that the maximal probability of success&#10;for teleporting the exact state $vertpsi&#13;angle$ to Bob is&#10;$p(d,k)=frac{k}{d(k&#45;1+d)}$ and present an explicit protocol to attain this&#10;performance. Then, by utilising $k$ copies of an arbitrary target state&#10;$vertpsi&#13;angle$, we show how the multicopy state teleportation protocol can&#10;be employed to enhance the success probability of storage and retrieval of&#10;quantum programs, which aims to universally retrieve the action of an arbitrary&#10;quantum channel that is stored in a state. Our proofs make use of group&#10;representation theory methods, which may find applications beyond the problems&#10;addressed in this work.&#10; | General | [Link](http://arxiv.org/abs/2409.10393v1) |&#10;| TPFL: Tsetlin&#45;Personalized Federated Learning with Confidence&#45;Based&#10; &#160;Clustering | Rasoul Jafari Gohari, Laya Aliahmadipour, Ezat Valipour | &#160;&#160;The world of Machine Learning (ML) has witnessed rapid changes in terms of&#10;new models and ways to process users data. The majority of work that has been&#10;done is focused on Deep Learning (DL) based approaches. However, with the&#10;emergence of new algorithms such as the Tsetlin Machine (TM) algorithm, there&#10;is growing interest in exploring alternative approaches that may offer unique&#10;advantages in certain domains or applications. One of these domains is&#10;Federated Learning (FL), in which users privacy is of utmost importance. Due to&#10;its novelty, FL has seen a surge in the incorporation of personalization&#10;techniques to enhance model accuracy while maintaining user privacy under&#10;personalized conditions. In this work, we propose a novel approach dubbed TPFL:&#10;Tsetlin&#45;Personalized Federated Learning, in which models are grouped into&#10;clusters based on their confidence towards a specific class. In this way,&#10;clustering can benefit from two key advantages. Firstly, clients share only&#10;what they are confident about, resulting in the elimination of wrongful weight&#10;aggregation among clients whose data for a specific class may have not been&#10;enough during the training. This phenomenon is prevalent when the data are&#10;non&#45;Independent and Identically Distributed (non&#45;IID). Secondly, by sharing&#10;only weights towards a specific class, communication cost is substantially&#10;reduced, making TPLF efficient in terms of both accuracy and communication&#10;cost. The results of TPFL demonstrated the highest accuracy on three different&#10;datasets; namely MNIST, FashionMNIST and FEMNIST.&#10; | General | [Link](http://arxiv.org/abs/2409.10392v1) |&#10;| Prompt&#45;and&#45;Transfer: Dynamic Class&#45;aware Enhancement for Few&#45;shot&#10; &#160;Segmentation | Hanbo Bi, Yingchao Feng, Wenhui Diao, Peijin Wang, Yongqiang Mao, Kun Fu, Hongqi Wang, Xian Sun | &#160;&#160;For more efficient generalization to unseen domains (classes), most Few&#45;shot&#10;Segmentation (FSS) would directly exploit pre&#45;trained encoders and only&#10;fine&#45;tune the decoder, especially in the current era of large models. However,&#10;such fixed feature encoders tend to be class&#45;agnostic, inevitably activating&#10;objects that are irrelevant to the target class. In contrast, humans can&#10;effortlessly focus on specific objects in the line of sight. This paper mimics&#10;the visual perception pattern of human beings and proposes a novel and powerful&#10;prompt&#45;driven scheme, called ``Prompt and Transfer&quot; (PAT), which constructs a&#10;dynamic class&#45;aware prompting paradigm to tune the encoder for focusing on the&#10;interested object (target class) in the current task. Three key points are&#10;elaborated to enhance the prompting: 1) Cross&#45;modal linguistic information is&#10;introduced to initialize prompts for each task. 2) Semantic Prompt Transfer&#10;(SPT) that precisely transfers the class&#45;specific semantics within the images&#10;to prompts. 3) Part Mask Generator (PMG) that works in conjunction with SPT to&#10;adaptively generate different but complementary part prompts for different&#10;individuals. Surprisingly, PAT achieves competitive performance on 4 different&#10;tasks including standard FSS, Cross&#45;domain FSS (e.g., CV, medical, and remote&#10;sensing domains), Weak&#45;label FSS, and Zero&#45;shot Segmentation, setting new&#10;state&#45;of&#45;the&#45;arts on 11 benchmarks.&#10; | General | [Link](http://arxiv.org/abs/2409.10389v1) |&#10;| Revising the Structure of Recurrent Neural Networks to Eliminate&#10; &#160;Numerical Derivatives in Forming Physics Informed Loss Terms with Respect to&#10; &#160;Time | Mahyar Jahani&#45;nasab, Mohamad Ali Bijarchi | &#160;&#160;Solving unsteady partial differential equations (PDEs) using recurrent neural&#10;networks (RNNs) typically requires numerical derivatives between each block of&#10;the RNN to form the physics informed loss function. However, this introduces&#10;the complexities of numerical derivatives into the training process of these&#10;models. In this study, we propose modifying the structure of the traditional&#10;RNN to enable the prediction of each block over a time interval, making it&#10;possible to calculate the derivative of the output with respect to time using&#10;the backpropagation algorithm. To achieve this, the time intervals of these&#10;blocks are overlapped, defining a mutual loss function between them.&#10;Additionally, the employment of conditional hidden states enables us to achieve&#10;a unique solution for each block. The forget factor is utilized to control the&#10;influence of the conditional hidden state on the prediction of the subsequent&#10;block. This new model, termed the Mutual Interval RNN (MI&#45;RNN), is applied to&#10;solve three different benchmarks: the Burgers equation, unsteady heat&#10;conduction in an irregular domain, and the Green vortex problem. Our results&#10;demonstrate that MI&#45;RNN can find the exact solution more accurately compared to&#10;existing RNN models. For instance, in the second problem, MI&#45;RNN achieved one&#10;order of magnitude less relative error compared to the RNN model with numerical&#10;derivatives.&#10; | General | [Link](http://arxiv.org/abs/2409.10388v1) |&#10;| Sharp decay rate for eigenfunctions of perturbed periodic Schrdinger&#10; &#160;operators | Wencai Liu, Rodrigo Matos, John N. Treuer | &#160;&#160;This paper investigates uniqueness results for perturbed periodic&#10;Schr&quot;odinger operators on $mathbb{Z}^d$. Specifically, we consider operators&#10;of the form $H = &#45;Delta + V + v$, where $Delta$ is the discrete Laplacian,&#10;$V: mathbb{Z}^d &#13;ightarrow mathbb{R}$ is a periodic potential, and $v:&#10;mathbb{Z}^d &#13;ightarrow mathbb{C}$ represents a decaying impurity. We&#10;establish quantitative conditions under which the equation $&#45;Delta u + V u + v&#10;u = &#10;ambda u$, for $&#10;ambda in mathbb{C}$, admits only the trivial solution&#10;$u equiv 0$. Key applications include the absence of embedded eigenvalues for&#10;operators with impurities decaying faster than any exponential function and the&#10;determination of sharp decay rates for eigenfunctions. Our findings extend&#10;previous works by providing precise decay conditions for impurities and&#10;analyzing different spectral regimes of $&#10;ambda$.&#10; | General | [Link](http://arxiv.org/abs/2409.10387v1) |&#10;| Mamba&#45;ST: State Space Model for Efficient Style Transfer | Filippo Botti, Alex Ergasti, Leonardo Rossi, Tomaso Fontanini, Claudio Ferrari, Massimo Bertozzi, Andrea Prati | &#160;&#160;The goal of style transfer is, given a content image and a style source,&#10;generating a new image preserving the content but with the artistic&#10;representation of the style source. Most of the state&#45;of&#45;the&#45;art architectures&#10;use transformers or diffusion&#45;based models to perform this task, despite the&#10;heavy computational burden that they require. In particular, transformers use&#10;self&#45; and cross&#45;attention layers which have large memory footprint, while&#10;diffusion models require high inference time. To overcome the above, this paper&#10;explores a novel design of Mamba, an emergent State&#45;Space Model (SSM), called&#10;Mamba&#45;ST, to perform style transfer. To do so, we adapt Mamba linear equation&#10;to simulate the behavior of cross&#45;attention layers, which are able to combine&#10;two separate embeddings into a single output, but drastically reducing memory&#10;usage and time complexity. We modified the Mamba&#39;s inner equations so to accept&#10;inputs from, and combine, two separate data streams. To the best of our&#10;knowledge, this is the first attempt to adapt the equations of SSMs to a vision&#10;task like style transfer without requiring any other module like&#10;cross&#45;attention or custom normalization layers. An extensive set of experiments&#10;demonstrates the superiority and efficiency of our method in performing style&#10;transfer compared to transformers and diffusion models. Results show improved&#10;quality in terms of both ArtFID and FID metrics. Code is available at&#10;https://github.com/FilippoBotti/MambaST.&#10; | General | [Link](http://arxiv.org/abs/2409.10385v1) |&#10;| Performance&#45;Portable Numerical Relativity with AthenaK | Hengrui Zhu, Jacob Fields, Francesco Zappa, David Radice, James Stone, Alireza Rashti, William Cook, Sebastiano Bernuzzi, Boris Daszuta | &#160;&#160;We present the numerical relativity module within AthenaK, an open source&#10;performance&#45;portable astrophysics code designed for exascale computing&#10;applications. This module employs the Z4c formulation to solve the Einstein&#10;equations. We demonstrate its accuracy through a series of standard numerical&#10;relativity tests, including convergence of the gravitational waveform from&#10;binary black hole coalescence. Furthermore, we conduct scaling tests on OLCF&#10;Frontier and NERSC Perlmutter, where AthenaK exhibits excellent weak scaling&#10;efficiency of 80% on up to 65,536 AMD MI250X GPUs on Frontier (relative to 4&#10;GPUs) and strong scaling efficiencies of 84% and 77% on AMD MI250X and NVIDIA&#10;A100 GPUs on Frontier and Perlmutter respectively. Additionally, we observe a&#10;significant performance boost, with two orders of magnitude speedup ($gtrsim&#10;200times$) on a GPU compared to a single CPU core, affirming that AthenaK is&#10;well&#45;suited for exascale computing, thereby expanding the potential for&#10;breakthroughs in numerical relativity research.&#10; | General | [Link](http://arxiv.org/abs/2409.10383v1) |&#10;| J&#45;UBIK: The JAX&#45;accelerated Universal Bayesian Imaging Kit | Vincent Eberle, Matteo Guardiani, Margret Westerkamp, Philipp Frank, Julian Rstig, Julia Stadler, Torsten A. Enlin | &#160;&#160;Many advances in astronomy and astrophysics originate from accurate images of&#10;the sky emission across multiple wavelengths. This often requires&#10;reconstructing spatially and spectrally correlated signals detected from&#10;multiple instruments. To facilitate the high&#45;fidelity imaging of these signals,&#10;we introduce the universal Bayesian imaging kit (UBIK). Specifically, we&#10;present J&#45;UBIK, a flexible and modular implementation leveraging the&#10;JAX&#45;accelerated NIFTy.re software as its backend. J&#45;UBIK streamlines the&#10;implementation of the key Bayesian inference components, providing for all the&#10;necessary steps of Bayesian imaging pipelines. First, it provides adaptable&#10;prior models for different sky realizations. Second, it includes likelihood&#10;models tailored to specific instruments. So far, the package includes three&#10;instruments: Chandra and eROSITA for X&#45;ray observations, and the James Webb&#10;Space Telescope (JWST) for the near&#45; and mid&#45;infrared. The aim is to expand&#10;this set in the future. Third, these models can be integrated with various&#10;inference and optimization schemes, such as maximum a posteriori estimation and&#10;variational inference. Explicit demos show how to integrate the individual&#10;modules into a full analysis pipeline. Overall, J&#45;UBIK enables efficient&#10;generation of high&#45;fidelity images via Bayesian pipelines that can be tailored&#10;to specific research objectives.&#10; | General | [Link](http://arxiv.org/abs/2409.10381v1) |&#10;| Thermolectricity in irradiated bilayer graphene flakes | Cynthia Ihuoma Osuala, Tanu Choudhary, Raju K. Biswas, Sudin Ganguly, Chunlei Qu, Santanu K. Maiti | &#160;&#160;We present a comprehensive study on enhancing the thermoelectric (TE)&#10;performance of bilayer graphene (BLG) through irradiation with arbitrarily&#10;polarized light, focusing on $AA$&#45; and $AB$&#45;stacked configurations with zigzag&#10;edges. Utilizing a combination of tight&#45;binding theory and density functional&#10;theory (DFT), we systematically analyze the impact of light irradiation on&#10;electronic and phononic transport properties. Light irradiation alters the&#10;electronic hopping parameters, creating an asymmetric transmission function,&#10;which significantly increases the Seebeck coefficient, thereby boosting the&#10;overall {it figure of merit} (FOM). For the phononic contribution, DFT&#10;calculations reveal that $AB$&#45;stacked BLG exhibits lower lattice thermal&#10;conductivity compared to $AA$&#45;stacked, attributed to enhanced anharmonic&#10;scattering and phonon group velocity. The combined analysis shows that FOM&#10;exceeds unity in both stacking types, with notable improvements near the&#10;irradiation&#45;induced gap. Additionally, we explore the dependence of FOM on the&#10;system dimensions and temperature, demonstrating that light&#45;irradiated BLG&#10;holds great promise for efficient thermoelectric energy conversion and waste&#10;heat recovery. Our results show favorable responses over a wide range of&#10;irradiation parameters. These findings provide crucial insights into optimizing&#10;BLG for advanced TE applications through light&#45;induced modifications.&#10; | General | [Link](http://arxiv.org/abs/2409.10380v1) |&#10;| Leveraging Joint Spectral and Spatial Learning with MAMBA for&#10; &#160;Multichannel Speech Enhancement | Wenze Ren, Haibin Wu, Yi&#45;Cheng Lin, Xuanjun Chen, Rong Chao, Kuo&#45;Hsuan Hung, You&#45;Jin Li, Wen&#45;Yuan Ting, Hsin&#45;Min Wang, Yu Tsao | &#160;&#160;In multichannel speech enhancement, effectively capturing spatial and&#10;spectral information across different microphones is crucial for noise&#10;reduction. Traditional methods, such as CNN or LSTM, attempt to model the&#10;temporal dynamics of full&#45;band and sub&#45;band spectral and spatial features.&#10;However, these approaches face limitations in fully modeling complex temporal&#10;dependencies, especially in dynamic acoustic environments. To overcome these&#10;challenges, we modify the current advanced model McNet by introducing an&#10;improved version of Mamba, a state&#45;space model, and further propose MCMamba.&#10;MCMamba has been completely reengineered to integrate full&#45;band and narrow&#45;band&#10;spatial information with sub&#45;band and full&#45;band spectral features, providing a&#10;more comprehensive approach to modeling spatial and spectral information. Our&#10;experimental results demonstrate that MCMamba significantly improves the&#10;modeling of spatial and spectral features in multichannel speech enhancement,&#10;outperforming McNet and achieving state&#45;of&#45;the&#45;art performance on the CHiME&#45;3&#10;dataset. Additionally, we find that Mamba performs exceptionally well in&#10;modeling spectral information.&#10; | General | [Link](http://arxiv.org/abs/2409.10376v1) |&#10;| Nonlinear Causality in Brain Networks: With Application to Motor Imagery&#10; &#160;vs Execution | Sipan Aslan, Hernando Ombao | &#160;&#160;One fundamental challenge of data&#45;driven analysis in neuroscience is modeling&#10;causal interactions and exploring the connectivity of nodes in a brain network.&#10;Various statistical methods, relying on various perspectives and employing&#10;different data modalities, are being developed to examine and comprehend the&#10;underlying causal structures inherent to brain dynamics. This study introduces&#10;a novel statistical approach, TAR4C, to dissect causal interactions in&#10;multichannel EEG recordings. TAR4C uses the threshold autoregressive model to&#10;describe the causal interaction between nodes or clusters of nodes in a brain&#10;network. The perspective involves testing whether one node, which may represent&#10;a brain region, can control the dynamics of the other. The node that has such&#10;an impact on the other is called a threshold variable and can be classified as&#10;a causative because its functionality is the leading source operating as an&#10;instantaneous switching mechanism that regulates the time&#45;varying&#10;autoregressive structure of the other. This statistical concept is commonly&#10;referred to as threshold non&#45;linearity. Once threshold non&#45;linearity has been&#10;verified between a pair of nodes, the subsequent essential facet of TAR&#10;modeling is to assess the predictive ability of the causal node for the current&#10;activity on the other and represent causal interactions in autoregressive&#10;terms. This predictive ability is what underlies Granger causality. The TAR4C&#10;approach can discover non&#45;linear and time&#45;dependent causal interactions without&#10;negating the G&#45;causality perspective. The efficacy of the proposed approach is&#10;exemplified by analyzing the EEG signals recorded during the motor&#10;movement/imagery experiment. The similarities and differences between the&#10;causal interactions manifesting during the execution and the imagery of a given&#10;motor movement are demonstrated by analyzing EEG recordings from multiple&#10;subjects.&#10; | General | [Link](http://arxiv.org/abs/2409.10374v1) |&#10;| Instigating Cooperation among LLM Agents Using Adaptive Information&#10; &#160;Modulation | Qiliang Chen, &#160;Alireza, &#160;Ilami, Nunzio Lore, Babak Heydari | &#160;&#160;This paper introduces a novel framework combining LLM agents as proxies for&#10;human strategic behavior with reinforcement learning (RL) to engage these&#10;agents in evolving strategic interactions within team environments. Our&#10;approach extends traditional agent&#45;based simulations by using strategic LLM&#10;agents (SLA) and introducing dynamic and adaptive governance through a&#10;pro&#45;social promoting RL agent (PPA) that modulates information access across&#10;agents in a network, optimizing social welfare and promoting pro&#45;social&#10;behavior. Through validation in iterative games, including the prisoner&#10;dilemma, we demonstrate that SLA agents exhibit nuanced strategic adaptations.&#10;The PPA agent effectively learns to adjust information transparency, resulting&#10;in enhanced cooperation rates. This framework offers significant insights into&#10;AI&#45;mediated social dynamics, contributing to the deployment of AI in real&#45;world&#10;team settings.&#10; | General | [Link](http://arxiv.org/abs/2409.10372v1) |&#10;| Learning Gentle Grasping from Human&#45;Free Force Control Demonstration | Mingxuan Li, Lunwei Zhang, Tiemin Li, Yao Jiang | &#160;&#160;Humans can steadily and gently grasp unfamiliar objects based on tactile&#10;perception. Robots still face challenges in achieving similar performance due&#10;to the difficulty of learning accurate grasp&#45;force predictions and force&#10;control strategies that can be generalized from limited data. In this article,&#10;we propose an approach for learning grasping from ideal force control&#10;demonstrations, to achieve similar performance of human hands with limited data&#10;size. Our approach utilizes objects with known contact characteristics to&#10;automatically generate reference force curves without human demonstrations. In&#10;addition, we design the dual convolutional neural networks (Dual&#45;CNN)&#10;architecture which incorporating a physics&#45;based mechanics module for learning&#10;target grasping force predictions from demonstrations. The described method can&#10;be effectively applied in vision&#45;based tactile sensors and enables gentle and&#10;stable grasping of objects from the ground. The described prediction model and&#10;grasping strategy were validated in offline evaluations and online experiments,&#10;and the accuracy and generalizability were demonstrated.&#10; | General | [Link](http://arxiv.org/abs/2409.10371v1) |&#10;| Uncovering the Mechanism of Hepatotoxiciy of PFAS Targeting L&#45;FABP Using&#10; &#160;GCN and Computational Modeling | Lucas Jividen, Tibo Duran, Xi&#45;Zhi Niu, Jun Bai | &#160;&#160;Per&#45; and polyfluoroalkyl substances (PFAS) are persistent environmental&#10;pollutants with known toxicity and bioaccumulation issues. Their widespread&#10;industrial use and resistance to degradation have led to global environmental&#10;contamination and significant health concerns. While a minority of PFAS have&#10;been extensively studied, the toxicity of many PFAS remains poorly understood&#10;due to limited direct toxicological data. This study advances the predictive&#10;modeling of PFAS toxicity by combining semi&#45;supervised graph convolutional&#10;networks (GCNs) with molecular descriptors and fingerprints. We propose a novel&#10;approach to enhance the prediction of PFAS binding affinities by isolating&#10;molecular fingerprints to construct graphs where then descriptors are set as&#10;the node features. This approach specifically captures the structural,&#10;physicochemical, and topological features of PFAS without overfitting due to an&#10;abundance of features. Unsupervised clustering then identifies representative&#10;compounds for detailed binding studies. Our results provide a more accurate&#10;ability to estimate PFAS hepatotoxicity to provide guidance in chemical&#10;discovery of new PFAS and the development of new safety regulations.&#10; | General | [Link](http://arxiv.org/abs/2409.10370v1) |&#10;| Stochastic Control of UAVs: An Optimal Tradeoff between Performance,&#10; &#160;Flight Smoothness and Control Effort | George Rapakoulias, Panagiotis Tsiotras | &#160;&#160;Safe and accurate control of unmanned aerial vehicles in the presence of&#10;winds is a challenging control problem due to the hard&#45;to&#45;model and highly&#10;stochastic nature of the disturbance forces acting upon the vehicle. To meet&#10;performance constraints, state&#45;of&#45;the&#45;art control methods such as Incremental&#10;Nonlinear Dynamic Inversion (INDI) or other adaptive control techniques require&#10;high control gains to mitigate the effects of uncertainty entering the system.&#10;While achieving good tracking performance, IDNI requires excessive control&#10;effort, results in high actuator strain, and reduced flight smoothness due to&#10;constant and aggressive corrective actions commanded by the controller. In this&#10;paper, we propose a novel control architecture that allows the user to&#10;systematically address the trade&#45;off between high authority control and&#10;performance constraint satisfaction. Our approach consists of two parts. To&#10;cancel out biases introduced by unmodelled aerodynamic effects we propose a&#10;hybrid, model&#45;based disturbance force estimator augmented with a neural&#10;network, that can adapt to external wind conditions using a Kalman Filter. We&#10;then utilize state&#45;of&#45;the&#45;art results from Covariance Steering theory, which&#10;offers a principled way of controlling the uncertainty of the tracking error&#10;dynamics. We first analyze the properties of the combined system and then&#10;provide extensive experimental results to verify the advantages of the proposed&#10;approach over existing methods&#10; | General | [Link](http://arxiv.org/abs/2409.10369v1) |&#10;| Integrated nowcasting of convective precipitation with Transformer&#45;based&#10; &#160;models using multi&#45;source data | alar Kk, Aitor Atencia, Markus Dabernig | &#160;&#160;Precipitation nowcasting is crucial for mitigating the impacts of severe&#10;weather events and supporting daily activities. Conventional models&#10;predominantly relying on radar data have limited performance in predicting&#10;cases with complex temporal features such as convection initiation,&#10;highlighting the need to integrate data from other sources for more&#10;comprehensive nowcasting. Unlike physics&#45;based models, machine learning&#10;(ML)&#45;based models offer promising solutions for efficiently integrating large&#10;volumes of diverse data. We present EF4INCA, a spatiotemporal Transformer model&#10;for precipitation nowcasting that integrates satellite&#45; and ground&#45;based&#10;observations with numerical weather prediction outputs. EF4INCA provides&#10;high&#45;resolution forecasts over Austria, accurately predicting the location and&#10;shape of precipitation fields with a spatial resolution of 1 kilometre and a&#10;temporal resolution of 5 minutes, up to 90 minutes ahead. Our evaluation shows&#10;that EF4INCA outperforms conventional nowcasting models, including the&#10;operational model of Austria, particularly in scenarios with complex temporal&#10;features such as convective initiation and rapid weather changes. EF4INCA&#10;maintains higher accuracy in location forecasting but generates smoother fields&#10;at later prediction times compared to traditional models. Interpretation of our&#10;model showed that precipitation products and SEVIRI infrared channels CH7 and&#10;CH9 are the most important data streams. These results underscore the&#10;importance of combining data from different domains, including physics&#45;based&#10;model products, with ML approaches. Our study highlights the robustness of&#10;EF4INCA and its potential for improved precipitation nowcasting. We provide&#10;access to our code repository, model weights, and the dataset curated for&#10;benchmarking, facilitating further development and application.&#10; | General | [Link](http://arxiv.org/abs/2409.10367v1) |&#10;&#10;">
<text font-weight="bold" text-anchor="middle" x="2191" y="-567.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922634606416_11 -->
<g id="node75" class="node">
<title>139922634606416_11</title>
<ellipse fill="#e8c4c6" stroke="#b59193" stroke-width="3" cx="2237" cy="-528" rx="102.88" ry="18"/>
<text text-anchor="middle" x="2237" y="-524.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">checking_agent (11)</text>
</g>
<!-- 139922752308304_6&#45;&gt;139922634606416_11 -->
<g id="edge82" class="edge">
<title>139922752308304_6&#45;&gt;139922634606416_11</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M2272.35,-587.91C2266.05,-577.42 2258.81,-565.36 2252.53,-554.89"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2269.53,-590.02 2277.68,-596.8 2275.54,-586.42 2269.53,-590.02"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2255.45,-552.95 2247.31,-546.18 2249.45,-556.55 2255.45,-552.95"/>
<text text-anchor="middle" x="2335" y="-567.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">Auto Select Speaker</text>
</g>
<!-- 1726553900.253555 -->
<g id="node80" class="node">
<title>1726553900.253555</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="1787.48,-385.54 1787.48,-400.46 1747.36,-411 1690.64,-411 1650.52,-400.46 1650.52,-385.54 1690.64,-375 1747.36,-375 1787.48,-385.54"/>
<text text-anchor="middle" x="1719" y="-389.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Termination</text>
</g>
<!-- 139922677986320_5&#45;&gt;1726553900.253555 -->
<g id="edge89" class="edge">
<title>139922677986320_5&#45;&gt;1726553900.253555</title>
<path fill="none" stroke="#6666ff" d="M1918.1,-510.15C1908.69,-492.24 1891.17,-464.77 1867,-452 1843.96,-439.82 1772.33,-457.44 1750,-444 1741.04,-438.6 1734.29,-429.52 1729.41,-420.57"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1732.5,-418.92 1724.99,-411.44 1726.2,-421.97 1732.5,-418.92"/>
<text text-anchor="middle" x="1878.5" y="-432.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">check_termination_and_human_reply</text>
</g>
<!-- eb5e54f4&#45;30a9&#45;40a2&#45;a2fa&#45;71fe7875432a -->
<g id="node74" class="node">
<title>eb5e54f4&#45;30a9&#45;40a2&#45;a2fa&#45;71fe7875432a</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="2046.24,-300.44 2101,-288 2155.76,-300.44 2155.71,-320.56 2046.29,-320.56 2046.24,-300.44"/>
<text text-anchor="middle" x="2101" y="-302.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">OpenAI</text>
</g>
<!-- 139922634606800_6 -->
<g id="node76" class="node">
<title>139922634606800_6</title>
<ellipse fill="#ebcfb9" stroke="#b89c86" stroke-width="3" cx="2230" cy="-393" rx="136.48" ry="18"/>
<text text-anchor="middle" x="2230" y="-389.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">speaker_selection_agent (6)</text>
</g>
<!-- eb5e54f4&#45;30a9&#45;40a2&#45;a2fa&#45;71fe7875432a&#45;&gt;139922634606800_6 -->
<g id="edge85" class="edge">
<title>eb5e54f4&#45;30a9&#45;40a2&#45;a2fa&#45;71fe7875432a&#45;&gt;139922634606800_6</title>
<path fill="none" stroke="#6666ff" d="M2150.16,-320.58C2183.1,-329.79 2220.71,-340.54 2222,-342 2227.49,-348.21 2230.02,-356.62 2231.03,-364.77"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2227.53,-364.99 2231.6,-374.77 2234.52,-364.59 2227.53,-364.99"/>
</g>
<!-- 139922634606416_11&#45;&gt;139922634606800_6 -->
<g id="edge83" class="edge">
<title>139922634606416_11&#45;&gt;139922634606800_6</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M2236.1,-509.88C2234.92,-487.44 2232.83,-447.8 2231.43,-421.21"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2234.92,-420.85 2230.9,-411.05 2227.93,-421.22 2234.92,-420.85"/>
<g id="a_edge83&#45;label"><a xlink:title="Read the above conversation. Then select the next role from [&#39;Admin&#39;, &#39;Engineer&#39;, &#39;Scientist&#39;, &#39;Planner&#39;, &#39;Executor&#39;, &#39;Critic&#39;] to play. Only return the role." style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="2296" y="-432.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 139922634606800_6&#45;&gt;eb5e54f4&#45;30a9&#45;40a2&#45;a2fa&#45;71fe7875432a -->
<g id="edge84" class="edge">
<title>139922634606800_6&#45;&gt;eb5e54f4&#45;30a9&#45;40a2&#45;a2fa&#45;71fe7875432a</title>
<path fill="none" stroke="#6666ff" d="M2143.21,-379.03C2119.5,-373.62 2098.3,-366.37 2091,-357 2085.09,-349.41 2086,-339.25 2089,-330.08"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2092.3,-331.25 2092.86,-320.67 2085.83,-328.59 2092.3,-331.25"/>
<g id="a_edge84&#45;label"><a xlink:title="Admin" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="2156.5" y="-345.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">generate_oai_reply</text>
</a>
</g>
</g>
<!-- 139922634606416_12 -->
<g id="node77" class="node">
<title>139922634606416_12</title>
<ellipse fill="#e8c4c6" stroke="#b59193" stroke-width="3" cx="2276" cy="-306" rx="102.88" ry="18"/>
<text text-anchor="middle" x="2276" y="-302.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">checking_agent (12)</text>
</g>
<!-- 139922634606800_6&#45;&gt;139922634606416_12 -->
<g id="edge86" class="edge">
<title>139922634606800_6&#45;&gt;139922634606416_12</title>
<path fill="none" stroke="#6666ff" stroke-dasharray="5,2" d="M2239.31,-374.8C2245.79,-362.82 2254.56,-346.62 2261.9,-333.06"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2265.02,-334.64 2266.71,-324.18 2258.87,-331.3 2265.02,-334.64"/>
<g id="a_edge86&#45;label"><a xlink:title="Admin" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="2319" y="-345.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">received_message</text>
</a>
</g>
</g>
<!-- 1726553896.849839 -->
<g id="node78" class="node">
<title>1726553896.849839</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="2305.56,-189 2161.5,-189 2124.44,-153 2268.5,-153 2305.56,-189"/>
<text text-anchor="middle" x="2215" y="-167.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Summarize</text>
</g>
<!-- 139922634606416_12&#45;&gt;1726553896.849839 -->
<g id="edge87" class="edge">
<title>139922634606416_12&#45;&gt;1726553896.849839</title>
<path fill="none" stroke="#6666ff" d="M2268.15,-287.88C2257.72,-265.14 2239.19,-224.74 2227,-198.16"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2230.17,-196.68 2222.82,-189.05 2223.81,-199.6 2230.17,-196.68"/>
<g id="a_edge87&#45;label"><a xlink:title="Admin" style="cursor: pointer;">
<text font-weight="bold" text-anchor="middle" x="2318" y="-210.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">_last_msg_as_summary</text>
</a>
</g>
</g>
<!-- a18f93b7&#45;bcae&#45;4b64&#45;872b&#45;2d511726fc00 -->
<g id="node79" class="node">
<title>a18f93b7&#45;bcae&#45;4b64&#45;872b&#45;2d511726fc00</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="2239.5,-102 2184.5,-102 2184.5,-66 2245.5,-66 2245.5,-96 2239.5,-102"/>
<polyline fill="none" stroke="#00be92" stroke-width="3" points="2239.5,-102 2239.5,-96 "/>
<polyline fill="none" stroke="#00be92" stroke-width="3" points="2245.5,-96 2239.5,-96 "/>
<text text-anchor="middle" x="2215" y="-80.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Admin</text>
</g>
<!-- 1726553896.849839&#45;&gt;a18f93b7&#45;bcae&#45;4b64&#45;872b&#45;2d511726fc00 -->
<g id="edge88" class="edge">
<title>1726553896.849839&#45;&gt;a18f93b7&#45;bcae&#45;4b64&#45;872b&#45;2d511726fc00</title>
<path fill="none" stroke="#6666ff" d="M2215,-152.8C2215,-141.16 2215,-125.55 2215,-112.24"/>
<polygon fill="#6666ff" stroke="#6666ff" points="2218.5,-112.18 2215,-102.18 2211.5,-112.18 2218.5,-112.18"/>
<text text-anchor="middle" x="2260.5" y="-123.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">next speaker</text>
</g>
<!-- 1726553900.255873 -->
<g id="node81" class="node">
<title>1726553900.255873</title>
<polygon fill="#ddfff7" stroke="#00be92" stroke-width="3" points="1809.56,-324 1665.5,-324 1628.44,-288 1772.5,-288 1809.56,-324"/>
<text text-anchor="middle" x="1719" y="-302.3" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#222222">Summarize</text>
</g>
<!-- 1726553900.253555&#45;&gt;1726553900.255873 -->
<g id="edge90" class="edge">
<title>1726553900.253555&#45;&gt;1726553900.255873</title>
<path fill="none" stroke="#6666ff" d="M1719,-374.8C1719,-363.16 1719,-347.55 1719,-334.24"/>
<polygon fill="#6666ff" stroke="#6666ff" points="1722.5,-334.18 1719,-324.18 1715.5,-334.18 1722.5,-334.18"/>
<g id="a_edge90&#45;label"><a xlink:title="exitcode: 0 (execution succeeded)&#10;Code output: &#10;| Title | Authors | Abstract | Domain | Source URL |&#10;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;|&#10;| The VIRUS&#45;dE Survey I: Stars in dwarf elliptical galaxies &#45; 3D dynamics&#10; &#160;and radially resolved stellar initial mass functions | Mathias Lipka, Jens Thomas, Roberto Saglia, Ralf Bender, Maximilian Fabricius, Gary J. Hill, Matthias Kluge, Martin Landriau, Ximena Mazzalay, Eva Noyola, Taniya Parikh, Jan Snigula | &#160;&#160;We analyse the stellar structure of a sample of dwarf ellipticals (dE)&#10;inhabiting various environments within the Virgo cluster. Integral&#45;field&#10;observations with a high spectral resolution allow us to robustly determine&#10;their low velocity dispersions ($sim25$ km s$^{&#45;1}$) and higher&#45;order&#10;kinematic moments out to the half&#45;light radius. We find the dEs exhibit a&#10;diversity in ages with the younger dEs being less enhanced than the older,&#10;suggesting a complex star formation history for those dEs that recently entered&#10;Virgo while others have been quenched shortly after reionization.&#10;Orbit&#45;superposition modeling allowed us to recover viewing angles, stellar&#10;mass&#45;to&#45;light ratios (with gradients), as well as the intrinsic orbit&#10;structure. We find that the angular momentum of the dEs is strongly suppressed&#10;compared to ordinary early&#45;type galaxies and correlates with the environment.&#10;Flattened dEs are so because of a suppressed kinetic energy perpendicular to&#10;their equatorial plane. Combining population and dynamical modeling results, we&#10;find an age&#45;dependent stellar initial mass function (IMF) or, alternatively,&#10;evidence for a more extended star formation history for those galaxies that&#10;have had higher initial mass and/or inhabited lower density environments. dEs&#10;appear to have a spatially homogeneous stellar structure but the state they&#10;were `frozen&#39; in as they stopped forming stars varies dramatically according to&#10;their initial conditions.&#10; | General | [Link](http://arxiv.org/abs/2409.10518v1) |&#10;| RetrievalAttention: Accelerating Long&#45;Context LLM Inference via Vector&#10; &#160;Retrieval | Di Liu, Meng Chen, Baotong Lu, Huiqiang Jiang, Zhenhua Han, Qianxi Zhang, Qi Chen, Chengruidong Zhang, Bailu Ding, Kai Zhang, Chen Chen, Fan Yang, Yuqing Yang, Lili Qiu | &#160;&#160;Transformer&#45;based large Language Models (LLMs) become increasingly important&#10;in various domains. However, the quadratic time complexity of attention&#10;operation poses a significant challenge for scaling to longer contexts due to&#10;the extremely high inference latency and GPU memory consumption for caching&#10;key&#45;value (KV) vectors. This paper proposes RetrievalAttention, a training&#45;free&#10;approach to accelerate attention computation. To leverage the dynamic sparse&#10;property of attention, RetrievalAttention builds approximate nearest neighbor&#10;search (ANNS) indexes upon KV vectors in CPU memory and retrieves the most&#10;relevant ones via vector search during generation. Due to the&#10;out&#45;of&#45;distribution (OOD) between query vectors and key vectors, off&#45;the&#45;shelf&#10;ANNS indexes still need to scan O(N) (usually 30% of all keys) data for&#10;accurate retrieval, which fails to exploit the high sparsity.&#10;RetrievalAttention first identifies the OOD challenge of ANNS&#45;based attention,&#10;and addresses it via an attention&#45;aware vector search algorithm that can adapt&#10;to queries and only access 1&#45;&#45;3% of data, thus achieving a sub&#45;linear time&#10;complexity. RetrievalAttention greatly reduces the inference cost of&#10;long&#45;context LLM with much lower GPU memory requirements while maintaining the&#10;model accuracy. Especially, RetrievalAttention only needs 16GB GPU memory for&#10;serving 128K tokens in LLMs with 8B parameters, which is capable of generating&#10;one token in 0.188 seconds on a single NVIDIA RTX4090 (24GB).&#10; | General | [Link](http://arxiv.org/abs/2409.10516v1) |&#10;| An Efficient Self&#45;Learning Framework For Interactive Spoken Dialog&#10; &#160;Systems | Hitesh Tulsiani, David M. Chan, Shalini Ghosh, Garima Lalwani, Prabhat Pandey, Ankish Bansal, Sri Garimella, Ariya Rastrow, Bjrn Hoffmeister | &#160;&#160;Dialog systems, such as voice assistants, are expected to engage with users&#10;in complex, evolving conversations. Unfortunately, traditional automatic speech&#10;recognition (ASR) systems deployed in such applications are usually trained to&#10;recognize each turn independently and lack the ability to adapt to the&#10;conversational context or incorporate user feedback. In this work, we introduce&#10;a general framework for ASR in dialog systems that can go beyond learning from&#10;single&#45;turn utterances and learn over time how to adapt to both explicit&#10;supervision and implicit user feedback present in multi&#45;turn conversations. We&#10;accomplish that by leveraging advances in student&#45;teacher learning and&#10;context&#45;aware dialog processing, and designing contrastive self&#45;supervision&#10;approaches with Ohm, a new online hard&#45;negative mining approach. We show that&#10;leveraging our new framework compared to traditional training leads to relative&#10;WER reductions of close to 10% in real&#45;world dialog systems, and up to 26% on&#10;public synthetic data.&#10; | General | [Link](http://arxiv.org/abs/2409.10515v1) |&#10;| Constraints on axions from patchy screening of the cosmic microwave&#10; &#160;background | Samuel Goldstein, Fiona McCarthy, Cristina Mondino, J. Colin Hill, Junwu Huang, Matthew C. Johnson | &#160;&#160;The resonant conversion of cosmic microwave background (CMB) photons into&#10;axions within large&#45;scale structure induces an anisotropic spectral distortion&#10;in CMB temperature maps. Applying state&#45;of&#45;the&#45;art foreground cleaning&#10;techniques to $textit{Planck}$ CMB observations, we construct maps of&#10;axion&#45;induced &quot;patchy screening&quot; of the CMB. We cross&#45;correlate these maps with&#10;data from the $textit{unWISE}$ galaxy survey and find no evidence of axions.&#10;We constrain the axion&#45;photon coupling, $g_{agammagamma} &#10;esssim 2 times&#10;10^{&#45;12}~{&#13;m GeV}^{&#45;1}$, at the 95% confidence level for axion masses in the&#10;range $10^{&#45;13}~{&#13;m eV} &#10;esssim m_a &#10;esssim 10^{&#45;12}~{&#13;m eV}$. These&#10;constraints are competitive with the tightest astrophysical axion limits in&#10;this mass range and are inferred from robust population&#45;level statistics, which&#10;makes them complementary to existing searches that rely on modeling of&#10;individual systems.&#10; | General | [Link](http://arxiv.org/abs/2409.10514v1) |&#10;| Weak Superimposed Codes of Improved Asymptotic Rate and Their Randomized&#10; &#160;Construction | Yu Tsunoda, Yuichiro Fujiwara | &#160;&#160;Weak superimposed codes are combinatorial structures related closely to&#10;generalized cover&#45;free families, superimposed codes, and disjunct matrices in&#10;that they are only required to satisfy similar but less stringent conditions.&#10;This class of codes may also be seen as a stricter variant of what are known as&#10;locally thin families in combinatorics. Originally, weak superimposed codes&#10;were introduced in the context of multimedia content protection against illegal&#10;distribution of copies under the assumption that a coalition of malicious users&#10;may employ the averaging attack with adversarial noise. As in many other kinds&#10;of codes in information theory, it is of interest and importance in the study&#10;of weak superimposed codes to find the highest achievable rate in the&#10;asymptotic regime and give an efficient construction that produces an infinite&#10;sequence of codes that achieve it. Here, we prove a tighter lower bound than&#10;the sharpest known one on the rate of optimal weak superimposed codes and give&#10;a polynomial&#45;time randomized construction algorithm for codes that&#10;asymptotically attain our improved bound with high probability. Our&#10;probabilistic approach is versatile and applicable to many other related codes&#10;and arrays.&#10; | General | [Link](http://arxiv.org/abs/2409.10511v1) |&#10;| Pennsieve &#45; A Collaborative Platform for Translational Neuroscience and&#10; &#160;Beyond | Zack Goldblum, Zhongchuan Xu, Haoer Shi, Patryk Orzechowski, Jamaal Spence, Kathryn A Davis, Brian Litt, Nishant Sinha, Joost Wagenaar | &#160;&#160;The exponential growth of neuroscientific data necessitates platforms that&#10;facilitate data management and multidisciplinary collaboration. In this paper,&#10;we introduce Pennsieve &#45; an open&#45;source, cloud&#45;based scientific data management&#10;platform built to meet these needs. Pennsieve supports complex multimodal&#10;datasets and provides tools for data visualization and analyses. It takes a&#10;comprehensive approach to data integration, enabling researchers to define&#10;custom metadata schemas and utilize advanced tools to filter and query their&#10;data. Pennsieve&#39;s modular architecture allows external applications to extend&#10;its capabilities, and collaborative workspaces with peer&#45;reviewed data&#10;publishing mechanisms promote high&#45;quality datasets optimized for downstream&#10;analysis, both in the cloud and on&#45;premises.&#10; &#160;Pennsieve forms the core for major neuroscience research programs including&#10;the NIH SPARC Initiative, NIH HEAL Initiative&#39;s PRECISION Human Pain Network,&#10;and NIH HEAL RE&#45;JOIN Initiative. It serves more than 80 research groups&#10;worldwide, along with several large&#45;scale, inter&#45;institutional projects at&#10;clinical sites through the University of Pennsylvania. Underpinning the&#10;SPARC.Science, Epilepsy.Science, and Pennsieve Discover portals, Pennsieve&#10;stores over 125 TB of scientific data, with 35 TB of data publicly available&#10;across more than 350 high&#45;impact datasets. It adheres to the findable,&#10;accessible, interoperable, and reusable (FAIR) principles of data sharing and&#10;is recognized as one of the NIH&#45;approved Data Repositories. By facilitating&#10;scientific data management, discovery, and analysis, Pennsieve fosters a robust&#10;and collaborative research ecosystem for neuroscience and beyond.&#10; | General | [Link](http://arxiv.org/abs/2409.10509v1) |&#10;| General&#45;relativistic resistive&#45;magnetohydrodynamics simulations of&#10; &#160;self&#45;consistent magnetized rotating neutron stars | Patrick Chi&#45;Kit Cheong, Antonios Tsokaros, Milton Ruiz, Fabrizio Venturi, Juno Chun Lung Chan, Anson Ka Long Yip, Koji Uryu | &#160;&#160;We present the first general&#45;relativistic resistive magnetohydrodynamics&#10;simulations of self&#45;consistent, rotating neutron stars with mixed poloidal and&#10;toroidal magnetic fields. Specifically, we investigate the role of resistivity&#10;in the dynamical evolution of neutron stars over a period of up to 100 ms and&#10;its effects on their quasi&#45;equilibrium configurations. Our results demonstrate&#10;that resistivity can significantly influence the development of&#10;magnetohydrodynamic instabilities, resulting in markedly different magnetic&#10;field geometries. Additionally, resistivity suppresses the growth of these&#10;instabilities, leading to a reduction in the amplitude of emitted gravitational&#10;waves. Despite the variations in magnetic field geometries, the ratio of&#10;poloidal to toroidal field energies remains consistently 9:1 throughout the&#10;simulations, for the models we investigated.&#10; | General | [Link](http://arxiv.org/abs/2409.10508v1) |&#10;| Beth&#45;Uhlenbeck equation for the thermodynamics of fluctuations in a&#10; &#160;generalised 2+1D Gross&#45;Neveu model | Biplab Mahato, David Blaschke, Dietmar Ebert | &#160;&#160;We study a generalised version of Gross&#45;Neveu model in 2+1 dimensions. The&#10;model is inspired from graphene which shows a linear dispersion relation near&#10;the Dirac points. The phase structure and the thermodynamic properties in the&#10;mean field approximation have been studied before. Here we go beyond the mean&#10;field level by deriving a Beth&#45;Uhlenbeck equation for Gaussian fluctuations,&#10;solutions of which we explore numerically, for the first time including their&#10;momentum dependence. We discuss the excitonic mass, fluctuation pressure and&#10;phase shifts. We also perform a comparison with the NJL model in 3+1 dimension&#10;and discuss its implication for graphene.&#10; | General | [Link](http://arxiv.org/abs/2409.10507v1) |&#10;| Context&#45;aware Code Segmentation for C&#45;to&#45;Rust Translation using Large&#10; &#160;Language Models | Momoko Shiraishi, Takahiro Shinagawa | &#160;&#160;There is strong motivation to translate C code into Rust code due to the&#10;continuing threat of memory safety vulnerabilities in existing C programs and&#10;the significant attention paid to Rust as an alternative to the C language.&#10;While large language models (LLMs) show promise for automating this translation&#10;by generating more natural and safer code than rule&#45;based methods, previous&#10;studies have shown that LLM&#45;generated Rust code often fails to compile, even&#10;for relatively small C programs, due to significant differences between the two&#10;languages and context window limitations. We propose an LLM&#45;based translation&#10;scheme that improves the success rate of translating large&#45;scale C code into&#10;compilable Rust code. Our approach involves three key techniques: (1)&#10;pre&#45;processing the C code to better align its structure and expressions with&#10;Rust, (2) segmenting the code into optimally sized translation units to avoid&#10;exceeding the LLM&#39;s context window limits, and (3) iteratively compiling and&#10;repairing errors while maintaining consistency between translation units using&#10;context&#45;supplementing prompts. Compilation success is an essential first step&#10;in achieving functional equivalence, as only compilable code can be further&#10;tested. In experiments with 20 benchmark C programs, including those exceeding&#10;4 kilo lines of code, we successfully translated all programs into compilable&#10;Rust code without losing corresponding parts of the original code.&#10; | General | [Link](http://arxiv.org/abs/2409.10506v1) |&#10;| Machine Learning Optimization of non&#45;Kasha Behavior and of Transient&#10; &#160;Dynamics in Model Retinal Isomerization | Davinder Singh, Chern Chuang, Paul Brumer | &#160;&#160;Designing a model of retinal isomerization in Rhodopsin, the first step in&#10;vision, that accounts for both experimental transient and stationary state&#10;observables is challenging. Here, multi&#45;objective Bayesian optimization is&#10;employed to refine the parameters of a minimal two&#45;state&#45;two&#45;mode (TM) model&#10;describing the photoisomerization of retinal in Rhodopsin. With an appropriate&#10;selection of objectives, the optimized retinal model predicts excitation&#10;wavelength&#45;dependent fluorescence spectra that closely align with&#10;experimentally observed non&#45;Kasha behavior in the non&#45;equilibrium steady state.&#10;Further, adjustments to the potential energy surface within the TM model reduce&#10;the discrepancies across the time domain. Overall, agreement with experimental&#10;data is excellent.&#10; | General | [Link](http://arxiv.org/abs/2409.10505v1) |&#10;| DILA: Dictionary Label Attention for Mechanistic Interpretability in&#10; &#160;High&#45;dimensional Multi&#45;label Medical Coding Prediction | John Wu, David Wu, Jimeng Sun | &#160;&#160;Predicting high&#45;dimensional or extreme multilabels, such as in medical&#10;coding, requires both accuracy and interpretability. Existing works often rely&#10;on local interpretability methods, failing to provide comprehensive&#10;explanations of the overall mechanism behind each label prediction within a&#10;multilabel set. We propose a mechanistic interpretability module called&#10;DIctionary Label Attention (method) that disentangles uninterpretable dense&#10;embeddings into a sparse embedding space, where each nonzero element (a&#10;dictionary feature) represents a globally learned medical concept. Through&#10;human evaluations, we show that our sparse embeddings are more human&#10;understandable than its dense counterparts by at least 50 percent. Our&#10;automated dictionary feature identification pipeline, leveraging large language&#10;models (LLMs), uncovers thousands of learned medical concepts by examining and&#10;summarizing the highest activating tokens for each dictionary feature. We&#10;represent the relationships between dictionary features and medical codes&#10;through a sparse interpretable matrix, enhancing the mechanistic and global&#10;understanding of the model&#39;s predictions while maintaining competitive&#10;performance and scalability without extensive human annotation.&#10; | General | [Link](http://arxiv.org/abs/2409.10504v1) |&#10;| Causal Language Modeling Can Elicit Search and Reasoning Capabilities on&#10; &#160;Logic Puzzles | Kulin Shah, Nishanth Dikkala, Xin Wang, Rina Panigrahy | &#160;&#160;Causal language modeling using the Transformer architecture has yielded&#10;remarkable capabilities in Large Language Models (LLMs) over the last few&#10;years. However, the extent to which fundamental search and reasoning&#10;capabilities emerged within LLMs remains a topic of ongoing debate. In this&#10;work, we study if causal language modeling can learn a complex task such as&#10;solving Sudoku puzzles. To solve a Sudoku, the model is first required to&#10;search over all empty cells of the puzzle to decide on a cell to fill and then&#10;apply an appropriate strategy to fill the decided cell. Sometimes, the&#10;application of a strategy only results in thinning down the possible values in&#10;a cell rather than concluding the exact value of the cell. In such cases,&#10;multiple strategies are applied one after the other to fill a single cell. We&#10;observe that Transformer models trained on this synthetic task can indeed learn&#10;to solve Sudokus (our model solves $94.21%$ of the puzzles fully correctly)&#10;when trained on a logical sequence of steps taken by a solver. We find that&#10;training Transformers with the logical sequence of steps is necessary and&#10;without such training, they fail to learn Sudoku. We also extend our analysis&#10;to Zebra puzzles (known as Einstein puzzles) and show that the model solves&#10;$92.04 %$ of the puzzles fully correctly. In addition, we study the internal&#10;representations of the trained Transformer and find that through linear&#10;probing, we can decode information about the set of possible values in any&#10;given cell from them, pointing to the presence of a strong reasoning engine&#10;implicit in the Transformer weights.&#10; | General | [Link](http://arxiv.org/abs/2409.10502v1) |&#10;| Alignment with nonlinear velocity couplings: collision&#45;avoidance and&#10; &#160;micro&#45;to&#45;macro mean&#45;field limits | Young&#45;Pil Choi, Micha Fabisiak, Jan Peszek | &#160;&#160;We investigate the pressureless fractional Euler&#45;alignment system with&#10;nonlinear velocity couplings, referred to as the $p$&#45;Euler&#45;alignment system.&#10;This model features a nonlinear velocity alignment force, interpreted as a&#10;density&#45;weighted fractional $p$&#45;Laplacian when the singularity parameter&#10;$alpha$ exceeds the spatial dimension $d$. Our primary goal is to establish&#10;the existence of solutions for strongly singular interactions ($alpha ge d$)&#10;and compactly supported initial conditions. We construct solutions as&#10;mean&#45;field limits of empirical measures from a kinetic variant of the&#10;$p$&#45;Euler&#45;alignment system. Specifically, we show that a sequence of empirical&#10;measures converges to a finite Radon measure, whose local density and velocity&#10;satisfy the $p$&#45;Euler&#45;alignment system. Our results are the first to prove the&#10;existence of solutions to this system in multi&#45;dimensional settings without&#10;significant initial data restrictions, covering both nonlinear ($p&gt;2$) and&#10;linear ($p=2$) cases. Additionally, we establish global existence, uniqueness,&#10;and collision avoidance for the corresponding particle ODE system under&#10;non&#45;collisional initial conditions, extending previous results for $1 &#10;e p &#10;e&#10;alpha + 2$. This analysis supports our mean&#45;field limit argument and&#10;contributes to understanding alignment models with singular communication.&#10; | General | [Link](http://arxiv.org/abs/2409.10501v1) |&#10;| Focus diverse phase retrieval test results on broadband continuous&#10; &#160;wavefront sensing in space telescope applications | Hyukmo Kang, Kyle Van Gorkom, Meghdoot Biswas, Daewook Kim, Ewan S. Douglas | &#160;&#160;Continuous wavefront sensing benefits space observatories in on&#45;orbit optical&#10;performance maintenance. To measure the phase of a wavefront, phase retrieval&#10;is an attractive technique as it uses multiple point spread function (PSF)&#10;images that are acquired by the telescope itself without extra metrology&#10;systems nor complicated calibration. The focus diverse phase retrieval utilizes&#10;PSFs from predetermined defocused positions to enhance the dynamic range of the&#10;algorithm. We describe an updated visible light active optics testbed with the&#10;addition of a linear motorized focus stage. The performance of the phase&#10;retrieval algorithm in broadband is tested under various cases. While broadband&#10;pass filters have advantages in higher signal&#45;to&#45;noise ratio (SNR), the&#10;performance of phase retrieval can be restricted due to blurred image caused by&#10;diffraction and increased computing cost. We used multiple bandpass filters (10&#10;nm, 88 nm, and 150 nm) and investigated effects of bandwidth on the accuracy&#10;and required image acquisition conditions such as SNR, reaching accuracies&#10;below 20 nm RMS wavefront error at the widest bandwidth. We also investigated&#10;the dynamic range of the phase retrieval algorithm depending on the bandwidth&#10;and required amount of defocus to expand dynamic range. Finally, we simulated&#10;the continuous wavefront sensing and correction loop with a range of&#10;statistically generated representative telescope disturbance time series to&#10;test for edge cases.&#10; | General | [Link](http://arxiv.org/abs/2409.10500v1) |&#10;| The role of higher&#45;order terms in trapped&#45;ion quantum computing with&#10; &#160;magnetic gradient induced coupling | Sebastian Nagies, Kevin T. Geier, Javed Akram, Junichi Okamoto, Dimitris Badounas, Christof Wunderlich, Michael Johanning, Philipp Hauke | &#160;&#160;Trapped&#45;ion hardware based on the Magnetic Gradient Induced Coupling (MAGIC)&#10;scheme is emerging as a promising platform for quantum computing. Nevertheless,&#10;in this (as in any other) quantum&#45;computing platform, many technical questions&#10;still have to be resolved before large&#45;scale and error&#45;tolerant applications&#10;are possible. In this work, we present a thorough discussion of the&#10;contribution of higher&#45;order terms to the MAGIC setup, which can occur due to&#10;anharmonicities in the external potential of the ion crystal (e.g., through&#10;Coulomb repulsion) or through curvature of the applied magnetic field. These&#10;terms take the form of three&#45;spin couplings as well as diverse terms that&#10;couple spins to phonons. We find that most of these are negligible in realistic&#10;situations, with only two contributions that need careful attention. First,&#10;there are parasitic longitudinal fields whose strength increases with chain&#10;length, but which can easily be compensated by a microwave detuning. Second,&#10;anharmonicities of the Coulomb interaction can lead to well&#45;known two&#45;to&#45;one&#10;conversions of phonon excitations, which can be avoided if the phonons are&#10;ground&#45;state cooled. Our detailed analysis constitutes an important&#10;contribution on the way of making magnetic&#45;gradient trapped&#45;ion quantum&#10;technology fit for large&#45;scale applications, and it may inspire new ways to&#10;purposefully design interaction terms.&#10; | General | [Link](http://arxiv.org/abs/2409.10498v1) |&#10;| MusicLIME: Explainable Multimodal Music Understanding | Theodoros Sotirou, Vassilis Lyberatos, Orfeas Menis Mastromichalakis, Giorgos Stamou | &#160;&#160;Multimodal models are critical for music understanding tasks, as they capture&#10;the complex interplay between audio and lyrics. However, as these models become&#10;more prevalent, the need for explainability grows&#45;understanding how these&#10;systems make decisions is vital for ensuring fairness, reducing bias, and&#10;fostering trust. In this paper, we introduce MusicLIME, a model&#45;agnostic&#10;feature importance explanation method designed for multimodal music models.&#10;Unlike traditional unimodal methods, which analyze each modality separately&#10;without considering the interaction between them, often leading to incomplete&#10;or misleading explanations, MusicLIME reveals how audio and lyrical features&#10;interact and contribute to predictions, providing a holistic view of the&#10;model&#39;s decision&#45;making. Additionally, we enhance local explanations by&#10;aggregating them into global explanations, giving users a broader perspective&#10;of model behavior. Through this work, we contribute to improving the&#10;interpretability of multimodal music models, empowering users to make informed&#10;choices, and fostering more equitable, fair, and transparent music&#10;understanding systems.&#10; | General | [Link](http://arxiv.org/abs/2409.10496v1) |&#10;| Incorporating Classifier&#45;Free Guidance in Diffusion Model&#45;Based&#10; &#160;Recommendation | Noah Buchanan, Susan Gauch, Quan Mai | &#160;&#160;This paper presents a diffusion&#45;based recommender system that incorporates&#10;classifier&#45;free guidance. Most current recommender systems provide&#10;recommendations using conventional methods such as collaborative or&#10;content&#45;based filtering. Diffusion is a new approach to generative AI that&#10;improves on previous generative AI approaches such as Variational Autoencoders&#10;(VAEs) and Generative Adversarial Networks (GANs). We incorporate diffusion in&#10;a recommender system that mirrors the sequence users take when browsing and&#10;rating items. Although a few current recommender systems incorporate diffusion,&#10;they do not incorporate classifier&#45;free guidance, a new innovation in diffusion&#10;models as a whole. In this paper, we present a diffusion recommender system&#10;that augments the underlying recommender system model for improved performance&#10;and also incorporates classifier&#45;free guidance. Our findings show improvements&#10;over state&#45;of&#45;the&#45;art recommender systems for most metrics for several&#10;recommendation tasks on a variety of datasets. In particular, our approach&#10;demonstrates the potential to provide better recommendations when data is&#10;sparse.&#10; | General | [Link](http://arxiv.org/abs/2409.10494v1) |&#10;| Renormalization of the Einstein&#45;Cartan Theory in First&#45;Order Form | F. T. Brandt, J. Frenkel, S. Martins&#45;Filho, D. G. C. McKeon | &#160;&#160;We examine the Einstein&#45;Cartan (EC) theory in first&#45;order form, which has a&#10;diffeomorphism as well as a local Lorentz invariance. We study the&#10;renormalizability of this theory in the framework of the Batalin&#45;Vilkovisky&#10;formalism, which allows for a gauge invariant renormalization. Using the&#10;background field method, we discuss the gauge invariance of the background&#10;effective action and analyze the Ward identities which reflect the symmetries&#10;of the EC theory. As an application, we compute, in a general background gauge,&#10;the self&#45;energy of the tetrad field at one&#45;loop order.&#10; | General | [Link](http://arxiv.org/abs/2409.10493v1) |&#10;| What we can learn from the angular differential rates (only) in&#10; &#160;semileptonic $B to D^* ell _ell$ decays | G. Martinelli, S. Simula, L. Vittorio | &#160;&#160;We present a new, simple approach to the study of semileptonic $B to D^*&#10;ell &#10;u_ell$ decays based on the angular distributions of the final state&#10;particles only. Our approach is model independent and never requires the&#10;knowledge of $vert V_{cb}vert$. By studying such distributions in the case of&#10;light leptons, a comparison between results from different data sets from the&#10;Belle and BelleII Collaborations and between data and Standard Model&#10;calculations is also given for several interesting quantities. A good&#10;consistency is observed between some of the experimental results and the&#10;theoretical predictions.&#10; | General | [Link](http://arxiv.org/abs/2409.10492v1) |&#10;| Code Vulnerability Detection: A Comparative Analysis of Emerging Large&#10; &#160;Language Models | Shaznin Sultana, Sadia Afreen, Nasir U. Eisty | &#160;&#160;The growing trend of vulnerability issues in software development as a result&#10;of a large dependence on open&#45;source projects has received considerable&#10;attention recently. This paper investigates the effectiveness of Large Language&#10;Models (LLMs) in identifying vulnerabilities within codebases, with a focus on&#10;the latest advancements in LLM technology. Through a comparative analysis, we&#10;assess the performance of emerging LLMs, specifically Llama, CodeLlama, Gemma,&#10;and CodeGemma, alongside established state&#45;of&#45;the&#45;art models such as BERT,&#10;RoBERTa, and GPT&#45;3. Our study aims to shed light on the capabilities of LLMs in&#10;vulnerability detection, contributing to the enhancement of software security&#10;practices across diverse open&#45;source repositories. We observe that CodeGemma&#10;achieves the highest F1&#45;score of 58 and a Recall of 87, amongst the recent&#10;additions of large language models to detect software security vulnerabilities.&#10; | General | [Link](http://arxiv.org/abs/2409.10490v1) |&#10;| Flash STU: Fast Spectral Transform Units | Y. Isabel Liu, Windsor Nguyen, Yagiz Devre, Evan Dogariu, Anirudha Majumdar, Elad Hazan | &#160;&#160;This paper describes an efficient, open source PyTorch implementation of the&#10;Spectral Transform Unit. We investigate sequence prediction tasks over several&#10;modalities including language, robotics, and simulated dynamical systems. We&#10;find that for the same parameter count, the STU and its variants outperform the&#10;Transformer as well as other leading state space models across various&#10;modalities.&#10; | General | [Link](http://arxiv.org/abs/2409.10489v1) |&#10;| Do Pre&#45;trained Vision&#45;Language Models Encode Object States? | Kaleb Newman, Shijie Wang, Yuan Zang, David Heffren, Chen Sun | &#160;&#160;For a vision&#45;language model (VLM) to understand the physical world, such as&#10;cause and effect, a first step is to capture the temporal dynamics of the&#10;visual world, for example how the physical states of objects evolve over time&#10;(e.g. a whole apple into a sliced apple). Our paper aims to investigate if VLMs&#10;pre&#45;trained on web&#45;scale data learn to encode object states, which can be&#10;extracted with zero&#45;shot text prompts. We curate an object state recognition&#10;dataset ChangeIt&#45;Frames, and evaluate nine open&#45;source VLMs, including models&#10;trained with contrastive and generative objectives. We observe that while these&#10;state&#45;of&#45;the&#45;art vision&#45;language models can reliably perform object&#10;recognition, they consistently fail to accurately distinguish the objects&#39;&#10;physical states. Through extensive experiments, we identify three areas for&#10;improvements for VLMs to better encode object states, namely the quality of&#10;object localization, the architecture to bind concepts to objects, and the&#10;objective to learn discriminative visual and language encoders on object&#10;states. Data and code are released.&#10; | General | [Link](http://arxiv.org/abs/2409.10488v1) |&#10;| A Host Galaxy Morphology Link Between Quasi&#45;Periodic Eruptions and Tidal&#10; &#160;Disruption Events | Olivier Gilbert, John J. Ruan, Michael Eracleous, Daryl Haggard, Jessie C. Runnoe | &#160;&#160;The physical processes that produce X&#45;ray Quasi&#45;Periodic Eruptions (QPEs)&#10;recently discovered from the nuclei of several low&#45;redshift galaxies are&#10;mysterious. Several pieces of observational evidence strongly suggest a link&#10;between QPEs and Tidal Disruption Events (TDE). Previous studies also reveal&#10;that the morphologies of TDE host galaxies are highly concentrated, with high&#10;Sersic indicies, bulge&#45;to&#45;total light (B/T) ratios, and stellar surface mass&#10;densities relative to the broader galaxy population. We use these distinctive&#10;properties to test the link between QPEs and TDEs, by comparing these&#10;parameters of QPE host galaxies to TDE host galaxies. We employ archival Legacy&#10;Survey images of a sample of 9 QPE host galaxies and a sample of 13 TDE host&#10;galaxies, and model their surface brightness profiles. We show that QPE host&#10;galaxies have high Sersic indices of ~3, high B/T ratios of ~0.5, and high&#10;surface mass densities of ~10^10 Msun kpc^&#45;2. These properties are similar to&#10;TDE host galaxies, but are in strong contrast to a mass&#45; and redshift&#45;matched&#10;control sample of galaxies. We also find tentative evidence that the central&#10;black holes in both QPE and TDE host galaxies are undermassive relative to&#10;their stellar mass. The morphological similarities between QPE and TDE host&#10;galaxies at the population level add to the mounting evidence of a physical&#10;link between these phenomena, and favor QPE models that also invoke TDEs.&#10; | General | [Link](http://arxiv.org/abs/2409.10486v1) |&#10;| Tuning the Rate of Tightly Packed Systems To Produce Planet Occurrence&#10; &#160;Trends with Galactic Height | Sarah Ballard | &#160;&#160;The formation of planetary systems has historically been considered in&#10;isolation, decoupled from processes on galactic scales. Recent findings&#10;employing data from ESA&#39;s Gaia mission challenge this narrative, identifying&#10;trends in planet occurrence with galactic kinematics and stellar age. The&#10;findings indicate changes in planet occurrence over and above the predicted&#10;changes from metallicity variation within the Milky Way, so that changes to&#10;stellar metallicity alone (long understood to be deterministic in planet&#10;outcomes) cannot explain the trends entirely. The scope of potential factors&#10;influencing planet formation has grown progressively wider, with accompanying&#10;theoretical support for galactic&#45;scale influences upon planet formation. In&#10;this manuscript, we investigate specifically how changes to the rate of Systems&#10;of Tightly&#45;packed Inner Planets (STIPs) could manifest as a trend in planet&#10;occurrence with galactic height. We focus our study upon M dwarf planetary&#10;systems for two reasons: first, they host STIPs at high rates, and secondly,&#10;their longevity makes them useful probes for kinematic trends over Gyr. We&#10;consider two models for a varying STIP rate: one in which STIP likelihood is&#10;determined by stellar age alone, irrespective of galactic time, and another in&#10;which the STIP likelihood suddenly increased in recent galactic history. Both&#10;models, which impose a higher STIP likelihood among younger stars, produce a&#10;negative gradient in planet occurrence with increasing height from the galactic&#10;midplane. We find that a step function model in which STIP likelihood increased&#10;by a factor of several ~a few Gyr ago resembles an observed trend among FGK&#10;dwarfs. We consider plausible physical mechanisms that could mimic the&#10;hypothesized model, given known links between STIP occurrence and other stellar&#10;and planetary properties.&#10; | General | [Link](http://arxiv.org/abs/2409.10485v1) |&#10;| XLM for Autonomous Driving Systems: A Comprehensive Review | Sonda Fourati, Wael Jaafar, Noura Baccar, Safwan Alfattani | &#160;&#160;Large Language Models (LLMs) have showcased remarkable proficiency in various&#10;information&#45;processing tasks. These tasks span from extracting data and&#10;summarizing literature to generating content, predictive modeling,&#10;decision&#45;making, and system controls. Moreover, Vision Large Models (VLMs) and&#10;Multimodal LLMs (MLLMs), which represent the next generation of language&#10;models, a.k.a., XLMs, can combine and integrate many data modalities with the&#10;strength of language understanding, thus advancing several information&#45;based&#10;systems, such as Autonomous Driving Systems (ADS). Indeed, by combining&#10;language communication with multimodal sensory inputs, e.g., panoramic images&#10;and LiDAR or radar data, accurate driving actions can be taken. In this&#10;context, we provide in this survey paper a comprehensive overview of the&#10;potential of XLMs towards achieving autonomous driving. Specifically, we review&#10;the relevant literature on ADS and XLMs, including their architectures, tools,&#10;and frameworks. Then, we detail the proposed approaches to deploy XLMs for&#10;autonomous driving solutions. Finally, we provide the related challenges to XLM&#10;deployment for ADS and point to future research directions aiming to enable XLM&#10;adoption in future ADS frameworks.&#10; | General | [Link](http://arxiv.org/abs/2409.10484v1) |&#10;| Efficient polarizable QM/MM using the direct reaction field Hamiltonian&#10; &#160;with electrostatic potential fitted multipole operators | Thomas P. Fay, Nicolas Ferr, Miquel Huix&#45;Rotllant | &#160;&#160;Electronic polarization and dispersion are decisive actors in determining&#10;interaction energies between molecules. These interactions have a particularly&#10;profound effect on excitation energies of molecules in complex environments,&#10;especially when the excitation involves a significant degree of charge&#10;reorganisation. The direct reaction field (DRF) approach, which has seen a&#10;recent revival of interest, provides a powerful framework for describing these&#10;interactions in quantum mechanics/molecular mechanics (QM/MM) models of&#10;systems, where a small subsystem of interest is described using quantum&#10;chemical methods and the remainder is treated with a simple MM force field. In&#10;this paper we show how the DRF approach can be combined with the electrostatic&#10;potential fitted (ESPF) multipole operator description of the QM region charge&#10;density, which reduces the scaling $mathcal{O}(N_mathrm{MM}^3)$ of the method&#10;with MM system to $mathcal{O}(N_mathrm{MM}^2)$. We also show how the DRF&#10;approach can be combined with fluctuating charge descriptions of the&#10;polarizable environment, as well as previously used atom&#45;centred&#10;dipole&#45;polarizability based models. We further show that the ESPF&#45;DRF method&#10;provides an accurate description of molecular interactions in both ground and&#10;excited electronic states of the QM system and apply it to predict the gas to&#10;aqueous solution solvatochromic shifts in the UV/visible absorption spectrum of&#10;acrolein.&#10; | General | [Link](http://arxiv.org/abs/2409.10483v1) |&#10;| Schrodinger&#39;s Memory: Large Language Models | Wei Wang, Qing Li | &#160;&#160;Memory is the foundation of LLMs&#39; functionality, yet past research has lacked&#10;an in&#45;depth exploration of their memory capabilities and underlying theory. In&#10;this paper, we apply UAT theory to explain the memory mechanism of LLMs and&#10;propose a new approach for evaluating LLM performance by comparing the memory&#10;capacities of different models. Through extensive experiments, we validate our&#10;theory and the memory abilities of LLMs. Finally, we compare the capabilities&#10;of the human brain and LLMs, highlighting both their similarities and&#10;differences in terms of working mechanisms.&#10; | General | [Link](http://arxiv.org/abs/2409.10482v1) |&#10;| Exploring 3D Face Reconstruction and Fusion Methods for Face&#10; &#160;Verification: A Case&#45;Study in Video Surveillance | Simone Maurizio La Cava, Sara Concas, Ruben Tolosana, Roberto Casula, Giulia Orr, Martin Drahansky, Julian Fierrez, Gian Luca Marcialis | &#160;&#160;3D face reconstruction (3DFR) algorithms are based on specific assumptions&#10;tailored to distinct application scenarios. These assumptions limit their use&#10;when acquisition conditions, such as the subject&#39;s distance from the camera or&#10;the camera&#39;s characteristics, are different than expected, as typically happens&#10;in video surveillance. Additionally, 3DFR algorithms follow various strategies&#10;to address the reconstruction of a 3D shape from 2D data, such as statistical&#10;model fitting, photometric stereo, or deep learning. In the present study, we&#10;explore the application of three 3DFR algorithms representative of the SOTA,&#10;employing each one as the template set generator for a face verification&#10;system. The scores provided by each system are combined by score&#45;level fusion.&#10;We show that the complementarity induced by different 3DFR algorithms improves&#10;performance when tests are conducted at never&#45;seen&#45;before distances from the&#10;camera and camera characteristics (cross&#45;distance and cross&#45;camera settings),&#10;thus encouraging further investigations on multiple 3DFR&#45;based approaches.&#10; | General | [Link](http://arxiv.org/abs/2409.10481v1) |&#10;| Addressing misspecification in contextual optimization | Omar Bennouna, Jiawei Zhang, Saurabh Amin, Asuman Ozdaglar | &#160;&#160;We study a linear contextual optimization problem where a decision maker has&#10;access to historical data and contextual features to learn a cost prediction&#10;model aimed at minimizing decision error. We adopt the predict&#45;then&#45;optimize&#10;framework for this analysis. Given that perfect model alignment with reality is&#10;often unrealistic in practice, we focus on scenarios where the chosen&#10;hypothesis set is misspecified. In this context, it remains unclear whether&#10;current contextual optimization approaches can effectively address such model&#10;misspecification. In this paper, we present a novel integrated learning and&#10;optimization approach designed to tackle model misspecification in contextual&#10;optimization. This approach offers theoretical generalizability, tractability,&#10;and optimality guarantees, along with strong practical performance. Our method&#10;involves minimizing a tractable surrogate loss that aligns with the performance&#10;value from cost vector predictions, regardless of whether the model&#10;misspecified or not, and can be optimized in reasonable time. To our knowledge,&#10;no previous work has provided an approach with such guarantees in the context&#10;of model misspecification.&#10; | General | [Link](http://arxiv.org/abs/2409.10479v1) |&#10;| Local SGD for Near&#45;Quadratic Problems: Improving Convergence under&#10; &#160;Unconstrained Noise Conditions | Andrey Sadchikov, Savelii Chezhegov, Aleksandr Beznosikov, Alexander Gasnikov | &#160;&#160;Distributed optimization plays an important role in modern large&#45;scale&#10;machine learning and data processing systems by optimizing the utilization of&#10;computational resources. One of the classical and popular approaches is Local&#10;Stochastic Gradient Descent (Local SGD), characterized by multiple local&#10;updates before averaging, which is particularly useful in distributed&#10;environments to reduce communication bottlenecks and improve scalability. A&#10;typical feature of this method is the dependence on the frequency of&#10;communications. But in the case of a quadratic target function with homogeneous&#10;data distribution over all devices, the influence of frequency of&#10;communications vanishes. As a natural consequence, subsequent studies include&#10;the assumption of a Lipschitz Hessian, as this indicates the similarity of the&#10;optimized function to a quadratic one to some extent. However, in order to&#10;extend the completeness of the Local SGD theory and unlock its potential, in&#10;this paper we abandon the Lipschitz Hessian assumption by introducing a new&#10;concept of $textit{approximate quadraticity}$. This assumption gives a new&#10;perspective on problems that have near quadratic properties. In addition,&#10;existing theoretical analyses of Local SGD often assume bounded variance. We,&#10;in turn, consider the unbounded noise condition, which allows us to broaden the&#10;class of studied problems.&#10; | General | [Link](http://arxiv.org/abs/2409.10478v1) |&#10;| SimInversion: A Simple Framework for Inversion&#45;Based Text&#45;to&#45;Image&#10; &#160;Editing | Qi Qian, Haiyang Xu, Ming Yan, Juhua Hu | &#160;&#160;Diffusion models demonstrate impressive image generation performance with&#10;text guidance. Inspired by the learning process of diffusion, existing images&#10;can be edited according to text by DDIM inversion. However, the vanilla DDIM&#10;inversion is not optimized for classifier&#45;free guidance and the accumulated&#10;error will result in the undesired performance. While many algorithms are&#10;developed to improve the framework of DDIM inversion for editing, in this work,&#10;we investigate the approximation error in DDIM inversion and propose to&#10;disentangle the guidance scale for the source and target branches to reduce the&#10;error while keeping the original framework. Moreover, a better guidance scale&#10;(i.e., 0.5) than default settings can be derived theoretically. Experiments on&#10;PIE&#45;Bench show that our proposal can improve the performance of DDIM inversion&#10;dramatically without sacrificing efficiency.&#10; | General | [Link](http://arxiv.org/abs/2409.10476v1) |&#10;| Leadership and Engagement Dynamics in Legislative Twitter Networks:&#10; &#160;Statistical Analysis and Modeling | Carolina Luque, Juan Sosa | &#160;&#160;In this manuscript, we analyze the interaction network on Twitter among&#10;members of the 117th U.S. Congress to assess the visibility of political&#10;leaders and explore how systemic properties and node attributes influence the&#10;formation of legislative connections. We employ descriptive social network&#10;statistical methods, the exponential random graph model (ERGM), and the&#10;stochastic block model (SBM) to evaluate the relative impact of network&#10;systemic properties, as well as institutional and personal traits, on the&#10;generation of online relationships among legislators. Our findings reveal that&#10;legislative networks on social media platforms like Twitter tend to reinforce&#10;the leadership of dominant political actors rather than diminishing their&#10;influence. However, we identify that these leadership roles can manifest in&#10;various forms. Additionally, we highlight that online connections within&#10;legislative networks are influenced by both the systemic properties of the&#10;network and institutional characteristics.&#10; | General | [Link](http://arxiv.org/abs/2409.10475v1) |&#10;| MacDiff: Unified Skeleton Modeling with Masked Conditional Diffusion | Lehong Wu, Lilang Lin, Jiahang Zhang, Yiyang Ma, Jiaying Liu | &#160;&#160;Self&#45;supervised learning has proved effective for skeleton&#45;based human action&#10;understanding. However, previous works either rely on contrastive learning that&#10;suffers false negative problems or are based on reconstruction that learns too&#10;much unessential low&#45;level clues, leading to limited representations for&#10;downstream tasks. Recently, great advances have been made in generative&#10;learning, which is naturally a challenging yet meaningful pretext task to model&#10;the general underlying data distributions. However, the representation learning&#10;capacity of generative models is under&#45;explored, especially for the skeletons&#10;with spacial sparsity and temporal redundancy. To this end, we propose Masked&#10;Conditional Diffusion (MacDiff) as a unified framework for human skeleton&#10;modeling. For the first time, we leverage diffusion models as effective&#10;skeleton representation learners. Specifically, we train a diffusion decoder&#10;conditioned on the representations extracted by a semantic encoder. Random&#10;masking is applied to encoder inputs to introduce a information bottleneck and&#10;remove redundancy of skeletons. Furthermore, we theoretically demonstrate that&#10;our generative objective involves the contrastive learning objective which&#10;aligns the masked and noisy views. Meanwhile, it also enforces the&#10;representation to complement for the noisy view, leading to better&#10;generalization performance. MacDiff achieves state&#45;of&#45;the&#45;art performance on&#10;representation learning benchmarks while maintaining the competence for&#10;generative tasks. Moreover, we leverage the diffusion model for data&#10;augmentation, significantly enhancing the fine&#45;tuning performance in scenarios&#10;with scarce labeled data. Our project is available at&#10;https://lehongwu.github.io/ECCV24MacDiff/.&#10; | General | [Link](http://arxiv.org/abs/2409.10473v1) |&#10;| Towards Semantic Versioning of Open Pre&#45;trained Language Model Releases&#10; &#160;on Hugging Face | Adekunle Ajibode, Abdul Ali Bangash, Filipe Roseiro Cogo, Bram Adams, Ahmed E. Hassan | &#160;&#160;The proliferation of open Pre&#45;trained Language Models (PTLMs) on model&#10;registry platforms like Hugging Face (HF) presents both opportunities and&#10;challenges for companies building products around them. Similar to traditional&#10;software dependencies, PTLMs continue to evolve after a release. However, the&#10;current state of release practices of PTLMs on model registry platforms are&#10;plagued by a variety of inconsistencies, such as ambiguous naming conventions&#10;and inaccessible model training documentation. Given the knowledge gap on&#10;current PTLM release practices, our empirical study uses a mixed&#45;methods&#10;approach to analyze the releases of 52,227 PTLMs on the most well&#45;known model&#10;registry, HF. Our results reveal 148 different naming practices for PTLM&#10;releases, with 40.87% of changes to model weight files not represented in the&#10;adopted name&#45;based versioning practice or their documentation. In addition, we&#10;identified that the 52,227 PTLMs are derived from only 299 different base&#10;models (the modified original models used to create 52,227 PTLMs), with&#10;Fine&#45;tuning and Quantization being the most prevalent modification methods&#10;applied to these base models. Significant gaps in release transparency, in&#10;terms of training dataset specifications and model card availability, still&#10;exist, highlighting the need for standardized documentation. While we&#10;identified a model naming practice explicitly differentiating between major and&#10;minor PTLM releases, we did not find any significant difference in the types of&#10;changes that went into either type of releases, suggesting that major/minor&#10;version numbers for PTLMs often are chosen arbitrarily. Our findings provide&#10;valuable insights to improve PTLM release practices, nudging the field towards&#10;more formal semantic versioning practices.&#10; | General | [Link](http://arxiv.org/abs/2409.10472v1) |&#10;| Real&#45;Time Whole&#45;Body Control of Legged Robots with Model&#45;Predictive Path&#10; &#160;Integral Control | Juan Alvarez&#45;Padilla, John Z. Zhang, Sofia Kwok, John M. Dolan, Zachary Manchester | &#160;&#160;This paper presents a system for enabling real&#45;time synthesis of whole&#45;body&#10;locomotion and manipulation policies for real&#45;world legged robots. Motivated by&#10;recent advancements in robot simulation, we leverage the efficient&#10;parallelization capabilities of the MuJoCo simulator to achieve fast sampling&#10;over the robot state and action trajectories. Our results show surprisingly&#10;effective real&#45;world locomotion and manipulation capabilities with a very&#10;simple control strategy. We demonstrate our approach on several hardware and&#10;simulation experiments: robust locomotion over flat and uneven terrains,&#10;climbing over a box whose height is comparable to the robot, and pushing a box&#10;to a goal position. To our knowledge, this is the first successful deployment&#10;of whole&#45;body sampling&#45;based MPC on real&#45;world legged robot hardware.&#10;Experiment videos and code can be found at: https://whole&#45;body&#45;mppi.github.io/&#10; | General | [Link](http://arxiv.org/abs/2409.10469v1) |&#10;| Assortativity in sympatric speciation and species classification | Joao U. F. Lizarraga, Flavia M. D. Marquitti, Marcus A. M. de Aguiar | &#160;&#160;We investigate the role of assortative mating in speciation using the&#10;sympatric model of Derrida and Higgs. The model explores the idea that genetic&#10;differences create incompatibilities between individuals, preventing mating if&#10;the number of such differences is too large. Speciation, however, only happens&#10;in this mating system if the number of genes is large. Here we show that&#10;speciation with small genome sizes can occur if assortative mating is&#10;introduced. In our model individuals are represented by three chromosomes: one&#10;responsible for reproductive compatibility, one for coding the trait on which&#10;assortativity will operate, and a neutral chromosome. Reproduction is possible&#10;if individuals are genetically similar with respect to the first chromosome,&#10;but among these compatible mating partners, the one with the most similar trait&#10;coded by the second chromosome is selected. We show that this type of&#10;assortativity facilitates speciation, which can happen with a small number of&#10;genes in the first chromosome. Species, classified according to reproductive&#10;isolation, dictated by the first chromosome, can display different traits&#10;values, as measured by the second and the third chromosomes. Therefore, species&#10;can also be identified based on similarity of the neutral trait, which works as&#10;a proxy for reproductive isolation.&#10; | General | [Link](http://arxiv.org/abs/2409.10466v1) |&#10;| A stabilized total pressure&#45;formulation of the Biot&#39;s poroelasticity&#10; &#160;equations in frequency domain: numerical analysis and applications | Cristian Crcamo, Alfonso Caiazzo, Felipe Galarce, Joaqun Mura | &#160;&#160;This work focuses on the numerical solution of the dynamics of a poroelastic&#10;material in the frequency domain. We provide a detailed stability analysis&#10;based on the application of the Fredholm alternative in the continuous case,&#10;considering a total pressure formulation of the Biot&#39;s equations. In the&#10;discrete setting, we propose a stabilized equal order finite element method&#10;complemented by an additional pressure stabilization to enhance the robustness&#10;of the numerical scheme with respect to the fluid permeability. Utilizing the&#10;Fredholm alternative, we extend the well&#45;posedness results to the discrete&#10;setting, obtaining theoretical optimal convergence for the case of linear&#10;finite elements. We present different numerical experiments to validate the&#10;proposed method. First, we consider model problems with known analytic&#10;solutions in two and three dimensions. As next, we show that the method is&#10;robust for a wide range of permeabilities, including the case of discontinuous&#10;coefficients. Lastly, we show the application for the simulation of brain&#10;elastography on a realistic brain geometry obtained from medical imaging.&#10; | General | [Link](http://arxiv.org/abs/2409.10465v1) |&#10;| New Direct Sum Tests | Alek Westover, Edward Yu, Kai Zheng | &#160;&#160;A function $f:[n]^{d} to mathbb{F}_2$ is a defn{direct sum} if there are&#10;functions $L_i:[n]to mathbb{F}_2$ such that ${f(x) = sum_{i}L_i(x_i)}$. In&#10;this work we give multiple results related to the property testing of direct&#10;sums.&#10; &#160;Our first result concerns a test proposed by Dinur and Golubev in 2019. We&#10;call their test the Diamond test and show that it is indeed a direct sum&#10;tester. More specifically, we show that if a function $f$ is $epsilon$&#45;far&#10;from being a direct sum function, then the Diamond test rejects $f$ with&#10;probability at least $Omega_{n,epsilon}(1)$. Even in the case of $n = 2$, the&#10;Diamond test is, to the best of our knowledge, novel and yields a new tester&#10;for the classic property of affinity.&#10; &#160;Apart from the Diamond test, we also analyze a broad family of direct sum&#10;tests, which at a high level, run an arbitrary affinity test on the restriction&#10;of $f$ to a random hypercube inside of $[n]^d$. This family of tests includes&#10;the direct sum test analyzed in cite{di19}, but does not include the Diamond&#10;test. As an application of our result, we obtain a direct sum test which works&#10;in the online adversary model of cite{KRV}.&#10; &#160;Finally, we also discuss a Fourier analytic interpretation of the diamond&#10;tester in the $n=2$ case, as well as prove local correction results for direct&#10;sum as conjectured by Dinur and Golubev.&#10; | General | [Link](http://arxiv.org/abs/2409.10464v1) |&#10;| Kolmogorov&#45;Arnold Networks in Low&#45;Data Regimes: A Comparative Study with&#10; &#160;Multilayer Perceptrons | Farhad Pourkamali&#45;Anaraki | &#160;&#160;Multilayer Perceptrons (MLPs) have long been a cornerstone in deep learning,&#10;known for their capacity to model complex relationships. Recently,&#10;Kolmogorov&#45;Arnold Networks (KANs) have emerged as a compelling alternative,&#10;utilizing highly flexible learnable activation functions directly on network&#10;edges, a departure from the neuron&#45;centric approach of MLPs. However, KANs&#10;significantly increase the number of learnable parameters, raising concerns&#10;about their effectiveness in data&#45;scarce environments. This paper presents a&#10;comprehensive comparative study of MLPs and KANs from both algorithmic and&#10;experimental perspectives, with a focus on low&#45;data regimes. We introduce an&#10;effective technique for designing MLPs with unique, parameterized activation&#10;functions for each neuron, enabling a more balanced comparison with KANs. Using&#10;empirical evaluations on simulated data and two real&#45;world data sets from&#10;medicine and engineering, we explore the trade&#45;offs between model complexity&#10;and accuracy, with particular attention to the role of network depth. Our&#10;findings show that MLPs with individualized activation functions achieve&#10;significantly higher predictive accuracy with only a modest increase in&#10;parameters, especially when the sample size is limited to around one hundred.&#10;For example, in a three&#45;class classification problem within additive&#10;manufacturing, MLPs achieve a median accuracy of 0.91, significantly&#10;outperforming KANs, which only reach a median accuracy of 0.53 with default&#10;hyperparameters. These results offer valuable insights into the impact of&#10;activation function selection in neural networks.&#10; | General | [Link](http://arxiv.org/abs/2409.10463v1) |&#10;| Effects of synapse location, delay and background stochastic activity on&#10; &#160;synchronising hippocampal CA1 neurons | Alessandro Fiasconaro, Michele Migliore | &#160;&#160;We study the synchronisation of neurons in a realistic model under the&#10;Hodgkin&#45;Huxley dynamics. To focus on the role of the different locations of the&#10;excitatory synapses, we use two identical neurons where the set of input&#10;signals is grouped at two different distances from the soma. The system is&#10;intended to represent a CA1 hippocampal neuron in which the synapses arriving&#10;from the CA3 neurons of the trisynaptic pathway appear to be localised in the&#10;apical dendritic region and are, in principle, either proximal or distal to the&#10;soma. Synchronisation is studied using a specifically defined spiking&#10;correlation function as a function of various parameters such as the distance&#10;from the soma of one of the synaptic groups, the inhibition weight and the&#10;associated activation delay. We found that the neurons&#39; spiking activity&#10;depends nonmonotonically on the relative dendritic location of the synapses and&#10;their inhibitory weight, whereas the synchronisation measure always decreases&#10;with inhibition, and strongly depends on its activation time delay. The&#10;background activity on the somas results essentially independent on the&#10;fluctuation intensity and strongly support the importance of the balance&#10;between inhibition and excitation for neuronal synchronization.&#10; | General | [Link](http://arxiv.org/abs/2409.10460v1) |&#10;| Efficiently Crowdsourcing Visual Importance with Punch&#45;Hole Annotation | Minsuk Chang, Soohyun Lee, Aeri Cho, Hyeon Jeon, Seokhyeon Park, Cindy Xiong Bearfield, Jinwook Seo | &#160;&#160;We introduce a novel crowdsourcing method for identifying important areas in&#10;graphical images through punch&#45;hole labeling. Traditional methods, such as gaze&#10;trackers and mouse&#45;based annotations, which generate continuous data, can be&#10;impractical in crowdsourcing scenarios. They require many participants, and the&#10;outcome data can be noisy. In contrast, our method first segments the graphical&#10;image with a grid and drops a portion of the patches (punch holes). Then, we&#10;iteratively ask the labeler to validate each annotation with holes, narrowing&#10;down the annotation only having the most important area. This approach aims to&#10;reduce annotation noise in crowdsourcing by standardizing the annotations while&#10;enhancing labeling efficiency and reliability. Preliminary findings from&#10;fundamental charts demonstrate that punch&#45;hole labeling can effectively&#10;pinpoint critical regions. This also highlights its potential for broader&#10;application in visualization research, particularly in studying large&#45;scale&#10;users&#39; graphical perception. Our future work aims to enhance the algorithm to&#10;achieve faster labeling speed and prove its utility through large&#45;scale&#10;experiments.&#10; | General | [Link](http://arxiv.org/abs/2409.10459v1) |&#10;| Full distribution of local observables in an exactly solvable current&#10; &#160;carrying steady states of a driven XXZ chain | Sandipan Manna, G J Sreejith | &#160;&#160;Current carrying steady states of interacting spins chains exhibit rich&#10;structures generated through an interplay of current induced correlations and&#10;energetic constraints from the Hamiltonian. The XXZ spin chain when coupled to&#10;maximally polarizing Lindblad terms admits an exact solution in a matrix&#10;product state (MPS) form. We use this exact solution to study the correlations&#10;and distributions of simple local spin observables in the non equilibrium&#10;steady state (NESS). We present exact expressions for spin correlators, entropy&#10;per site, cumulant generating functions for distributions of local observables&#10;in the XX limit (Ising anisotropy $Delta=0$). Further, we use the exact MPS&#10;solution in systems with $Delta&gt;0$, to numerically exactly calculate the&#10;entropy, correlations, as well as distributions of spin observables in blocks&#10;as large as $nsim 200$ sites allowing an estimation of the rate functions. The&#10;$z$ magnetization distribution is consistant with short range spin correlations&#10;in the $z$ direction while the $x$&#45;magnetization shows a double peak structure&#10;at larger $Delta$ suggesting short range ferromagnetic ordering. We find that&#10;the distribution of $z$&#45;magnetization sharpens for parameters where the current&#10;is maximized.&#10; | General | [Link](http://arxiv.org/abs/2409.10458v1) |&#10;| Mean Residual Life Ageing Intensity Function | Ashutosh Singh, Ishapathik Das, Asok Kumar Nanda, Sumen Sen | &#160;&#160;The ageing intensity function is a powerful analytical tool that provides&#10;valuable insights into the ageing process across diverse domains such as&#10;reliability engineering, actuarial science, and healthcare. Its applications&#10;continue to expand as researchers delve deeper into understanding the complex&#10;dynamics of ageing and its implications for society. One common approach to&#10;defining the ageing intensity function is through the hazard rate or failure&#10;rate function, extensively explored in scholarly literature. Equally&#10;significant to the hazard rate function is the mean residual life function,&#10;which plays a crucial role in analyzing the ageing patterns exhibited by units&#10;or components. This article introduces the mean residual life ageing intensity&#10;(MRLAI) function to delve into component ageing behaviours across various&#10;distributions. Additionally, we scrutinize the closure properties of the MRLAI&#10;function across different reliability operations. Furthermore, a new order&#10;termed the mean residual life ageing intensity order is defined to analyze the&#10;ageing behaviour of a system, and the closure property of this order under&#10;various reliability operations is discussed.&#10; | General | [Link](http://arxiv.org/abs/2409.10456v1) |&#10;| Quantile Fourier regressions for decision making under uncertainty | Arash Khojaste, Geoffrey Pritchard, Golbon Zakeri | &#160;&#160;Weconsider Markov decision processes arising from a Markov model of an&#10;underlying natural phenomenon. Such phenomena are usually periodic (e.g.&#10;annual) in time, and so the Markov processes modelling them must be&#10;time&#45;inhomogeneous, with cyclostationary rather than stationary behaviour. We&#10;describe a technique for constructing such processes that allows for periodic&#10;variations both in the values taken by the process and in the serial dependence&#10;structure. We include two illustrative numerical examples: a hydropower&#10;scheduling problem and a model of offshore wind power integration.&#10; | General | [Link](http://arxiv.org/abs/2409.10455v1) |&#10;| The Debiased Near&#45;Earth Object Population from ATLAS Telescopes | Rogerio Deienno, Larry Denneau, David Nesvorn, David Vokrouhlick, William F. Bottke, Robert Jedicke, Shantanu Naidu, Steven R. Chesley, Davide Farnocchia, Paul W. Chodas | &#160;&#160;This work is dedicated to debias the Near&#45;Earth Objects (NEO) population&#10;based on observations from the Asteroid Terrestrial&#45;impact Last Alert System&#10;(ATLAS) telescopes. We have applied similar methods used to develop the&#10;recently released NEO model generator (NEOMOD), once debiasing the NEO&#10;population using data from Catalina Sky Survey (CSS) G96 telescope. ATLAS is&#10;composed of four different telescopes. We first analyzed observational data&#10;from each of all four telescopes separately and later combined them. Our&#10;results highlight main differences between CSS and ATLAS, e.g., sky coverage&#10;and survey power at debiasing the NEO population. ATLAS has a much larger sky&#10;coverage than CSS, allowing it to find bright NEOs that would be constantly&#10;&quot;hiding&quot; from CSS. Consequently, ATLAS is more powerful than CSS at debiasing&#10;the NEO population for H $&#10;esssim$ 19. With its intrinsically greater&#10;sensitivity and emphasis on observing near opposition, CSS excels in the&#10;debiasing of smaller objects. ATLAS, as an all sky survey designed to find&#10;imminent hazardous objects, necessarily spends a significant fraction of time&#10;looking at places on the sky where objects do not appear, reducing its power&#10;for debiasing the population of small objects. We estimate a NEO population&#10;completeness of $approx$ 88%$^{+3%}_{&#45;2%}$ for H $&lt;$ 17.75 and $approx$&#10;36%$^{+1%}_{&#45;1%}$ for H $&lt;$ 22.25. Those numbers are similar to previous&#10;estimates (within error bars for H $&lt;$ 17.75) from CSS, yet, around 3% and 8%&#10;smaller at their face values, respectively. We also confirm previous finding&#10;that the $&#10;u_6$ secular resonance is the main source of small and faint NEOs&#10;at H = 28, whereas the 3:1 mean motion resonance with Jupiter dominates for&#10;larger and brighter NEOs at H = 15.&#10; | General | [Link](http://arxiv.org/abs/2409.10453v1) |&#10;| Signed Graph Autoencoder for Explainable and Polarization&#45;Aware Network&#10; &#160;Embeddings | Nikolaos Nakis, Chrysoula Kosma, Giannis Nikolentzos, Michalis Chatzianastasis, Iakovos Evdaimon, Michalis Vazirgiannis | &#160;&#160;Autoencoders based on Graph Neural Networks (GNNs) have garnered significant&#10;attention in recent years for their ability to extract informative latent&#10;representations, characterizing the structure of complex topologies, such as&#10;graphs. Despite the prevalence of Graph Autoencoders, there has been limited&#10;focus on developing and evaluating explainable neural&#45;based graph generative&#10;models specifically designed for signed networks. To address this gap, we&#10;propose the Signed Graph Archetypal Autoencoder (SGAAE) framework. SGAAE&#10;extracts node&#45;level representations that express node memberships over distinct&#10;extreme profiles, referred to as archetypes, within the network. This is&#10;achieved by projecting the graph onto a learned polytope, which governs its&#10;polarization. The framework employs a recently proposed likelihood for&#10;analyzing signed networks based on the Skellam distribution, combined with&#10;relational archetypal analysis and GNNs. Our experimental evaluation&#10;demonstrates the SGAAEs&#39; capability to successfully infer node memberships over&#10;the different underlying latent structures while extracting competing&#10;communities formed through the participation of the opposing views in the&#10;network. Additionally, we introduce the 2&#45;level network polarization problem&#10;and show how SGAAE is able to characterize such a setting. The proposed model&#10;achieves high performance in different tasks of signed link prediction across&#10;four real&#45;world datasets, outperforming several baseline models.&#10; | General | [Link](http://arxiv.org/abs/2409.10452v1) |&#10;| Why you should also use OLS estimation of tail exponents | Thiago Trafane Oliveira Santos, Daniel Oliveira Cajueiro | &#160;&#160;Even though practitioners often estimate Pareto exponents running OLS&#10;rank&#45;size regressions, the usual recommendation is to use the Hill MLE with a&#10;small&#45;sample correction instead, due to its unbiasedness and efficiency. In&#10;this paper, we advocate that you should also apply OLS in empirical&#10;applications. On the one hand, we demonstrate that, with a small&#45;sample&#10;correction, the OLS estimator is also unbiased. On the other hand, we show that&#10;the MLE assigns significantly greater weight to smaller observations. This&#10;suggests that the OLS estimator may outperform the MLE in cases where the&#10;distribution is (i) strictly Pareto but only in the upper tail or (ii)&#10;regularly varying rather than strictly Pareto. We substantiate our theoretical&#10;findings with Monte Carlo simulations and real&#45;world applications,&#10;demonstrating the practical relevance of the OLS method in estimating tail&#10;exponents.&#10; | General | [Link](http://arxiv.org/abs/2409.10448v1) |&#10;| Hydrodynamic hovering of swimming bacteria above surfaces | Pyae Hein Htet, Debasish Das, Eric Lauga | &#160;&#160;Flagellated bacteria are hydrodynamically attracted to rigid walls, yet past&#10;work shows a &#39;hovering&#39; state where they swim stably at a finite height above&#10;surfaces. We use numerics and theory to reveal the physical origin of hovering.&#10;Simulations first show that hovering requires an elongated cell body and&#10;results from a tilt away from the wall. Theoretical models then identify two&#10;essential asymmetries: the response of width&#45;asymmetric cells to active flows&#10;created by length&#45;asymmetric cells. A minimal model reconciles near and&#10;far&#45;field hydrodynamics, capturing all key features of hovering.&#10; | General | [Link](http://arxiv.org/abs/2409.10447v1) |&#10;| KoroT&#45;3E: A Personalized Musical Mnemonics Tool for Enhancing Memory&#10; &#160;Retention of Complex Computer Science Concepts | Xiangzhe Yuan, Jiajun Wang, Siying Hu, Andrew Cheung, Zhicong Lu | &#160;&#160;As the demand for computer science (CS) skills grows, mastering foundational&#10;concepts is crucial yet challenging for novice learners. To address this&#10;challenge, we present KoroT&#45;3E, an AI&#45;based system that creates personalized&#10;musical mnemonics to enhance both memory retention and understanding of&#10;concepts in CS. KoroT&#45;3E enables users to transform complex concepts into&#10;memorable lyrics and compose melodies that suit their musical preferences. We&#10;conducted semi&#45;structured interviews (n=12) to investigate why novice learners&#10;find it challenging to memorize and understand CS concepts. The findings,&#10;combined with constructivist learning theory, established our initial design,&#10;which was then refined following consultations with CS education experts. An&#10;empirical experiment(n=36) showed that those using KoroT&#45;3E (n=18)&#10;significantly outperformed the control group (n=18), with improved memory&#10;efficiency, increased motivation, and a positive learning experience. These&#10;findings demonstrate the effectiveness of integrating multimodal generative AI&#10;into CS education to create personalized and interactive learning experiences.&#10; | General | [Link](http://arxiv.org/abs/2409.10446v1) |&#10;| Deep&#45;Wide Learning Assistance for Insect Pest Classification | Toan Nguyen, Huy Nguyen, Huy Ung, Hieu Ung, Binh Nguyen | &#160;&#160;Accurate insect pest recognition plays a critical role in agriculture. It is&#10;a challenging problem due to the intricate characteristics of insects. In this&#10;paper, we present DeWi, novel learning assistance for insect pest&#10;classification. With a one&#45;stage and alternating training strategy, DeWi&#10;simultaneously improves several Convolutional Neural Networks in two&#10;perspectives: discrimination (by optimizing a triplet margin loss in a&#10;supervised training manner) and generalization (via data augmentation). From&#10;that, DeWi can learn discriminative and in&#45;depth features of insect pests&#10;(deep) yet still generalize well to a large number of insect categories (wide).&#10;Experimental results show that DeWi achieves the highest performances on two&#10;insect pest classification benchmarks (76.44% accuracy on the IP102 dataset&#10;and 99.79% accuracy on the D0 dataset, respectively). In addition, extensive&#10;evaluations and ablation studies are conducted to thoroughly investigate our&#10;DeWi and demonstrate its superiority. Our source code is available at&#10;https://github.com/toannguyen1904/DeWi.&#10; | General | [Link](http://arxiv.org/abs/2409.10445v1) |&#10;| LLM as BT&#45;Planner: Leveraging LLMs for Behavior Tree Generation in Robot&#10; &#160;Task Planning | Jicong Ao, Fan Wu, Yansong Wu, Abdalla Swikir, Sami Haddadin | &#160;&#160;Robotic assembly tasks are open challenges due to the long task horizon and&#10;complex part relations. Behavior trees (BTs) are increasingly used in robot&#10;task planning for their modularity and flexibility, but manually designing them&#10;can be effort&#45;intensive. Large language models (LLMs) have recently been&#10;applied in robotic task planning for generating action sequences, but their&#10;ability to generate BTs has not been fully investigated. To this end, We&#10;propose LLM as BT&#45;planner, a novel framework to leverage LLMs for BT generation&#10;in robotic assembly task planning and execution. Four in&#45;context learning&#10;methods are introduced to utilize the natural language processing and inference&#10;capabilities of LLMs to produce task plans in BT format, reducing manual effort&#10;and ensuring robustness and comprehensibility. We also evaluate the performance&#10;of fine&#45;tuned, fewer&#45;parameter LLMs on the same tasks. Experiments in simulated&#10;and real&#45;world settings show that our framework enhances LLMs&#39; performance in&#10;BT generation, improving success rates in BT generation through in&#45;context&#10;learning and supervised fine&#45;tuning.&#10; | General | [Link](http://arxiv.org/abs/2409.10444v1) |&#10;| The James Webb Space Telescope Absolute Flux Calibration. II.&#10; &#160;Mid&#45;Infrared Instrument Imaging and Coronagraphy | Karl D. Gordon, G. C. Sloan, Macarena Garcia Marin, Mattia Libralato, George Rieke, Jonathan A. Aguilar, Ralph Bohlin, Misty Cracraft, Marjorie Decleir, Andras Gaspar, David R. Law, Alberto Noriega&#45;Crespo, Michael Regan | &#160;&#160;The absolute flux calibration of the Mid&#45;Infrared Instrument Imaging and&#10;Coronagraphy is based on observations of multiple stars taken during the first&#10;2.5 years of JWST operations. The observations were designed to ensure that the&#10;flux calibration is valid for a range of flux densities, different subarrays,&#10;and different types of stars. The flux calibration was measured by combining&#10;observed aperture photometry corrected to infinite aperture with predictions&#10;based on previous observations and models of stellar atmospheres. A subset of&#10;these observations were combined with model point&#45;spread&#45;functions to measure&#10;the corrections to infinite aperture. Variations in the calibration factor with&#10;time, flux density, background level, type of star, subarray, integration time,&#10;rate, and well depth were investigated, and the only significant variations&#10;were with time and subarray. Observations of the same star taken approximately&#10;every month revealed a modest time&#45;dependent response loss seen mainly at the&#10;longest wavelengths. This loss is well characterized by a decaying exponential&#10;with a time constant of ~200 days. After correcting for the response loss, the&#10;band&#45;dependent scatter around the corrected average (aka repeatability) was&#10;found to range from 0.1 to 1.2%. Signals in observations taken with different&#10;subarrays can be lower by up to 3.4% compared to FULL frame. After correcting&#10;for the time and subarray dependencies, the scatter in the calibration factors&#10;measured for individual stars ranges from 1 to 4% depending on the band. The&#10;formal uncertainties on the flux calibration averaged for all observations are&#10;0.3 to 1.0%, with longer&#45;wavelength bands generally having larger&#10;uncertainties.&#10; | General | [Link](http://arxiv.org/abs/2409.10443v1) |&#10;| CtRNet&#45;X: Camera&#45;to&#45;Robot Pose Estimation in Real&#45;world Conditions Using&#10; &#160;a Single Camera | Jingpei Lu, Zekai Liang, Tristin Xie, Florian Ritcher, Shan Lin, Sainan Liu, Michael C. Yip | &#160;&#160;Camera&#45;to&#45;robot calibration is crucial for vision&#45;based robot control and&#10;requires effort to make it accurate. Recent advancements in markerless pose&#10;estimation methods have eliminated the need for time&#45;consuming physical setups&#10;for camera&#45;to&#45;robot calibration. While the existing markerless pose estimation&#10;methods have demonstrated impressive accuracy without the need for cumbersome&#10;setups, they rely on the assumption that all the robot joints are visible&#10;within the camera&#39;s field of view. However, in practice, robots usually move in&#10;and out of view, and some portion of the robot may stay out&#45;of&#45;frame during the&#10;whole manipulation task due to real&#45;world constraints, leading to a lack of&#10;sufficient visual features and subsequent failure of these approaches. To&#10;address this challenge and enhance the applicability to vision&#45;based robot&#10;control, we propose a novel framework capable of estimating the robot pose with&#10;partially visible robot manipulators. Our approach leverages the&#10;Vision&#45;Language Models for fine&#45;grained robot components detection, and&#10;integrates it into a keypoint&#45;based pose estimation network, which enables more&#10;robust performance in varied operational conditions. The framework is evaluated&#10;on both public robot datasets and self&#45;collected partial&#45;view datasets to&#10;demonstrate our robustness and generalizability. As a result, this method is&#10;effective for robot pose estimation in a wider range of real&#45;world manipulation&#10;scenarios.&#10; | General | [Link](http://arxiv.org/abs/2409.10441v1) |&#10;| Successive topological phase transitions in two distinct spin&#45;flop&#10; &#160;phases on the honeycomb lattice | Xudong Li, Jize Zhao, Jinbin Li, Qiang Luo | &#160;&#160;The Kitaev magnets with bond&#45;dependent interactions have garnered&#10;considerable attention in recent years for their ability to harbor exotic&#10;phases and nontrivial excitations. The topological magnons, which are indicated&#10;by nonzero Chern number and thermal Hall conductivity, are proposed to&#10;partially explain thermal Hall measurements in real materials. Hitherto,&#10;topological magnons have been extensively explored when the magnetic field is&#10;normal to the honeycomb plane, but their topological characteristics are less&#10;studied in the presence of in&#45;plane magnetic field. Here, we study two distinct&#10;in&#45;plane field induced spin&#45;flop phases in the $Gamma$&#45;$Gamma&#39;$ model, both&#10;of which are off&#45;diagonal couplings that have intimate relation to the Kitaev&#10;interaction. The two spin&#45;flop phases are distinguished by their out&#45;of&#45;plane&#10;spin components which can be either antiparallel or parallel, thus dubbing&#10;antiferromagnetic (AFM) or ferromagnetic (FM) spin&#45;flop phases, respectively.&#10;We map out topological phase diagrams for both phases, revealing a rich pattern&#10;of the Chern number over exchange parameters and magnetic field. We&#10;analytically calculate the boundaries of topological phase transitions when the&#10;magnetic field is along the $a$ and $b$ directions. We find that the thermal&#10;Hall conductivity and its derivative display contrasting behaviors when&#10;crossing different topological phase transitions. The striking difference of&#10;the two phases lies in that when the magnetic field is along the $b$ direction,&#10;topological magnons are totally absent in the AFM spin&#45;flop phase, while they&#10;can survive in the FM analogue in certain parameter regions.&#10; | General | [Link](http://arxiv.org/abs/2409.10439v1) |&#10;| A functorial approach to $n$&#45;abelian categories | Vitor Gulisz | &#160;&#160;We develop a functorial approach to the study of $n$&#45;abelian categories by&#10;reformulating their axioms in terms of their categories of finitely presented&#10;functors. Such an approach allows the use of classical homological algebra and&#10;representation theory techniques to understand higher homological algebra. As&#10;an application, we present two possible generalizations of the axioms &quot;every&#10;monomorphism is a kernel&quot; and &quot;every epimorphism is a cokernel&quot; of an abelian&#10;category to $n$&#45;abelian categories. We also specialize our results to modules&#10;over rings, thereby describing when the category of finitely generated&#10;projective modules over a ring is $n$&#45;abelian. Moreover, we establish a&#10;correspondence for $n$&#45;abelian categories with additive generators, which&#10;extends the higher Auslander correspondence.&#10; | General | [Link](http://arxiv.org/abs/2409.10438v1) |&#10;| Color symmetry breaking in the Potts spin glass | Jean&#45;Christophe Mourrat | &#160;&#160;The Potts spin glass is an analogue of the Sherrington&#45;Kirkpatrick model in&#10;which each spin can take one of $kappa$ possible values, which we interpret as&#10;colors. It was suggested in arXiv:2310.06745 that the order parameter for this&#10;model is always invariant with respect to permutations of the colors. We show&#10;here that this is false whenever $kappa ge 58$.&#10; | General | [Link](http://arxiv.org/abs/2409.10437v1) |&#10;| Infector characteristics exposed by spatial analysis of SARS&#45;CoV&#45;2&#10; &#160;sequence and demographic data analysed at fine geographical scales | Anna Gama, Samantha Lycett, Will Harvey, Joseph Hughes, Sema Nickbakhsh, David L Robertson, Alison Smith Palmer, Anthony Wood, Rowland Kao | &#160;&#160;Characterising drivers of SARS&#45;CoV&#45;2 circulation is crucial for understanding&#10;COVID&#45;19 because of the severity of control measures adopted during the&#10;pandemic. Whole genome sequence data augmented with demographic metadata&#10;provides the best opportunity to do this. We use Random Forest Decision Tree&#10;models to analyse a combination of over 4000 SARS&#45;CoV2 sequences from a densely&#10;sampled, mixed urban and rural population (Tayside) in Scotland in the period&#10;from August 2020 to July 2021, with fine scale geographical and&#10;socio&#45;demographic metadata. Comparing periods in versus out of &quot;lockdown&quot;&#10;restrictions, we show using genetic distance relationships that individuals&#10;from more deprived areas are more likely to get infected during lockdown but&#10;less likely to spread the infection further. As disadvantaged communities were&#10;the most affected by both COVID&#45;19 and its restrictions, our finding has&#10;important implications for informing future approaches to control future&#10;pandemics driven by similar respiratory infections.&#10; | General | [Link](http://arxiv.org/abs/2409.10436v1) |&#10;| A study of pure multi&#45;strange hadrons production in Pb+Pb collisions at&#10; &#160;LHC energies using HYDJET++ model | Gauri Devi, B. K. Singh | &#160;&#160;For the present work, we have used the HYDJET++ model to explore the&#10;production of pure multi&#45;strange hadrons in Pb+Pb collisions at&#10;$sqrt{s_{NN}}$= 2.76 TeV and $sqrt{s_{NN}}$= 5.02 TeV collision energies,&#10;respectively. We have simulated the $p_{T}$&#45;spectra and elliptic flow ($v_{2}$)&#10;of $phi$&#45;meson and $Omega$&#45;baryons comparing our results with ALICE&#10;experimental data and several phenomenological models (HIJING/$Boverline{B}$,&#10;VISHNU, EPOS, AMPT, and Krakow) across various centrality intervals.&#10;Additionally, we have calculated the nuclear modification factors ($R_{AA}$ and&#10;$R_{CP}$), which provide a perception of jet quenching phenomena. Hence, our&#10;findings enable the study of the energy and system dependence of $phi$ and&#10;$Omega$ hadrons production over a wide range of ultra&#45;relativistic collision&#10;energies. We also present the particle ratios ($Omega/phi$,&#10;$overline{Omega}^{+}/Omega^{&#45;}$, $Omega/pi$, and $phi/pi$), offering&#10;insights on the strangeness enhancement and chemical properties of the medium&#10;at both LHC collision energies.&#10; | General | [Link](http://arxiv.org/abs/2409.10435v1) |&#10;| Magnetic metamaterials by ion&#45;implantation | Christina Vantaraki, Petter Strm, Tuan T. Tran, Matas P. Grassi, Giovanni Fevola, Michael Foerster, Jerzy T. Sadowski, Daniel Primetzhofer, Vassilios Kapaklis | &#160;&#160;We present a method for the additive fabrication of planar magnetic&#10;nanoarrays with minimal surface roughness. Synthesis is accomplished by&#10;combining electron&#45;beam lithography, used to generate nanometric patterned&#10;masks, with ion implantation in thin films. By implanting $^{56}$Fe$^{+}$ ions,&#10;we are able to introduce magnetic functionality in a controlled manner into&#10;continuous Pd thin films, achieving 3D spatial resolution down to a few tens of&#10;nanometers. Our results demonstrate the successful application of this&#10;technique in fabricating square artificial spin ice lattices, which exhibit&#10;well&#45;defined magnetization textures and interactions among the patterned&#10;magnetic elements.&#10; | General | [Link](http://arxiv.org/abs/2409.10433v1) |&#10;| Structure&#45;preserving learning for multi&#45;symplectic PDEs | Sleyman Yldz, Pawan Goyal, Peter Benner | &#160;&#160;This paper presents an energy&#45;preserving machine learning method for&#10;inferring reduced&#45;order models (ROMs) by exploiting the multi&#45;symplectic form&#10;of partial differential equations (PDEs). The vast majority of&#10;energy&#45;preserving reduced&#45;order methods use symplectic Galerkin projection to&#10;construct reduced&#45;order Hamiltonian models by projecting the full models onto a&#10;symplectic subspace. However, symplectic projection requires the existence of&#10;fully discrete operators, and in many cases, such as black&#45;box PDE solvers,&#10;these operators are inaccessible. In this work, we propose an energy&#45;preserving&#10;machine learning method that can infer the dynamics of the given PDE using data&#10;only, so that the proposed framework does not depend on the fully discrete&#10;operators. In this context, the proposed method is non&#45;intrusive. The proposed&#10;method is grey box in the sense that it requires only some basic knowledge of&#10;the multi&#45;symplectic model at the partial differential equation level. We prove&#10;that the proposed method satisfies spatially discrete local energy conservation&#10;and preserves the multi&#45;symplectic conservation laws. We test our method on the&#10;linear wave equation, the Korteweg&#45;de Vries equation, and the&#10;Zakharov&#45;Kuznetsov equation. We test the generalization of our learned models&#10;by testing them far outside the training time interval.&#10; | General | [Link](http://arxiv.org/abs/2409.10432v1) |&#10;| Hippocampal synchronization in a realistic CA1 neuron model | Alessandro Fiasconaro, Michele Migliore | &#160;&#160;This work delves into studying the synchronization in two realistic neuron&#10;models using Hodgkin&#45;Huxley dynamics. Unlike simplistic point&#45;like models,&#10;excitatory synapses are here randomly distributed along the dendrites,&#10;introducing strong stochastic contributions into their signal propagation. To&#10;focus on the role of different excitatory positions, we use two copies of the&#10;same neuron whose synapses are located at different distances from the soma and&#10;are exposed to identical Poissonian distributed current pulses. The&#10;synchronization is investigated through a specifically defined spiking&#10;correlation function, and its behavior is analyzed as a function of several&#10;parameters: inhibition weight, distance from the soma of one synaptic group,&#10;excitatory inactivation delay, and weight of the excitatory synapses.&#10; | General | [Link](http://arxiv.org/abs/2409.10431v1) |&#10;| Meta&#45;Whisper: Speech&#45;Based Meta&#45;ICL for ASR on Low&#45;Resource Languages | Ming&#45;Hao Hsu, Kuan Po Huang, Hung&#45;yi Lee | &#160;&#160;This paper presents Meta&#45;Whisper, a novel approach to improve automatic&#10;speech recognition (ASR) for low&#45;resource languages using the Whisper model. By&#10;leveraging Meta In&#45;Context Learning (Meta&#45;ICL) and a k&#45;Nearest Neighbors (KNN)&#10;algorithm for sample selection, Meta&#45;Whisper enhances Whisper&#39;s ability to&#10;recognize speech in unfamiliar languages without extensive fine&#45;tuning.&#10;Experiments on the ML&#45;SUPERB dataset show that Meta&#45;Whisper significantly&#10;reduces the Character Error Rate (CER) for low&#45;resource languages compared to&#10;the original Whisper model. This method offers a promising solution for&#10;developing more adaptable multilingual ASR systems, particularly for languages&#10;with limited resources.&#10; | General | [Link](http://arxiv.org/abs/2409.10429v1) |&#10;| User&#45;Authenticated Device&#45;Independent Quantum Secure Direct&#10; &#160;Communication Protocol | Nayana Das, Saikat Basu, Goutam Paul, Vijay S. Rao | &#160;&#160;Device&#45;Independent Quantum Secure Direct Communication (DI&#45;QSDC) enhances&#10;quantum cryptography by enabling secure message transmission without relying on&#10;the trustworthiness of the devices involved. This approach mitigates risks&#10;associated with compromised or untrusted devices, common in traditional quantum&#10;communication.&#10; &#160;In this paper, we propose the first of its kind DI&#45;QSDC protocol with user&#10;identity authentication. This ensures the authenticity of both the sender and&#10;receiver prior to message exchange. We then discuss the security of the&#10;proposed protocol against common attacks, demonstrating that no eavesdropper&#10;gains any information from either the quantum or the classical channel. Next,&#10;we implement the protocol on IBM&#39;s quantum hardware and evaluate its&#10;performance in a realistic noisy environment. Additionally, by simulating&#10;common attack models, we showcase that the protocol is secure against any&#10;eavesdropper in the channel. These findings highlight the protocol&#39;s robust&#10;security and practical feasibility for real&#45;world secure quantum communication.&#10; | General | [Link](http://arxiv.org/abs/2409.10427v1) |&#10;| Role of kinematic constraints in the time reversal symmetry breaking of&#10; &#160;a model active matter | Soumen Das, Shankar Ghosh, Tridib Sadhu, Juliane U Klamser | &#160;&#160;Active&#45;matter systems are inherently out&#45;of&#45;equilibrium and perform&#10;mechanical work by utilizing their internal energy sources. Breakdown of&#10;time&#45;reversal symmetry (BTRS) is a hallmark of such dissipative non&#45;equilibrium&#10;dynamics. We introduce a robust, experimentally accessible, noninvasive,&#10;quantitative measure of BTRS in terms of the Kullback&#45;Leibler divergence in&#10;collision events, demonstrated in our novel artificial active matter, comprised&#10;of battery&#45;powered spherical rolling robots whose energetics in different modes&#10;of motion can be measured with high precision. Our dimensionless measure&#10;characterizes how dissipation and internal energetics are influenced by&#10;kinematic constraints from interactions with the environment. We propose this&#10;measure of BTRS as an empirical estimate of the distance from equilibrium. An&#10;energetic insight into this departure of active matter from equilibrium comes&#10;from our demonstration of a non&#45;trivial fluctuation symmetry, which reveals a&#10;potentially universal thermodynamic characteristic of active energetics. As a&#10;many&#45;body consequence of BTRS in our experimental active system, we demonstrate&#10;the emergence of activity&#45;induced herding, which has no equilibrium analogue.&#10; | General | [Link](http://arxiv.org/abs/2409.10425v1) |&#10;| Unveiling V Modes: Enhancing CMB Sensitivity to BSM Physics with a&#10; &#160;Non&#45;Ideal Half&#45;Wave Plate | N. Raffuzzi, M. Lembo, S. Giardiello, M. Gerbino, M. Lattanzi, P. Natoli, L. Pagano | &#160;&#160;V&#45;mode polarization of the cosmic microwave background is expected to be&#10;vanishingly small in the $Lambda$CDM model and, hence, usually ignored.&#10;Nonetheless, several astrophysical effects, as well as beyond standard model&#10;physics could produce it at a detectable level. A realistic half&#45;wave plate &#45;&#10;an optical element commonly used in CMB experiments to modulate the polarized&#10;signal &#45; can provide sensitivity to V modes without significantly spoiling that&#10;to linear polarization. We assess this sensitivity for some new&#45;generation CMB&#10;experiments, such as the LiteBIRD satellite, the ground&#45;based Simons&#10;Observatory and a CMB&#45;S4&#45;like experiment. We forecast the efficiency of these&#10;experiments to constrain the phenomenology of certain classes of BSM models&#10;inducing mixing of linear polarization states and generation of V modes in the&#10;CMB. We find that new&#45;generation experiments can improve current limits by&#10;1&#45;to&#45;3 orders of magnitude, depending on the data combination. The inclusion of&#10;V&#45;mode information dramatically boosts the sensitivity to these BSM models.&#10; | General | [Link](http://arxiv.org/abs/2409.10424v1) |&#10;| Initial data for a deformed isolated horizon | Ale Flandera, David Kofro, Tom Ledvinka | &#160;&#160;Within the isolated horizon formalism, we investigate a static axisymmetric&#10;space&#45;time of a black hole influenced by matter in its neighborhood. To&#10;illustrate the role of ingredients and assumptions in this formalism, we first&#10;show how, in spherical symmetry, the field equations and gauge conditions imply&#10;the isolated horizon initial data leading to the Schwarzschild space&#45;time.&#10;Then, we construct the initial data for a static axisymmetric isolated horizon&#10;representing a deformed black hole. The space&#45;time description in the&#10;Bondi&#45;like coordinates is then found as a series expansion in the vicinity of&#10;the horizon. To graphically illustrate this construction, we also find a&#10;numerical solution for a black hole deformed by a particular analytic model of&#10;a thin accretion disk. We also discuss how an accretion disk affects the&#10;analytical properties of the horizon geometry.&#10; | General | [Link](http://arxiv.org/abs/2409.10423v1) |&#10;| Learning Semi&#45;Supervised Medical Image Segmentation from Spatial&#10; &#160;Registration | Qianying Liu, Paul Henderson, Xiao Gu, Hang Dai, Fani Deligianni | &#160;&#160;Semi&#45;supervised medical image segmentation has shown promise in training&#10;models with limited labeled data and abundant unlabeled data. However,&#10;state&#45;of&#45;the&#45;art methods ignore a potentially valuable source of unsupervised&#10;semantic information &#45;&#45; spatial registration transforms between image volumes.&#10;To address this, we propose CCT&#45;R, a contrastive cross&#45;teaching framework&#10;incorporating registration information. To leverage the semantic information&#10;available in registrations between volume pairs, CCT&#45;R incorporates two&#10;proposed modules: Registration Supervision Loss (RSL) and Registration&#45;Enhanced&#10;Positive Sampling (REPS). The RSL leverages segmentation knowledge derived from&#10;transforms between labeled and unlabeled volume pairs, providing an additional&#10;source of pseudo&#45;labels. REPS enhances contrastive learning by identifying&#10;anatomically&#45;corresponding positives across volumes using registration&#10;transforms. Experimental results on two challenging medical segmentation&#10;benchmarks demonstrate the effectiveness and superiority of CCT&#45;R across&#10;various semi&#45;supervised settings, with as few as one labeled case. Our code is&#10;available at&#10;https://github.com/kathyliu579/ContrastiveCross&#45;teachingWithRegistration.&#10; | General | [Link](http://arxiv.org/abs/2409.10422v1) |&#10;| Multidimensional Deconvolution with Profiling | Huanbiao Zhu, Krish Desai, Mikael Kuusela, Vinicius Mikuni, Benjamin Nachman, Larry Wasserman | &#160;&#160;In many experimental contexts, it is necessary to statistically remove the&#10;impact of instrumental effects in order to physically interpret measurements.&#10;This task has been extensively studied in particle physics, where the&#10;deconvolution task is called unfolding. A number of recent methods have shown&#10;how to perform high&#45;dimensional, unbinned unfolding using machine learning.&#10;However, one of the assumptions in all of these methods is that the detector&#10;response is accurately modeled in the Monte Carlo simulation. In practice, the&#10;detector response depends on a number of nuisance parameters that can be&#10;constrained with data. We propose a new algorithm called Profile OmniFold&#10;(POF), which works in a similar iterative manner as the OmniFold (OF) algorithm&#10;while being able to simultaneously profile the nuisance parameters. We&#10;illustrate the method with a Gaussian example as a proof of concept&#10;highlighting its promising capabilities.&#10; | General | [Link](http://arxiv.org/abs/2409.10421v1) |&#10;| HiFi&#45;CS: Towards Open Vocabulary Visual Grounding For Robotic Grasping&#10; &#160;Using Vision&#45;Language Models | Vineet Bhat, Prashanth Krishnamurthy, Ramesh Karri, Farshad Khorrami | &#160;&#160;Robots interacting with humans through natural language can unlock numerous&#10;applications such as Referring Grasp Synthesis (RGS). Given a text query, RGS&#10;determines a stable grasp pose to manipulate the referred object in the robot&#39;s&#10;workspace. RGS comprises two steps: visual grounding and grasp pose estimation.&#10;Recent studies leverage powerful Vision&#45;Language Models (VLMs) for visually&#10;grounding free&#45;flowing natural language in real&#45;world robotic execution.&#10;However, comparisons in complex, cluttered environments with multiple instances&#10;of the same object are lacking. This paper introduces HiFi&#45;CS, featuring&#10;hierarchical application of Featurewise Linear Modulation (FiLM) to fuse image&#10;and text embeddings, enhancing visual grounding for complex attribute rich text&#10;queries encountered in robotic grasping. Visual grounding associates an object&#10;in 2D/3D space with natural language input and is studied in two scenarios:&#10;Closed and Open Vocabulary. HiFi&#45;CS features a lightweight decoder combined&#10;with a frozen VLM and outperforms competitive baselines in closed vocabulary&#10;settings while being 100x smaller in size. Our model can effectively guide&#10;open&#45;set object detectors like GroundedSAM to enhance open&#45;vocabulary&#10;performance. We validate our approach through real&#45;world RGS experiments using&#10;a 7&#45;DOF robotic arm, achieving 90.33% visual grounding accuracy in 15 tabletop&#10;scenes. We include our codebase in the supplementary material.&#10; | General | [Link](http://arxiv.org/abs/2409.10419v1) |&#10;| X&#45;ray reverberation as an explanation for UV/optical variability in&#10; &#160;nearby Seyferts | M. Papoutsis, I. E. Papadakis, C. Panagiotou, M. Doviak, E. Kammoun | &#160;&#160;Active galactic nuclei (AGNs) are known to be variable across all&#10;wavelengths. Significant observational efforts have been invested in the last&#10;decade in studying their ultraviolet (UV) and optical variability. Long and&#10;densely sampled, multi&#45;wavelength monitoring campaigns of numerous Seyfert&#10;galaxies have been conducted with the aim of determining the X&#45;ray/UV/optical&#10;continuum time lags. Time&#45;lag studies can be used to constrain theoretical&#10;models. The observed time lags can be explained by thermal reprocessing of the&#10;X&#45;rays illuminating the accretion disc (known as the X&#45;ray reverberation&#10;model). However, the observed light curves contain more information that can be&#10;used to further constrain physical models. Our primary objective is to&#10;investigate whether, in addition to time lags, the X&#45;ray reverberation model&#10;can also explain the UV/optical variability amplitude of nearby Seyferts. To do&#10;this, we measured the excess variance of four sources (namely Mrk 509, NGC&#10;4151, NGC 2617, and Mrk 142) as a function of wavelength using data from&#10;archival long, multi&#45;wavelength campaigns with Swift, and ground&#45;based&#10;telescopes. We also computed the model excess variance in the case of the X&#45;ray&#10;reverberation model by determining the disc&#39;s transfer function and assuming a&#10;bending power law for the X&#45;ray power spectrum. We tested the validity of the&#10;model by comparing the measured and model variances for a range of accretion&#10;rates and X&#45;ray source heights. We conclude that the X&#45;ray thermal&#10;reverberation model can fit both the continuum, UV/optical time lags, as well&#10;as the variance in these AGNs, for the same physical parameters. Our results&#10;suggest that the accretion disc is constant and that all the observed&#10;UV/optical variations, on timescales of days and up to a few weeks, can be&#10;fully explained by the variable X&#45;rays as they illuminate the accretion disc.&#10; | General | [Link](http://arxiv.org/abs/2409.10417v1) |&#10;| Local central limit theorem for Mallows measure | Alexey Bufetov, Kailun Chen | &#160;&#160;We study the statistics of the Mallows measure on permutations in the limit&#10;pioneered by Starr (2009). Our main result is the local central limit theorem&#10;for its height function. We also re&#45;derive versions of the law of large numbers&#10;and the large deviation principle, obtain the standard central limit theorem&#10;from the local one, and establish a multi&#45;point version of the local central&#10;limit theorem.&#10; | General | [Link](http://arxiv.org/abs/2409.10415v1) |&#10;| On interactive anisotropic walks in two dimensions generated from a&#10; &#160;three state opinion dynamics model | Surajit Saha, Parongama Sen | &#160;&#160;A system of interacting walkers on a two&#45;dimensional space where the dynamics&#10;of each walker are governed by the opinions of agents of a three&#45;state opinion&#10;dynamics model are considered. Such walks, inspired by Ising&#45;like models and&#10;opinions dynamics models, are usually considered in one&#45;dimensional virtual&#10;spaces. Here, the mapping is done in such a way that the walk is directed along&#10;the $y$ axis while it can move either way along the $x$ axis. We explore the&#10;properties of such walks as the parameter representing the noise in the opinion&#10;dynamics model, responsible for a continuous phase transition, is varied. The&#10;walk features show marked differences as the system crosses the critical point.&#10;The bivariate distribution of the displacements below the critical point is a&#10;modified biased Gaussian function of x and y which is symmetric about the X&#10;axis.&#10; &#160;The marginal probability distributions can be extracted and the scaling forms&#10;of different quantities, showing power law behaviour, are obtained. The&#10;directed nature of the walk is reflected in the marginal distributions as well&#10;as in the exponents.&#10; | General | [Link](http://arxiv.org/abs/2409.10413v1) |&#10;| A Large&#45;Scale Privacy Assessment of Android Third&#45;Party SDKs | Mark Huasong Meng, Chuan Yan, Yun Hao, Qing Zhang, Zeyu Wang, Kailong Wang, Sin Gee Teo, Guangdong Bai, Jin Song Dong | &#160;&#160;Third&#45;party Software Development Kits (SDKs) are widely adopted in Android&#10;app development, to effortlessly accelerate development pipelines and enhance&#10;app functionality. However, this convenience raises substantial concerns about&#10;unauthorized access to users&#39; privacy&#45;sensitive information, which could be&#10;further abused for illegitimate purposes like user tracking or monetization.&#10;Our study offers a targeted analysis of user privacy protection among Android&#10;third&#45;party SDKs, filling a critical gap in the Android software supply chain.&#10;It focuses on two aspects of their privacy practices, including data&#10;exfiltration and behavior&#45;policy compliance (or privacy compliance), utilizing&#10;techniques of taint analysis and large language models. It covers 158&#10;widely&#45;used SDKs from two key SDK release platforms, the official one and a&#10;large alternative one. From them, we identified 338 instances of privacy data&#10;exfiltration. On the privacy compliance, our study reveals that more than 30%&#10;of the examined SDKs fail to provide a privacy policy to disclose their data&#10;handling practices. Among those that provide privacy policies, 37% of them&#10;over&#45;collect user data, and 88% falsely claim access to sensitive data. We&#10;revisit the latest versions of the SDKs after 12 months. Our analysis&#10;demonstrates a persistent lack of improvement in these concerning trends. Based&#10;on our findings, we propose three actionable recommendations to mitigate the&#10;privacy leakage risks and enhance privacy protection for Android users. Our&#10;research not only serves as an urgent call for industry attention but also&#10;provides crucial insights for future regulatory interventions.&#10; | General | [Link](http://arxiv.org/abs/2409.10411v1) |&#10;| A point process approach for the classification of noisy calcium imaging&#10; &#160;data | Arianna Burzacchi, Nicoletta D&#39;Angelo, David Payares&#45;Garcia, Jorge Mateu | &#160;&#160;We study noisy calcium imaging data, with a focus on the classification of&#10;spike traces. As raw traces obscure the true temporal structure of neuron&#39;s&#10;activity, we performed a tuned filtering of the calcium concentration using two&#10;methods: a biophysical model and a kernel mapping. The former characterizes&#10;spike trains related to a particular triggering event, while the latter filters&#10;out the signal and refines the selection of the underlying neuronal response.&#10;Transitioning from traditional time series analysis to point process theory,&#10;the study explores spike&#45;time distance metrics and point pattern prototypes to&#10;describe repeated observations. We assume that the analyzed neuron&#39;s firing&#10;events, i.e. spike occurrences, are temporal point process events. In&#10;particular, the study aims to categorize 47 point patterns by depth, assuming&#10;the similarity of spike occurrences within specific depth categories. The&#10;results highlight the pivotal roles of depth and stimuli in discerning diverse&#10;temporal structures of neuron firing events, confirming the point process&#10;approach based on prototype analysis is largely useful in the classification of&#10;spike traces.&#10; | General | [Link](http://arxiv.org/abs/2409.10409v1) |&#10;| Variational closures for composite homogenised fluid flows | Theo Diamantakis, Ruiao Hu | &#160;&#160;The Stochastic Advection by Lie Transport is a variational formulation of&#10;stochastic fluid dynamics introduced to model the effects of unresolved scales,&#10;whilst preserving the geometric structure of ideal fluid flows. In this work,&#10;we show that the SALT equations can arise from the decomposition of the fluid&#10;flow map into its mean and fluctuating components. The fluctuating component is&#10;realised as a prescribed stochastic diffeomorphism that introduces stochastic&#10;transport into the system and we construct it using homogenisation theory. The&#10;dynamics of the mean component are derived from a variational principle&#10;utilising particular forms of variations that preserve the composite structure&#10;of the flow. Using a new variational principle, we show that SALT equations can&#10;arise from random Lagrangians and are equivalent to random coefficient PDEs. We&#10;also demonstrate how to modify the composite flow and the associated&#10;variational principle to derive models inspired by the Lagrangian Averaged&#10;Euler&#45;Poincare (LAEP) theory.&#10; | General | [Link](http://arxiv.org/abs/2409.10408v1) |&#10;| Bitcoin Transaction Behavior Modeling Based on Balance Data | Yu Zhang, Claudio Tessone | &#160;&#160;When analyzing Bitcoin users&#39; balance distribution, we observed that it&#10;follows a log&#45;normal pattern. Drawing parallels from the successful application&#10;of Gibrat&#39;s law of proportional growth in explaining city size and word&#10;frequency distributions, we tested whether the same principle could account for&#10;the log&#45;normal distribution in Bitcoin balances. However, our calculations&#10;revealed that the exponent parameters in both the drift and variance terms&#10;deviate slightly from one. This suggests that Gibrat&#39;s proportional growth rule&#10;alone does not fully explain the log&#45;normal distribution observed in Bitcoin&#10;users&#39; balances. During our exploration, we discovered an intriguing&#10;phenomenon: Bitcoin users tend to fall into two distinct categories based on&#10;their behavior, which we refer to as ``poor&quot; and ``wealthy&quot; users. Poor users,&#10;who initially purchase only a small amount of Bitcoin, tend to buy more&#10;bitcoins first and then sell out all their holdings gradually over time. The&#10;certainty of selling all their coins is higher and higher with time. In&#10;contrast, wealthy users, who acquire a large amount of Bitcoin from the start,&#10;tend to sell off their holdings over time. The speed at which they sell their&#10;bitcoins is lower and lower over time and they will hold at least a small part&#10;of their initial holdings at last. Interestingly, the wealthier the user, the&#10;larger the proportion of their balance and the higher the certainty they tend&#10;to sell. This research provided an interesting perspective to explore bitcoin&#10;users&#39; behaviors which may apply to other finance markets.&#10; | General | [Link](http://arxiv.org/abs/2409.10407v1) |&#10;| Stochastic Data&#45;Driven Predictive Control: Chance&#45;Constraint&#10; &#160;Satisfaction with Identified Multi&#45;step Predictors | Haldun Balim, Andrea Carron, Melanie N. Zeilinger, Johannes Khler | &#160;&#160;We propose a novel data&#45;driven stochastic model predictive control framework&#10;for uncertain linear systems with noisy output measurements. Our approach&#10;leverages multi&#45;step predictors to efficiently propagate uncertainty, ensuring&#10;chance constraint satisfaction with minimal conservatism. In particular, we&#10;present a strategy to identify multi&#45;step predictors and quantify the&#10;associated uncertainty using a surrogate (data&#45;driven) state space model. Then,&#10;we utilize the derived distribution to formulate a constraint tightening that&#10;ensures chance constraint satisfaction. A numerical example highlights the&#10;reduced conservatism of handling parametric uncertainty in the proposed method&#10;compared to state&#45;of&#45;the&#45;art solutions.&#10; | General | [Link](http://arxiv.org/abs/2409.10405v1) |&#10;| A Knowledge&#45;Enhanced Disease Diagnosis Method Based on Prompt Learning&#10; &#160;and BERT Integration | Zhang Zheng | &#160;&#160;This paper proposes a knowledge&#45;enhanced disease diagnosis method based on a&#10;prompt learning framework. The method retrieves structured knowledge from&#10;external knowledge graphs related to clinical cases, encodes it, and injects it&#10;into the prompt templates to enhance the language model&#39;s understanding and&#10;reasoning capabilities for the task.We conducted experiments on three public&#10;datasets: CHIP&#45;CTC, IMCS&#45;V2&#45;NER, and KUAKE&#45;QTR. The results show that the&#10;proposed method significantly outperforms existing models across multiple&#10;evaluation metrics, with an F1 score improvement of 2.4% on the CHIP&#45;CTC&#10;dataset, 3.1% on the IMCS&#45;V2&#45;NER dataset,and 4.2% on the KUAKE&#45;QTR dataset.&#10;Additionally,ablation studies confirmed the critical role of the knowledge&#10;injection module,as the removal of this module resulted in a significant drop&#10;in F1 score. The experimental results demonstrate that the proposed method not&#10;only effectively improves the accuracy of disease diagnosis but also enhances&#10;the interpretability of the predictions, providing more reliable support and&#10;evidence for clinical diagnosis.&#10; | General | [Link](http://arxiv.org/abs/2409.10403v1) |&#10;| A Statistical Equilibrium Approach to Adam Smith&#39;s Labor Theory of Value | Ellis Scharfenaker, Bruno Theodosio, Duncan K. Foley | &#160;&#160;Adam Smith&#39;s inquiry into the emergence and stability of the&#10;self&#45;organization of the division of labor in commodity production and exchange&#10;is considered using statistical equilibrium methods from statistical physics.&#10;We develop a statistical equilibrium model of the distribution of independent&#10;direct producers in a hub&#45;and&#45;spoke framework that predicts both the center of&#10;gravity of producers across lines of production as well as the endogenous&#10;fluctuations between lines of production that arise from Smith&#39;s concept of&#10;&quot;perfect liberty&quot;. The ergodic distribution of producers implies a long&#45;run&#10;balancing of &quot;advantages to disadvantages&quot; across lines of employment and&#10;gravitation of market prices around Smith&#39;s natural prices.&#10; | General | [Link](http://arxiv.org/abs/2409.10402v1) |&#10;| Hydrodynamic mechanism for stable spindle positioning in meiosis II&#10; &#160;oocytes | Weida Liao, Eric Lauga | &#160;&#160;Cytoplasmic streaming, the persistent flow of fluid inside a cell, induces&#10;intracellular transport, which plays a key role in fundamental biological&#10;processes. In meiosis II mouse oocytes (developing egg cells) awaiting&#10;fertilisation, the spindle, which is the protein structure responsible for&#10;dividing genetic material in a cell, must maintain its position near the cell&#10;cortex (the thin actin network bound to the cell membrane) for many hours.&#10;However, the cytoplasmic streaming that accompanies this stable positioning&#10;would intuitively appear to destabilise the spindle position. Here, through a&#10;combination of numerical and analytical modelling, we reveal a new,&#10;hydrodynamic mechanism for stable spindle positioning beneath the cortical cap.&#10;We show that this stability depends critically on the spindle size and the&#10;active driving from the cortex, and demonstrate that stable spindle positioning&#10;can result purely from a hydrodynamic suction force exerted on the spindle by&#10;the cytoplasmic flow. Our findings show that local fluid dynamic forces can be&#10;sufficient to stabilise the spindle, explaining robustness against&#10;perturbations not only perpendicular but also parallel to the cortex. Our&#10;results shed light on the importance of cytoplasmic streaming in mammalian&#10;meiosis.&#10; | General | [Link](http://arxiv.org/abs/2409.10401v1) |&#10;| Sherpa: An Open Source Python Fitting Package | Aneta Siemiginowska, Douglas Burke, Hans Moritz Gnther, Nicholas P. Lee, Warren McLaughlin, David A. Principe, Harlan Cheer, Antonella Fruscione, Omar Laurino, Jonathan McDowell, Marie Terrell | &#160;&#160;We present an overview of Sherpa, an open source Python project, and discuss&#10;its development history, broad design concepts and capabilities. Sherpa&#10;contains powerful tools for combining parametric models into complex&#10;expressions that can be fit to data using a variety of statistics and&#10;optimization methods. It is easily extensible to include user&#45;defined models,&#10;statistics, and optimization methods. It provides a high&#45;level User Interface&#10;for interactive data&#45;analysis, such as within a Jupyter notebook, and it can&#10;also be used as a library component, providing fitting and modeling&#10;capabilities to an application. We include a few examples of Sherpa&#10;applications to multiwavelength astronomical data. The code is available&#10;GitHub: https://github.com/sherpa/sherpa&#10; | General | [Link](http://arxiv.org/abs/2409.10400v1) |&#10;| Minimally coupled $$&#45;exponential inflation with an $R^2$ term in&#10; &#160;the Palatini formulation | Nilay Bostan, Rafid H. Dejrah | &#160;&#160;We focus on the inflationary predictions of $beta$&#45;exponential potential&#10;models, in which the inflaton is a representation of the field delineating the&#10;size of extra&#45;dimension. Since it offers a well&#45;motivated starting point for&#10;the study of physics at very high energies, we incorporate an $R^2$ term in the&#10;Palatini gravity. In addition, afterward the inflation, the inflaton oscillates&#10;about the minimum of the inflation potential, and reheats the universe. This&#10;occurs during the reheating phase, at which the inflaton decays into the&#10;standard model particles, which fill the universe. We extend our examination by&#10;considering the reheating effects on inflationary observables by employing the&#10;different scenarios of the reheat temperature. Supposing the standard thermal&#10;history after inflation, we display the inflationary predictions, $n_s, r,&#10;mathrm{d}n_s/mathrm{d}&#10;n k$ of $beta$&#45;exponential potential with minimal&#10;coupling in Palatini $R^2$ gravity. Also, different kinds of constraints from a&#10;variety of observations, such as BICEP/Keck, Planck 2018, as well as future&#10;possible detectable sensitivities that might be reached by CMB experiments:&#10;CMB&#45;S4 and LiteBIRD are taken into account in this work. We indicate that our&#10;results are consistent with both the latest data and the future sensitivity&#10;forecasts of LiteBIRD/Planck and CMB&#45;S4. Finally, the results in this study&#10;highlight the viability of our model even in the case of the existence of more&#10;stringent constraints expected from future achievable confidence level limits.&#10; | General | [Link](http://arxiv.org/abs/2409.10398v1) |&#10;| Quantifying Observational Projection Effects with a Simulation&#45;based hot&#10; &#160;CGM model | Soumya Shreeram, Johan Comparat, Andrea Merloni, Yi Zhang, Gabriele Ponti, Kirpal Nandra, John ZuHone, Ilaria Marini, Stephan Vladutescu&#45;Zopp, Paola Popesso, Ruediger Pakmor, Riccardo Seppi, Celine Peroux, Daniele Sorini | &#160;&#160;The hot phase of the circumgalactic medium (CGM) allows us to probe the&#10;inflow and outflow of gas within a galaxy, which is responsible for dictating&#10;the evolution of the galaxy. Studying the hot CGM sheds light on a better&#10;understanding of gas physics, which is crucial to inform and constrain&#10;simulation models. With the recent advances in observational measurements&#10;probing the hot CGM in X&#45;rays and tSZ, we have a new avenue for widening our&#10;knowledge of gas physics and feedback by exploiting the information from&#10;current/future observations. In this paper, we use the TNG300 hydrodynamical&#10;simulations to build a fully self&#45;consistent forward model for the hot CGM. We&#10;construct a lightcone and generate mock X&#45;ray observations. We quantify the&#10;projection effects, namely the locally correlated large&#45;scale structure in&#10;X&#45;rays and the effect due to satellite galaxies misclassified as centrals which&#10;affects the measured hot CGM galactocentric profiles in stacking experiments.&#10;We present an analytical model that describes the intrinsic X&#45;ray surface&#10;brightness profile across the stellar and halo mass bins. The increasing&#10;stellar mass bins result in decreasing values of $beta$, the exponent&#10;quantifying the slope of the intrinsic galactocentric profiles. We carry&#10;forward the current state&#45;of&#45;the&#45;art by also showing the impact of the locally&#10;correlated environment on the measured X&#45;ray surface brightness profiles. We&#10;also present, for the first time, the effect of misclassified centrals in&#10;stacking experiments for three stellar mass bins: $10^{10.5&#45;11} M_odot$,&#10;$10^{11&#45;11.2} M_odot$, and $10^{11.2&#45;11.5} M_odot$. We find that the&#10;contaminating effect of the misclassified centrals on the stacked profiles&#10;increases when the stellar mass decreases.&#10; | General | [Link](http://arxiv.org/abs/2409.10397v1) |&#10;| MOST: MR reconstruction Optimization for multiple downStream Tasks via&#10; &#160;continual learning | Hwihun Jeong, Se Young Chun, Jongho Lee | &#160;&#160;Deep learning&#45;based Magnetic Resonance (MR) reconstruction methods have&#10;focused on generating high&#45;quality images but they often overlook the impact on&#10;downstream tasks (e.g., segmentation) that utilize the reconstructed images.&#10;Cascading separately trained reconstruction network and downstream task network&#10;has been shown to introduce performance degradation due to error propagation&#10;and domain gaps between training datasets. To mitigate this issue, downstream&#10;task&#45;oriented reconstruction optimization has been proposed for a single&#10;downstream task. Expanding this optimization to multi&#45;task scenarios is not&#10;straightforward. In this work, we extended this optimization to sequentially&#10;introduced multiple downstream tasks and demonstrated that a single MR&#10;reconstruction network can be optimized for multiple downstream tasks by&#10;deploying continual learning (MOST). MOST integrated techniques from&#10;replay&#45;based continual learning and image&#45;guided loss to overcome catastrophic&#10;forgetting. Comparative experiments demonstrated that MOST outperformed a&#10;reconstruction network without finetuning, a reconstruction network with&#10;na&quot;ive finetuning, and conventional continual learning methods. This&#10;advancement empowers the application of a single MR reconstruction network for&#10;multiple downstream tasks. The source code is available at:&#10;https://github.com/SNU&#45;LIST/MOST&#10; | General | [Link](http://arxiv.org/abs/2409.10394v1) |&#10;| Multicopy quantum state teleportation with application to storage and&#10; &#160;retrieval of quantum programs | Frdric Grosshans, Micha Horodecki, Mio Murao, Tomasz Mynik, Marco Tlio Quintino, Micha Studziski, Satoshi Yoshida | &#160;&#160;This work considers a teleportation task for Alice and Bob in a scenario&#10;where Bob cannot perform corrections. In particular, we analyse the task of&#10;textit{multicopy state teleportation}, where Alice has $k$ identical copies of&#10;an arbitrary unknown $d$&#45;dimensional qudit state $vertpsi&#13;angle$ to teleport&#10;a single copy of $vertpsi&#13;angle$ to Bob using a maximally entangled&#10;two&#45;qudit state shared between Alice and Bob without Bob&#39;s correction. Alice&#10;may perform a joint measurement on her half of the entangled state and the $k$&#10;copies of $vertpsi&#13;angle$. We prove that the maximal probability of success&#10;for teleporting the exact state $vertpsi&#13;angle$ to Bob is&#10;$p(d,k)=frac{k}{d(k&#45;1+d)}$ and present an explicit protocol to attain this&#10;performance. Then, by utilising $k$ copies of an arbitrary target state&#10;$vertpsi&#13;angle$, we show how the multicopy state teleportation protocol can&#10;be employed to enhance the success probability of storage and retrieval of&#10;quantum programs, which aims to universally retrieve the action of an arbitrary&#10;quantum channel that is stored in a state. Our proofs make use of group&#10;representation theory methods, which may find applications beyond the problems&#10;addressed in this work.&#10; | General | [Link](http://arxiv.org/abs/2409.10393v1) |&#10;| TPFL: Tsetlin&#45;Personalized Federated Learning with Confidence&#45;Based&#10; &#160;Clustering | Rasoul Jafari Gohari, Laya Aliahmadipour, Ezat Valipour | &#160;&#160;The world of Machine Learning (ML) has witnessed rapid changes in terms of&#10;new models and ways to process users data. The majority of work that has been&#10;done is focused on Deep Learning (DL) based approaches. However, with the&#10;emergence of new algorithms such as the Tsetlin Machine (TM) algorithm, there&#10;is growing interest in exploring alternative approaches that may offer unique&#10;advantages in certain domains or applications. One of these domains is&#10;Federated Learning (FL), in which users privacy is of utmost importance. Due to&#10;its novelty, FL has seen a surge in the incorporation of personalization&#10;techniques to enhance model accuracy while maintaining user privacy under&#10;personalized conditions. In this work, we propose a novel approach dubbed TPFL:&#10;Tsetlin&#45;Personalized Federated Learning, in which models are grouped into&#10;clusters based on their confidence towards a specific class. In this way,&#10;clustering can benefit from two key advantages. Firstly, clients share only&#10;what they are confident about, resulting in the elimination of wrongful weight&#10;aggregation among clients whose data for a specific class may have not been&#10;enough during the training. This phenomenon is prevalent when the data are&#10;non&#45;Independent and Identically Distributed (non&#45;IID). Secondly, by sharing&#10;only weights towards a specific class, communication cost is substantially&#10;reduced, making TPLF efficient in terms of both accuracy and communication&#10;cost. The results of TPFL demonstrated the highest accuracy on three different&#10;datasets; namely MNIST, FashionMNIST and FEMNIST.&#10; | General | [Link](http://arxiv.org/abs/2409.10392v1) |&#10;| Prompt&#45;and&#45;Transfer: Dynamic Class&#45;aware Enhancement for Few&#45;shot&#10; &#160;Segmentation | Hanbo Bi, Yingchao Feng, Wenhui Diao, Peijin Wang, Yongqiang Mao, Kun Fu, Hongqi Wang, Xian Sun | &#160;&#160;For more efficient generalization to unseen domains (classes), most Few&#45;shot&#10;Segmentation (FSS) would directly exploit pre&#45;trained encoders and only&#10;fine&#45;tune the decoder, especially in the current era of large models. However,&#10;such fixed feature encoders tend to be class&#45;agnostic, inevitably activating&#10;objects that are irrelevant to the target class. In contrast, humans can&#10;effortlessly focus on specific objects in the line of sight. This paper mimics&#10;the visual perception pattern of human beings and proposes a novel and powerful&#10;prompt&#45;driven scheme, called ``Prompt and Transfer&quot; (PAT), which constructs a&#10;dynamic class&#45;aware prompting paradigm to tune the encoder for focusing on the&#10;interested object (target class) in the current task. Three key points are&#10;elaborated to enhance the prompting: 1) Cross&#45;modal linguistic information is&#10;introduced to initialize prompts for each task. 2) Semantic Prompt Transfer&#10;(SPT) that precisely transfers the class&#45;specific semantics within the images&#10;to prompts. 3) Part Mask Generator (PMG) that works in conjunction with SPT to&#10;adaptively generate different but complementary part prompts for different&#10;individuals. Surprisingly, PAT achieves competitive performance on 4 different&#10;tasks including standard FSS, Cross&#45;domain FSS (e.g., CV, medical, and remote&#10;sensing domains), Weak&#45;label FSS, and Zero&#45;shot Segmentation, setting new&#10;state&#45;of&#45;the&#45;arts on 11 benchmarks.&#10; | General | [Link](http://arxiv.org/abs/2409.10389v1) |&#10;| Revising the Structure of Recurrent Neural Networks to Eliminate&#10; &#160;Numerical Derivatives in Forming Physics Informed Loss Terms with Respect to&#10; &#160;Time | Mahyar Jahani&#45;nasab, Mohamad Ali Bijarchi | &#160;&#160;Solving unsteady partial differential equations (PDEs) using recurrent neural&#10;networks (RNNs) typically requires numerical derivatives between each block of&#10;the RNN to form the physics informed loss function. However, this introduces&#10;the complexities of numerical derivatives into the training process of these&#10;models. In this study, we propose modifying the structure of the traditional&#10;RNN to enable the prediction of each block over a time interval, making it&#10;possible to calculate the derivative of the output with respect to time using&#10;the backpropagation algorithm. To achieve this, the time intervals of these&#10;blocks are overlapped, defining a mutual loss function between them.&#10;Additionally, the employment of conditional hidden states enables us to achieve&#10;a unique solution for each block. The forget factor is utilized to control the&#10;influence of the conditional hidden state on the prediction of the subsequent&#10;block. This new model, termed the Mutual Interval RNN (MI&#45;RNN), is applied to&#10;solve three different benchmarks: the Burgers equation, unsteady heat&#10;conduction in an irregular domain, and the Green vortex problem. Our results&#10;demonstrate that MI&#45;RNN can find the exact solution more accurately compared to&#10;existing RNN models. For instance, in the second problem, MI&#45;RNN achieved one&#10;order of magnitude less relative error compared to the RNN model with numerical&#10;derivatives.&#10; | General | [Link](http://arxiv.org/abs/2409.10388v1) |&#10;| Sharp decay rate for eigenfunctions of perturbed periodic Schrdinger&#10; &#160;operators | Wencai Liu, Rodrigo Matos, John N. Treuer | &#160;&#160;This paper investigates uniqueness results for perturbed periodic&#10;Schr&quot;odinger operators on $mathbb{Z}^d$. Specifically, we consider operators&#10;of the form $H = &#45;Delta + V + v$, where $Delta$ is the discrete Laplacian,&#10;$V: mathbb{Z}^d &#13;ightarrow mathbb{R}$ is a periodic potential, and $v:&#10;mathbb{Z}^d &#13;ightarrow mathbb{C}$ represents a decaying impurity. We&#10;establish quantitative conditions under which the equation $&#45;Delta u + V u + v&#10;u = &#10;ambda u$, for $&#10;ambda in mathbb{C}$, admits only the trivial solution&#10;$u equiv 0$. Key applications include the absence of embedded eigenvalues for&#10;operators with impurities decaying faster than any exponential function and the&#10;determination of sharp decay rates for eigenfunctions. Our findings extend&#10;previous works by providing precise decay conditions for impurities and&#10;analyzing different spectral regimes of $&#10;ambda$.&#10; | General | [Link](http://arxiv.org/abs/2409.10387v1) |&#10;| Mamba&#45;ST: State Space Model for Efficient Style Transfer | Filippo Botti, Alex Ergasti, Leonardo Rossi, Tomaso Fontanini, Claudio Ferrari, Massimo Bertozzi, Andrea Prati | &#160;&#160;The goal of style transfer is, given a content image and a style source,&#10;generating a new image preserving the content but with the artistic&#10;representation of the style source. Most of the state&#45;of&#45;the&#45;art architectures&#10;use transformers or diffusion&#45;based models to perform this task, despite the&#10;heavy computational burden that they require. In particular, transformers use&#10;self&#45; and cross&#45;attention layers which have large memory footprint, while&#10;diffusion models require high inference time. To overcome the above, this paper&#10;explores a novel design of Mamba, an emergent State&#45;Space Model (SSM), called&#10;Mamba&#45;ST, to perform style transfer. To do so, we adapt Mamba linear equation&#10;to simulate the behavior of cross&#45;attention layers, which are able to combine&#10;two separate embeddings into a single output, but drastically reducing memory&#10;usage and time complexity. We modified the Mamba&#39;s inner equations so to accept&#10;inputs from, and combine, two separate data streams. To the best of our&#10;knowledge, this is the first attempt to adapt the equations of SSMs to a vision&#10;task like style transfer without requiring any other module like&#10;cross&#45;attention or custom normalization layers. An extensive set of experiments&#10;demonstrates the superiority and efficiency of our method in performing style&#10;transfer compared to transformers and diffusion models. Results show improved&#10;quality in terms of both ArtFID and FID metrics. Code is available at&#10;https://github.com/FilippoBotti/MambaST.&#10; | General | [Link](http://arxiv.org/abs/2409.10385v1) |&#10;| Performance&#45;Portable Numerical Relativity with AthenaK | Hengrui Zhu, Jacob Fields, Francesco Zappa, David Radice, James Stone, Alireza Rashti, William Cook, Sebastiano Bernuzzi, Boris Daszuta | &#160;&#160;We present the numerical relativity module within AthenaK, an open source&#10;performance&#45;portable astrophysics code designed for exascale computing&#10;applications. This module employs the Z4c formulation to solve the Einstein&#10;equations. We demonstrate its accuracy through a series of standard numerical&#10;relativity tests, including convergence of the gravitational waveform from&#10;binary black hole coalescence. Furthermore, we conduct scaling tests on OLCF&#10;Frontier and NERSC Perlmutter, where AthenaK exhibits excellent weak scaling&#10;efficiency of 80% on up to 65,536 AMD MI250X GPUs on Frontier (relative to 4&#10;GPUs) and strong scaling efficiencies of 84% and 77% on AMD MI250X and NVIDIA&#10;A100 GPUs on Frontier and Perlmutter respectively. Additionally, we observe a&#10;significant performance boost, with two orders of magnitude speedup ($gtrsim&#10;200times$) on a GPU compared to a single CPU core, affirming that AthenaK is&#10;well&#45;suited for exascale computing, thereby expanding the potential for&#10;breakthroughs in numerical relativity research.&#10; | General | [Link](http://arxiv.org/abs/2409.10383v1) |&#10;| J&#45;UBIK: The JAX&#45;accelerated Universal Bayesian Imaging Kit | Vincent Eberle, Matteo Guardiani, Margret Westerkamp, Philipp Frank, Julian Rstig, Julia Stadler, Torsten A. Enlin | &#160;&#160;Many advances in astronomy and astrophysics originate from accurate images of&#10;the sky emission across multiple wavelengths. This often requires&#10;reconstructing spatially and spectrally correlated signals detected from&#10;multiple instruments. To facilitate the high&#45;fidelity imaging of these signals,&#10;we introduce the universal Bayesian imaging kit (UBIK). Specifically, we&#10;present J&#45;UBIK, a flexible and modular implementation leveraging the&#10;JAX&#45;accelerated NIFTy.re software as its backend. J&#45;UBIK streamlines the&#10;implementation of the key Bayesian inference components, providing for all the&#10;necessary steps of Bayesian imaging pipelines. First, it provides adaptable&#10;prior models for different sky realizations. Second, it includes likelihood&#10;models tailored to specific instruments. So far, the package includes three&#10;instruments: Chandra and eROSITA for X&#45;ray observations, and the James Webb&#10;Space Telescope (JWST) for the near&#45; and mid&#45;infrared. The aim is to expand&#10;this set in the future. Third, these models can be integrated with various&#10;inference and optimization schemes, such as maximum a posteriori estimation and&#10;variational inference. Explicit demos show how to integrate the individual&#10;modules into a full analysis pipeline. Overall, J&#45;UBIK enables efficient&#10;generation of high&#45;fidelity images via Bayesian pipelines that can be tailored&#10;to specific research objectives.&#10; | General | [Link](http://arxiv.org/abs/2409.10381v1) |&#10;| Thermolectricity in irradiated bilayer graphene flakes | Cynthia Ihuoma Osuala, Tanu Choudhary, Raju K. Biswas, Sudin Ganguly, Chunlei Qu, Santanu K. Maiti | &#160;&#160;We present a comprehensive study on enhancing the thermoelectric (TE)&#10;performance of bilayer graphene (BLG) through irradiation with arbitrarily&#10;polarized light, focusing on $AA$&#45; and $AB$&#45;stacked configurations with zigzag&#10;edges. Utilizing a combination of tight&#45;binding theory and density functional&#10;theory (DFT), we systematically analyze the impact of light irradiation on&#10;electronic and phononic transport properties. Light irradiation alters the&#10;electronic hopping parameters, creating an asymmetric transmission function,&#10;which significantly increases the Seebeck coefficient, thereby boosting the&#10;overall {it figure of merit} (FOM). For the phononic contribution, DFT&#10;calculations reveal that $AB$&#45;stacked BLG exhibits lower lattice thermal&#10;conductivity compared to $AA$&#45;stacked, attributed to enhanced anharmonic&#10;scattering and phonon group velocity. The combined analysis shows that FOM&#10;exceeds unity in both stacking types, with notable improvements near the&#10;irradiation&#45;induced gap. Additionally, we explore the dependence of FOM on the&#10;system dimensions and temperature, demonstrating that light&#45;irradiated BLG&#10;holds great promise for efficient thermoelectric energy conversion and waste&#10;heat recovery. Our results show favorable responses over a wide range of&#10;irradiation parameters. These findings provide crucial insights into optimizing&#10;BLG for advanced TE applications through light&#45;induced modifications.&#10; | General | [Link](http://arxiv.org/abs/2409.10380v1) |&#10;| Leveraging Joint Spectral and Spatial Learning with MAMBA for&#10; &#160;Multichannel Speech Enhancement | Wenze Ren, Haibin Wu, Yi&#45;Cheng Lin, Xuanjun Chen, Rong Chao, Kuo&#45;Hsuan Hung, You&#45;Jin Li, Wen&#45;Yuan Ting, Hsin&#45;Min Wang, Yu Tsao | &#160;&#160;In multichannel speech enhancement, effectively capturing spatial and&#10;spectral information across different microphones is crucial for noise&#10;reduction. Traditional methods, such as CNN or LSTM, attempt to model the&#10;temporal dynamics of full&#45;band and sub&#45;band spectral and spatial features.&#10;However, these approaches face limitations in fully modeling complex temporal&#10;dependencies, especially in dynamic acoustic environments. To overcome these&#10;challenges, we modify the current advanced model McNet by introducing an&#10;improved version of Mamba, a state&#45;space model, and further propose MCMamba.&#10;MCMamba has been completely reengineered to integrate full&#45;band and narrow&#45;band&#10;spatial information with sub&#45;band and full&#45;band spectral features, providing a&#10;more comprehensive approach to modeling spatial and spectral information. Our&#10;experimental results demonstrate that MCMamba significantly improves the&#10;modeling of spatial and spectral features in multichannel speech enhancement,&#10;outperforming McNet and achieving state&#45;of&#45;the&#45;art performance on the CHiME&#45;3&#10;dataset. Additionally, we find that Mamba performs exceptionally well in&#10;modeling spectral information.&#10; | General | [Link](http://arxiv.org/abs/2409.10376v1) |&#10;| Nonlinear Causality in Brain Networks: With Application to Motor Imagery&#10; &#160;vs Execution | Sipan Aslan, Hernando Ombao | &#160;&#160;One fundamental challenge of data&#45;driven analysis in neuroscience is modeling&#10;causal interactions and exploring the connectivity of nodes in a brain network.&#10;Various statistical methods, relying on various perspectives and employing&#10;different data modalities, are being developed to examine and comprehend the&#10;underlying causal structures inherent to brain dynamics. This study introduces&#10;a novel statistical approach, TAR4C, to dissect causal interactions in&#10;multichannel EEG recordings. TAR4C uses the threshold autoregressive model to&#10;describe the causal interaction between nodes or clusters of nodes in a brain&#10;network. The perspective involves testing whether one node, which may represent&#10;a brain region, can control the dynamics of the other. The node that has such&#10;an impact on the other is called a threshold variable and can be classified as&#10;a causative because its functionality is the leading source operating as an&#10;instantaneous switching mechanism that regulates the time&#45;varying&#10;autoregressive structure of the other. This statistical concept is commonly&#10;referred to as threshold non&#45;linearity. Once threshold non&#45;linearity has been&#10;verified between a pair of nodes, the subsequent essential facet of TAR&#10;modeling is to assess the predictive ability of the causal node for the current&#10;activity on the other and represent causal interactions in autoregressive&#10;terms. This predictive ability is what underlies Granger causality. The TAR4C&#10;approach can discover non&#45;linear and time&#45;dependent causal interactions without&#10;negating the G&#45;causality perspective. The efficacy of the proposed approach is&#10;exemplified by analyzing the EEG signals recorded during the motor&#10;movement/imagery experiment. The similarities and differences between the&#10;causal interactions manifesting during the execution and the imagery of a given&#10;motor movement are demonstrated by analyzing EEG recordings from multiple&#10;subjects.&#10; | General | [Link](http://arxiv.org/abs/2409.10374v1) |&#10;| Instigating Cooperation among LLM Agents Using Adaptive Information&#10; &#160;Modulation | Qiliang Chen, &#160;Alireza, &#160;Ilami, Nunzio Lore, Babak Heydari | &#160;&#160;This paper introduces a novel framework combining LLM agents as proxies for&#10;human strategic behavior with reinforcement learning (RL) to engage these&#10;agents in evolving strategic interactions within team environments. Our&#10;approach extends traditional agent&#45;based simulations by using strategic LLM&#10;agents (SLA) and introducing dynamic and adaptive governance through a&#10;pro&#45;social promoting RL agent (PPA) that modulates information access across&#10;agents in a network, optimizing social welfare and promoting pro&#45;social&#10;behavior. Through validation in iterative games, including the prisoner&#10;dilemma, we demonstrate that SLA agents exhibit nuanced strategic adaptations.&#10;The PPA agent effectively learns to adjust information transparency, resulting&#10;in enhanced cooperation rates. This framework offers significant insights into&#10;AI&#45;mediated social dynamics, contributing to the deployment of AI in real&#45;world&#10;team settings.&#10; | General | [Link](http://arxiv.org/abs/2409.10372v1) |&#10;| Learning Gentle Grasping from Human&#45;Free Force Control Demonstration | Mingxuan Li, Lunwei Zhang, Tiemin Li, Yao Jiang | &#160;&#160;Humans can steadily and gently grasp unfamiliar objects based on tactile&#10;perception. Robots still face challenges in achieving similar performance due&#10;to the difficulty of learning accurate grasp&#45;force predictions and force&#10;control strategies that can be generalized from limited data. In this article,&#10;we propose an approach for learning grasping from ideal force control&#10;demonstrations, to achieve similar performance of human hands with limited data&#10;size. Our approach utilizes objects with known contact characteristics to&#10;automatically generate reference force curves without human demonstrations. In&#10;addition, we design the dual convolutional neural networks (Dual&#45;CNN)&#10;architecture which incorporating a physics&#45;based mechanics module for learning&#10;target grasping force predictions from demonstrations. The described method can&#10;be effectively applied in vision&#45;based tactile sensors and enables gentle and&#10;stable grasping of objects from the ground. The described prediction model and&#10;grasping strategy were validated in offline evaluations and online experiments,&#10;and the accuracy and generalizability were demonstrated.&#10; | General | [Link](http://arxiv.org/abs/2409.10371v1) |&#10;| Uncovering the Mechanism of Hepatotoxiciy of PFAS Targeting L&#45;FABP Using&#10; &#160;GCN and Computational Modeling | Lucas Jividen, Tibo Duran, Xi&#45;Zhi Niu, Jun Bai | &#160;&#160;Per&#45; and polyfluoroalkyl substances (PFAS) are persistent environmental&#10;pollutants with known toxicity and bioaccumulation issues. Their widespread&#10;industrial use and resistance to degradation have led to global environmental&#10;contamination and significant health concerns. While a minority of PFAS have&#10;been extensively studied, the toxicity of many PFAS remains poorly understood&#10;due to limited direct toxicological data. This study advances the predictive&#10;modeling of PFAS toxicity by combining semi&#45;supervised graph convolutional&#10;networks (GCNs) with molecular descriptors and fingerprints. We propose a novel&#10;approach to enhance the prediction of PFAS binding affinities by isolating&#10;molecular fingerprints to construct graphs where then descriptors are set as&#10;the node features. This approach specifically captures the structural,&#10;physicochemical, and topological features of PFAS without overfitting due to an&#10;abundance of features. Unsupervised clustering then identifies representative&#10;compounds for detailed binding studies. Our results provide a more accurate&#10;ability to estimate PFAS hepatotoxicity to provide guidance in chemical&#10;discovery of new PFAS and the development of new safety regulations.&#10; | General | [Link](http://arxiv.org/abs/2409.10370v1) |&#10;| Stochastic Control of UAVs: An Optimal Tradeoff between Performance,&#10; &#160;Flight Smoothness and Control Effort | George Rapakoulias, Panagiotis Tsiotras | &#160;&#160;Safe and accurate control of unmanned aerial vehicles in the presence of&#10;winds is a challenging control problem due to the hard&#45;to&#45;model and highly&#10;stochastic nature of the disturbance forces acting upon the vehicle. To meet&#10;performance constraints, state&#45;of&#45;the&#45;art control methods such as Incremental&#10;Nonlinear Dynamic Inversion (INDI) or other adaptive control techniques require&#10;high control gains to mitigate the effects of uncertainty entering the system.&#10;While achieving good tracking performance, IDNI requires excessive control&#10;effort, results in high actuator strain, and reduced flight smoothness due to&#10;constant and aggressive corrective actions commanded by the controller. In this&#10;paper, we propose a novel control architecture that allows the user to&#10;systematically address the trade&#45;off between high authority control and&#10;performance constraint satisfaction. Our approach consists of two parts. To&#10;cancel out biases introduced by unmodelled aerodynamic effects we propose a&#10;hybrid, model&#45;based disturbance force estimator augmented with a neural&#10;network, that can adapt to external wind conditions using a Kalman Filter. We&#10;then utilize state&#45;of&#45;the&#45;art results from Covariance Steering theory, which&#10;offers a principled way of controlling the uncertainty of the tracking error&#10;dynamics. We first analyze the properties of the combined system and then&#10;provide extensive experimental results to verify the advantages of the proposed&#10;approach over existing methods&#10; | General | [Link](http://arxiv.org/abs/2409.10369v1) |&#10;| Integrated nowcasting of convective precipitation with Transformer&#45;based&#10; &#160;models using multi&#45;source data | alar Kk, Aitor Atencia, Markus Dabernig | &#160;&#160;Precipitation nowcasting is crucial for mitigating the impacts of severe&#10;weather events and supporting daily activities. Conventional models&#10;predominantly relying on radar data have limited performance in predicting&#10;cases with complex temporal features such as convection initiation,&#10;highlighting the need to integrate data from other sources for more&#10;comprehensive nowcasting. Unlike physics&#45;based models, machine learning&#10;(ML)&#45;based models offer promising solutions for efficiently integrating large&#10;volumes of diverse data. We present EF4INCA, a spatiotemporal Transformer model&#10;for precipitation nowcasting that integrates satellite&#45; and ground&#45;based&#10;observations with numerical weather prediction outputs. EF4INCA provides&#10;high&#45;resolution forecasts over Austria, accurately predicting the location and&#10;shape of precipitation fields with a spatial resolution of 1 kilometre and a&#10;temporal resolution of 5 minutes, up to 90 minutes ahead. Our evaluation shows&#10;that EF4INCA outperforms conventional nowcasting models, including the&#10;operational model of Austria, particularly in scenarios with complex temporal&#10;features such as convective initiation and rapid weather changes. EF4INCA&#10;maintains higher accuracy in location forecasting but generates smoother fields&#10;at later prediction times compared to traditional models. Interpretation of our&#10;model showed that precipitation products and SEVIRI infrared channels CH7 and&#10;CH9 are the most important data streams. These results underscore the&#10;importance of combining data from different domains, including physics&#45;based&#10;model products, with ML approaches. Our study highlights the robustness of&#10;EF4INCA and its potential for improved precipitation nowcasting. We provide&#10;access to our code repository, model weights, and the dataset curated for&#10;benchmarking, facilitating further development and application.&#10; | General | [Link](http://arxiv.org/abs/2409.10367v1) |&#10;&#10;">
<text font-weight="bold" text-anchor="middle" x="1801" y="-345.8" font-family="Helvetica, DejaVu Sans, Arial, Courier, sans-serif" font-size="14.00" fill="#fafafa">_last_msg_as_summary</text>
</a>
</g>
</g>
</g>
<defs><pattern height="40" width="40" id="bg_pattern" patternUnits="userSpaceOnUse"><rect x="0" y="0" width="40" height="40" fill="#222222" /><circle cx="15" cy="15" r="14" stroke="#2A2A2A" stroke-width="1" fill="none" /><text x="7" y="19" font-family="Arial" font-size="12" fill="#2A2A2A">AG</text></pattern></defs>
</svg>
